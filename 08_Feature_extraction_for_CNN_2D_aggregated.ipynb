{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-1PkcG8ARink"
   },
   "source": [
    "### Centro Universitário da Fundação Educacional Inaciana \"Padre Sabóia de Medeiros\" (FEI)\n",
    "\n",
    "\n",
    "*FEI's Stricto Sensu Graduate Program in Electrical Engineering*\n",
    "\n",
    "Concentration area: ARTIFICIAL INTELLIGENCE APPLIED TO AUTOMATION AND ROBOTICS\n",
    "\n",
    "Master's thesis student Andre Luiz Florentino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "pd = tf.config.experimental.list_physical_devices()\n",
    "for i in pd:\n",
    "    print(i)\n",
    "print('------------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
    "\n",
    "print(tf.test.is_built_with_cuda)\n",
    "# <function is_built_with_cuda at 0x000001AA24AFEC10>\n",
    "\n",
    "print(tf.test.gpu_device_name())\n",
    "# /device:GPU:0\n",
    "\n",
    "#gvd = tf.config.get_visible_devices()\n",
    "for j in tf.config.get_visible_devices():\n",
    "    print(j)\n",
    "# PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
    "# PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: Feature extraction for CNN 2D (Convolutional Neural Network)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "import mimetypes\n",
    "\n",
    "\n",
    "import pandas     as pd\n",
    "import seaborn    as sns\n",
    "import numpy      as np\n",
    "import IPython.display as ipd\n",
    "\n",
    "from random import sample\n",
    "\n",
    "from matplotlib  import pyplot  as plt\n",
    "\n",
    "from tqdm                        import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# For the picture names\n",
    "pic_first_name = '08_Feature_extraction_for_CNN_2D_agg_'\n",
    "\n",
    "# For Librosa\n",
    "FRAME_SIZE  = 1024\n",
    "HOP_LENGTH  = 512\n",
    "SEED        = 1000\n",
    "SR          = 22050\n",
    "N_FTT       = 2048\n",
    "BANDS       = 60\n",
    "\n",
    "# Values for feature extraction\n",
    "threshold   = 60\n",
    "frames      = 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 9)\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "mimetypes.init()\n",
    "mimetypes.add_type('audio/ogg','.ogg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dataset\n",
    "\n",
    "opcD = 0\n",
    "while str(opcD) not in '1234':\n",
    "    print()\n",
    "    print(\"1-) ESC-10\")\n",
    "    print(\"2-) BDLib2\")\n",
    "    print(\"3-) US8K\")\n",
    "    print(\"4-) US8K_AV\")\n",
    "\n",
    "    opcD = input(\"\\nSelect the dataset: \")\n",
    "    if opcD.isdigit():\n",
    "        opcD = int(opcD)\n",
    "    else:\n",
    "        opcD = 0\n",
    "\n",
    "if opcD == 1:\n",
    "\n",
    "    path        = os.path.join(current_path, \"_dataset\", \"ESC-10\")\n",
    "    path_pic    = os.path.join(current_path, \"ESC-10_results\")\n",
    "    path_models = os.path.join(current_path, \"ESC-10_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "   \n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'ESC-10' \n",
    "    csv_file    = 'ESC-10.csv'\n",
    "    fold        = 1\n",
    "    dog_set     = 'Dog bark'\n",
    "    time_length = 5\n",
    "    windowingNo = 9\n",
    "    aug_factor  = 6\n",
    "    \n",
    "    pkl_features          = 'ESC-10_features_original.pkl'\n",
    "    pkl_aug_features      = 'ESC-10_features_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features = 'ESC-10_features_augmented.pkl'\n",
    "    \n",
    "    pkl_features_CNN_2D          = 'ESC-10_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'ESC-10_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'ESC-10_features_CNN_2D_augmented.pkl'\n",
    "    \n",
    "\n",
    "    \n",
    "if opcD == 2:\n",
    "    \n",
    "    path        = os.path.join(current_path, \"_dataset\", \"BDLib2\")\n",
    "    path_pic    = os.path.join(current_path, \"BDLib2_results\")\n",
    "    path_models = os.path.join(current_path, \"BDLib2_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "\n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'BDLib2' \n",
    "    csv_file    = 'BDLib2.csv'\n",
    "    fold        = 'fold-1'\n",
    "    dog_set     = 'dogs'\n",
    "    time_length = 10\n",
    "    windowingNo = 19\n",
    "    aug_factor  = 6\n",
    "\n",
    "    pkl_features          = 'BDLib2_features_original.pkl'\n",
    "    pkl_aug_features      = 'BDLib2_features_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features = 'BDLib2_features_augmented.pkl'\n",
    "    \n",
    "    pkl_features_CNN_2D          = 'BDLib2_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'BDLib2_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'BDLib2_features_CNN_2D_augmented.pkl'\n",
    "    \n",
    "    \n",
    "if opcD == 3:\n",
    "    \n",
    "    path        = os.path.join(current_path, \"_dataset\", \"US8K\")\n",
    "    path_pic    = os.path.join(current_path, \"US8K_results\")\n",
    "    path_models = os.path.join(current_path, \"US8K_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "        \n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'US8K' \n",
    "    csv_file    = 'US8K.csv'\n",
    "    fold        = '1'\n",
    "    dog_set     = 'dog_bark'\n",
    "    time_length = 4\n",
    "    windowingNo = 7\n",
    "    aug_factor  = 6\n",
    "\n",
    "    pkl_features          = 'US8K_features_original.pkl'\n",
    "    pkl_aug_features      = 'US8K_features_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features = 'US8K_features_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large\n",
    "\n",
    "    pkl_features_CNN_2D          = 'US8K_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'US8K_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'US8K_features_CNN_2D_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large\n",
    "    \n",
    "    \n",
    "if opcD == 4:\n",
    "\n",
    "    path        = os.path.join(current_path, \"_dataset\", \"US8K_AV\")\n",
    "    path_pic    = os.path.join(current_path, \"US8K_AV_results\")\n",
    "    path_models = os.path.join(current_path, \"US8K_AV_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "\n",
    "\n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'US8K_AV' \n",
    "    csv_file    = 'US8K_AV.csv'\n",
    "    fold        = '1'\n",
    "    dog_set     = 'dog_bark'\n",
    "    time_length = 4\n",
    "    windowingNo = 7\n",
    "    aug_factor  = 6\n",
    "\n",
    "    pkl_features          = 'US8K_AV_features_original.pkl'\n",
    "    pkl_aug_features      = 'US8K_AV_features_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features = 'US8K_AV_features_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large\n",
    "    \n",
    "    pkl_features_CNN_2D          = 'US8K_AV_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'US8K_AV_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'US8K_AV_features_CNN_2D_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_file_number(folder: str):\n",
    "    files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) and f.startswith(pic_first_name)]\n",
    "    if not files:\n",
    "        return 1\n",
    "    else:\n",
    "        numbers = [int(f.split('.')[0].split('_')[-1]) for f in files]\n",
    "        return max(numbers) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MT_loadDataset import loadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadDataset = loadDataset(path)\n",
    "DB          = loadDataset.db_B\n",
    "\n",
    "print(\"\\nClasses:\\n--------------------\")\n",
    "print(DB[\"Class_categorical\"].value_counts())\n",
    "print(\"\\nTotal number of unique files..........: \", len(np.unique(DB[\"File_name\"])))\n",
    "print(\"Total number of AUDIO files...........: \", len(DB))\n",
    "DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the class balancing\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "gTitle = f'{nom_dataset} - Number of classes = ' + str(len(pd.Series(DB['Class_categorical']).unique()))\n",
    "g = sns.displot(DB,x='Class_categorical', hue='Class_categorical',height = 5, aspect = 2).set(title=gTitle)\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set_titles('Number of classes')\n",
    "\n",
    "# Retrieve the axes object from the plot\n",
    "axes = g.ax\n",
    "\n",
    "# Iterate over each bar in the plot\n",
    "for p in axes.patches:\n",
    "    # Get the coordinates of the bar\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    cord_x, cord_y = p.get_xy()\n",
    "    if height > 0:\n",
    "        axes.annotate(f'{height}', (cord_x + width/2, cord_y + height), ha='center')\n",
    "        \n",
    "g._legend.remove()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing the data (Features extraction)\n",
    "\n",
    "### Exploratory code that lead to a class for extracting the features\n",
    "\n",
    "Hand crafting the features into the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the class and get one random sample of each class\n",
    "k = DB.groupby('Class_categorical')['Class_OHEV'].apply(lambda s: s.sample(1))\n",
    "print(k)\n",
    "\n",
    "# Convert the pandas series into a dataframe\n",
    "temp_k_df = k.reset_index()\n",
    "\n",
    "# Delete the index from the grouppby result\n",
    "del temp_k_df['level_1']\n",
    "\n",
    "# Set the \"Class\" as the dataframe index\n",
    "temp_k_df.set_index(\"Class_categorical\", inplace=True)\n",
    "\n",
    "# Convert the dataframe to a dictionary (Class: Class_encoder)\n",
    "encoder_dict = temp_k_df[\"Class_OHEV\"].to_dict()\n",
    "encoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(DB['Class_OHEV'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_dict[dog_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pkl file with the augmented features extracted\n",
    "\n",
    "opc = 0\n",
    "while str(opc) not in '123':\n",
    "    print()\n",
    "    print(\"1-) Features original\")\n",
    "    print(\"2-) Features augmented\")\n",
    "    print(\"3-) Features augmented and windowed (US8K is only windowed)\")\n",
    "\n",
    "    opc = input(\"\\nSelect the dataset: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "\n",
    "if opc == 1:\n",
    "    DB_from_pkl      = pd.read_pickle(os.path.join(path_models, pkl_features))\n",
    "    model_surname    = '_original'\n",
    "    pkl_feature_file = pkl_features_CNN_2D \n",
    "    check_agg        = 1\n",
    "\n",
    "elif opc == 2:\n",
    "    DB_from_pkl      = pd.read_pickle(os.path.join(path_models, pkl_aug_features))\n",
    "    model_surname    = '_augmented'\n",
    "    pkl_feature_file = pkl_aug_features_CNN_2D\n",
    "    check_agg        =  aug_factor\n",
    "\n",
    "elif (opcD == 3 or opcD == 4) and opc == 3:\n",
    "    DB_from_pkl      = pd.read_pickle(os.path.join(path_models, pkl_aug_wind_features))\n",
    "    model_surname    = '_windowed'\n",
    "    pkl_feature_file = pkl_aug_wind_features_CNN_2D\n",
    "    check_agg        =  windowingNo * 1\n",
    "\n",
    "elif opc == 3:\n",
    "    DB_from_pkl      = pd.read_pickle(os.path.join(path_models, pkl_aug_wind_features))\n",
    "    model_surname    = '_windowed'\n",
    "    pkl_feature_file = pkl_aug_wind_features_CNN_2D\n",
    "    check_agg        =  windowingNo * aug_factor\n",
    "    \n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duration = 0\n",
    "for audio in DB_from_pkl['Audio']:\n",
    "    total_duration = total_duration + librosa.get_duration(y=audio)\n",
    "print('Total duration of the dataset: ' , \"{:0.4f} h\".format(total_duration / 3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in DB_from_pkl.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl = DB_from_pkl[['Audio', 'Class_categorical', 'Class_OHEV', 'Fold']]\n",
    "DB_from_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = DB_from_pkl[DB_from_pkl['Class_categorical'] == dog_set]\n",
    "dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = random.choice(dog.index.tolist())\n",
    "random_sample = dog['Audio'][random_idx]\n",
    "print(f'Dataframe index....: {random_idx}')\n",
    "print(f'Sample file name...: {random_sample}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(random_sample, rate = SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X      = DB_from_pkl['Audio'].values\n",
    "y_cat  = DB_from_pkl['Class_categorical'].values\n",
    "y_OHEV = DB_from_pkl['Class_OHEV'].values\n",
    "folds  = DB_from_pkl['Fold'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(DB_from_pkl['Class_OHEV'][random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.get_duration(y = dog['Audio'][random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dog['Audio'][random_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_features_CNN_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to extract the Log-Mel + Deltas as input for the CNN 2D\n",
    "        \n",
    "def LogMel_extractor(audio_clips:list):\n",
    "    \n",
    "    log_specgrams = []\n",
    "    framesLst     = []\n",
    "\n",
    "    for signal in tqdm(audio_clips):\n",
    "        melspec = librosa.feature.melspectrogram(y          = signal, \n",
    "                                                 n_mels     = BANDS,\n",
    "                                                 hop_length = HOP_LENGTH, \n",
    "                                                 n_fft      = N_FTT, \n",
    "                                                 sr         = SR) \n",
    "\n",
    "        #logspec = librosa.core.amplitude_to_db(melspec)\n",
    "        logspec = librosa.power_to_db(melspec)\n",
    "        frames = logspec.shape[1]\n",
    "        framesLst.append(frames)\n",
    "\n",
    "        # Flattens the array (bands , frames) to (bands * frames , 1) E.g.: (60 , 216) --> (12.960 , 1)\n",
    "        logspec = logspec.flatten()[:, np.newaxis]\n",
    "\n",
    "        # Appends to array\n",
    "        log_specgrams.append(logspec)\n",
    "\n",
    "    # Reshape to audio, bands, frames and channels E.g.: (Depends on the model Ori or Aug, 60, 44, 1)\n",
    "    log_specgrams = np.asarray(log_specgrams,dtype='float32').reshape(len(log_specgrams),BANDS,frames,1)\n",
    "\n",
    "    # Initiate zeros for the log mel spectrogram delta\n",
    "    features = np.concatenate((log_specgrams,\n",
    "                               np.zeros(np.shape(log_specgrams)),\n",
    "                               np.zeros(np.shape(log_specgrams))), axis=3)\n",
    "\n",
    "    # Add the delta for the log mel spectrogram as channels\n",
    "    for i in tqdm(range(len(features))):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0], order = 1)\n",
    "        features[i, :, :, 2] = librosa.feature.delta(features[i, :, :, 0], order = 2)\n",
    "\n",
    "    # Vertically stack up the deltas to created an aggregated structures of features\n",
    "    mel, delta1, delta2 = np.split(features, 3, axis=3)\n",
    "    aggregated          = np.concatenate((mel, delta1, delta2), axis=1)\n",
    "        \n",
    "    if len(set(framesLst)) == 1:\n",
    "        duration = \"{:.2f}\".format((framesLst[0]*HOP_LENGTH)/SR)\n",
    "        print(f\"Mel spectrogram created by a {duration} seconds audio. Number of frames: {framesLst[0]}\")\n",
    "        \n",
    "    return np.array(aggregated), np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_channel = LogMel_extractor(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = random.randint(1,len(X))\n",
    "random_sample_agg = X[index]\n",
    "print(index)\n",
    "print(random_sample_agg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = X_channel[index]\n",
    "print(index)\n",
    "print(random_sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl['Audio'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl['Class_categorical'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(DB_from_pkl['Audio'][index], rate = SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mel, X_mel_delta, X_mel_delta2 = np.split(random_sample, 3, axis=2)\n",
    "\n",
    "print(X_mel.shape)\n",
    "print(X_mel_delta.shape)\n",
    "print(X_mel_delta2.shape)\n",
    "\n",
    "\n",
    "X_mel = np.squeeze(X_mel) \n",
    "X_mel_delta = np.squeeze(X_mel_delta)\n",
    "X_mel_delta2 = np.squeeze(X_mel_delta2)\n",
    "\n",
    "\n",
    "print(X_mel.shape)\n",
    "print(X_mel_delta.shape)\n",
    "print(X_mel_delta2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mel[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mel_delta[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mel_delta2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = X[index]\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_s = np.squeeze(t) \n",
    "t_s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split based on the number of mel bands\n",
    "\n",
    "array1 = t_s[:60, :]\n",
    "array2 = t_s[60:120, :]\n",
    "array3 = t_s[120:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_mel[0] == array1[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_mel_delta[0] == array2[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_mel_delta2[0] == array3[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(17,7))\n",
    "\n",
    "librosa.display.specshow(X_mel, sr=SR, x_axis='time', y_axis='mel')\n",
    "plt.colorbar()\n",
    "plt.title(f\"Mel frequency spectrogram of {DB_from_pkl['Class_categorical'][index]} (model: {model_surname})\" )\n",
    "\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(17,7))\n",
    "\n",
    "librosa.display.specshow(X_mel_delta, sr=SR, x_axis='time', y_axis='mel')\n",
    "plt.colorbar()\n",
    "plt.title(f\"Delta Mel frequency spectrogram of {DB_from_pkl['Class_categorical'][index]} (model: {model_surname})\" )\n",
    "\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(17,7))\n",
    "\n",
    "librosa.display.specshow(X_mel_delta2, sr=SR, x_axis='time', y_axis='mel')\n",
    "plt.colorbar()\n",
    "plt.title(f\"Delta Delta Mel frequency spectrogram of {DB_from_pkl['Class_categorical'][index]} (model: {model_surname})\" )\n",
    "\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(17,7))\n",
    "\n",
    "librosa.display.specshow(array1, sr=SR, x_axis='time', y_axis='mel')\n",
    "plt.colorbar()\n",
    "plt.title(f\"Mel frequency spectrogram of {DB_from_pkl['Class_categorical'][index]} from split aggregated feature (model: {model_surname})\" )\n",
    "\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(17,7))\n",
    "\n",
    "librosa.display.specshow(array2, sr=SR, x_axis='time', y_axis='mel')\n",
    "plt.colorbar()\n",
    "plt.title(f\"Delta Mel frequency spectrogram of {DB_from_pkl['Class_categorical'][index]} from split aggregated feature (model: {model_surname})\" )\n",
    "\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(17,7))\n",
    "\n",
    "librosa.display.specshow(array3, sr=SR, x_axis='time', y_axis='mel')\n",
    "plt.colorbar()\n",
    "plt.title(f\"Delta Delta Mel frequency spectrogram of {DB_from_pkl['Class_categorical'][index]} from split aggregated feature (model: {model_surname})\" )\n",
    "\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the array to DataFrame\n",
    "array_list = [X[i] for i in range(X.shape[0])]\n",
    "\n",
    "# Insert the label colum in the DataFrame\n",
    "DB_from_pkl.insert(loc = 4, column = 'features', value = array_list)\n",
    "\n",
    "# Drops the audio data\n",
    "DB_features = DB_from_pkl.copy()\n",
    "DB_features = DB_features.drop(columns='Audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_feature_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the features to a pickle file\n",
    "\n",
    "DB_features.to_pickle(os.path.join(path_models, pkl_feature_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pkl file with the features extracted for the CNN classifier\n",
    "\n",
    "DB_retrieved_pkl = pd.read_pickle(os.path.join(path_models, pkl_feature_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_retrieved_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the information from DataFrame as numpy array\n",
    "X3 = DB_retrieved_pkl['features'].to_numpy()\n",
    "y3 = DB_retrieved_pkl['Class_OHEV'].values\n",
    "\n",
    "#Reshape to the correct dimension\n",
    "X3_reshaped = np.stack(X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X == X3_reshaped).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for arr1,arr2 in zip(y_OHEV,y3):\n",
    "    if np.array_equal(arr1,arr2) == False:\n",
    "        count = count + 1\n",
    "if count > 0:\n",
    "    print(\"The arrays are NOT identical\")\n",
    "else:\n",
    "    print(\"The arrays are identical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Log mel spectogram manually created data against the aggregated method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windowing function \n",
    "\n",
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield int(start), int(start + window_size)\n",
    "        start += (window_size / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to augment the audio and extract the features\n",
    "        \n",
    "def window_audio_file(data: list, SR: int ):\n",
    "\n",
    "    frames_no      = frames\n",
    "    window_size    = 512 * (frames_no - 1)\n",
    "    audio_windowed = []\n",
    "       \n",
    "    for (start, end) in windows(data, window_size):\n",
    "        if(len(data[start:end]) == window_size):\n",
    "\n",
    "            # Window the audio\n",
    "            signal  = data[start:end]\n",
    "\n",
    "            # Appends to array\n",
    "            audio_windowed.append(signal)\n",
    "    \n",
    "    return np.array(audio_windowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(files:list, time_length:int):\n",
    "    \n",
    "    time_length       = time_length  \n",
    "    silence_threshold = threshold\n",
    "    target_samples    = int(time_length * SR)\n",
    "    audio_array       = []\n",
    "\n",
    "\n",
    "    for i, audio in tqdm(enumerate(files, start=0)):\n",
    "\n",
    "        # Split the audio into non-silent intervals\n",
    "        non_silent_intervals = librosa.effects.split(audio, \n",
    "                                                     top_db       = silence_threshold,\n",
    "                                                     frame_length = FRAME_SIZE, \n",
    "                                                     hop_length   = HOP_LENGTH)\n",
    "\n",
    "        # Extract non-silent segments from the original audio data\n",
    "        non_silent_audio  = []\n",
    "        for interval in non_silent_intervals:\n",
    "            start, end = interval\n",
    "            non_silent_audio.extend(audio[start:end])\n",
    "\n",
    "        # Convert the list back to a NumPy array\n",
    "        non_silent_audio_array = np.array(non_silent_audio)\n",
    "\n",
    "        # Repeat the non-silent audio array to fit the target time length\n",
    "        extended_audio = np.tile(non_silent_audio_array, target_samples // len(non_silent_audio_array) + 1)\n",
    "\n",
    "        # Truncate the extended audio to match the desired duration\n",
    "        audio_array.append(extended_audio[:target_samples])\n",
    "    \n",
    "    return audio_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(files:list):\n",
    "    \n",
    "    audio_augmented = []\n",
    "    \n",
    "    for rawdata in files:\n",
    "\n",
    "        start_  = int(np.random.uniform(-4800,4800))\n",
    "\n",
    "        # Time shifting (randomly)\n",
    "        if start_ >= 0:\n",
    "            audio_time_shift = np.r_[rawdata[start_:], np.random.uniform(-0.001,0.001, start_)]\n",
    "        else:\n",
    "            audio_time_shift = np.r_[np.random.uniform(-0.001,0.001, -start_), rawdata[:start_]]\n",
    "\n",
    "        audio_augmented.append(rawdata)\n",
    "        audio_augmented.append(audio_time_shift)\n",
    "\n",
    "        # Time stretching\n",
    "        audio_augmented.append(librosa.effects.time_stretch(rawdata, rate=0.85))\n",
    "        audio_augmented.append(librosa.effects.time_stretch(rawdata, rate=1.15))\n",
    "\n",
    "        # Pitch shifting\n",
    "        audio_augmented.append(librosa.effects.pitch_shift(rawdata, sr = SR, n_steps = 4))\n",
    "        audio_augmented.append(librosa.effects.pitch_shift(rawdata, sr = SR, n_steps = -4))\n",
    "        \n",
    "    audio_augmented = pre_processing(audio_augmented, time_length)\n",
    "\n",
    "    return audio_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets a random index from the original dataset\n",
    "\n",
    "index_chk = random.randint(1,len(DB))\n",
    "index_chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a probe list from the random index\n",
    "\n",
    "probe_list = []\n",
    "t = DB['Path'][index_chk]\n",
    "print(t)\n",
    "probe, _ = librosa.load(t, sr = SR)\n",
    "probe_list.append(probe)\n",
    "print(probe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from original audio dataset\n",
    "\n",
    "print(DB['Class_categorical'][index_chk])\n",
    "print('Audio file duration: ' , \"{:0.4f} s\".format(librosa.get_duration(y=probe)))\n",
    "print(len(probe))\n",
    "ipd.Audio(probe, rate = SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(probe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio normalization\n",
    "\n",
    "audio_pp = pre_processing(probe_list, time_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(audio_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio augmentation\n",
    "\n",
    "audio_aug = augmentation(probe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(audio_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from original audio dataset pre-processed individually\n",
    "\n",
    "print('Audio file duration: ' , \"{:0.4f} s\".format(librosa.get_duration(y=audio_pp[0])))\n",
    "print(len(audio_pp[0]))\n",
    "ipd.Audio(audio_pp[0], rate = SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio framing (windowing)\n",
    "\n",
    "windowed = window_audio_file(audio_pp[0], SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from original audio dataset pre-processed individually and windowed\n",
    "\n",
    "print('Audio file duration: ' , \"{:0.4f} s\".format(librosa.get_duration(y=windowed[0])))\n",
    "print(len(windowed[0]))\n",
    "ipd.Audio(windowed[0], rate = SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent sample from the augmented dataset\n",
    "\n",
    "print(DB_from_pkl['Class_categorical'][index_chk * check_agg])\n",
    "print('Audio file duration: ' , \"{:0.4f} s\".format(librosa.get_duration(y=DB_from_pkl['Audio'][index_chk * check_agg])))\n",
    "DB_from_pkl['Audio'][index_chk * check_agg]\n",
    "ipd.Audio(DB_from_pkl['Audio'][index_chk * check_agg], rate = SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowed[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl['Audio'][index_chk * check_agg].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_chk * check_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opc == 1:\n",
    "    array_check = audio_pp[0]\n",
    "    \n",
    "elif opc == 2:\n",
    "    array_check = audio_aug[0]\n",
    "    \n",
    "else:\n",
    "    array_check = windowed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(array_check == DB_from_pkl['Audio'][index_chk * check_agg]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the audio data if uncomented in line 62 --> DB_features = DB_features.drop(columns='Audio')\n",
    "# Not needed anymore, used utilized during script development to check the data consistency\n",
    "\n",
    "# (array_check == DB_retrieved_pkl['Audio'][index_chk * check_agg]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the audio data if uncomented in line 62 --> DB_features = DB_features.drop(columns='Audio')\n",
    "# Not needed anymore, used utilized during script development to check the data consistency\n",
    "\n",
    "# (array_check == DB_features['Audio'][index_chk * check_agg]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XS  = librosa.feature.melspectrogram(y          = array_check,\n",
    "                                     sr         = SR, \n",
    "                                     n_fft      = N_FTT,\n",
    "                                     hop_length = HOP_LENGTH,\n",
    "                                     n_mels     = BANDS)\n",
    "\n",
    "Xdb = librosa.power_to_db(XS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XS.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdb_delta = librosa.feature.delta(Xdb, order = 1)\n",
    "Xdb_delta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xdb_delta2 = librosa.feature.delta(Xdb, order = 2)\n",
    "Xdb_delta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_mel, X_mel_delta, X_mel_delta2 = np.split(X_channel[0], 3, axis=2)\n",
    "#print(X_mel.shape)  # Output: (60, 41, 1)\n",
    "#print(X_mel_delta.shape)  # Output: (60, 41, 1)\n",
    "#print(X_mel_delta2.shape)  # Output: (60, 41, 1)\n",
    "\n",
    "#X_mel = np.squeeze(X_mel) \n",
    "#X_mel_delta = np.squeeze(X_mel_delta)\n",
    "#X_mel_delta2 = np.squeeze(X_mel_delta2)\n",
    "\n",
    "#print(X_mel.shape)  # Output: (60, 41, 1)\n",
    "#print(X_mel_delta.shape)  # Output: (60, 41, 1)\n",
    "#print(X_mel_delta2.shape)  # Output: (60, 41, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_chk * check_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DB_retrieved_pkl['Class_categorical'][index_chk * check_agg])\n",
    "temp = np.squeeze(X3[index_chk * check_agg]).astype('float32') \n",
    "X_mel, X_mel_delta, X_mel_delta2 = temp[:60, :], temp[60:120, :], temp[120:, :]\n",
    "\n",
    "print(X_mel.shape)  # Output: (60, 41, 1)\n",
    "print(X_mel_delta.shape)  # Output: (60, 41, 1)\n",
    "print(X_mel_delta2.shape)  # Output: (60, 41, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((Xdb        == X_mel).all())\n",
    "print((Xdb_delta  == X_mel_delta).all())\n",
    "print((Xdb_delta2 == X_mel_delta2).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a test\n",
    "\n",
    "frames = np.linspace(1, 216, num=216)\n",
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mel spectrogram and plot result\n",
    "\n",
    "def mel_spectrogram_aug(audio_mel:list, title_add:str):\n",
    "    \n",
    "    picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "    \n",
    "    frames_x = np.linspace(0, audio_mel.shape[1], num=audio_mel.shape[1])\n",
    "    mels_y   = np.linspace(0, audio_mel.shape[0], num=audio_mel.shape[0])\n",
    "    \n",
    "    plt.figure(figsize = (20, 8))\n",
    "    \n",
    "    librosa.display.specshow(audio_mel, sr=SR, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format = \"%+2.0f dB\")\n",
    "    \n",
    "    plt.title(nom_dataset + f\" - Log mel frequency spectrogram for the seletec sample \" + title_add, fontsize = 16)\n",
    "    plt.xlabel(\"Time\")\n",
    "    \n",
    "    for i, frame in enumerate(frames_x):\n",
    "        plt.annotate(str(int(frame)), (i/len(frames_x), 0.0), xycoords='axes fraction', ha='center')\n",
    "    \n",
    "    # Plot the y space based on the number of mels --> image of 41 frames x 60 mels.\n",
    "    # Works only if the y_axis = 'linear'\n",
    "    #y_min = 0\n",
    "    #y_max = 1\n",
    "    #y_coords = np.linspace(0, y_max, num=60)\n",
    "    #for y_coord, y_val in zip(y_coords, mels_y):\n",
    "    #    plt.annotate(str(int(y_val)), (1, y_coord), ha='right', va='top', xycoords='axes fraction', fontsize = 6)\n",
    "      \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_pic, picture_name))\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X_mel:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Xdb:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram_aug(Xdb, '(manually created for ' + model_surname + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram_aug(X_mel, '(from the method for ' + model_surname + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram_aug(Xdb_delta, '(Delta - manually created for ' + model_surname + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram_aug(X_mel_delta, '(Delta - from the method for ' + model_surname + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram_aug(Xdb_delta2, '(Delta 2 - manually created for ' + model_surname + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram_aug(X_mel_delta2, '(Delta 2 - from the method for ' + model_surname + ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xdb == X_mel).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xdb_delta == X_mel_delta.astype(np.float32)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xdb_delta2 == X_mel_delta2.astype(np.float32)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mark3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
