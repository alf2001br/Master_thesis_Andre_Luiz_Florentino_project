{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3faa6a4b",
   "metadata": {},
   "source": [
    "### Faculdade de Engenharia Industrial - FEI\n",
    "\n",
    "### Centro Universitário da Fundação Educacional Inaciana \"Padre Sabóia de Medeiros\" (FEI)\n",
    "\n",
    "\n",
    "*FEI's Stricto Sensu Graduate Program in Electrical Engineering*\n",
    "\n",
    "Concentration area: ARTIFICIAL INTELLIGENCE APPLIED TO AUTOMATION AND ROBOTICS\n",
    "\n",
    "Master's thesis student Andre Luiz Florentino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd16632",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d17ec4",
   "metadata": {},
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b237808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "pd = tf.config.experimental.list_physical_devices()\n",
    "for i in pd:\n",
    "    print(i)\n",
    "print('------------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
    "\n",
    "print(tf.test.is_built_with_cuda)\n",
    "# <function is_built_with_cuda at 0x000001AA24AFEC10>\n",
    "\n",
    "print(tf.test.gpu_device_name())\n",
    "# /device:GPU:0\n",
    "\n",
    "#gvd = tf.config.get_visible_devices()\n",
    "for j in tf.config.get_visible_devices():\n",
    "    print(j)\n",
    "# PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
    "# PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de63c0",
   "metadata": {},
   "source": [
    "# Chapter 3: Neural networks\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4504379",
   "metadata": {},
   "source": [
    "## Importe modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import os\n",
    "import warnings\n",
    "import itertools\n",
    "import time\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import pandas     as pd\n",
    "import seaborn    as sns\n",
    "import numpy      as np\n",
    "\n",
    "from matplotlib  import pyplot  as plt\n",
    "from keras       import backend as K\n",
    "\n",
    "from tqdm                        import tqdm\n",
    "from collections                 import Counter\n",
    "\n",
    "from sklearn                     import metrics\n",
    "from sklearn.model_selection     import train_test_split\n",
    "from sklearn.metrics             import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow                  import keras\n",
    "from tensorflow.keras.models     import Sequential, load_model\n",
    "from tensorflow.keras.layers     import Dense, Dropout, Conv1D, GlobalAveragePooling1D, MaxPooling1D, Flatten, GlobalMaxPooling1D\n",
    "\n",
    "from keras.callbacks             import ModelCheckpoint, EarlyStopping\n",
    "from keras.regularizers          import l2\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 9)\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "\n",
    "cmap_cm   = plt.cm.Blues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0dbe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# For the picture names\n",
    "pic_first_name = '06_Neural_network_'\n",
    "\n",
    "# For Librosa\n",
    "FRAME_SIZE  = 1024\n",
    "HOP_LENGTH  = 512\n",
    "SEED        = 1000\n",
    "SR          = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53326eea",
   "metadata": {},
   "source": [
    "## Loading the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dataset\n",
    "\n",
    "opc = 0\n",
    "while str(opc) not in '1234':\n",
    "    print()\n",
    "    print(\"1-) ESC-10\")\n",
    "    print(\"2-) BDLib2\")\n",
    "    print(\"3-) US8K\")\n",
    "    print(\"4-) US8K_AV\")\n",
    "\n",
    "\n",
    "    opc = input(\"\\nSelect the dataset: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "\n",
    "if opc == 1:\n",
    "\n",
    "    path        = os.path.join(current_path, \"_dataset\", \"ESC-10\")\n",
    "    path_pic    = os.path.join(current_path, \"ESC-10_results\")\n",
    "    path_models = os.path.join(current_path, \"ESC-10_saved_models\")\n",
    "    \n",
    "   \n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'ESC-10' \n",
    "    csv_file    = 'ESC-10.csv'\n",
    "    fold        = '1'\n",
    "\n",
    "    pkl_features          = 'ESC-10_features_original.pkl'\n",
    "    pkl_aug_features      = 'ESC-10_features_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features = 'ESC-10_features_augmented.pkl'\n",
    "\n",
    "    \n",
    "if opc == 2:\n",
    "    \n",
    "    path        = os.path.join(current_path, \"_dataset\", \"BDLib2\")\n",
    "    path_pic    = os.path.join(current_path, \"BDLib2_results\")\n",
    "    path_models = os.path.join(current_path, \"BDLib2_saved_models\")\n",
    "\n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'BDLib2' \n",
    "    csv_file    = 'BDLib2.csv'\n",
    "    fold        = 'fold-1'\n",
    "\n",
    "    pkl_features          = 'BDLib2_features_original.pkl'\n",
    "    pkl_aug_features      = 'BDLib2_features_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features = 'BDLib2_features_augmented.pkl'\n",
    "\n",
    "    \n",
    "if opc == 3:\n",
    "    \n",
    "    path        = os.path.join(current_path, \"_dataset\", \"US8K\")\n",
    "    path_pic    = os.path.join(current_path, \"US8K_results\")\n",
    "    path_models = os.path.join(current_path, \"US8K_saved_models\")\n",
    "    \n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'US8K' \n",
    "    csv_file    = 'US8K.csv'\n",
    "    fold        = '1'\n",
    "    \n",
    "    pkl_features          = 'US8K_features_original.pkl'\n",
    "    pkl_aug_features      = 'US8K_features_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features = 'US8K_features_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large\n",
    "    \n",
    "\n",
    "if opc == 4:\n",
    "\n",
    "    path        = os.path.join(current_path, \"_dataset\", \"US8K_AV\")\n",
    "    path_pic    = os.path.join(current_path, \"US8K_AV_results\")\n",
    "    path_models = os.path.join(current_path, \"US8K_AV_saved_models\")\n",
    "\n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'US8K_AV' \n",
    "    csv_file    = 'US8K_AV.csv'\n",
    "    fold        = '1'\n",
    "\n",
    "    pkl_features          = 'US8K_AV_features_original.pkl'\n",
    "    pkl_aug_features      = 'US8K_AV_features_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features = 'US8K_AV_features_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339e815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_file_number(folder: str):\n",
    "    files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) and f.startswith(pic_first_name)]\n",
    "    if not files:\n",
    "        return 1\n",
    "    else:\n",
    "        numbers = [int(f.split('.')[0].split('_')[-1]) for f in files]\n",
    "        return max(numbers) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9974f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MT_loadDataset import loadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aca6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadDataset = loadDataset(path)\n",
    "DB          = loadDataset.db_B\n",
    "\n",
    "print(\"\\nClasses:\\n--------------------\")\n",
    "print(DB[\"Class_categorical\"].value_counts())\n",
    "print(\"\\nTotal number of unique files..........: \", len(np.unique(DB[\"File_name\"])))\n",
    "print(\"Total number of AUDIO files...........: \", len(DB))\n",
    "DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7923e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72726b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the class balancing\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "gTitle = f'{nom_dataset} - Number of classes = ' + str(len(pd.Series(DB['Class_categorical']).unique()))\n",
    "g = sns.displot(DB,x='Class_categorical', hue='Class_categorical',height = 5, aspect = 2).set(title=gTitle)\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set_titles('Number of classes')\n",
    "\n",
    "# Retrieve the axes object from the plot\n",
    "axes = g.ax\n",
    "\n",
    "# Iterate over each bar in the plot\n",
    "for p in axes.patches:\n",
    "    # Get the coordinates of the bar\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    cord_x, cord_y = p.get_xy()\n",
    "    if height > 0:\n",
    "        axes.annotate(f'{height}', (cord_x + width/2, cord_y + height), ha='center')\n",
    "        \n",
    "g._legend.remove()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9727f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pkl file with the augmented features extracted\n",
    "\n",
    "opc = 0\n",
    "while str(opc) not in '123':\n",
    "    print()\n",
    "    print(\"1-) Features original\")\n",
    "    print(\"2-) Features augmented\")\n",
    "    print(\"3-) Features augmented and windowed (US8K only windowed)\")\n",
    "\n",
    "    opc = input(\"\\nSelect the dataset: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "\n",
    "if opc == 1:\n",
    "    DB_from_pkl   = pd.read_pickle(os.path.join(path_models, pkl_features))\n",
    "    model_surname = '_original'\n",
    "\n",
    "if opc == 2:\n",
    "    DB_from_pkl   = pd.read_pickle(os.path.join(path_models, pkl_aug_features))\n",
    "    model_surname = '_augmented'\n",
    "\n",
    "if opc == 3:\n",
    "    DB_from_pkl = pd.read_pickle(os.path.join(path_models, pkl_aug_wind_features))\n",
    "    model_surname = '_windowed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2befe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9f36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duration = 0\n",
    "for audio in DB_from_pkl['Audio']:\n",
    "    total_duration = total_duration + librosa.get_duration(y=audio)\n",
    "print('Total duration of the dataset: ' , \"{:0.4f} h\".format(total_duration / 3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5a4f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(DB_from_pkl['Fold'][0][0]))\n",
    "print(type(DB_from_pkl['Class_OHEV'][0][0]))\n",
    "print(type(DB_from_pkl['Class_OHEV'][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad53881",
   "metadata": {},
   "source": [
    "## Input split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b3e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate 1 fold for validation and create a DB for the training / testing according to the datasets specification\n",
    "\n",
    "DB_from_pkl_VAL = DB_from_pkl[DB_from_pkl['Fold'] == fold].copy()\n",
    "DB_from_pkl_TRN = DB_from_pkl[DB_from_pkl['Fold'] != fold].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(DB_from_pkl_VAL))\n",
    "print(len(DB_from_pkl_TRN))\n",
    "print('Total: ', len(DB_from_pkl_VAL) + len(DB_from_pkl_TRN),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl_VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a0a434",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl_TRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0c05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in DB_from_pkl_TRN.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c4b4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating data and labels\n",
    "\n",
    "X      = DB_from_pkl_TRN.drop(columns=['Audio','Class_categorical','Class_OHEV', 'Fold'])\n",
    "y      = np.array(DB_from_pkl_TRN.Class_categorical.to_list())\n",
    "y_OHEV = np.array(DB_from_pkl_TRN.Class_OHEV.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e3f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the augmented dataset (only validation set)\n",
    "\n",
    "X_val      = DB_from_pkl_VAL.drop(columns=['Audio','Class_categorical','Class_OHEV', 'Fold'])\n",
    "y_val      = np.array(DB_from_pkl_VAL.Class_categorical.to_list())\n",
    "y_OHEV_val = np.array(DB_from_pkl_VAL.Class_OHEV.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e67353",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d0edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd62f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e485221",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_OHEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = X.apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard = X.apply(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102f1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ee1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = X_norm.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98e4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard = X_standard.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16f79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aa62e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d29f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_OHEV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a638bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9017e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ec6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94008013",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_OHEV_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55830538",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_norm = X_val.apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b03ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_standard = X_val.apply(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e56612",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a2eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_standard.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc7df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_norm = X_val_norm.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eec3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_standard = X_val_standard.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb06ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebc21b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_standard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0bb619",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_OHEV_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd2a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_OHEV_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8087fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter_val = Counter(map(tuple, y_OHEV_val))\n",
    "Counter_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b398cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the class and get one random sample of each class\n",
    "k = DB_from_pkl.groupby('Class_categorical')['Class_OHEV'].apply(lambda s: s.sample(1))\n",
    "print(k)\n",
    "\n",
    "# Convert the pandas series into a dataframe\n",
    "temp_k_df = k.reset_index()\n",
    "\n",
    "# Delete the index from the grouppby result\n",
    "del temp_k_df['level_1']\n",
    "\n",
    "# Set the \"Class\" as the dataframe index\n",
    "temp_k_df.set_index(\"Class_categorical\", inplace=True)\n",
    "\n",
    "# Convert the dataframe to a dictionary (Class: Class_encoder)\n",
    "encoder_dict = temp_k_df[\"Class_OHEV\"].to_dict()\n",
    "encoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28674adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_classes = list(encoder_dict.keys())\n",
    "nom_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53876a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes in the dataset\n",
    "\n",
    "num_classes = len(encoder_dict.keys())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0504cb8",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee250105",
   "metadata": {},
   "outputs": [],
   "source": [
    "del DB_from_pkl_VAL, DB_from_pkl_TRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e866b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate 1 fold for validation and create a DB for the training / testing\n",
    "\n",
    "opc = 0\n",
    "while str(opc) not in '12':\n",
    "    print()\n",
    "    print(\"1-) Normalization\")\n",
    "    print(\"2-) Standardization\")\n",
    "\n",
    "    opc = input(\"\\nSelect the dataset: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "\n",
    "\n",
    "    DB_from_pkl_VAL = DB_from_pkl[DB_from_pkl['Fold'] == fold].copy()\n",
    "    DB_from_pkl_TRN = DB_from_pkl[DB_from_pkl['Fold'] != fold].copy()\n",
    "    \n",
    "    X      = DB_from_pkl_TRN.drop(columns=['Audio','Class_categorical','Class_OHEV', 'Fold'])\n",
    "    y      = np.array(DB_from_pkl_TRN.Class_categorical.to_list())\n",
    "    y_OHEV = np.array(DB_from_pkl_TRN.Class_OHEV.to_list())\n",
    "\n",
    "    X_val      = DB_from_pkl_VAL.drop(columns=['Audio','Class_categorical','Class_OHEV', 'Fold'])\n",
    "    y_val      = np.array(DB_from_pkl_VAL.Class_categorical.to_list())\n",
    "    y_OHEV_val = np.array(DB_from_pkl_VAL.Class_OHEV.to_list())\n",
    "\n",
    "    X_statistics = pd.DataFrame({'mean': X.mean(), 'std': X.std(), 'min': X.min(), 'max': X.max()})\n",
    "\n",
    "    X_mean   = X_statistics.values[:, 0]\n",
    "    X_std    = X_statistics.values[:, 1]\n",
    "    X_min    = X_statistics.values[:, 2]\n",
    "    X_max    = X_statistics.values[:, 3]\n",
    "    \n",
    "    # Normalization or standardization using values from the training set.\n",
    "    if opc == 1:\n",
    "        X_norm     = (X.values - X_min) / (X_max - X_min)\n",
    "        X_val_norm = (X_val.values - X_min) / (X_max - X_min)\n",
    "        norm_type  = '_norm'\n",
    "\n",
    "    if opc == 2:\n",
    "        X_norm     = (X.values - X_mean) / X_std\n",
    "        X_val_norm = (X_val.values - X_mean) / X_std\n",
    "        norm_type  = '_std'\n",
    "\n",
    "    # Retrieve the indexes used for training the classifiers\n",
    "    idx_trn = np.genfromtxt(os.path.join(path_models, '_idx_trn_' + nom_dataset + model_surname + '.csv'), delimiter=',', dtype = int)\n",
    "    idx_tst = np.genfromtxt(os.path.join(path_models, '_idx_tst_' + nom_dataset + model_surname + '.csv'), delimiter=',', dtype = int)\n",
    "\n",
    "    X_train      = X_norm[idx_trn]\n",
    "    X_test       = X_norm[idx_tst]\n",
    "    y_train      = y[idx_trn]\n",
    "    y_test       = y[idx_tst]\n",
    "    y_train_OHEV = y_OHEV[idx_trn]\n",
    "    y_test_OHEV  = y_OHEV[idx_tst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d793b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n==================================\")\n",
    "print(\"Training set\\n\")\n",
    "\n",
    "print(f'X_train.........: {np.shape(X_train)}')\n",
    "print(f'y_train.........: {np.shape(y_train)}')\n",
    "print(f'y_train_OHEV....: {np.shape(y_train_OHEV)}')\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Testing set\\n\")\n",
    "\n",
    "print(f'X_test..........: {np.shape(X_test)}')\n",
    "print(f'y_test..........: {np.shape(y_test)}')\n",
    "print(f'y_test_OHEV.....: {np.shape(y_test_OHEV)}')\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Validation set\\n\")\n",
    "\n",
    "print(f'X_val_norm......: {np.shape(X_val_norm)}')\n",
    "print(f'y_val...........: {np.shape(y_val)}')\n",
    "print(f'y_OHEV_val......: {np.shape(y_OHEV_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple confusion matrix\n",
    "\n",
    "def simple_conf_matrix(y_true, y_pred, nom_classes, clf, acc):\n",
    "    \n",
    "    picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "    conf_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "    title = nom_dataset + model_surname + norm_type + ' - Classifier ' + clf + ' - Validation accuracy: '+ str(\"{:0.2f} %\".format(acc*100))\n",
    "\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sns.heatmap(conf_matrix, \n",
    "                annot=True, \n",
    "                fmt='g', \n",
    "                cmap=cmap_cm, \n",
    "                annot_kws={\"size\": 8}, \n",
    "                xticklabels=nom_classes, \n",
    "                yticklabels=nom_classes)\n",
    "    plt.title(title, fontsize = 12)\n",
    "    plt.savefig(os.path.join(path_pic, picture_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149e7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title, cmap, normalize):\n",
    "\n",
    "    picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "    if labels is not None:\n",
    "        tick_marks = np.arange(len(labels))\n",
    "        plt.xticks(tick_marks, labels, fontsize=10, rotation=45)\n",
    "        plt.yticks(tick_marks, labels, fontsize=10)\n",
    "   \n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 8)\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 8)\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title, fontsize=13)\n",
    "    plt.colorbar(shrink=1)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(None)\n",
    "    plt.savefig(os.path.join(path_pic, picture_name))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15571e04",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240cc9bf",
   "metadata": {},
   "source": [
    "- **Multilayer Perceptron** (MLP) is a type of Artificial Neural Network (ANN) used for supervised learning tasks, including classification, regression, and pattern recognition. It's a feedforward neural network that consists of multiple layers of nodes, including an input layer, one or more hidden layers, and an output layer. Each node, or neuron, in the network is connected to every node in the adjacent layers, and these connections have weights that are adjusted during training. MLP is capable of modeling complex relationships in data, making it suitable for tasks where the relationship between inputs and outputs is non-linear and intricate. It uses activation functions to introduce non-linearity into the network, allowing it to learn and approximate a wide variety of functions. One of the key advantages of MLP is its ability to learn from large and high-dimensional datasets. However, this advantage comes with the cost of increased complexity, making it more challenging to train and requiring careful tuning of hyperparameters like the number of hidden layers, the number of neurons in each layer, and the learning rate. Additionally, MLP is sensitive to feature scaling, and preprocessing techniques such as normalization are often applied to the input data to improve performance.\n",
    "***\n",
    "- **Convolutional Neural Networks** (CNNs) are a class of deep learning algorithms specifically designed for processing grid-like data, such as images and videos. CNNs are highly effective in tasks related to computer vision, including image recognition, object detection, and image segmentation. They are characterized by their ability to automatically and adaptively learn spatial hierarchies of features from input data. CNNs consist of multiple layers, including convolutional layers, pooling layers, and fully connected layers. The convolutional layers apply convolution operations to the input data, enabling the network to automatically learn patterns and features from images, such as edges, textures, and more complex structures. The pooling layers downsample the spatial dimensions of the data, reducing computational complexity while retaining important features. Fully connected layers at the end of the network process the learned features and make predictions based on them. One of the significant advantages of CNNs is their ability to capture local patterns and spatial hierarchies of features. By using shared weights and biases in the convolutional layers, CNNs are capable of learning translation-invariant features, making them well-suited for tasks where the spatial arrangement of features in the input data is essential. Additionally, CNNs can automatically learn relevant features from raw pixel values, eliminating the need for manual feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72775254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of the dimensions of the input layer\n",
    "\n",
    "n_dim       = X_norm.shape[1]\n",
    "n_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843264dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For OHEV\n",
    "\n",
    "Counter_test = Counter(map(tuple, y_test_OHEV))\n",
    "Counter_train = Counter(map(tuple, y_train_OHEV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020f71ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training samples')\n",
    "Counter_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a4668",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Testing samples')\n",
    "Counter_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4357c48",
   "metadata": {},
   "source": [
    "### ANN - Grid search for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffbac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def create_model():\n",
    "    \n",
    "#    model = Sequential()\n",
    "#    model.add(Dense(n_dim, activation='relu', input_shape=(n_dim,)))\n",
    "#    model.add(Dropout(0.2))\n",
    "#    model.add(Dense(375, activation='relu'))\n",
    "#    model.add(Dropout(0.2))\n",
    "#    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "#    model.compile(loss='MeanSquaredError', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "#    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8805a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for the batch size and epochs\n",
    "\n",
    "#model = KerasClassifier(build_fn = create_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "#batch_size  = [20, 40, 80, 160]\n",
    "#epochs      = [100, 250, 500]\n",
    "#param_grid  = dict(batch_size = batch_size, epochs = epochs)\n",
    "#grid        = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs=-1, cv=3)\n",
    "#grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "#print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#means  = grid_result.cv_results_['mean_test_score']\n",
    "#stds   = grid_result.cv_results_['std_test_score']\n",
    "#params = grid_result.cv_results_['params']\n",
    "\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "#    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7140571e",
   "metadata": {},
   "source": [
    "Results of the above GridSearch:\n",
    "\n",
    "Best: 0.857639 using {'batch_size': 80, 'epochs': 100}\n",
    "\n",
    "0.815972 (0.032200) with: {'batch_size': 20, 'epochs': 100}\n",
    "0.836806 (0.017705) with: {'batch_size': 20, 'epochs': 250}\n",
    "0.840278 (0.004910) with: {'batch_size': 20, 'epochs': 500}\n",
    "0.836806 (0.032200) with: {'batch_size': 40, 'epochs': 100}\n",
    "0.854167 (0.017010) with: {'batch_size': 40, 'epochs': 250}\n",
    "0.840278 (0.024552) with: {'batch_size': 40, 'epochs': 500}\n",
    "0.857639 (0.027340) with: {'batch_size': 80, 'epochs': 100}\n",
    "0.854167 (0.030666) with: {'batch_size': 80, 'epochs': 250}\n",
    "0.802083 (0.038976) with: {'batch_size': 80, 'epochs': 500}\n",
    "0.840278 (0.041955) with: {'batch_size': 160, 'epochs': 100}\n",
    "0.850694 (0.029869) with: {'batch_size': 160, 'epochs': 250}\n",
    "0.836806 (0.032200) with: {'batch_size': 160, 'epochs': 500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f7bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model\n",
    "#K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68655d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, Adamax, Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d49a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for hidden layers, neurons, activation, dropout_rate and optimizer\n",
    "\n",
    "#def tune_model(hidden_layers, neurons, activation, dropout_rate, optimizer='adam', learning_rate=0.001, momentum=0.9, nesterov=False, rho=0.9, epsilon=1e-07, centered=False, \n",
    "#                 initial_accumulator_value=0.1, amsgrad=False, beta_1=0.9, beta_2=0.999):\n",
    "    \n",
    "#    model = Sequential()\n",
    "#    model.add(Dense(units = neurons, activation = activation, input_shape = (n_dim,)))\n",
    "\n",
    "#    for i in range(hidden_layers):\n",
    "#        model.add(Dense(units = neurons, activation = activation))\n",
    "#        model.add(Dropout(dropout_rate))\n",
    "\n",
    "#    model.add(Dense(units = num_classes, activation = 'sigmoid'))\n",
    "    \n",
    "#    if optimizer == 'sgd':\n",
    "#        optimizer = SGD(lr=learning_rate, momentum=momentum, nesterov=nesterov)\n",
    "#    elif optimizer == 'rmsprop':\n",
    "#        optimizer = RMSprop(lr=learning_rate, rho=rho, epsilon=epsilon, centered=centered)\n",
    "#    elif optimizer == 'adam':\n",
    "#        optimizer = Adam(lr=learning_rate, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon, amsgrad=amsgrad)\n",
    "#    elif optimizer == 'adagrad':\n",
    "#        optimizer = Adagrad(lr=learning_rate, initial_accumulator_value=initial_accumulator_value, epsilon=epsilon)\n",
    "#    elif optimizer == 'adadelta':\n",
    "#        optimizer = Adadelta(lr=learning_rate, rho=rho, epsilon=epsilon)\n",
    "#    elif optimizer == 'adamax':\n",
    "#        optimizer = Adamax(lr=learning_rate, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon)\n",
    "#    elif optimizer == 'nadam':\n",
    "#        optimizer = Nadam(lr=learning_rate, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon)\n",
    "        \n",
    "#    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "#    return model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3748cb9a",
   "metadata": {},
   "source": [
    "'learning_rate' represents the learning rate of the optimizer.\n",
    "'momentum' is the momentum factor for optimizers like SGD and RMSprop.\n",
    "'nesterov' is a boolean indicating whether to apply Nesterov momentum for SGD.\n",
    "'rho' is the decay factor for RMSprop.\n",
    "'epsilon' is a small constant for numerical stability.\n",
    "'centered' is a boolean indicating whether to compute centralized gradients for RMSprop.\n",
    "'initial_accumulator_value' is the starting value for accumulators in Adagrad.\n",
    "'amsgrad' is a boolean indicating whether to use the AMSGrad variant of Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a075bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden_layers  = [1, 2, 3]\n",
    "#neurons        = [375, 500, 750, 1000]\n",
    "#activation     = ['relu', 'sigmoid']\n",
    "#dropout_rate   = [0.1, 0.2, 0.3]\n",
    "#optimizer      = ['sgd', 'rmsprop', 'adam', 'adagrad', 'adadelta', 'adamax', 'nadam']\n",
    "\n",
    "#learning_rate  = [0.001, 0.01, 0.1]\n",
    "\n",
    "#param_grid     = dict(hidden_layers = hidden_layers, \n",
    "#                      neurons       = neurons, \n",
    "#                      activation    = activation,\n",
    "#                     dropout_rate  = dropout_rate,\n",
    "#                      optimizer     = optimizer,\n",
    "#                      learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa178c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.autograph.set_verbosity(0)\n",
    "#tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f5e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = KerasClassifier(build_fn = tune_model, verbose=1, epochs = 100, batch_size = 80)\n",
    "#grid  = GridSearchCV(estimator = model, param_grid = param_grid, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc2f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## summarize results\n",
    "#print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#means  = grid_result.cv_results_['mean_test_score']\n",
    "#stds   = grid_result.cv_results_['std_test_score']\n",
    "#params = grid_result.cv_results_['params']\n",
    "\n",
    "#for mean, stdev, param in zip(means, stds, params):\n",
    "#    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237bc9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model_ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f466e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN (Artificial Neural Network) or MLP (Multi layer Perceptron) using Tensorflow\n",
    "\n",
    "initializer = keras.initializers.Ones()\n",
    "\n",
    "def build_ANN_model(model_name: str, neurons: int):\n",
    "    \n",
    "    #optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9, nesterov=False)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.0001, \n",
    "                                      beta_1=0.5, \n",
    "                                      beta_2=0.999, \n",
    "                                      epsilon=1e-07, \n",
    "                                      amsgrad=True)\n",
    "    \n",
    "    \n",
    "    model = Sequential(name = model_name)\n",
    "    model.add(Dense(neurons, activation = 'relu', input_shape = (neurons,), name = 'Input'))\n",
    "\n",
    "    # First hiden layer with 375 neurons\n",
    "    model.add(Dense(neurons, activation ='relu', name = 'Hiden_1'))\n",
    "\n",
    "    # Dropout de 20%\n",
    "    model.add(Dropout(0.2, name = 'Dropout_1'))\n",
    "    \n",
    "    # Second hiden layer with 750 neurons (Kolmogorov's theorem)\n",
    "    model.add(Dense(n_dim * 2, activation ='relu', name = 'Hiden_2'))\n",
    "\n",
    "    # Dropout de 20%\n",
    "    model.add(Dropout(0.2, name = 'Dropout_2'))\n",
    "\n",
    "    # Final classification layer, with 1 neuron for each output class. Softmax divides the probability of each class.\n",
    "    model.add(Dense(num_classes, activation='softmax', name = 'Output'))\n",
    "\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer, metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=150, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "if not os.path.exists(path_models):\n",
    "    os.makedirs(os.path.join(path_base, path.split(\"\\\\\")[-2]))\n",
    "\n",
    "filepath       = os.path.join(path_models, 'Model_ANN_weights_0_best' + norm_type + model_surname + '.hdf5')\n",
    "checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint,es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ANN = build_ANN_model('ANN_1', neurons = n_dim)\n",
    "model_ANN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649f2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model_ANN, to_file= os.path.join(path_models, 'Model_ANN' + norm_type + model_surname + '.png'), show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7006273",
   "metadata": {},
   "source": [
    "### Understanding the column \"Param\":\n",
    "\n",
    "- 141,000 parameters is the result of 375 neurons with 375 features + 375  bias values\n",
    "- 141,000 parameters is the result of 375 neurons with 375 features + 375  bias values\n",
    "- 282,000 parameters is the result of 750 neurons with 375 features + 750 bias values\n",
    "- 3,755   parameters is the result of 750 neurons with 5 features  + 5  bias values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f2fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n==================================\")\n",
    "print(\"Training set\\n\")\n",
    "\n",
    "print(f'X_train.........: {np.shape(X_train)}')\n",
    "print(f'y_train.........: {np.shape(y_train)}')\n",
    "print(f'y_train_OHEV....: {np.shape(y_train_OHEV)}')\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Testing set\\n\")\n",
    "\n",
    "print(f'X_test..........: {np.shape(X_test)}')\n",
    "print(f'y_test..........: {np.shape(y_test)}')\n",
    "print(f'y_test_OHEV.....: {np.shape(y_test_OHEV)}')\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Validation set\\n\")\n",
    "\n",
    "print(f'X_val_norm......: {np.shape(X_val_norm)}')\n",
    "print(f'y_val...........: {np.shape(y_val)}')\n",
    "print(f'y_OHEV_val......: {np.shape(y_OHEV_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c3f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_OHEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fe4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_ANN = 20\n",
    "epochs_ANN     = 350\n",
    "\n",
    "history_ANN    = model_ANN.fit(X_train, y_train_OHEV,\n",
    "                               batch_size      = batch_size_ANN,\n",
    "                               epochs          = epochs_ANN,\n",
    "                               verbose         = 1,\n",
    "                               validation_data = (X_test, y_test_OHEV),\n",
    "                               callbacks       = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ca30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ANN = model_ANN.evaluate(X_test, y_test_OHEV, verbose=0, batch_size = 20)\n",
    "print('Test loss:', score_ANN[0])\n",
    "print('Test accuracy:', score_ANN[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b5d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ANN[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b45b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "fig.suptitle(nom_dataset + norm_type + model_surname + ' - ANN - Training / Testing loss and accuracy', fontsize = 18)\n",
    "ax[0].plot(history_ANN.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history_ANN.history['val_loss'], color='r', label=\"Testing loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True, fontsize = 14)\n",
    "ax[0].tick_params(axis='x', labelsize=14)\n",
    "ax[0].tick_params(axis='y', labelsize=14)\n",
    "\n",
    "ax[1].plot(history_ANN.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history_ANN.history['val_accuracy'], color='r',label=\"Testing accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True, fontsize = 14)\n",
    "ax[1].tick_params(axis='x', labelsize=14)\n",
    "ax[1].tick_params(axis='y', labelsize=14)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(os.path.join(path_pic, picture_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1723f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file (not the best model though)\n",
    "\n",
    "#model_ANN.save(path_models + \"Model_ANN.h5\")\n",
    "#print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c8a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ANN = np.argmax(model_ANN.predict(X_val_norm),axis=1)\n",
    "y_pred_ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71e5f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_enc = np.argmax(y_OHEV_val, axis=1)\n",
    "y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b650a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set_ANN = classification_report(y_test_enc, y_pred_ANN, target_names=nom_classes)\n",
    "print(metrics_set_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07704de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with the highest accuracy\n",
    "\n",
    "model_ANN_saved = load_model(os.path.join(path_models, 'Model_ANN_weights_0_best' + norm_type + model_surname + '.hdf5'))\n",
    "model_ANN_saved.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690dfa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ANN_saved = model_ANN_saved.evaluate(X_val_norm, y_OHEV_val, verbose=1, batch_size = 20)\n",
    "print('Test loss:', score_ANN_saved[0])\n",
    "print('Test accuracy:', score_ANN_saved[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62882b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ANN_saved = np.argmax(model_ANN_saved.predict(X_val_norm),axis=1)\n",
    "y_pred_ANN_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceba4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set_ANN_saved = classification_report(y_test_enc, y_pred_ANN_saved, target_names=nom_classes)\n",
    "print(metrics_set_ANN_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ade4c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple confusion matrix\n",
    "\n",
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "conf_matrix = metrics.confusion_matrix(y_test_enc, y_pred_ANN_saved)\n",
    "title = nom_dataset + norm_type + model_surname + ' - Classifier ANN (best model) - Highest accuracy test: '+ str(\"{:0.2f}%\".format(score_ANN_saved[1]*100))\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True, \n",
    "            fmt='g', \n",
    "            cmap=cmap_cm, \n",
    "            annot_kws={\"size\": 8}, \n",
    "            xticklabels=nom_classes, \n",
    "            yticklabels=nom_classes)\n",
    "plt.title(title, fontsize = 12)\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7b9cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ANN_saved.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_ANN_saved.layers:\n",
    "    print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c9686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model_ANN_saved.get_layer('Output').get_weights()\n",
    "weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f7bc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del model_CNN_1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b430548",
   "metadata": {},
   "source": [
    "### CNN 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deabf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN (Convolutional Neural Network) using Tensorflow\n",
    "\n",
    "def build_CNN_1D_model(model_name: str, neurons: int):\n",
    "    \n",
    "    model = Sequential(name = model_name)\n",
    "\n",
    "    # 1st conv layer\n",
    "    model.add(Conv1D(28, 7, activation = 'relu', input_shape = (neurons, 1), name = 'Conv1D_1'))\n",
    "    #model.add(MaxPooling1D(3, name = 'MaxPool1D_1'))\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(Conv1D(34, 5, activation = 'relu', kernel_regularizer=l2(0.001), bias_regularizer=l2(0.01), padding='same', name = 'Conv1D_2'))\n",
    "    #model.add(MaxPooling1D(2, name = 'MaxPool1D_2'))\n",
    "    \n",
    "    # 3nd conv layer \n",
    "    model.add(Conv1D(56, 3, activation = 'relu', kernel_regularizer=l2(0.001), bias_regularizer=l2(0.01), padding='same', name = 'Conv1D_3'))\n",
    "    model.add(MaxPooling1D(2, name = 'MaxPool1D_3'))\n",
    "    model.add(Dropout(0.2, name = 'Dropout_1'))\n",
    "    \n",
    "    # 4nd conv layer + dropout 20%\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, name = 'Dense'))\n",
    "\n",
    "    # Final classification layer, with 1 neuron for each output class. Softmax divides the probability of each class.\n",
    "    model.add(Dense(num_classes, activation = 'softmax', name = 'Output'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adamax', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e20c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=50, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "if not os.path.exists(path_models):\n",
    "    os.makedirs(os.path.join(path_base, path.split(\"\\\\\")[-2]))\n",
    "    \n",
    "filepath       = os.path.join(path_models, 'Model_CNN_1D_weights_0_best' + norm_type + model_surname + '.hdf5')\n",
    "checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint, monitor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe8a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN_1D = build_CNN_1D_model('CNN_1D', neurons = n_dim)\n",
    "model_CNN_1D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a28354",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model_ANN, to_file= os.path.join(path_models, 'Model_CNN_1D' + norm_type + model_surname + '.png'), show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372210cd",
   "metadata": {},
   "source": [
    "### Understanding the column \"Param\":\n",
    "\n",
    "1. For `Conv1D` layer:\n",
    "   - The number of parameters for a `Conv1D` layer is calculated as `(kernel_size * input_channels + 1) * output_channels`, where `kernel_size` is the size of the convolutional kernel, `input_channels` is the number of input channels (1 in this case), and `output_channels` is the number of output channels.\n",
    "\n",
    "2. For `Dense` layer:\n",
    "   - The number of parameters for a `Dense` layer is calculated as `(input_units + 1) * output_units`, where `input_units` is the number of input units and `output_units` is the number of output units.\n",
    "   \n",
    "3. In the calculation of parameters for a convolutional layer, the term \"channels\" refers to the number of filters used in that layer.\n",
    "\n",
    "- 224   parameters is the result of 28 filters * (7 kernels * 1 filter + 1)\n",
    "- 4,794 parameters is the result of 34 filter * (5 kernels * 28 filters + 1)\n",
    "- 5,768  parameters is the result of 56 filters * (3 kernels * 34 filters + 1)\n",
    "- 515,250  parameters is the result of 50 neurons with 10,304 features + 50 bias values\n",
    "- 255    parameters is the result of 5 neurons with 50 features + 5 bias values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda9a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_CNN_1D = 20\n",
    "epochs_CNN_1D     = 150\n",
    "\n",
    "history_CNN_1D    = model_CNN_1D.fit(X_train[..., np.newaxis], y_train_OHEV,\n",
    "                                     batch_size      = batch_size_CNN_1D,\n",
    "                                     epochs          = epochs_CNN_1D,\n",
    "                                     verbose         = 1,\n",
    "                                     validation_data =(X_test[..., np.newaxis], y_test_OHEV),\n",
    "                                     callbacks       = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331031ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_CNN_1D = model_CNN_1D.evaluate(X_test[..., np.newaxis], y_test_OHEV, verbose=0, batch_size = 20)\n",
    "print('Test loss:', score_CNN_1D[0])\n",
    "print('Test accuracy:', score_CNN_1D[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975bf891",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_CNN_1D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b09bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "fig.suptitle(nom_dataset + norm_type + model_surname + ' - CNN 1D - Training / Testing loss and accuracy', fontsize = 18)\n",
    "ax[0].plot(history_CNN_1D.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history_CNN_1D.history['val_loss'], color='r', label=\"Testing loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True, fontsize = 14)\n",
    "ax[0].tick_params(axis='x', labelsize=14)\n",
    "ax[0].tick_params(axis='y', labelsize=14)\n",
    "\n",
    "ax[1].plot(history_CNN_1D.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history_CNN_1D.history['val_accuracy'], color='r',label=\"Testing accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True, fontsize = 14)\n",
    "ax[1].tick_params(axis='x', labelsize=14)\n",
    "ax[1].tick_params(axis='y', labelsize=14)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(os.path.join(path_pic, picture_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1768a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file (Not the best model though)\n",
    "\n",
    "#model_CNN_1D.save(path_models + \"Model_CNN_1D.h5\")\n",
    "#print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb21a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_CNN_1D = np.argmax(model_CNN_1D.predict(X_val_norm[..., np.newaxis]),axis=1)\n",
    "y_pred_CNN_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37047e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_enc = np.argmax(y_OHEV_val, axis=1)\n",
    "y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04983276",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set_CNN_1D = classification_report(y_test_enc, y_pred_CNN_1D, target_names=nom_classes)\n",
    "print(metrics_set_CNN_1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with the highest accuracy\n",
    "\n",
    "model_CNN_1D_saved = load_model(os.path.join(path_models, 'Model_CNN_1D_weights_0_best' + norm_type + model_surname + '.hdf5'))\n",
    "model_CNN_1D_saved.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d38f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_CNN_1D_saved = model_CNN_1D_saved.evaluate(X_val_norm[..., np.newaxis], y_OHEV_val, verbose=1, batch_size = 20)\n",
    "print('Test loss:', score_CNN_1D_saved[0])\n",
    "print('Test accuracy:', score_CNN_1D_saved[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b118cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_CNN_1D_saved = np.argmax(model_CNN_1D_saved.predict(X_val_norm[..., np.newaxis]),axis=1)\n",
    "y_pred_CNN_1D_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8731110",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set_CNN_1D_saved = classification_report(y_test_enc, y_pred_CNN_1D_saved, target_names=nom_classes)\n",
    "print(metrics_set_CNN_1D_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26e1dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple confusion matrix\n",
    "\n",
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "conf_matrix = metrics.confusion_matrix(y_test_enc, y_pred_CNN_1D_saved)\n",
    "title = nom_dataset + norm_type + model_surname + ' - Classifier CNN 1D (best model) - Highest accuracy test: '+ str(\"{:0.2f}%\".format(score_CNN_1D_saved[1]*100))\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True, \n",
    "            fmt='g', \n",
    "            cmap=cmap_cm, \n",
    "            annot_kws={\"size\": 8}, \n",
    "            xticklabels=nom_classes, \n",
    "            yticklabels=nom_classes)\n",
    "plt.title(title, fontsize = 12)\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0322d5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN_1D_saved.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0847ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_CNN_1D_saved.layers:\n",
    "    print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b7df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model_CNN_1D_saved.get_layer('Output').get_weights()\n",
    "weights[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73169e4d",
   "metadata": {},
   "source": [
    "## Metrics for the classifiers\n",
    "\n",
    "\n",
    "1. Accuracy: Accuracy is a measure of how many correct predictions a model makes overall, i.e., the ratio of correct predictions to the total number of predictions. It's a commonly used metric for evaluating models, but it may not be suitable in certain situations.\n",
    "\n",
    "2. Precision: Precision measures the ratio of true positives (correctly predicted positive instances) to all instances predicted as positive. It focuses on the accuracy of positive predictions.\n",
    "\n",
    "3. Recall: Recall, also known as sensitivity or true positive rate, measures the ratio of true positives to all actual positive instances. It focuses on how well a model captures all the positive instances.\n",
    "\n",
    "4. F1 Score: The F1 score is the harmonic mean of precision and recall. It provides a balanced measure that takes into account both false positives and false negatives. The F1 score is especially useful when you want to strike a balance between precision and recall.\n",
    "\n",
    "\n",
    "The F1 score is a metric that combines precision and recall, and it is particularly useful in situations where class imbalance or unequal misclassification costs are present. In such contexts, the F1 score can be more informative and meaningful than accuracy.\n",
    "\n",
    "A context where considering the F1 score makes more sense than accuracy:\n",
    "\n",
    "**Medical Diagnosis:**\n",
    "\n",
    "Imagine you're developing a model to diagnose a rare disease, and only 5% of the population has this disease. In this case, you have a significant class imbalance, where the majority of cases are negative (non-disease) and only a small fraction are positive (disease). If you were to use accuracy as the evaluation metric, the model could achieve a high accuracy by simply predicting \"negative\" for every case, because it would be correct 95% of the time due to the class imbalance. However, this would be entirely useless for detecting the actual disease.\n",
    "\n",
    "In this scenario, you'd be more interested in the F1 score. The F1 score considers both precision and recall, helping you find a balance between correctly identifying the disease (high recall) and not making too many false positive predictions (high precision). A high F1 score in this context indicates that your model is effective at correctly identifying the disease while minimizing false alarms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46413ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['ANN', 'CNN_1D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a186ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to run the classifiers and their metrics\n",
    "\n",
    "def model_classifiers(classifiers:list, \n",
    "                      db: pd.DataFrame, \n",
    "                      scalerOpt: str, \n",
    "                      use_PCA = False):\n",
    "    \n",
    "    # Clear the session to start a new training\n",
    "    K.clear_session()\n",
    " \n",
    "    es = EarlyStopping(monitor='accuracy', min_delta=0.0001, patience=50, verbose=1, mode='auto', restore_best_weights=True)\n",
    "    \n",
    "    count       = 1\n",
    "    batch_size  = 20\n",
    "    verbose     = True\n",
    "    models      = []\n",
    "    acc_set     = pd.DataFrame(index=None, columns=['Model',\n",
    "                                                    'Fold',\n",
    "                                                    'Accuracy(Train)',\n",
    "                                                    'Accuracy(Val)',\n",
    "                                                    'F1(Train)',\n",
    "                                                    'F1(Val)', \n",
    "                                                    'Precision(Train)',\n",
    "                                                    'Precision(Val)', \n",
    "                                                    'Recall(Train)',\n",
    "                                                    'Recall(Val)', \n",
    "                                                    'Conf_M',\n",
    "                                                    'Process_time',                                                     \n",
    "                                                    'Class_report(Val)'])\n",
    "    \n",
    "    for fold in np.unique(db['Fold']):\n",
    "        print(f\"Validation fold: {fold}\")\n",
    "\n",
    "        DB_VAL = db[db['Fold'] == fold]\n",
    "        DB_TRN = db[db['Fold'] != fold]\n",
    "\n",
    "        X      = DB_TRN.drop(columns=['Audio','Class_categorical','Class_OHEV', 'Fold'])\n",
    "        y      = np.array(DB_TRN.Class_categorical.to_list())\n",
    "        y_OHEV = np.array(DB_TRN.Class_OHEV.to_list())\n",
    "\n",
    "        X_val      = DB_VAL.drop(columns=['Audio','Class_categorical','Class_OHEV', 'Fold'])\n",
    "        y_val      = np.array(DB_VAL.Class_categorical.to_list())\n",
    "        y_OHEV_val = np.array(DB_VAL.Class_OHEV.to_list())\n",
    "        \n",
    "        neurons  = X.shape[1]\n",
    "        \n",
    "        X_statistics = pd.DataFrame({'mean': X.mean(), 'std': X.std(), 'min': X.min(), 'max': X.max()})\n",
    "\n",
    "        X_mean   = X_statistics.values[:, 0]\n",
    "        X_std    = X_statistics.values[:, 1]\n",
    "        X_min    = X_statistics.values[:, 2]\n",
    "        X_max    = X_statistics.values[:, 3]\n",
    "        \n",
    "        if scalerOpt == \"normalization\":\n",
    "            X_train_norm = (X.values - X_min) / (X_max - X_min)\n",
    "            X_val_norm   = (X_val.values - X_min) / (X_max - X_min)\n",
    "            batch_type    = '_norm'\n",
    "            print(f'X_train_norm shape...:{X_train_norm.shape}')\n",
    "            print(f'X_val_norm shape.....:{X_val_norm.shape}\\n')\n",
    "            \n",
    "        elif scalerOpt == \"standardization\":\n",
    "            X_train_norm = (X.values - X_mean) / X_std\n",
    "            X_val_norm   = (X_val.values - X_mean) / X_std\n",
    "            batch_type    = '_std'\n",
    "            print(f'X_train_norm shape...:{X_train_norm.shape}')\n",
    "            print(f'X_val_norm shape.....:{X_val_norm.shape}\\n')\n",
    "            \n",
    "        else:\n",
    "            sys.exit()\n",
    "            \n",
    "        if use_PCA:\n",
    "            pcaT = PCA()\n",
    "            pcaT.fit(X_train_norm)\n",
    "            ratio = pcaT.explained_variance_ratio_\n",
    "\n",
    "            batch_type = batch_type + '_PCA'\n",
    "\n",
    "            T           = 0.98\n",
    "            current_sum = 0\n",
    "            countComp   = 0\n",
    "\n",
    "            for element in ratio:\n",
    "                current_sum += element\n",
    "                countComp   += 1\n",
    "\n",
    "                if current_sum >= T:\n",
    "                    break\n",
    "\n",
    "            # Print the result\n",
    "            print(\"Sum of elements:\", current_sum)\n",
    "            print(\"Number of elements summed:\", countComp)           \n",
    "\n",
    "            pca          = PCA(n_components = countComp)\n",
    "            X_train_norm = pca.fit_transform(X_train_norm)\n",
    "            X_val_norm   = pca.transform(X_val_norm)\n",
    "            neurons      = countComp\n",
    "        \n",
    "        X_train_norm, X_test_norm, y_train, y_test = train_test_split(X_train_norm, y_OHEV, test_size=0.1, random_state=42, stratify=y_OHEV)\n",
    "\n",
    "\n",
    "        for i in tqdm(range(len(classifiers))):\n",
    "            \n",
    "            name         = classifiers[i]\n",
    "            model_name   = ('Model_' + classifiers[i] + '_' + str(count))\n",
    "            count        = count + 1\n",
    "            \n",
    "            if classifiers[i] == 'ANN':\n",
    "                \n",
    "                filepath       = os.path.join(path_models, 'Model_ANN_weights_0_best' + norm_type + model_surname + '.hdf5')\n",
    "                checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "                callbacks_list = [checkpoint, es]\n",
    "               \n",
    "                model = build_ANN_model(model_name, neurons)\n",
    "                model.summary()\n",
    "                print(name)\n",
    "                print(np.shape(X_train_norm))    \n",
    "\n",
    "                model.fit(X_train_norm, \n",
    "                          y_train, \n",
    "                          batch_size      = batch_size, \n",
    "                          epochs          = 350, \n",
    "                          verbose         = verbose,                               \n",
    "                          validation_data = (X_test_norm, y_test),\n",
    "                          callbacks       = callbacks_list)\n",
    "                \n",
    "                model= load_model(os.path.join(path_models, 'Model_ANN_weights_0_best' + norm_type + model_surname + '.hdf5'))\n",
    "                print('Best model loaded')\n",
    "\n",
    "            else:\n",
    "\n",
    "                filepath       = os.path.join(path_models, 'Model_CNN_1D_weights_0_best' + norm_type + model_surname + '.hdf5')\n",
    "                checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "                callbacks_list = [checkpoint]                \n",
    "\n",
    "                X_train_norm = X_train_norm[..., np.newaxis]\n",
    "                X_val_norm   = X_val_norm[..., np.newaxis]\n",
    "                X_test_norm  = X_test_norm[..., np.newaxis]\n",
    "\n",
    "                model = build_CNN_1D_model(model_name, neurons)\n",
    "                model.summary()\n",
    "                print(name)\n",
    "                print(np.shape(X_train_norm))    \n",
    "                \n",
    "                model.fit(X_train_norm, \n",
    "                          y_train, \n",
    "                          batch_size = batch_size, \n",
    "                          epochs = 150, \n",
    "                          verbose = verbose,                          \n",
    "                          validation_data = (X_test_norm, y_test),\n",
    "                          callbacks       = callbacks_list)\n",
    "\n",
    "                model= load_model(os.path.join(path_models, 'Model_CNN_1D_weights_0_best' + norm_type + model_surname + '.hdf5'))\n",
    "                print('Best model loaded')\n",
    "\n",
    "            # Get the model predictions\n",
    "            y_train_enc = np.argmax(y_train, axis=1)\n",
    "            y_val_enc   = np.argmax(y_OHEV_val, axis=1)\n",
    "\n",
    "            y_train_predicted = np.argmax(model.predict(X_train_norm), axis=1)\n",
    "            \n",
    "            t_srt             = time.process_time_ns()\n",
    "            y_val_predicted   = np.argmax(model.predict(X_val_norm), axis=1)\n",
    "            t_end             = time.process_time_ns()\n",
    "            proc_time         = ((t_end - t_srt) / 1000000)         \n",
    "    \n",
    "            # Compute the classifier metrics\n",
    "            accuracy_train = metrics.accuracy_score(y_train_enc, y_train_predicted)\n",
    "            accuracy_val   = metrics.accuracy_score(y_val_enc,  y_val_predicted)\n",
    "\n",
    "            f1_Score_train = metrics.f1_score(y_train_enc, y_train_predicted, average = 'weighted')\n",
    "            f1_Score_val   = metrics.f1_score(y_val_enc,  y_val_predicted,  average = 'weighted')\n",
    "\n",
    "            precision_score_train = metrics.precision_score(y_train_enc, y_train_predicted, average = 'weighted')\n",
    "            precision_score_val   = metrics.precision_score(y_val_enc,  y_val_predicted,  average = 'weighted')\n",
    "\n",
    "            recall_score_train = metrics.recall_score(y_train_enc, y_train_predicted, average = 'weighted')\n",
    "            recall_score_val   = metrics.recall_score(y_val_enc,  y_val_predicted,  average = 'weighted')\n",
    "\n",
    "            class_report_val = classification_report(y_val_enc, y_val_predicted, target_names = nom_classes)\n",
    "            print(class_report_val)\n",
    "            \n",
    "            # Compute the confusion matrix\n",
    "            CM = metrics.confusion_matrix(y_val_enc, y_val_predicted)\n",
    "            y_val_enc       = []\n",
    "            y_val_predicted = []\n",
    "\n",
    "            # Store the name, test accuracy results and model\n",
    "            models.append((name, accuracy_val, model))\n",
    "            \n",
    "            K.clear_session()\n",
    "            del model\n",
    "                    \n",
    "            acc_set = pd.concat([acc_set, pd.DataFrame({'Model': [name],\n",
    "                                                        'Fold': [fold],\n",
    "                                                        'Accuracy(Train)': [accuracy_train],\n",
    "                                                        'Accuracy(Val)': [accuracy_val],\n",
    "                                                        'F1(Train)': [f1_Score_train],\n",
    "                                                        'F1(Val)': [f1_Score_val],\n",
    "                                                        'Precision(Train)': [precision_score_train],\n",
    "                                                        'Precision(Val)': [precision_score_val],\n",
    "                                                        'Recall(Train)': [recall_score_train],\n",
    "                                                        'Recall(Val)': [recall_score_val],\n",
    "                                                        'Conf_M': [CM],\n",
    "                                                        'Process_time': [proc_time],\n",
    "                                                        'Class_report(Val)': class_report_val})], ignore_index = True)\n",
    "                   \n",
    "    return acc_set, models, batch_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358bab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option for scalerOpt is either \"normalization\" or \"standardization\"\n",
    "\n",
    "metrics_set, models_set, batch_name = model_classifiers(classifiers, \n",
    "                                                        DB_from_pkl, \n",
    "                                                        scalerOpt = 'standardization',\n",
    "                                                        use_PCA = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a578bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Model and Accuracy test. Reset the index.\n",
    "\n",
    "metrics_set = metrics_set.sort_values(['Model', 'Accuracy(Val)'], ascending = [True, True]).reset_index()\n",
    "metrics_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af9afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set[['Model', 'Accuracy(Val)']].style.background_gradient(cmap = cmap_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6fa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_accuracy = metrics_set.groupby('Model')['Accuracy(Val)'].max()\n",
    "highest_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40226fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dictionary of each classifier and its data explanation\n",
    "\n",
    "unique_models = []\n",
    "results       = {}\n",
    "\n",
    "for c in classifiers:\n",
    "    unique_models.append(c)\n",
    "\n",
    "for model in unique_models:\n",
    "    result = metrics_set[metrics_set['Model'] == model].describe().round(4)\n",
    "    results[model] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a5ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in results.keys():\n",
    "    print(f'Model...: {model}')\n",
    "    display(results[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b38499",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set_no_cm = metrics_set.drop(['Conf_M', 'Class_report(Val)'], axis=1)\n",
    "metrics_set_no_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea27fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set_name       = nom_dataset + '_NN_metrics_set' + batch_name +  model_surname + '.pkl'\n",
    "metrics_set_name_no_cm = nom_dataset + '_NN_metrics_set' + batch_name +  model_surname + '_no_cm.csv'\n",
    "\n",
    "print(metrics_set_name)\n",
    "print(metrics_set_name_no_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d17b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes de results to a PKL and CSV file\n",
    "\n",
    "with open(os.path.join(path_models, metrics_set_name), 'wb') as file:\n",
    "    pickle.dump(metrics_set, file)\n",
    "    \n",
    "metrics_set_no_cm.to_csv(os.path.join(path_models, metrics_set_name_no_cm), sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb90a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set_from_pkl = pd.read_pickle(os.path.join(path_models, metrics_set_name))\n",
    "metrics_set_from_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea2f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = metrics_set.groupby('Model')['Accuracy(Val)'].idxmax()\n",
    "conf_matrices = metrics_set.loc[idx, ['Model','Accuracy(Val)','Conf_M']]\n",
    "conf_matrices.set_index('Model', inplace=True)\n",
    "conf_matrices_dict = conf_matrices.to_dict('index')\n",
    "conf_matrices_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrices_dict['ANN']['Conf_M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, idx in zip(conf_matrices_dict.keys(), range(1, len(conf_matrices_dict) + 1)):\n",
    "    print(idx)\n",
    "    print(i)\n",
    "    print(conf_matrices_dict[i]['Accuracy(Val)'])\n",
    "    print(conf_matrices_dict[i]['Conf_M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e53550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix for the highest accuracy test classifiers\n",
    "\n",
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.suptitle(nom_dataset + model_surname + batch_name + ' - Confusion matrices of the best results for each classifier', fontsize = 16,  y=0.99)\n",
    "for i, idx in zip(conf_matrices_dict.keys(), range(1, len(conf_matrices_dict) + 1)):\n",
    "    title = 'Classifier '+ i + ' (Highest accuracy validation of the best models: ' + str(\"{:0.4f}\".format(conf_matrices_dict[i]['Accuracy(Val)'])) +')'\n",
    "    plt.subplot(1,2,idx)\n",
    "    plot_confusion_matrix(conf_matrices_dict[i]['Conf_M'],  \n",
    "                          nom_classes, \n",
    "                          title,\n",
    "                          cmap = None,                          \n",
    "                          normalize = False)\n",
    "plt.tight_layout(pad=1.0)\n",
    "plt.savefig(os.path.join(path_pic, picture_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f0df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.suptitle(f'{nom_dataset} - Box plot each classifier (batch type: {model_surname + batch_name})', fontsize = 16,  y=0.97)\n",
    "box_plot = sns.boxplot(data=metrics_set, x=\"Model\", y=\"Accuracy(Val)\", showfliers = True)\n",
    "\n",
    "medians = list(metrics_set.groupby(['Model'])['Accuracy(Val)'].median())\n",
    "medians = [round(element, 2) for element in medians]\n",
    "\n",
    "vertical_offset = metrics_set['Accuracy(Val)'].median()*0.001  # offset from median for display\n",
    "\n",
    "for xtick in box_plot.get_xticks():\n",
    "    box_plot.text(xtick, medians[xtick] + vertical_offset, medians[xtick], \n",
    "            horizontalalignment='center',size='medium',color='w',weight='semibold')\n",
    "plt.savefig(os.path.join(path_pic, picture_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41968385",
   "metadata": {},
   "source": [
    "## Results ESC-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cece92",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e275303",
   "metadata": {},
   "source": [
    "## Results BDLib2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc69cc24",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b29ab96b",
   "metadata": {},
   "source": [
    "## Results US8K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568845ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85e46c9c",
   "metadata": {},
   "source": [
    "## Results US8K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7294ed2a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb45a0d9",
   "metadata": {},
   "source": [
    "# End of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93509039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75d9f7d3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc57de80",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6abcdd9",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
