{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-1PkcG8ARink"
   },
   "source": [
    "### Faculdade de Engenharia Industrial - FEI\n",
    "\n",
    "### Centro Universitário da Fundação Educacional Inaciana \"Padre Sabóia de Medeiros\" (FEI)\n",
    "\n",
    "\n",
    "*FEI's Stricto Sensu Graduate Program in Electrical Engineering*\n",
    "\n",
    "Concentration area: ARTIFICIAL INTELLIGENCE APPLIED TO AUTOMATION AND ROBOTICS\n",
    "\n",
    "Master's thesis student Andre Luiz Florentino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "pd = tf.config.experimental.list_physical_devices()\n",
    "for i in pd:\n",
    "    print(i)\n",
    "print('------------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
    "\n",
    "print(tf.test.is_built_with_cuda)\n",
    "# <function is_built_with_cuda at 0x000001AA24AFEC10>\n",
    "\n",
    "print(tf.test.gpu_device_name())\n",
    "# /device:GPU:0\n",
    "\n",
    "#gvd = tf.config.get_visible_devices()\n",
    "for j in tf.config.get_visible_devices():\n",
    "    print(j)\n",
    "# PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
    "# PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: Convolutional Neural Network (2D)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The paper entitled \"ESC-ConvNet: Environmental Sound Classification with Convolutional Neural Networks\" (PICZAK, 2015) serves as the foundation for the following analysis. In this study, the author employs Convolutional Neural Networks (CNNs) for image classification, utilizing fixed dimension images that consist of multiple channels (such as RGB for color images). The network undergoes various stages of convolution, pooling, and fully connected layers, ultimately outputting class probabilities for the given image. With the aim to replicate this approach using sound clips, the utilization of log-scaled mel-spectrograms and their respective deltas from each sound clip is proposed instead of directly using the sound file as an amplitude vs. time signal. In order to address the requirement of fixed size input, the sound clips are segmented into 60x41 segments (60 bands and 41 frames - windowing techinique). The log-scaled mel-spectrograms are extracted from all the recordings, which were resampled to 22050 Hz and normalized with a window size of 1024, a hop length of 512, and 60 mel-bands.\n",
    "\n",
    "- The human auditory system perceives sound on a logarithmic scale, rendering it difficult to distinguish closely-scaled frequencies. This effect becomes more pronounced with increasing frequency. Therefore, only the power within different frequency bands is considered. As a result, the mel-spectrograms and their corresponding deltas are transformed into two channels that are subsequently inputted into the CNN for analysis.\n",
    "\n",
    "- During the iterative process of file exploration, it is noted that each sound is 5 seconds in duration and has in its duration (sometimes) silent periods. In order to achieve a more representative \"sound image\", for each sound, the \"extract_feature\" methods are utilized to trim the silent periods and duplicate the sound, effectively doubling its trimmed length (augmented audio). Subsequently, the aforementioned features, along with the class labels, are calculated and appended to arrays.\n",
    "\n",
    "- The final result transformed the audio file into a spectrogram image consisting of 60 bands, 41 frames, and 2 channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "import itertools\n",
    "import mimetypes\n",
    "import time\n",
    "\n",
    "import pandas     as pd\n",
    "import seaborn    as sns\n",
    "import numpy      as np\n",
    "\n",
    "from matplotlib  import pyplot  as plt\n",
    "from keras       import backend as K\n",
    "\n",
    "from tqdm                        import tqdm\n",
    "\n",
    "from sklearn                     import metrics\n",
    "from sklearn.model_selection     import train_test_split\n",
    "from sklearn.metrics             import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow                  import keras\n",
    "from tensorflow.keras.models     import Sequential, load_model\n",
    "from tensorflow.keras.layers     import Dense, Dropout, Flatten, InputLayer, Conv2D\n",
    "from tensorflow.keras.layers     import MaxPooling2D, BatchNormalization, Activation\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks             import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers            import SGD\n",
    "from keras.constraints           import maxnorm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 12)\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "\n",
    "cmap_cm   = plt.cm.Blues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# For the picture names\n",
    "pic_first_name = '09_CNN_2D_'\n",
    "\n",
    "# For Librosa\n",
    "FRAME_SIZE  = 1024\n",
    "HOP_LENGTH  = 512\n",
    "SEED        = 1000\n",
    "SR          = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dataset\n",
    "\n",
    "opcD = 0\n",
    "while str(opcD) not in '1234':\n",
    "    print()\n",
    "    print(\"1-) ESC-10\")\n",
    "    print(\"2-) BDLib2\")\n",
    "    print(\"3-) US8K\")\n",
    "    print(\"4-) US8K_AV\")\n",
    "\n",
    "    opcD = input(\"\\nSelect the dataset: \")\n",
    "    if opcD.isdigit():\n",
    "        opcD = int(opcD)\n",
    "    else:\n",
    "        opcD = 0\n",
    "\n",
    "if opcD == 1:\n",
    "\n",
    "    path        = os.path.join(current_path, \"_dataset\", \"ESC-10\")\n",
    "    path_pic    = os.path.join(current_path, \"ESC-10_results\")\n",
    "    path_models = os.path.join(current_path, \"ESC-10_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "   \n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'ESC-10' \n",
    "    csv_file    = 'ESC-10.csv'\n",
    "    fold        = 1\n",
    "    dog_set     = 'Dog bark'\n",
    "    \n",
    "    pkl_features_CNN_2D          = 'ESC-10_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'ESC-10_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'ESC-10_features_CNN_2D_augmented.pkl'\n",
    "    \n",
    "\n",
    "    \n",
    "if opcD == 2:\n",
    "    \n",
    "    path        = os.path.join(current_path, \"_dataset\", \"BDLib2\")\n",
    "    path_pic    = os.path.join(current_path, \"BDLib2_results\")\n",
    "    path_models = os.path.join(current_path, \"BDLib2_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "\n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'BDLib2' \n",
    "    csv_file    = 'BDLib2.csv'\n",
    "    fold        = 'fold-1'\n",
    "    dog_set     = 'dogs'\n",
    "    \n",
    "    pkl_features_CNN_2D          = 'BDLib2_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'BDLib2_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'BDLib2_features_CNN_2D_augmented.pkl'\n",
    "    \n",
    "    \n",
    "if opcD == 3:\n",
    "    \n",
    "    path        = os.path.join(current_path, \"_dataset\", \"US8K\")\n",
    "    path_pic    = os.path.join(current_path, \"US8K_results\")\n",
    "    path_models = os.path.join(current_path, \"US8K_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "        \n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'US8K' \n",
    "    csv_file    = 'US8K.csv'\n",
    "    fold        = '1'\n",
    "    dog_set     = 'dog_bark'\n",
    "\n",
    "    pkl_features_CNN_2D          = 'US8K_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'US8K_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'US8K_features_CNN_2D_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large\n",
    "    \n",
    "    \n",
    "if opcD == 4:\n",
    "\n",
    "    path        = os.path.join(current_path, \"_dataset\", \"US8K_AV\")\n",
    "    path_pic    = os.path.join(current_path, \"US8K_AV_results\")\n",
    "    path_models = os.path.join(current_path, \"US8K_AV_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "\n",
    "\n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'US8K_AV' \n",
    "    csv_file    = 'US8K_AV.csv'\n",
    "    fold        = '1'\n",
    "    dog_set     = 'dog_bark'\n",
    "    \n",
    "    pkl_features_CNN_2D          = 'US8K_AV_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'US8K_AV_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'US8K_AV_features_CNN_2D_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_file_number(folder: str):\n",
    "    files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) and f.startswith(pic_first_name)]\n",
    "    if not files:\n",
    "        return 1\n",
    "    else:\n",
    "        numbers = [int(f.split('.')[0].split('_')[-1]) for f in files]\n",
    "        return max(numbers) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MT_loadDataset import loadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadDataset = loadDataset(path)\n",
    "DB          = loadDataset.db_B\n",
    "\n",
    "print(\"\\nClasses:\\n--------------------\")\n",
    "print(DB[\"Class_categorical\"].value_counts())\n",
    "print(\"\\nTotal number of unique files..........: \", len(np.unique(DB[\"File_name\"])))\n",
    "print(\"Total number of AUDIO files...........: \", len(DB))\n",
    "DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the class balancing\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "gTitle = f'{nom_dataset} - Number of classes = ' + str(len(pd.Series(DB['Class_categorical']).unique()))\n",
    "g = sns.displot(DB,x='Class_categorical', hue='Class_categorical',height = 5, aspect = 2).set(title=gTitle)\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set_titles('Number of classes')\n",
    "\n",
    "# Retrieve the axes object from the plot\n",
    "axes = g.ax\n",
    "\n",
    "# Iterate over each bar in the plot\n",
    "for p in axes.patches:\n",
    "    # Get the coordinates of the bar\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    cord_x, cord_y = p.get_xy()\n",
    "    if height > 0:\n",
    "        axes.annotate(f'{height}', (cord_x + width/2, cord_y + height), ha='center')\n",
    "        \n",
    "g._legend.remove()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pkl file with the augmented features extracted\n",
    "\n",
    "opc = 0\n",
    "while str(opc) not in '123':\n",
    "    print()\n",
    "    print(\"1-) Features original\")\n",
    "    print(\"2-) Features augmented\")\n",
    "    print(\"3-) Features augmented and windowed (US8K is only windowed)\")\n",
    "\n",
    "    opc = input(\"\\nSelect the dataset: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "\n",
    "if opc == 1:\n",
    "    DB_from_pkl      = pd.read_pickle(os.path.join(path_models, pkl_features_CNN_2D))\n",
    "    model_surname    = '_original'\n",
    "\n",
    "elif opc == 2:\n",
    "    DB_from_pkl      = pd.read_pickle(os.path.join(path_models, pkl_aug_features_CNN_2D))\n",
    "    model_surname    = '_augmented'\n",
    "\n",
    "elif opc == 3:\n",
    "    DB_from_pkl      = pd.read_pickle(os.path.join(path_models, pkl_aug_wind_features_CNN_2D))\n",
    "    model_surname    = '_windowed'\n",
    "    \n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the class balancing\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "gTitle = f'{nom_dataset} - Number of classes = ' + str(len(pd.Series(DB_from_pkl['Class_categorical']).unique()))\n",
    "g = sns.displot(DB_from_pkl,x='Class_categorical', hue='Class_categorical',height = 5, aspect = 2).set(title=gTitle)\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set_titles('Number of classes')\n",
    "\n",
    "# Retrieve the axes object from the plot\n",
    "axes = g.ax\n",
    "\n",
    "# Iterate over each bar in the plot\n",
    "for p in axes.patches:\n",
    "    # Get the coordinates of the bar\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    cord_x, cord_y = p.get_xy()\n",
    "    if height > 0:\n",
    "        axes.annotate(f'{height}', (cord_x + width/2, cord_y + height), ha='center')\n",
    "        \n",
    "g._legend.remove()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in np.unique(DB_from_pkl['Fold']):\n",
    "    print(f\"Validation fold: {fold}\")\n",
    "    \n",
    "    valsize = len(DB_from_pkl[DB_from_pkl['Fold'] == fold])\n",
    "    trnsize = len(DB_from_pkl[DB_from_pkl['Fold'] != fold])\n",
    "    print(f'dbComplete_VAL size: {valsize}')\n",
    "    print(f'dbComplete_TRN size: {trnsize}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl['Class_OHEV'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DB_from_pkl['Fold'].shape)\n",
    "print(DB_from_pkl['Class_OHEV'][0].shape)\n",
    "print(DB_from_pkl['features'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(DB_from_pkl['Fold'][0][0]))\n",
    "print(type(DB_from_pkl['Class_OHEV'][0][0]))\n",
    "print(type(DB_from_pkl['features'][0][0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the class and get one random sample of each class\n",
    "k = DB_from_pkl.groupby('Class_categorical')['Class_OHEV'].apply(lambda s: s.sample(1))\n",
    "print(k)\n",
    "\n",
    "# Convert the pandas series into a dataframe\n",
    "temp_k_df = k.reset_index()\n",
    "\n",
    "# Delete the index from the grouppby result\n",
    "del temp_k_df['level_1']\n",
    "\n",
    "# Set the \"Class\" as the dataframe index\n",
    "temp_k_df.set_index(\"Class_categorical\", inplace=True)\n",
    "\n",
    "# Convert the dataframe to a dictionary (Class: Class_encoder)\n",
    "encoder_dict = temp_k_df[\"Class_OHEV\"].to_dict()\n",
    "encoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes in the dataset\n",
    "\n",
    "num_classes = len(encoder_dict.keys())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the classes\n",
    "\n",
    "nom_classes = list(encoder_dict.keys())\n",
    "nom_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate 1 fold for validation and create a DB for the training / testing\n",
    "\n",
    "DB_from_pkl_VAL = DB_from_pkl[DB_from_pkl['Fold'] == fold].copy()\n",
    "DB_from_pkl_TRN = DB_from_pkl[DB_from_pkl['Fold'] != fold].copy()\n",
    "\n",
    "X      = DB_from_pkl_TRN['features'].to_numpy()\n",
    "y      = np.array(DB_from_pkl_TRN.Class_categorical.to_list())\n",
    "y_OHEV = np.array(DB_from_pkl_TRN.Class_OHEV.to_list())\n",
    "\n",
    "X_val      = DB_from_pkl_VAL['features'].to_numpy()\n",
    "y_val      = np.array(DB_from_pkl_VAL.Class_categorical.to_list())\n",
    "y_OHEV_val = np.array(DB_from_pkl_VAL.Class_OHEV.to_list())\n",
    "\n",
    "\n",
    "# Stackup and pass all values to float32\n",
    "X = np.stack(X)\n",
    "X = np.asarray(X).astype(np.float32)\n",
    "\n",
    "X_val = np.stack(X_val)\n",
    "X_val = np.asarray(X_val).astype(np.float32)\n",
    "\n",
    "y_OHEV     = np.asarray(y_OHEV).astype(np.float32)\n",
    "y_OHEV_val = np.asarray(y_OHEV_val).astype(np.float32)\n",
    "\n",
    "\n",
    "# Retrieve the indexes used for training the classifiers\n",
    "idx_trn = np.genfromtxt(os.path.join(path_models, '_idx_trn_' + nom_dataset + model_surname + '.csv'), delimiter=',', dtype = int)\n",
    "idx_tst = np.genfromtxt(os.path.join(path_models, '_idx_tst_' + nom_dataset + model_surname + '.csv'), delimiter=',', dtype = int)\n",
    "\n",
    "X_train      = X[idx_trn]\n",
    "X_test       = X[idx_tst]\n",
    "y_train      = y[idx_trn]\n",
    "y_test       = y[idx_tst]\n",
    "y_train_OHEV = y_OHEV[idx_trn]\n",
    "y_test_OHEV  = y_OHEV[idx_tst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n==================================\")\n",
    "print(\"Training set\\n\")\n",
    "\n",
    "print(f'X_train.........: {np.shape(X_train)}')\n",
    "print(f'y_train.........: {np.shape(y_train)}')\n",
    "print(f'y_train_OHEV....: {np.shape(y_train_OHEV)}')\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Testing set\\n\")\n",
    "\n",
    "print(f'X_test..........: {np.shape(X_test)}')\n",
    "print(f'y_test..........: {np.shape(y_test)}')\n",
    "print(f'y_test_OHEV.....: {np.shape(y_test_OHEV)}')\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Validation set\\n\")\n",
    "\n",
    "print(f'X_val...........: {np.shape(X_val)}')\n",
    "print(f'y_val...........: {np.shape(y_val)}')\n",
    "print(f'y_OHEV_val......: {np.shape(y_OHEV_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple confusion matrix\n",
    "\n",
    "def simple_conf_matrix(y_true, y_pred, nom_classes, clf, acc):\n",
    "    \n",
    "    picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "    conf_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "    title = nom_dataset + model_surname + norm_type + ' - Classifier ' + clf + ' - Validation accuracy: '+ str(\"{:0.2f} %\".format(acc*100))\n",
    "\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sns.heatmap(conf_matrix, \n",
    "                annot=True, \n",
    "                fmt='g', \n",
    "                cmap=cmap_cm, \n",
    "                annot_kws={\"size\": 8}, \n",
    "                xticklabels=nom_classes, \n",
    "                yticklabels=nom_classes)\n",
    "    plt.title(title, fontsize = 12)\n",
    "    plt.savefig(os.path.join(path_pic, picture_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title, cmap, normalize):\n",
    "\n",
    "    if labels is not None:\n",
    "        tick_marks = np.arange(len(labels))\n",
    "        plt.xticks(tick_marks, labels, fontsize=10, rotation=45)\n",
    "        plt.yticks(tick_marks, labels, fontsize=10)\n",
    "   \n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 8)\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 8)\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title, fontsize=13)\n",
    "    plt.colorbar(shrink=1)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(None)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G41d4lWCSIXW"
   },
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Convolutional Neural Networks** (CNNs) are a class of deep learning algorithms specifically designed for processing grid-like data, such as images and videos. CNNs are highly effective in tasks related to computer vision, including image recognition, object detection, and image segmentation. They are characterized by their ability to automatically and adaptively learn spatial hierarchies of features from input data. CNNs consist of multiple layers, including convolutional layers, pooling layers, and fully connected layers. The convolutional layers apply convolution operations to the input data, enabling the network to automatically learn patterns and features from images, such as edges, textures, and more complex structures. The pooling layers downsample the spatial dimensions of the data, reducing computational complexity while retaining important features. Fully connected layers at the end of the network process the learned features and make predictions based on them. One of the significant advantages of CNNs is their ability to capture local patterns and spatial hierarchies of features. By using shared weights and biases in the convolutional layers, CNNs are capable of learning translation-invariant features, making them well-suited for tasks where the spatial arrangement of features in the input data is essential. Additionally, CNNs can automatically learn relevant features from raw pixel values, eliminating the need for manual feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputShape = X_train[0].shape\n",
    "inputShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjU1o2LPQ8Qi"
   },
   "outputs": [],
   "source": [
    "# Architecture based on Su et al. (2019)\n",
    "\n",
    "def basemodel_Su(model_name):\n",
    "       \n",
    "    model = Sequential(name = model_name)\n",
    "    \n",
    "    # Input is 44 x 180\n",
    "    # If we have N x N image size and F x F filter size, afer the convolution the result will be\n",
    "    # (N x N) * (F x F) = (N - F + 1) x (N - F + 1)\n",
    "    # (44 - 7 + 1) x (180 - 7 + 1) = (38 x 174)\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(inputShape), padding='same', strides=(2,2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), strides=(2,2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten(name='Flatten'))\n",
    "\n",
    "    model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    epochs  = 100\n",
    "    lrate   = 0.001\n",
    "    decay   = lrate/epochs\n",
    "    sgd     = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture based on Luz et al. (2021)\n",
    "\n",
    "def basemodel_Luz(model_name):\n",
    "       \n",
    "    model = Sequential(name = model_name)\n",
    "    \n",
    "    model.add(Conv2D(24, (5, 5), input_shape=(inputShape), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(48, (5, 5), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(48, (5, 5), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(48, (5, 5), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten(name='Flatten'))\n",
    "\n",
    "    model.add(Dense(64, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    epochs  = 100\n",
    "    lrate   = 0.001\n",
    "    decay   = lrate/epochs\n",
    "    sgd     = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-kw6vXfvbsx"
   },
   "outputs": [],
   "source": [
    "monitor = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=30, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "if not os.path.exists(path_models):\n",
    "    os.makedirs(path_models)\n",
    "\n",
    "filepath       = os.path.join(path_models, 'Model_CNN_2D_weights_0_best' + model_surname + '.hdf5')\n",
    "checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint, monitor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "lw99-PBBaMkh",
    "outputId": "ff226441-ccbe-4ee2-8392-728db38108c2"
   },
   "outputs": [],
   "source": [
    "# Select the model\n",
    "\n",
    "opc = 0\n",
    "while str(opc) not in '12':\n",
    "    print()\n",
    "    print(\"1-) Architecture based on Su et al. (2019)\")\n",
    "    print(\"2-) Architecture based on Luz et al. (2021)\")\n",
    "\n",
    "    opc = input(\"\\nSelect the model: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "\n",
    "if opc == 1:\n",
    "    basemodel = basemodel_Su\n",
    "    surName = '_Su'\n",
    "\n",
    "elif opc == 2:\n",
    "    basemodel = basemodel_Luz\n",
    "    surName = '_Luz'\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n",
    "Model_CNN_2D = basemodel('Model_CNN_2D' + surName)\n",
    "print(Model_CNN_2D.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(Model_CNN_2D, to_file= os.path.join(path_models, 'Model_CNN_2D' + model_surname + '.png'), show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the column \"Param\":\n",
    "\n",
    "1. For `Conv1D` layer:\n",
    "   - The number of parameters for a `Conv1D` layer is calculated as `(kernel_size * input_channels + 1) * output_channels`, where `kernel_size` is the size of the convolutional kernel, `input_channels` is the number of input channels (1 in this case), and `output_channels` is the number of output channels.\n",
    "\n",
    "2. For `Dense` layer:\n",
    "   - The number of parameters for a `Dense` layer is calculated as `(input_units + 1) * output_units`, where `input_units` is the number of input units and `output_units` is the number of output units.\n",
    "   \n",
    "3. In the calculation of parameters for a convolutional layer, the term \"channels\" refers to the number of filters used in that layer.\n",
    "4. Params = (filter_height * filter_width * input_channels + 1) * number_of_filters\n",
    "\n",
    "\n",
    "- 624   parameters is the result of 24 filters * (5 kernels * 5 kernels * 1 channel + 1)\n",
    "- 28,848 parameters is the result of 48 filter * (5 kernels * 5 kernels * 24 channels + 1)\n",
    "- 57,648 parameters is the result of 48 filter * (5 kernels * 5 kernels * 48 channels + 1)\n",
    "- 57,648 parameters is the result of 48 filter * (5 kernels * 5 kernels * 48 channels + 1)\n",
    "- 67,648  parameters is the result of 64 neurons with 1,056 features + 64 bias values\n",
    "- 8,320  parameters is the result of 128 neurons with 64 features + 128 bias values\n",
    "- 645  parameters is the result of 5 neurons with 128 features + 5 bias values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cx0OsC7UNwui"
   },
   "source": [
    "### CNN 2D adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n========================================================================\")\n",
    "print(\"Training set\\n\")\n",
    "\n",
    "print(f'X_train.........: {np.shape(X_train)} ...type: {type(X_train[0][0][0][0])}')\n",
    "print(f'y_train_OHEV....: {np.shape(y_train_OHEV)} ............type: {type(y_train_OHEV[0][0])}')\n",
    "\n",
    "print(\"\\n========================================================================\")\n",
    "print(\"Testing set\\n\")\n",
    "\n",
    "print(f'X_test..........: {np.shape(X_test)} ....type: {type(X_test[0][0][0][0])}')\n",
    "print(f'y_test_OHEV.....: {np.shape(y_test_OHEV)} .............type: {type(y_test_OHEV[0][0])}')\n",
    "\n",
    "print(\"\\n========================================================================\")\n",
    "print(\"Validation set\\n\")\n",
    "\n",
    "print(f'X_val...........: {np.shape(X_val)} ....type: {type(X_val[0][0][0][0])}')\n",
    "print(f'y_OHEV_val......: {np.shape(y_OHEV_val)} .............type: {type(y_OHEV_val[0][0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs     = 100\n",
    "history    = Model_CNN_2D.fit(X_train, y_train_OHEV,\n",
    "                              batch_size      = batch_size,\n",
    "                              epochs          = epochs,\n",
    "                              verbose         = 1,\n",
    "                              validation_data = (X_test, y_test_OHEV),\n",
    "                              steps_per_epoch=int(np.ceil(X_train.shape[0] / float(batch_size))),\n",
    "                              callbacks       = callbacks_list,\n",
    "                              use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_CNN_2D = Model_CNN_2D.evaluate(X_val, y_OHEV_val, verbose=1, batch_size = batch_size)\n",
    "print('Test loss:', score_CNN_2D[0])\n",
    "print('Test accuracy:', score_CNN_2D[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "fig.suptitle('CNN 2D - Training / Validation loss and accuracy')\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)\n",
    "fig.tight_layout()\n",
    "plt.savefig(os.path.join(path_pic, picture_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file (not the best model though)\n",
    "\n",
    "# Model_CNN_2D.save(path_models + \"Model_CNN_2D.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_CNN_2d = np.argmax(Model_CNN_2D.predict(X_val),axis=1)\n",
    "y_pred_CNN_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_enc = np.argmax(y_OHEV_val, axis=1)\n",
    "y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_CNN_2D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set_CNN_2D = classification_report(y_test_enc, y_pred_CNN_2d, target_names=nom_classes)\n",
    "print(metrics_set_CNN_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with the highest accuracy\n",
    "\n",
    "Model_CNN_2D_saved = load_model(os.path.join(path_models, 'Model_CNN_2D_weights_0_best' + model_surname + '.hdf5'))\n",
    "Model_CNN_2D_saved.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_CNN_2D_saved = Model_CNN_2D_saved.evaluate(X_val, y_OHEV_val, verbose=1, batch_size = batch_size)\n",
    "print('Test loss:', score_CNN_2D_saved[0])\n",
    "print('Test accuracy:', score_CNN_2D_saved[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_CNN_2D_saved = np.argmax(Model_CNN_2D_saved.predict(X_val),axis=1)\n",
    "y_pred_CNN_2D_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.round(Model_CNN_2D_saved.predict(X_val)[7],6)\n",
    "for i in prob:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set_CNN_2D_saved = classification_report(y_test_enc, y_pred_CNN_2D_saved, target_names=nom_classes)\n",
    "print(metrics_set_CNN_2D_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple confusion matrix\n",
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "conf_matrix = metrics.confusion_matrix(y_test_enc, y_pred_CNN_2D_saved)\n",
    "title = nom_dataset + model_surname + ' - Classifier CNN 2D (best model) - Highest accuracy test: '+ str(\"{:0.2f}%\".format(score_CNN_2D_saved[1]*100))\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True, \n",
    "            fmt='g', \n",
    "            cmap=cmap_cm, \n",
    "            annot_kws={\"size\": 8}, \n",
    "            xticklabels=nom_classes, \n",
    "            yticklabels=nom_classes)\n",
    "plt.title(title, fontsize = 12)\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_CNN_2D_saved.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in Model_CNN_2D_saved.layers:\n",
    "    print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 13652
    },
    "colab_type": "code",
    "id": "fIDuoBKNFu9Q",
    "outputId": "5329416e-8b59-4453-ac94-c4dd6247960f"
   },
   "source": [
    "## Metrics for the classifiers\n",
    "\n",
    "\n",
    "1. Accuracy: Accuracy is a measure of how many correct predictions a model makes overall, i.e., the ratio of correct predictions to the total number of predictions. It's a commonly used metric for evaluating models, but it may not be suitable in certain situations.\n",
    "\n",
    "2. Precision: Precision measures the ratio of true positives (correctly predicted positive instances) to all instances predicted as positive. It focuses on the accuracy of positive predictions.\n",
    "\n",
    "3. Recall: Recall, also known as sensitivity or true positive rate, measures the ratio of true positives to all actual positive instances. It focuses on how well a model captures all the positive instances.\n",
    "\n",
    "4. F1 Score: The F1 score is the harmonic mean of precision and recall. It provides a balanced measure that takes into account both false positives and false negatives. The F1 score is especially useful when you want to strike a balance between precision and recall.\n",
    "\n",
    "\n",
    "The F1 score is a metric that combines precision and recall, and it is particularly useful in situations where class imbalance or unequal misclassification costs are present. In such contexts, the F1 score can be more informative and meaningful than accuracy.\n",
    "\n",
    "A context where considering the F1 score makes more sense than accuracy:\n",
    "\n",
    "**Medical Diagnosis:**\n",
    "\n",
    "Imagine you're developing a model to diagnose a rare disease, and only 5% of the population has this disease. In this case, you have a significant class imbalance, where the majority of cases are negative (non-disease) and only a small fraction are positive (disease). If you were to use accuracy as the evaluation metric, the model could achieve a high accuracy by simply predicting \"negative\" for every case, because it would be correct 95% of the time due to the class imbalance. However, this would be entirely useless for detecting the actual disease.\n",
    "\n",
    "In this scenario, you'd be more interested in the F1 score. The F1 score considers both precision and recall, helping you find a balance between correctly identifying the disease (high recall) and not making too many false positive predictions (high precision). A high F1 score in this context indicates that your model is effective at correctly identifying the disease while minimizing false alarms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['Model_CNN_2D_Su', 'Model_CNN_2D_Luz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to run the classifiers and their metrics\n",
    "\n",
    "def model_classifiers(classifiers:list, db: pd.DataFrame):\n",
    "    \n",
    "    # Clear the session to start a new training\n",
    "    K.clear_session()\n",
    "                      \n",
    "    monitor = EarlyStopping(monitor='val_accuracy', \n",
    "                        min_delta = 0.0001, \n",
    "                        patience = 30, \n",
    "                        verbose = 1, \n",
    "                        mode = 'auto', \n",
    "                        restore_best_weights = True)\n",
    "                      \n",
    "    count       = 1\n",
    "    verbose     = True\n",
    "    models      = []\n",
    "    acc_set     = pd.DataFrame(index=None, columns=['Model',\n",
    "                                                    'Fold',\n",
    "                                                    'Accuracy(Train)',\n",
    "                                                    'Accuracy(Val)',\n",
    "                                                    'F1(Train)',\n",
    "                                                    'F1(Val)', \n",
    "                                                    'Precision(Train)',\n",
    "                                                    'Precision(Val)', \n",
    "                                                    'Recall(Train)',\n",
    "                                                    'Recall(Val)', \n",
    "                                                    'Conf_M',\n",
    "                                                    'Process_time',                                                     \n",
    "                                                    'Class_report(Val)'])\n",
    "                      \n",
    "    for fold in np.unique(db['Fold']):\n",
    "        print(f\"\\nValidation fold: {fold}\")\n",
    "\n",
    "        DB_VAL = db[db['Fold'] == fold]\n",
    "        DB_TRN = db[db['Fold'] != fold]\n",
    "\n",
    "        X      = DB_TRN['features'].to_numpy()\n",
    "        y      = np.array(DB_TRN.Class_categorical.to_list())\n",
    "        y_OHEV = np.array(DB_TRN.Class_OHEV.to_list())\n",
    "\n",
    "        X_val      = DB_VAL['features'].to_numpy()\n",
    "        y_val      = np.array(DB_VAL.Class_categorical.to_list())\n",
    "        y_OHEV_val = np.array(DB_VAL.Class_OHEV.to_list())\n",
    "\n",
    "\n",
    "        # Stackup and pass all values to float32\n",
    "        X = np.stack(X)\n",
    "        X = np.asarray(X).astype(np.float32)\n",
    "\n",
    "        X_val = np.stack(X_val)\n",
    "        X_val = np.asarray(X_val).astype(np.float32)\n",
    "\n",
    "        y_OHEV     = np.asarray(y_OHEV).astype(np.float32)\n",
    "        y_OHEV_val = np.asarray(y_OHEV_val).astype(np.float32)\n",
    "\n",
    "        X_train_final, X_test, y_train_final, y_test = train_test_split(X,\n",
    "                                                                        y_OHEV, \n",
    "                                                                        test_size = 0.1, \n",
    "                                                                        random_state = 100, \n",
    "                                                                        stratify = y_OHEV)\n",
    "        \n",
    "        print(\"\\n========================================================================\")\n",
    "        print(\"Training set\\n\")\n",
    "\n",
    "        print(f'X_train.........: {np.shape(X_train_final)} ...type: {type(X_train_final[0][0][0][0])}')\n",
    "        print(f'y_train_OHEV....: {np.shape(y_train_final)} ............type: {type(y_train_final[0][0])}')\n",
    "\n",
    "        print(\"\\n========================================================================\")\n",
    "        print(\"Testing set\\n\")\n",
    "\n",
    "        print(f'X_test..........: {np.shape(X_test)} ....type: {type(X_test[0][0][0][0])}')\n",
    "        print(f'y_test_OHEV.....: {np.shape(y_test)} .............type: {type(y_test[0][0])}')\n",
    "\n",
    "        print(\"\\n========================================================================\")\n",
    "        print(\"Validation set\\n\")\n",
    "\n",
    "        print(f'X_val...........: {np.shape(X_val)} ....type: {type(X_val[0][0][0][0])}')\n",
    "        print(f'y_OHEV_val......: {np.shape(y_OHEV_val)} .............type: {type(y_OHEV_val[0][0])}')\n",
    "        print()\n",
    "\n",
    "        \n",
    "        for i in tqdm(range(len(classifiers))):\n",
    "            \n",
    "            name         = classifiers[i]\n",
    "            model_name   = (classifiers[i] + '_' + str(count))\n",
    "            count        = count + 1\n",
    "            \n",
    "            if not os.path.exists(path_models):\n",
    "                os.makedirs(path_models)\n",
    "\n",
    "            filepath       = os.path.join(path_models, classifiers[i] + '_weights_0_best' + model_surname + '.hdf5')\n",
    "            checkpoint     = ModelCheckpoint(filepath, \n",
    "                                             monitor = 'val_accuracy', \n",
    "                                             verbose = 1, \n",
    "                                             save_best_only = True, \n",
    "                                             mode = 'max')\n",
    "            callbacks_list = [checkpoint, monitor]\n",
    "\n",
    "            if classifiers[i] == 'Model_CNN_2D_Su':\n",
    "                model = basemodel_Su(classifiers[i])\n",
    "                model.summary()\n",
    "                print(model_name)\n",
    "            \n",
    "            elif classifiers[i] == 'Model_CNN_2D_Luz':\n",
    "                model = basemodel_Luz(classifiers[i])\n",
    "                model.summary()\n",
    "                print(model_name)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "            model.fit(X_train_final, \n",
    "                      y_train_final,\n",
    "                      batch_size          = batch_size,\n",
    "                      epochs              = epochs,\n",
    "                      verbose             = 1,\n",
    "                      validation_data     = (X_test, y_test),\n",
    "                      steps_per_epoch     = int(np.ceil(X_train_final.shape[0] / float(batch_size))),\n",
    "                      callbacks           = callbacks_list,\n",
    "                      use_multiprocessing = True)\n",
    "                      \n",
    "            # Get the model predictions\n",
    "            y_train_enc = np.argmax(y_train_final, axis=1)\n",
    "            y_val_enc   = np.argmax(y_OHEV_val, axis=1)\n",
    "\n",
    "            y_train_predicted = np.argmax(model.predict(X_train_final), axis=1)\n",
    "\n",
    "            t_srt             = time.process_time_ns()\n",
    "            y_val_predicted   = np.argmax(model.predict(X_val), axis=1)\n",
    "            t_end             = time.process_time_ns()\n",
    "            proc_time         = ((t_end - t_srt) / 1000000)   \n",
    "            \n",
    "            # Compute the classifier metrics\n",
    "            accuracy_train = metrics.accuracy_score(y_train_enc, y_train_predicted)\n",
    "            accuracy_val   = metrics.accuracy_score(y_val_enc,  y_val_predicted)\n",
    "\n",
    "            f1_Score_train = metrics.f1_score(y_train_enc, y_train_predicted, average = 'weighted')\n",
    "            f1_Score_val   = metrics.f1_score(y_val_enc,  y_val_predicted,  average = 'weighted')\n",
    "\n",
    "            precision_score_train = metrics.precision_score(y_train_enc, y_train_predicted, average = 'weighted')\n",
    "            precision_score_val   = metrics.precision_score(y_val_enc,  y_val_predicted,  average = 'weighted')\n",
    "\n",
    "            recall_score_train = metrics.recall_score(y_train_enc, y_train_predicted, average = 'weighted')\n",
    "            recall_score_val   = metrics.recall_score(y_val_enc,  y_val_predicted,  average = 'weighted')\n",
    "\n",
    "            class_report_val = classification_report(y_val_enc, y_val_predicted, target_names = nom_classes)\n",
    "            print(class_report_val)\n",
    "            \n",
    "            # Compute the confusion matrix\n",
    "            CM = metrics.confusion_matrix(y_val_enc, y_val_predicted)\n",
    "            y_val_enc       = []\n",
    "            y_val_predicted = []\n",
    "\n",
    "            # Store the name, test accuracy results and model\n",
    "            models.append((name, accuracy_val, model))\n",
    "            \n",
    "            K.clear_session()\n",
    "            del model\n",
    "                    \n",
    "            acc_set = pd.concat([acc_set, pd.DataFrame({'Model': [name],\n",
    "                                                        'Fold': [fold],\n",
    "                                                        'Accuracy(Train)': [accuracy_train],\n",
    "                                                        'Accuracy(Val)': [accuracy_val],\n",
    "                                                        'F1(Train)': [f1_Score_train],\n",
    "                                                        'F1(Val)': [f1_Score_val],\n",
    "                                                        'Precision(Train)': [precision_score_train],\n",
    "                                                        'Precision(Val)': [precision_score_val],\n",
    "                                                        'Recall(Train)': [recall_score_train],\n",
    "                                                        'Recall(Val)': [recall_score_val],\n",
    "                                                        'Conf_M': [CM],\n",
    "                                                        'Process_time': [proc_time],\n",
    "                                                        'Class_report(Val)': class_report_val})], ignore_index = True)\n",
    "                   \n",
    "    return acc_set, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set, models_set  = model_classifiers(classifiers, DB_from_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Model and Accuracy test. Reset the index.\n",
    "\n",
    "metrics_set = metrics_set.sort_values(['Model', 'Accuracy(Val)'], ascending = [True, True]).reset_index()\n",
    "metrics_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set[['Model', 'Accuracy(Val)']].style.background_gradient(cmap = cmap_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_accuracy = metrics_set.groupby('Model')['Accuracy(Val)'].max()\n",
    "highest_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dictionary of each classifier and its data explanation\n",
    "\n",
    "unique_models = []\n",
    "results       = {}\n",
    "\n",
    "for c in classifiers:\n",
    "    unique_models.append(c)\n",
    "\n",
    "for model in unique_models:\n",
    "    result = metrics_set[metrics_set['Model'] == model].describe().round(4)\n",
    "    results[model] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in results.keys():\n",
    "    print(f'Model...: {model}')\n",
    "    display(results[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set_no_cm = metrics_set.drop(['Conf_M', 'Class_report(Val)'], axis=1)\n",
    "metrics_set_no_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set_name       = nom_dataset + '_metrics_set_CNN_2D' +  model_surname + '.pkl'\n",
    "metrics_set_name_no_cm = nom_dataset + '_metrics_set_CNN_2D' +  model_surname + '_no_cm.csv'\n",
    "\n",
    "print(metrics_set_name)\n",
    "print(metrics_set_name_no_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes de results to a PKL and CSV file\n",
    "\n",
    "with open(os.path.join(path_models, metrics_set_name), 'wb') as file:\n",
    "    pickle.dump(metrics_set, file)\n",
    "    \n",
    "metrics_set_no_cm.to_csv(os.path.join(path_models, metrics_set_name_no_cm), sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_set_from_pkl = pd.read_pickle(os.path.join(path_models, metrics_set_name))\n",
    "metrics_set_from_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = metrics_set.groupby('Model')['Accuracy(Val)'].idxmax()\n",
    "conf_matrices = metrics_set.loc[idx, ['Model','Accuracy(Val)','Conf_M']]\n",
    "conf_matrices.set_index('Model', inplace=True)\n",
    "conf_matrices_dict = conf_matrices.to_dict('index')\n",
    "conf_matrices_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrices_dict['Model_CNN_2D_Su']['Conf_M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, idx in zip(conf_matrices_dict.keys(), range(1, len(conf_matrices_dict) + 1)):\n",
    "    print(idx)\n",
    "    print(i)\n",
    "    print(conf_matrices_dict[i]['Accuracy(Val)'])\n",
    "    print(conf_matrices_dict[i]['Conf_M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix for the highest accuracy test classifiers\n",
    "\n",
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.suptitle(nom_dataset + model_surname + ' - Confusion matrices of the best results for each classifier', fontsize = 16,  y=0.99)\n",
    "for i, idx in zip(conf_matrices_dict.keys(), range(1, len(conf_matrices_dict) + 1)):\n",
    "    title = 'Classifier '+ i + ' (Highest accuracy validation of the best models: ' + str(\"{:0.4f}\".format(conf_matrices_dict[i]['Accuracy(Val)'])) +')'\n",
    "    plt.subplot(1,2,idx)\n",
    "    plot_confusion_matrix(conf_matrices_dict[i]['Conf_M'],  \n",
    "                          nom_classes, \n",
    "                          title,\n",
    "                          cmap = None,                          \n",
    "                          normalize = False)\n",
    "\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.suptitle(f'{nom_dataset} - Box plot each classifier (batch type: {model_surname})', fontsize = 16,  y=0.97)\n",
    "box_plot = sns.boxplot(data=metrics_set, x=\"Model\", y=\"Accuracy(Val)\", showfliers = True)\n",
    "\n",
    "medians = list(metrics_set.groupby(['Model'])['Accuracy(Val)'].median())\n",
    "medians = [round(element, 2) for element in medians]\n",
    "\n",
    "vertical_offset = metrics_set['Accuracy(Val)'].median()*0.0001  # offset from median for display\n",
    "\n",
    "for xtick in box_plot.get_xticks():\n",
    "    box_plot.text(xtick, medians[xtick] + vertical_offset, medians[xtick], \n",
    "            horizontalalignment='center',size='medium',color='w',weight='semibold')\n",
    "plt.savefig(os.path.join(path_pic, picture_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mark3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
