{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-1PkcG8ARink"
   },
   "source": [
    "### Faculdade de Engenharia Industrial - FEI\n",
    "\n",
    "### Centro Universitário da Fundação Educacional Inaciana \"Padre Sabóia de Medeiros\" (FEI)\n",
    "\n",
    "\n",
    "*FEI's Stricto Sensu Graduate Program in Electrical Engineering*\n",
    "\n",
    "Concentration area: ARTIFICIAL INTELLIGENCE APPLIED TO AUTOMATION AND ROBOTICS\n",
    "\n",
    "Master's thesis student Andre Luiz Florentino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')\n",
      "------------------------------------------------------------------------------------------\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "<function is_built_with_cuda at 0x00000141347E00D0>\n",
      "/device:GPU:0\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "pd = tf.config.experimental.list_physical_devices()\n",
    "for i in pd:\n",
    "    print(i)\n",
    "print('------------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
    "\n",
    "print(tf.test.is_built_with_cuda)\n",
    "# <function is_built_with_cuda at 0x000001AA24AFEC10>\n",
    "\n",
    "print(tf.test.gpu_device_name())\n",
    "# /device:GPU:0\n",
    "\n",
    "#gvd = tf.config.get_visible_devices()\n",
    "for j in tf.config.get_visible_devices():\n",
    "    print(j)\n",
    "# PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
    "# PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
    "\n",
    "#physical_devices = tf.config.experimental.list_physical_devices()\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[2], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: Convolutional Neural Network (2D)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The paper entitled \"ESC-ConvNet: Environmental Sound Classification with Convolutional Neural Networks\" (PICZAK, 2015) serves as the foundation for the following analysis. In this study, the author employs Convolutional Neural Networks (CNNs) for image classification, utilizing fixed dimension images that consist of multiple channels (such as RGB for color images). The network undergoes various stages of convolution, pooling, and fully connected layers, ultimately outputting class probabilities for the given image. With the aim to replicate this approach using sound clips, the utilization of log-scaled mel-spectrograms and their respective deltas from each sound clip is proposed instead of directly using the sound file as an amplitude vs. time signal. In order to address the requirement of fixed size input, the sound clips are segmented into 60x41 segments (60 bands and 44 frames - windowing techinique). The log-scaled mel-spectrograms are extracted from all the recordings, which were resampled to 22050 Hz and normalized with a window size of 1024, a hop length of 512, and 60 mel-bands.\n",
    "\n",
    "- The human auditory system perceives sound on a logarithmic scale, rendering it difficult to distinguish closely-scaled frequencies. This effect becomes more pronounced with increasing frequency. Therefore, only the power within different frequency bands is considered. As a result, the mel-spectrograms and their corresponding deltas are transformed into two channels that are subsequently inputted into the CNN for analysis.\n",
    "\n",
    "- During the iterative process of file exploration, it was noticed that each sound is 4, 5 or 10 seconds in duration and has in its duration (sometimes) silent periods. In order to achieve a more representative \"sound image\", for each sound, the \"extract_feature\" methods are utilized to trim the silent periods and duplicate the sound, effectively doubling its trimmed length (augmented audio). Subsequently, the aforementioned features, along with the class labels, are calculated and appended to arrays.\n",
    "\n",
    "- The final result transformed the audio file into a spectrogram image consisting of 60 bands, 44 frames, and 2 channels. After a few cross-validations, it was confirmed the accuracy has improved when the deltas are aggreated to the image instead of using them as channels, therefore, the final image dimension was 180 (60 mels, 60 delta 1 and 60 delta 2) x 44 frames. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "import itertools\n",
    "import mimetypes\n",
    "import time\n",
    "\n",
    "import pandas     as pd\n",
    "import seaborn    as sns\n",
    "import numpy      as np\n",
    "\n",
    "from matplotlib  import pyplot  as plt\n",
    "from keras       import backend as K\n",
    "\n",
    "from tqdm                        import tqdm\n",
    "\n",
    "from sklearn                     import metrics\n",
    "from sklearn.model_selection     import train_test_split\n",
    "from sklearn.metrics             import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow                  import keras\n",
    "from tensorflow.keras.models     import Sequential, load_model\n",
    "from tensorflow.keras.layers     import Dense, Dropout, Flatten, InputLayer, Conv2D\n",
    "from tensorflow.keras.layers     import MaxPooling2D, BatchNormalization, Activation\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks             import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers            import SGD\n",
    "from keras.constraints           import maxnorm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 12)\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "\n",
    "cmap_cm   = plt.cm.Blues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# For the picture names\n",
    "pic_first_name = '09_CNN_2D_'\n",
    "\n",
    "# For Librosa\n",
    "FRAME_SIZE  = 1024\n",
    "HOP_LENGTH  = 512\n",
    "SEED        = 1000\n",
    "SR          = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1-) ESC-10\n",
      "2-) BDLib2\n",
      "3-) US8K\n",
      "4-) US8K_AV\n",
      "\n",
      "Select the dataset: 4\n"
     ]
    }
   ],
   "source": [
    "# Select the dataset\n",
    "\n",
    "opcD = 0\n",
    "while str(opcD) not in '1234':\n",
    "    print()\n",
    "    print(\"1-) ESC-10\")\n",
    "    print(\"2-) BDLib2\")\n",
    "    print(\"3-) US8K\")\n",
    "    print(\"4-) US8K_AV\")\n",
    "\n",
    "    opcD = input(\"\\nSelect the dataset: \")\n",
    "    if opcD.isdigit():\n",
    "        opcD = int(opcD)\n",
    "    else:\n",
    "        opcD = 0\n",
    "\n",
    "if opcD == 1:\n",
    "\n",
    "    path        = os.path.join(current_path, \"_dataset\", \"ESC-10\")\n",
    "    path_pic    = os.path.join(current_path, \"ESC-10_results\")\n",
    "    path_models = os.path.join(current_path, \"ESC-10_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "   \n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'ESC-10' \n",
    "    csv_file    = 'ESC-10.csv'\n",
    "    fold        = 1\n",
    "    dog_set     = 'Dog bark'\n",
    "    \n",
    "    pkl_features_CNN_2D          = 'ESC-10_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'ESC-10_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'ESC-10_features_CNN_2D_augmented.pkl'\n",
    "    \n",
    "\n",
    "    \n",
    "if opcD == 2:\n",
    "    \n",
    "    path        = os.path.join(current_path, \"_dataset\", \"BDLib2\")\n",
    "    path_pic    = os.path.join(current_path, \"BDLib2_results\")\n",
    "    path_models = os.path.join(current_path, \"BDLib2_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "\n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'BDLib2' \n",
    "    csv_file    = 'BDLib2.csv'\n",
    "    fold        = 'fold-1'\n",
    "    dog_set     = 'dogs'\n",
    "    \n",
    "    pkl_features_CNN_2D          = 'BDLib2_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'BDLib2_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'BDLib2_features_CNN_2D_augmented.pkl'\n",
    "    \n",
    "    \n",
    "if opcD == 3:\n",
    "    \n",
    "    path        = os.path.join(current_path, \"_dataset\", \"US8K\")\n",
    "    path_pic    = os.path.join(current_path, \"US8K_results\")\n",
    "    path_models = os.path.join(current_path, \"US8K_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "        \n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'US8K' \n",
    "    csv_file    = 'US8K.csv'\n",
    "    fold        = '1'\n",
    "    dog_set     = 'dog_bark'\n",
    "\n",
    "    pkl_features_CNN_2D          = 'US8K_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'US8K_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'US8K_features_CNN_2D_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large\n",
    "    \n",
    "    \n",
    "if opcD == 4:\n",
    "\n",
    "    path        = os.path.join(current_path, \"_dataset\", \"US8K_AV\")\n",
    "    path_pic    = os.path.join(current_path, \"US8K_AV_results\")\n",
    "    path_models = os.path.join(current_path, \"US8K_AV_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "\n",
    "\n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'US8K_AV' \n",
    "    csv_file    = 'US8K_AV.csv'\n",
    "    fold        = '1'\n",
    "    dog_set     = 'dog_bark'\n",
    "    \n",
    "    pkl_features_CNN_2D          = 'US8K_AV_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'US8K_AV_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'US8K_AV_features_CNN_2D_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_file_number(folder: str):\n",
    "    files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) and f.startswith(pic_first_name)]\n",
    "    if not files:\n",
    "        return 1\n",
    "    else:\n",
    "        numbers = [int(f.split('.')[0].split('_')[-1]) for f in files]\n",
    "        return max(numbers) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MT_loadDataset import loadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes:\n",
      "--------------------\n",
      "Class_categorical\n",
      "dog_bark            1000\n",
      "children_playing    1000\n",
      "background          1000\n",
      "siren                929\n",
      "car_horn             429\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total number of unique files..........:  4358\n",
      "Total number of AUDIO files...........:  4358\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Folder_name</th>\n",
       "      <th>Class_OHEV</th>\n",
       "      <th>Class_categorical</th>\n",
       "      <th>File_name</th>\n",
       "      <th>Path</th>\n",
       "      <th>classID</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>fold5</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100032-3-0-0.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>fold5</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-117.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>fold5</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-121.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>fold5</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-126.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>fold5</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-137.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4353</th>\n",
       "      <td>7</td>\n",
       "      <td>fold7</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>car_horn</td>\n",
       "      <td>99812-1-2-0.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-2-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>99812</td>\n",
       "      <td>159.522205</td>\n",
       "      <td>163.522205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354</th>\n",
       "      <td>7</td>\n",
       "      <td>fold7</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>car_horn</td>\n",
       "      <td>99812-1-3-0.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-3-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>99812</td>\n",
       "      <td>181.142431</td>\n",
       "      <td>183.284976</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355</th>\n",
       "      <td>7</td>\n",
       "      <td>fold7</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>car_horn</td>\n",
       "      <td>99812-1-4-0.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-4-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>99812</td>\n",
       "      <td>242.691902</td>\n",
       "      <td>246.197885</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>7</td>\n",
       "      <td>fold7</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>car_horn</td>\n",
       "      <td>99812-1-5-0.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-5-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>99812</td>\n",
       "      <td>253.209850</td>\n",
       "      <td>255.741948</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357</th>\n",
       "      <td>7</td>\n",
       "      <td>fold7</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>car_horn</td>\n",
       "      <td>99812-1-6-0.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-6-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>99812</td>\n",
       "      <td>332.289233</td>\n",
       "      <td>334.821332</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4358 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fold Folder_name       Class_OHEV Class_categorical           File_name                                                                                                Path  classID    fsID       start         end  salience\n",
       "0        5       fold5  [0, 0, 0, 1, 0]          dog_bark    100032-3-0-0.wav    C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100032-3-0-0.wav        3  100032    0.000000    0.317551         1\n",
       "1        5       fold5  [0, 0, 1, 0, 0]  children_playing  100263-2-0-117.wav  C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-117.wav        2  100263   58.500000   62.500000         1\n",
       "2        5       fold5  [0, 0, 1, 0, 0]  children_playing  100263-2-0-121.wav  C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-121.wav        2  100263   60.500000   64.500000         1\n",
       "3        5       fold5  [0, 0, 1, 0, 0]  children_playing  100263-2-0-126.wav  C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-126.wav        2  100263   63.000000   67.000000         1\n",
       "4        5       fold5  [0, 0, 1, 0, 0]  children_playing  100263-2-0-137.wav  C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-137.wav        2  100263   68.500000   72.500000         1\n",
       "...    ...         ...              ...               ...                 ...                                                                                                 ...      ...     ...         ...         ...       ...\n",
       "4353     7       fold7  [0, 1, 0, 0, 0]          car_horn     99812-1-2-0.wav     C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-2-0.wav        1   99812  159.522205  163.522205         2\n",
       "4354     7       fold7  [0, 1, 0, 0, 0]          car_horn     99812-1-3-0.wav     C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-3-0.wav        1   99812  181.142431  183.284976         2\n",
       "4355     7       fold7  [0, 1, 0, 0, 0]          car_horn     99812-1-4-0.wav     C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-4-0.wav        1   99812  242.691902  246.197885         2\n",
       "4356     7       fold7  [0, 1, 0, 0, 0]          car_horn     99812-1-5-0.wav     C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-5-0.wav        1   99812  253.209850  255.741948         2\n",
       "4357     7       fold7  [0, 1, 0, 0, 0]          car_horn     99812-1-6-0.wav     C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-6-0.wav        1   99812  332.289233  334.821332         2\n",
       "\n",
       "[4358 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadDataset = loadDataset(path)\n",
    "DB          = loadDataset.db_B\n",
    "\n",
    "print(\"\\nClasses:\\n--------------------\")\n",
    "print(DB[\"Class_categorical\"].value_counts())\n",
    "print(\"\\nTotal number of unique files..........: \", len(np.unique(DB[\"File_name\"])))\n",
    "print(\"Total number of AUDIO files...........: \", len(DB))\n",
    "DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHQAAAHqCAYAAABlWBkiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABno0lEQVR4nO3deVhUZePG8XvYQVHADSRey33JBRdwy4XSyj3ELJfUNPe9TE0rS03N0txxN1PLXAtzNyu1ME1fLcvUckdRAUnZl/n9wc95ndxFOAx8P9fFpZxzhrnPzBzPcPs8Z0xms9ksAAAAAAAA2Aw7owMAAAAAAADgwVDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAJBFOnfurM6dO99xfVBQkEaMGGG17NixYxoyZIjq1aunJ598UvXr19fgwYP1+++/33L77du3Kzg4WP7+/mrSpIlmzpyp5ORky/q1a9eqXLlyOnfu3C23XbJkicqVK6dBgwYpJSXlofavY8eOKleunDZu3GhZlpCQoBo1aqhnz553vF10dLSefPJJTZ48+aHu94Zz586pXLlyCg4OVmpq6i3r9+7dq3Llymnv3r2Zup/7dbvnMye4ePGiOnXqpMqVK6tOnTpKSEh44J9xt9dSXjNkyBCVK1fulq9vvvnG6GgAgDzGwegAAAAgw/Hjx9W+fXtVqVJFo0aNUuHChXXx4kUtW7ZM7du312effaZq1apJkvbs2aP+/furWbNmev3113Xs2DFNmTJF0dHReuedd+56P59++qkmTJigli1batKkSbK3t3/grKdPn9b+/ftVtmxZff7552rWrJkkydXVVc2bN9eaNWsUHR0tLy+vW267YcMGpaSkqG3btg98v7dz5MgRzZ8/X3369HkkPy+3+fTTT3Xw4EFNnjxZxYoVk6urq9GRbNoff/yhVq1aqWPHjlbLS5QoYVAiAEBexQgdAAByiMWLF8vDw0MLFixQs2bNFBAQoFatWmnJkiXy8vLS7NmzLduuXbtWxYsX1+TJk1WvXj1169ZNXbp00ZdffnnXETdLly7VBx98oLZt2+rDDz98qDJHktasWSNvb2/17dtXP//8s/766y/LupCQEKWmplqN3LnZ+vXrVbNmTZUsWfKh7vvfChQooFmzZun48eOP5OflNlevXlXRokXVrFkz1ahRw+g4Ni0hIUGnT59W3bp1Va1aNasvT09Po+MBAPIYCh0AAHKIK1euSJLMZrPVcjc3N40cOVLPP/+8ZVlycrJcXV2tChlPT0+lpKQoLi7utj9/6dKlGj9+vDp06KDx48fLzu7h3gakpaVp/fr1atSokYKCguTu7q6VK1da1lepUkVly5ZVWFjYLbc9fvy4jhw5onbt2j3Ufd9Or169lD9/fo0YMUJpaWl33O5OU7D+PTUuKChIM2fO1IQJExQYGCh/f3+9/vrriouL07x589SgQQPVqFFDAwYMUExMjNXPSklJ0bhx41SrVi3VqlVLw4cPV3R0tNU2+/fvV6dOnVS1alUFBATcss3atWtVsWJFrVq1SvXr11eDBg3uWFZdu3ZNEyZM0DPPPKPKlSurRYsWWr16tdW+rF27VhERESpXrpxmzJhxx8dnz5496tixo/z9/VW/fn298847io2NveP2q1atUnBwsKpVq6YqVaqodevWViVeenq6pk2bpqCgID355JMKCgrSlClTrArHjRs3qlWrVqpSpYpq166tN954Q5cuXbrlfpo3b64nn3xSjRo10owZM6ym2EVHR+uNN95QvXr1VLlyZbVu3Vrr16+/Y25Jt50ydeMrKCjojrf7888/lZ6ergoVKtz15wMAkB2YcgUAQA7RqFEjff/993rppZfUtm1b1a5dWyVLlpTJZNJzzz1ntW3Hjh3Vo0cPLViwQC+++KL+/vtvffrpp2rYsKE8PDxu+dmfffaZxo8fr86dO2v06NGZyrl7925FRkbqhRdekLOzs5o1a6b169dr6NChcnFxkSS1bdtWEyZM0JkzZ/Sf//zHctt169Ypf/78evbZZzOV4WZeXl565513NGTIEC1YsEC9evXK9M9cvHix6tatq6lTp+rXX3/VlClTdOTIERUrVkxjx47VyZMn9eGHH6pw4cJ69913LbfbtGmTqlSpookTJyo6OlofffSRTp8+rS+++EKStG/fPnXr1k21a9fWJ598otjYWE2bNk2vvPKKVq9ebXn80tLSFBoaqnHjxik6OlqlS5e+JWNiYqI6dOigK1euaMCAAfLz89P27ds1atQoXblyRb1799bMmTP1ySef6Pfff9fMmTPl7e192/39/vvv1bt3bwUFBWnq1KmKjY3V5MmTdfr0aX366ae3bL98+XKNGzdO/fv31/Dhw3X16lXNnz9fw4YNU7Vq1VS8eHHNnz9fy5cv1/Dhw+Xn56dDhw5p6tSpcnR01IABA/TLL7/ojTfeUN++fVWrVi1dvHhRkydP1uuvv67PPvtMkjR37lxNnTpVnTp10siRI/XHH39oxowZunDhgj744ANJ0rBhwxQVFaX33ntP+fLl09dff63hw4fLx8dHgYGBt93fmwvIf3Nycrrjuj/++EOS9Pnnn2v79u2KjY1VlSpVNHz4cFWtWvWOtwMAICtQ6AAAkEN06NBBly9f1sKFC/X+++9Lyhh1U79+fXXu3NnqF8bAwEB1795dkydPtlxcuGLFivr4449v+bnLly/XokWLZDKZbhkt8jDWrFmjkiVLWq7nExISopUrV2rTpk164YUXJEmtWrXSRx99pK+//lr9+/eXlFFShIWFqUWLFo/8Oi7NmjXT5s2bNXPmTAUFBalMmTKZ+nn58uXT1KlT5eDgoLp162rdunW6dOmSVq1aJXd3dzVs2FDh4eE6cOCA1e0KFCigBQsWKH/+/JIynr9+/fpp9+7dql+/vj7++GM98cQTmjt3rmV0VdWqVS3XHbr5uiy9e/dWo0aN7phx7dq1OnbsmFasWGGZSvXUU08pNTVVs2fP1ksvvaSKFSvKy8tLTk5OlufrdqZPn67y5ctr1qxZlmUuLi6aMmWKIiMjb9n+7NmzevXVV9WvXz/Lsscee0zBwcE6cOCAihcvrp9//lmVKlWyXCspICBArq6ulsfml19+kbOzs1577TU5OztLkjw8PPTrr7/KbDbr+vXrmjNnjtq3b28pIevXry8PDw+NHj1a3bp1U5kyZfTzzz+rb9++euaZZyRlHBseHh53nU54t8fibm4UOklJSZoyZYquXr2qefPm6ZVXXtHKlStVvnz5h/q5AAA8DKZcAQBgIJPJZPX9oEGDtGvXLn388ccKCQlR/vz5FRYWpvbt21uNlHj33Xe1cOFC9enTx3JdnJiYGPXo0eOWTzFatGiRBg4cqF69eumbb77RqlWrHjpvTEyMvv32Wz3//PP6559/9M8//+jxxx/XE088YRmFImWMmgkKCrKadrVnzx5dunTpntOtUlNTrb7S09PvK9u7775rmZ52t6lX96NKlSpycPjf/3sVKVJEJUuWlLu7u2WZh4eHrl27ZnW7hg0bWgoLKWPKk6Ojo3788UclJCTo0KFDatiwocxms2X//Pz8VKpUKe3Zs8fqZ5UtW/auGX/++Wf5+vrecl2cVq1aKSkpSYcOHbqvfU1MTNSRI0cshcgNzz77rLZs2aJixYrdcpsRI0Zo2LBhunbtmn799VeFhYVp+fLlkmSZUhUYGKgff/xRHTp00OLFi/XXX3+pU6dOatOmjSSpVq1aSkxMVMuWLTV16lT98ssvql+/vvr37y+TyaSDBw8qISFBQUFBVq+HG1OibjxegYGBmjFjhgYNGqS1a9cqOjpaw4cPV82aNe+4z/9+jd38dbfXTteuXbVkyRJNnDhRgYGBevbZZ7V48WK5uroqNDT0vh5vAAAeFUboAACQRdzc3HT16tU7rr9xHZx/K1iwoFq0aKEWLVpIkn7//Xe9+eab+uijj9SqVSslJyfryy+/VK9evTR48GBJGb/UVq5cWS1bttSaNWvUqVMny88bNGiQ+vbtq5SUFO3atUvjx49X9erVVapUqQfep6+++kopKSmaNWuW1WiOG44ePWoZpRASEqLXXntNhw8fVpUqVfTVV1+pfPnyevLJJ+96H5UqVbL6vn///howYMA9sxUqVEhvv/22Xn/9dS1cuDBTU2BuLmVuuJ9RRYULF7b63s7OTh4eHpbyKz09XfPnz9f8+fNvue2NUSo3FCpU6K73FRsbe8v93Zzhn3/+uWfeGz/HbDbf8/5udubMGb3zzjsKDw+Xg4ODSpYsqXLlykn63zWgevTooXz58mnNmjWaNGmSJk6cqLJly+qtt95SnTp15O/vr3nz5mnJkiVauHChQkNDVaRIEb322mvq0qWL5djp2bPnbTPcuNbO1KlTFRoaqk2bNmnz5s2ys7NT3bp1NWbMGPn5+d32tv9+jd3M19dX33777W3XlSxZ8paLeRcoUEDVq1fX0aNH7/yAAQCQBSh0AADIIoULF9axY8duuy45OVnR0dGWX74jIyPVtm1bDRo06JYRLBUrVtTgwYPVr18/nT17VmlpaTKbzapevbrVdmXLlpWHh8ctF9Bt1aqVJMnR0VGTJ09WcHCwBg8erNWrV99SItzL2rVrVbVqVb3++utWyxMTE9WnTx99/vnneu+99yRlTI/x9vZWWFiYSpYsqe3bt2vYsGH3vI+bL+orSUWLFr3vfC1atNDmzZs1Y8YMjRgxwmrdjdFQ/x7xExcXp3z58t33fdzNv0uUtLQ0xcTEqFChQsqXL59MJpO6du2q5s2b33LbB52GVrBgQZ0+ffqW5ZcvX5ak+/7Upfz58992Ol5ycrJ++uknValSxWp5enq6evbsKUdHR3355ZeqWLGiHBwcdOLECX399deW7ezs7NSxY0d17NhRUVFR+v777xUaGqoBAwboxx9/lJOTk5566ik99dRTSkhIUHh4uGW0WbVq1VSgQAFJ0kcffaTHH3/8ltw3jh13d3cNGzZMw4YN099//60dO3Zo9uzZeu+997RgwYLb7vO/X2M3u9s1dL755ht5eHioXr16VsuTkpL4lCsAQLZjyhUAAFkkICBAEREROnz48C3rtm/frrS0NNWuXVtSxi+nDg4OWrFihZKSkm7Z/u+//5azs7NKlCihEiVKyN7eXr/88sst21y9elWPPfbYHTOVKlVKw4YN07FjxzRhwoQH2p9ff/1Vf/75p4KDgxUYGGj11bBhQ9WvX19hYWGWT9mys7PTCy+8oG3btunbb7+V2WxWy5Yt73k/lStXtvq63ZSfuxkzZozc3Nw0depUq+U3Rt1cuHDBsiw2NtbqI9cz68cff7T6BKYtW7YoNTVVgYGByp8/vypWrKi///7bav/KlCmjmTNn3vLpW/dSq1YtnT9//pbXwddffy1HR8dbipg7yZcvnypUqKAdO3ZYLd+9e7d69uypixcvWi2PiYnRyZMnFRISYjU17YcffpD0v8LspZde0rhx4yRljDYKDg5Wx44dde3aNV2/fl2TJk1SSEiIzGazXF1d1bhxYw0fPlxSxnNUtWpVOTo6KjIy0urxcnR01Mcff6xz587p/PnzatiwoTZv3iwpYwTNa6+9prp1696S+2b/fo3d/HVjpNHtrFixQmPGjFFycrJlWWRkpA4cOKCAgID7erwBAHhUGKEDAEAWadasmT799FO99tpr6tWrlypVqqT09HQdOHBACxYsUPPmzS2jbOzt7TVmzBj169dPbdu2VceOHVWqVCklJCRoz549Wr58uQYNGqSCBQtKkrp06aKFCxdKkurWrauIiAjNnDlTxYsX14svvnjXXJ06ddLOnTv1+eefq27dumratOl97c+aNWvk6Oh4x0+oatOmjb7//nuFhYXppZdekpTxaVehoaGaNWuWmjRpYsmflQoXLqxRo0bdMhqoXLly8vHx0cyZM+Xu7i47OzvNmzfvkV6g+cYnTnXu3FmnTp3SlClTVK9ePdWpU0eSNHToUPXs2VOvv/66WrVqpbS0NC1atEiHDh1Snz59Hui+goODtWLFCvXv318DBw6Un5+fvv32W61Zs0b9+/e3jHC5HwMHDlSfPn00ePBgBQcHKzo6Wh9//LEaN26sChUqWC4GLGWUM76+vlq+fLm8vb1VoEAB7d6923KNpxvXcKpVq5YWLVqkwoULy9/fX5GRkVq8eLECAgLk5eWlOnXqaPHixRoxYoRatWqllJQULViwQB4eHqpdu7Y8PDzUo0cPTZs2TdevX1dgYKAiIyM1bdo0mUwmlS9fXu7u7vL29ta4ceN0/fp1/ec//9Fvv/2m77///pF82tm/9evXT927d9eAAQPUsWNHxcbGaubMmSpQoIC6d+/+yO8PAIC7odABACCLODo6atmyZQoNDdWqVas0ffp02dnZqUSJEhoyZIjVdW6kjI8t//LLLy3XE4mOjpaTk5MqVqyoqVOnWhUvb775pooVK6YvvvhCixYtUtGiRVWvXj0NGTLkvkqTCRMmqGXLlho9erQqVaokX1/fu26flJSkb775RvXq1bvj1JJnnnlGBQoU0BdffGEpdPz8/BQYGKjw8HDLVKzs0KpVK23evNlq1Im9vb2mT5+uDz74QEOHDlXhwoXVpUsX/f333zp58uQjud8XX3xRiYmJ6tevn5ycnNSyZUsNGzbMMt2rfv36WrhwoWbOnKmBAwfK0dFRlSpV0uLFix/4k5dcXV312Wef6eOPP9b06dN1/fp1lSxZUuPHj1dISMgD/azGjRtr7ty5mjFjhvr16ydPT089//zzGjRo0G23nz17tsaPH68RI0bIyclJpUuX1pw5c/TBBx9o//796ty5swYNGiQnJyetWbNGs2bNkru7u4KCgizT9Ro0aKCPPvpIixYtslwIuUaNGlq6dKk8PDwkSYMHD1aRIkW0YsUKLViwQAULFlSdOnU0dOhQywWqZ86cqSlTpmjatGmKiYmRj4+P+vfvf8dr72RG3bp1tWDBAs2aNUtDhgyRnZ2d6tevr2HDhj1QgQYAwKNgMt+4ch0AAAAAAABsAiN0AADI425cZPlebv4YbwAAABiLEToAAORxnTt31s8//3zP7f78889sSAMAAID7QaEDAEAe9/fff1s+mepuKleunA1pAAAAcD8odAAAAAAAAGyMndEBAAAAAAAA8GAodAAAAAAAAGwMhQ4AAAAAAICN4fNHb+PKlWviykJ4WF5e+RQdfe+LiwK5FccA8jqOAYDjAOAYQGYVKeJ+z20YoQM8QiaTZG9vJ5PJ6CSAMTgGkNdxDAAcBwDHALILhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh3gHmJiYtS+fRsdOLDfsuzIkd/02mtd1KTJU2rXrpU2bFhvdZuNGzeoffs2euaZ+urevbN+++2wZV1aWppmzZqmli2bqkmTBhoxYqiuXLmSXbsDPDCOAQAA5wIAyHkodIC7OHz4v+rdu5vOnz9nWfbPP/9o2LBBeu655tq0aadGjHhb06dP1e+//yZJ2rt3r6ZOnaxRo8Zo8+bv1LTpcxoxYqgSExMlSZ9+ulA//xyuBQuWav36jXJ2dtakSWMN2T/gXjgGAACcCwAgZ6LQAe5g06YNeu+90erZs6/V8u+//1YFChRU27YvysHBQTVq1FLTps9p7dpVkqRVq1bpmWeaqkqVanJwcFD79h1VsKCHduzYKknasOErdezYRcWKeStfvvwaNOgNhYf/aPUmCcgJOAYAAJwLACDnotAB7iAgoLZWrlyvp59uarX85Mm/VKpUKatljz/+hE6cOC5JOnHihEqWvP3669ev69KlSJUqVdqyzsurkNzdC+ivv05k0Z4AD4djAADAuQAAci5DC53o6Gg1adJEe/futSw7dOiQ2rVrJ39/fwUFBWnVqlVWt1m3bp2aNGmiatWqKTg4WAcPHrSsS0tL06RJk1S3bl35+/urT58+unTpUrbtD3KXQoUKy8HB4Zbl8fHxcnFxtVrm4uKihIR4SVJcXJxcXW+/Pj4+zvL9nW4P5BQcAwAAzgUAkHMZVuj88ssvat++vc6cOWNZFhsbq549e6pNmzbat2+fxo8frwkTJujw4YwLqO3du1djx47VxIkTtW/fPrVq1Up9+vRRQkKCJGnOnDnas2eP1qxZo127dsnFxUWjR482ZP+Qe7m4uCopKdFqWWJiotzc3CRJrq6ulvnh/15/443P3W4P5HQcAwAAzgUAYDxDCp1169bpjTfe0JAhQ6yWb926VR4eHurYsaMcHBxUp04dtWzZUsuXL5eUMRe3efPmqlGjhhwdHdW1a1d5enpq48aNlvWvvfaafHx8lD9/fo0aNUo//PCDzp49m+37iNyrZMlSOnnyb6tlp06dtAwrLlOmzB3XFyhQQEWKFLVaHxV1Rf/8E6uSJUsLsAUcAwAAzgUAYDxDCp369etr27ZtatasmdXy48ePq2zZslbLSpcuraNHj0rKmIt7p/XXrl3TxYsXrdYXLlxYBQsW1J9//plFe4K8qGHDxoqKitKXX65QamqqDhzYr61bN6t589aSpJCQEG3dulkHDuxXamqqvvxyhaKjo9WgQWNJUrNmLfXppwsVEXFe8fFxmj79Y1WrVl2+vo8ZuVvAfeMYAABwLgAA4906ITYbFClS5LbL7zTXNj7+7nNx4+PjFReXMRf338M0XVxcLOvul8n0QJvnOHZ2JplsfSdyIHt7Ozk42KlQIS/NmDFHU6ZM1oIFc+Xp6amhQ4cpICBAJpNUp04dvfnmCH388URduhSpJ54opalTZ8jLy1OS9NprPZWenqZ+/V5TfHy8atSoqQ8++FAODlyj/FExmSSz2egUuQ/HgO0wm81KT+cgMMKN0y+nYWPxXijrcC6wDZwHjMW5ANnFZDYb+2tPuXLltHTpUgUGBmrcuHG6dOmSpk+fbln/2Wefac2aNVq/fr1atWqlF198UZ06dbKsHzBggHx8fNSvXz8FBAQoLCzMapROYGCgxo8fr2eeeSZb98tI6Waz7PjXA3kYxwDyPHO6ZOKXIuRd5vR0mew4BpB3cQwAeYMhI3TupGzZstqzZ4/VshMnTqhMmTKSMubiHj9+/Jb1DRo0UMGCBVWsWDGraVmXL1/W1atXb5mmdS9RUdds9n/37e3t5OmZT+t/Oauoa4n3vgEeLZPk4uykxKRkyUZfQ7auSAEXtarup+SjO5R2mY8+zXYmydXZUQlJKRwDBrHLX1jO/m0VExOntLR0o+PkOSaTVKiQu02/l7B1N94LXQn7RilR0UbHyZt4P2Qox0JeKtyyOecBA3EuwKNQuLD7PbfJUYVOkyZNNHnyZC1ZskQdO3bUL7/8orCwMM2ePVtSxlzcfv366fnnn1eNGjW0fPlyRUVFqUmTJpKk4OBgzZkzR5UrV5anp6c++OADBQQE6D//+c8D5TCbbX+6RtS1RF2MpdAxgpubWfHxSUbHyLNMdhkjc9Ljryr9nwsGp8l7TJLk5ixzfBLv4XMAWz+X2bLc8F7C1iVHRSs58pLRMfIkkyQHN2clcy4wxM2POf8OGYtzAbJajip0PD09tWjRIo0fP17Tp0+Xl5eXRo8erdq1a0vKmIv77rvvasyYMYqMjFTp0qU1f/58eXh4SJL69eun1NRUdezYUXFxcQoMDNQnn3xi3A4BAAAAAABkAcMLnX9/AlXlypX1xRdf3HH71q1bq3Xr1rdd5+joqDfeeENvvPHGI80IAAAAAACQk3ClLAAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGOBgdAAAAAAAAW3D69ClNm/aRfv/9N7m55VPr1sHq3Lmb7Ozs9N13O7RkyUJFRJyXp6eHnnuuubp06SE7OzuZzWatWLFU69evUWxsrCpUqKRBg4aqZMnSRu8SbBiFDgAAAAAA9xAfH6+hQ/srIKC2xo+frNjYqxo+fIjS0tJUt+5TGjv2Hb3//kTVrVtP165dUffuPeTi4qaXX+6k1atXasWKpZo4cYoqVKik9etXa+DA3lq2bLU8PDyM3jXYKKZcAQAAAABwD4cP/1cxMTEaOnS4XF1d5e3to1deeVXr16/RxYsRatOmrerVe0p2dnYqVaqUGjRopEOHDkiStm3brJCQl1S5clU5ODgoJOQlFSzooZ07txu8V7BljNABAAAAAOAe0tPT5ejoIAeH//0abTLZKTo6StWr11KjRk9blicmJurHH3eradPnLbd1cXG1+nkmk51Onz6VLdmROzFCBwAAAACAe6hcuaqcnV0UGjpTiYmJunjxgj7/fKkkKTk5ybJdXFyc+vXrJ2dnF7Vv30GS1LBhkFav/kLHj/+p1NRUrV+/WmfPnlZSUtJt7wu4H4zQAQAAAADgHtzd3fXRR9M0Y8ZUBQc3l6/vY3ruueb644/flT+/uyTpzJlTGjXqTRUrVlQzZoTKzS2fJOnllzspKSlRI0e+oZSUZAUFNVVAQG25u7sbuUuwcRQ6AAAAAADcQ0pKitLS0jR9eqhMJpMkad261Xr88ZJycXHRTz/t1pgxo9Sq1QsaPXqkrl5NkNmccdsrVy6rRYvW6tGjtyQpNTVV7dq10vPPtzRqd5ALMOUKAAAAAIB7MJvNGjKkv7755iuZzWYdPfqHli5dpBdffFm//far3nprmAYMGKr+/QdbXWdHkrZv36IRI15XbOxVxcfHKzR0phwdHVWv3lMG7Q1yA0boAAAAAEAuY2/P/90/ag4OLpo8eYo++eRjTZ8+RZ6eXurcuauCg9vqjTcGKzU1VdOmfaRp0z6SyWSS2WxW1ar++uSTmerUqbMuX45Up07tlJKSoqpV/TVz5lzly+d67zvGA0tPNys93Wx0jCxHoQMAAAAAucSNqUAFClAUZIWgoAYKCmpwy/KFC+ff87YffDBO0rgsSIV/S083KyYmLteXOhQ6AAAAAJDL/H34sqIuXjc6Rp5kkuTi4qjExBTl7johZ8pXwFkVaxeXnZ2JQgcAAAAAYFsS4pJ1PYaPxDaCSVK6m1nx8ckUOshSTKwEAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI3JkYXOkSNH1LFjR9WsWVP169fXuHHjlJycLEk6dOiQ2rVrJ39/fwUFBWnVqlVWt123bp2aNGmiatWqKTg4WAcPHjRiFwAAAAAAALJMjit00tPT1atXLz377LP6+eeftXr1au3evVvz589XbGysevbsqTZt2mjfvn0aP368JkyYoMOHD0uS9u7dq7Fjx2rixInat2+fWrVqpT59+ighIcHgvQIAAAAAAHh0clyhExsbq8uXLys9PV1ms1mSZGdnJ1dXV23dulUeHh7q2LGjHBwcVKdOHbVs2VLLly+XJK1atUrNmzdXjRo15OjoqK5du8rT01MbN240cpcAAAAAAAAeqRxX6Hh6eqpr166aNGmSKleurIYNG+rxxx9X165ddfz4cZUtW9Zq+9KlS+vo0aOSpBMnTtx1PQAAAAAAQG7gYHSAf0tPT5eLi4vefvtthYSE6PTp0+rfv7+mT5+uuLg4ubq6Wm3v4uKi+Ph4Sbrn+vtlMmVuH5B33XjtmEzS/w8wg4E4lA1g+t+fJo4Bw3E+y343nwdgLJM4DxiGc0GOwDFgII4BQ938us/t5+McV+hs27ZNW7Zs0ebNmyVJZcqUUb9+/TR+/Hi1bNlS165ds9o+MTFR+fLlkyS5uroqMTHxlvWenp4PlKFQIfdM7EHO4OLiJLcU/vUwiqurs9ER8ixnJ0dJkouzg+TG82AUN44B47hkHAOenvkMDpK35Yb3ErbOxcVJDpwHDMW5wBgOzhnnASdnB7m5ORmcJm9zc+XxN4JLHnovlOMKnQsXLlg+0eoGBwcHOTo6qmzZstqzZ4/VuhMnTqhMmTKSMsqf48eP37K+QYMGD5QhKuqazY6usLe3k6dnPiUmJis+PsnoOHmOyZRR5iQkJNnsa8jWJTlnzCRNTEpVOsdA9jNlvIGPT0iSOAYMYXJIkaukmJg4paWlGx0nzzGZMsocW34vYetufi+UzHnAGJwLDOWUlCJJSk5KVXx88j22RpYwZZQ58QnJHAMGsHPOGJZj6++FChe+938O5bhr6NSvX1+XL19WaGio0tLSdPbsWc2ZM0ctW7ZUkyZNdOXKFS1ZskQpKSkKDw9XWFiY2rZtK0kKCQlRWFiYwsPDlZKSoiVLligqKkpNmjR5oAxms+1+wVg3ngOei5zBzFe2f1netJiNz5JXv25m9Dkpr37x2Bv/+Os+jhW+su7L8o+R2fgsefHrBqNz5OUvyxNhNj5LXv26wehz0qM4n91NjhuhU7p0ac2dO1effPKJFixYIHd3d7Vq1Ur9+vWTk5OTFi1apPHjx2v69Ony8vLS6NGjVbt2bUlSnTp19O6772rMmDGKjIxU6dKlNX/+fHl4eBi7UwAAAAAAAI9Qjit0JKlu3bqqW7fubddVrlxZX3zxxR1v27p1a7Vu3TqrogEAAAAAABgux025AgAAAAAAwN1R6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgY3JkoXP16lW9+eabCgwMVK1atdS3b19dunRJknTo0CG1a9dO/v7+CgoK0qpVq6xuu27dOjVp0kTVqlVTcHCwDh48aMQuAAAAAAAAZJkcWegMGDBA8fHx2rZtm3bu3Cl7e3u9/fbbio2NVc+ePdWmTRvt27dP48eP14QJE3T48GFJ0t69ezV27FhNnDhR+/btU6tWrdSnTx8lJCQYvEcAAAAAAACPTo4rdH777TcdOnRIEydOVIECBZQ/f36NHTtWb7zxhrZu3SoPDw917NhRDg4OqlOnjlq2bKnly5dLklatWqXmzZurRo0acnR0VNeuXeXp6amNGzcavFcAAAAAAACPjoPRAf7t8OHDKl26tL788kt9/vnnSkhI0FNPPaXhw4fr+PHjKlu2rNX2pUuX1urVqyVJJ06cUNu2bW9Zf/To0QfKYDJlbh+Qd9147ZhMktlsbBZIHMoGMP3vTxPHgOE4n2W/m88DMJZJnAcMw7kgR+AYMBDHgKFuft3n9vNxjit0YmNj9eeff+rJJ5/UunXrlJiYqDfffFPDhw9X4cKF5erqarW9i4uL4uPjJUlxcXF3XX+/ChVyz9xO5AAuLk5yS+FfD6O4ujobHSHPcnZylCS5ODtIbjwPRnHjGDCOS8Yx4OmZz+AgeVtueC9h61xcnOTAecBQnAuM4eCccR5wcnaQm5uTwWnyNjdXHn8juOSh90I5rtBxcsp40Y8aNUrOzs7Knz+/Bg8erBdffFHBwcFKTEy02j4xMVH58mU8Ua6urrdd7+np+UAZoqKu2ezoCnt7O3l65lNiYrLi45OMjpPnmEwZZU5CQpLNvoZsXZJzxkzSxKRUpXMMZD9Txhv4+IQkiWPAECaHFLlKiomJU1pautFx8hyTKaPMseX3Erbu5vdCyZwHjMG5wFBOSSmSpOSkVMXHJxucJo8yZZQ58QnJHAMGsHPOGJZj6++FChe+938O5bhCp3Tp0kpPT1dKSoqcnTNa/fT0jCehQoUKWrFihdX2J06cUJkyZSRJZcqU0fHjx29Z36BBgwfKYDYzXQYP58brhtdPzsDTkP0sw4rNPP5GuXlkMf8WGYf3EsYzi3+HjMK5IGfgGDAOx4Cxbn7Mc/u5OMddFLlu3bry8/PTW2+9pbi4OEVHR2vq1Kl65pln1KJFC125ckVLlixRSkqKwsPDFRYWZrluTkhIiMLCwhQeHq6UlBQtWbJEUVFRatKkicF7BQAAAAAA8OjkuELH0dFRn332mezt7fXss8/q2Weflbe3tz744AN5enpq0aJF2rx5swIDAzV69GiNHj1atWvXliTVqVNH7777rsaMGaOAgAB98803mj9/vjw8PIzdKQAAAAAAgEcox025kqRixYpp6tSpt11XuXJlffHFF3e8bevWrdW6deusigYAAAAAAGC4RzZC5/r164/qRwEAAAAAAOAuHrjQCQgIuO3yRo0aZTYLAAAAAAAA7sN9Tbk6ffq03nnnHZnNZl2/fl2vvPKK1frr16+rQIECWRIQAAAAAAAA1u6r0ClRooSaNm2qmJgYHThw4JZROk5OTgoKCsqSgAAAAAAAALB23xdF7tixoyTpscceU5s2bbIqDwAAAAAAAO7hgT/lqk2bNjp8+LBOnjwps9l8yzoAAAAAAABkrQcudKZMmaL58+erSJEicnD4381NJhOFDgAAAAAAQDZ44ELnq6++UmhoqBo2bJgVeQAAAAAAAHAPD/yx5fHx8WrQoEFWZAEAAAAAAMB9eOBCp1GjRgoLC8uKLAAAAAAAALgPDzzlKikpSSNGjFBoaKgKFy5stW7p0qWPLBgAAAAAAABu74ELnbJly6ps2bJZkQUAAAAAAAD34YELnf79+2dFDgAAAAAAANynBy50Ro4cecd1EyZMyFQYAAAAAAAA3NsDXxT532JiYrRp0ya5ubk9ijwAAAAAAAC4hwceoXO7UTg//vijVqxY8UgCAQAAAAAA4O4yPUJHkurWravw8PBH8aMAAAAAAABwDw88QuffUlNTtWHDBnl5eT2KPAAAAAAAALiHBy50ypcvL5PJZLXM3t5eo0aNemShAAAAAAAAcGcPXOgsXbrU6ns7OzuVKFFCRYoUeWShAAAAAAAAcGcPfA2dgIAA1axZUy4uLrpy5YokqVChQo88GAAAAAAAAG7vgUfoXL58Wb1799bRo0fl4eGhmJgYPf7441q0aJG8vb2zIiMAAAAAAABu8sAjdCZNmqTHH39cP//8s/bs2aO9e/eqQoUKt/04cwAAAAAAADx6DzxCJzw8XJs3b1a+fPkkSe7u7hozZoyefvrpRx4OAAAAAAAAt3rgETrp6em3fMqVyWSSo6PjIwsFAAAAAACAO3vgQicwMFBjxoxRfHy8JCkuLk5jxoxRQEDAIw8HAAAAAACAWz3wlKthw4apW7duCggIkIeHh65evapSpUpp3rx5WZEPAAAAAAAA//JAhY7ZbFZqaqq++eYb7d+/X1FRUTp//ry6d+8ue3v7rMoIAAAAAACAm9z3lKv4+Hi9/PLL+vDDD+Xg4KDatWurdu3amjlzpjp37myZggUAAAAAAICsdd+Fzpw5c+To6Kj33nvPsqxQoULauXOnUlNTNXfu3CwJCAAAAAAAAGv3Xehs2bJF48aNU6FChayWFypUSO+99542b978yMMBAAAAAADgVvdd6ERFRalEiRK3XVehQgVdvnz5kYUCAAAAAADAnd13oZM/f37FxMTcdt3Vq1fl6ur6yEIBAAAAAADgzu670KlTp46WL19+23UrVqxQtWrVHlUmAAAAAAAA3MV9f2x5r169FBwcrJiYGDVr1kxFihTRpUuXtGnTJq1Zs0bLli3LypwAAAAAAAD4f/dd6DzxxBNauHCh3n33XS1fvlwmk0lms1lly5bV/Pnz9eSTT2ZlTgAAAAAAAPy/+y50JKl69eoKCwvT2bNnFR0drSJFiqh48eJZlQ0AAAAAAAC38UCFzg1+fn7y8/N71FkAAAByvLS0NA0a1Ec+PsU1atQYSdJ33+3QkiULFRFxXp6eHnruuebq0qWH7OzsZDabtWLFUq1fv0axsbGqUKGSBg0aqpIlSxu7IwAAwKbd90WRAQAAIC1ePF+HD//X8v3Ro39o7Nh39NprfbRly07Nnz9fGzdu0MqVKyRJq1ev1IoVS/XOO2O1ceMOPfVUAw0c2FtXr141ZgcAAECuQKEDAABwn375ZZ++++5bNWwYZFl28WKE2rRpq3r1npKdnZ1KlSqlBg0a6dChA5Kkbds2KyTkJVWuXFUODg4KCXlJBQt6aOfO7UbtBgAAyAUodAAAAO5DTEy0Jk4cq3ffHScXFxfL8kaNntaAAUMt3ycmJurHH3erXLkKkqT09HS5uLha/SyTyU6nT5/KltwAACB3otABAAC4h/T0dL3//ttq376DypQpe8ft4uLi1K9fPzk7u6h9+w6SpIYNg7R69Rc6fvxPpaamav361Tp79rSSkpKyKz4AAMiFHuqiyAAAAHnJZ58tlpOTk0JCXrrjNmfOnNKoUW+qWLGimjEjVG5u+SRJL7/cSUlJiRo58g2lpCQrKKipAgJqy93dPbviAwCAXIhCBwAA4B62bNmoK1eu6LnnGknKmFYlSbt2fafNm7/TTz/t1pgxo9Sq1QsaPXqkrl5NkNmccdsrVy6rRYvW6tGjtyQpNTVV7dq10vPPt8z+HQEAALkGhQ4AAMA9rFixxur78ePHSJJGjRqj3377VW+9NUyvvz5CLVu2loOD9dur7du3aPv2rZo2bbYcHZ20aNE8OTo6ql69p7IrPgAAyIUodAAAyIXs7blMXlYymUySJAcHOy1btlipqamaNu0jTZv2kUwmk8xms6pW9dcnn8xUp06ddflypDp1aqeUlBRVreqvmTPnKl8+13vcCx4Gr30AQF5BoQMAQG6S0TOoQAHKgqw0depHlr8vXDj/ntt/8ME4SeOyMBFulm5Ol30+N6NjAACQpSh0AADIRf5/4Ih+OL1HJ2NOGZolLzKZJBcXRyUmpliuoYPsVTifl5qXeV52zi733hgAABtGoQMAQC4UmxirS3GXjI6R55hMkpvZWfHxSRQ6BrFjxhUAII/glAcAAAAAAGBjKHQAAAAAAABsTI4tdNLS0tS5c2eNGDHCsuzQoUNq166d/P39FRQUpFWrVlndZt26dWrSpImqVaum4OBgHTx4MLtjAwAAAAAAZLkcW+jMnDlT+/fvt3wfGxurnj17qk2bNtq3b5/Gjx+vCRMm6PDhw5KkvXv3auzYsZo4caL27dunVq1aqU+fPkpISDBqFwAAAAAAALJEjix0fvrpJ23dulVNmza1LNu6das8PDzUsWNHOTg4qE6dOmrZsqWWL18uSVq1apWaN2+uGjVqyNHRUV27dpWnp6c2btxo1G4AAAAAAABkiRz3KVdRUVEaNWqUZs+erSVLlliWHz9+XGXLlrXatnTp0lq9erUk6cSJE2rbtu0t648ePfrAGW585CvwoG68dkwm8ekmOQCHsgFM//vTxDFgKJOJ85nRePyNx1NgEM4FOYJJHAOG4Rgw1M2v+9x+Ls5RhU56erqGDRumbt26qXz58lbr4uLi5OrqarXMxcVF8fHx97X+QRQq5P7At8lpXFyc5JbCvx5GcXV1NjpCnuXs5ChJcnF2kNx4HozixjFgnP8/BpycHOTGMWAYHnvjODs7/u9PngdDcS4whsP/HwNOzg5yc3MyOE3e5ubK428EF5eMY8DTM5/BSbJejip05s6dKycnJ3Xu3PmWda6urrp27ZrVssTEROXLl8+yPjEx8Zb1np6eD5wjKuqazY6usLe3k6dnPiUmJis+PsnoOHmOyZRR5iQkJNnsa8jWJTlnzCRNTEpVOsdA9jNlvIGPT0iSOAYMYeeUIhdJycmpnAcM4ubmzGNvoCS7lIw/k1J4HozCucBQTkkZx0ByUqri45MNTpNHmTLKnPiEZI4BA9g5ZwzLiYmJU1pausFpHl7hwvceaJKjCp2vvvpKly5dUs2aNSXJUtBs375db775pvbs2WO1/YkTJ1SmTBlJUpkyZXT8+PFb1jdo0OCBc5jNTJfBw7nxuuH1kzPwNGQ/y7BiM4+/0TiXGePmod08/sbjKTAG54KcwSwef6NwDBjr5sc8t5+Lc9RFkTdv3qwDBw5o//792r9/v1q0aKEWLVpo//79atKkia5cuaIlS5YoJSVF4eHhCgsLs1w3JyQkRGFhYQoPD1dKSoqWLFmiqKgoNWnSxOC9AgAAAAAAeLRy1Aidu/H09NSiRYs0fvx4TZ8+XV5eXho9erRq164tSapTp47effddjRkzRpGRkSpdurTmz58vDw8PY4MDAAAAAAA8Yjm60Jk4caLV95UrV9YXX3xxx+1bt26t1q1bZ3UsAAAAAAAAQ+WoKVcAAAAAAAC4NwodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGNyZKFz9OhRdevWTQEBAapXr57efPNNRUdHS5IOHTqkdu3ayd/fX0FBQVq1apXVbdetW6cmTZqoWrVqCg4O1sGDB43YBQAAAAAAgCyT4wqdxMRE9ejRQ/7+/tq9e7c2bNigq1ev6q233lJsbKx69uypNm3aaN++fRo/frwmTJigw4cPS5L27t2rsWPHauLEidq3b59atWqlPn36KCEhweC9AgAAAAAAeHRyXKETERGh8uXLq1+/fnJycpKnp6fat2+vffv2aevWrfLw8FDHjh3l4OCgOnXqqGXLllq+fLkkadWqVWrevLlq1KghR0dHde3aVZ6entq4caPBewUAAAAAAPDoOBgd4N9KliypBQsWWC3bsmWLKlWqpOPHj6ts2bJW60qXLq3Vq1dLkk6cOKG2bdvesv7o0aMPlMFkeojggP732jGZJLPZ2CyQOJQNYPrfnyaOAUOZTJzPjMbjbzyeAoNwLsgRTOIYMAzHgKFuft3n9nNxjit0bmY2m/XJJ59o586dWrZsmZYuXSpXV1erbVxcXBQfHy9JiouLu+v6+1WokHvmgucALi5OckvhXw+juLo6Gx0hz3J2cpQkuTg7SG48D0Zx4xgwzv8fA05ODnLjGDAMj71xnJ0d//cnz4OhOBcYw+H/jwEnZwe5uTkZnCZvc3Pl8TeCi0vGMeDpmc/gJFkvxxY6169f18iRI3XkyBEtW7ZM5cqVk6urq65du2a1XWJiovLly3iiXF1dlZiYeMt6T0/PB7rvqKhrNju6wt7eTp6e+ZSYmKz4+CSj4+Q5JlNGmZOQkGSzryFbl+ScMZM0MSlV6RwD2c+U8QY+PiFJ4hgwhJ1TilwkJSench4wiJubM4+9gZLsUjL+TErheTAK5wJDOSVlHAPJSamKj082OE0eZcooc+ITkjkGDGDnnDEsJyYmTmlp6QaneXiFC997oEmOLHTOnDmj1157TcWLF9fq1avl5eUlSSpbtqz27Nljte2JEydUpkwZSVKZMmV0/PjxW9Y3aNDgge7fbGa6DB7OjdcNr5+cgach+1mGFZt5/I3GucwYNw/t5vE3Hk+BMTgX5Axm8fgbhWPAWDc/5rn9XJzjLoocGxurLl26qHr16lq4cKGlzJGkJk2a6MqVK1qyZIlSUlIUHh6usLAwy3VzQkJCFBYWpvDwcKWkpGjJkiWKiopSkyZNjNodAAAAAACARy7HjdBZu3atIiIitGnTJm3evNlq3cGDB7Vo0SKNHz9e06dPl5eXl0aPHq3atWtLkurUqaN3331XY8aMUWRkpEqXLq358+fLw8PDgD0BAAAAAADIGjmu0OnWrZu6det2x/WVK1fWF198ccf1rVu3VuvWrbMiGgAAAAAAQI6Q46ZcAQAAAAAA4O4odAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNyXWFTlRUlPr27auaNWsqMDBQ48ePV2pqqtGxAAAAAAAAHplcV+gMHjxYbm5u2rVrl1avXq2ffvpJS5YsMToWAAAAAADAI5OrCp3Tp0/r559/1rBhw+Tq6io/Pz/17dtXy5cvNzoaAAAAAADAI5OrCp3jx4/Lw8NDxYoVsywrVaqUIiIi9M8//xiYDAAAAAAA4NFxMDrAoxQXFydXV1erZTe+j4+PV4ECBe7r59jZSWbzI4+XrXy93OTqnKueXttgkuzt7ZXm7ijZ+GvIVnnld5YkORQpIXtHR4PT5EEmSfb2ckxL4xgwiMmtoCSpfOGyKuzmZXCavMnewU5pqelGx8iz8jnly/izSiU5/+cxg9PkXQ729nJOSzM6Rp5k7+omSfIt46kij+U3OE3eZW9vp7Q0zgVGcHC0t/zdLlcNYblVrvqN383NTQkJCVbLbnyfL1+++/45Xl7ujzSXEZ6r4mt0BMBQDn41JT+jU+RdVGnGK1OotMoUKm10DMAwbo8/bnQEwFAehd2MjgAYytPz/jsAW5Wr+qoyZcro6tWrunLlimXZX3/9JW9vb7m7235JAwAAAAAAIOWyQufxxx9XjRo19MEHH+j69es6e/asZs+erZCQEKOjAQAAAAAAPDIms9nWrxZj7cqVK3r//fe1d+9e2dnZqU2bNnrjjTdkb29/7xsDAAAAAADYgFxX6AAAAAAAAOR2uWrKFQAAAAAAQF5AoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgfIpP3799+y7Nq1a3r99dcNSAMAAAAAyAscjA4A2Lq+fftqyZIlqlixoiRp9+7deuutt1SoUCGDkwHZo3PnzjKZTLcsd3R0lJeXlxo3bqxmzZoZkAzIPsePH9eHH36oU6dOKT093Wrdjh07DEoFZK2RI0fec5sJEyZkQxLAeMnJyYqOjr7lHFC8eHGDEiEvoNABMmnEiBF67bXXFBoaqjVr1mj16tXq1auX+vTpY3Q0IFtUrVpVK1eu1Isvvig/Pz9FRERo5cqVatCggQoXLqzx48crKipKnTt3NjoqkGXeeecdubq6qmfPnnJw4O0V8paYmBjt2rVLjRs3lp+fnyIjI7Vt2zY1bdrU6GhAtti0aZPeffddXbt2zbLMbDbLZDLpjz/+MDAZcjuT2Ww2Gx0CsHWrVq3SO++8o9KlS+vDDz9UhQoVjI4EZJsOHTpo6NChqlmzpmXZoUOHNHnyZC1btkxHjx7VoEGDtGXLFgNTAlmrevXq+uGHH5Q/f36jowDZrnfv3mrXrp2efvppy7Ldu3crNDRUy5YtMzAZkD2aNWumpk2b6oUXXril1Pf19TUoFfIC/gsJeEj79u2z/P3xxx9XixYtdODAAV29etWyrlatWkbFA7LNsWPHVL16datllStX1u+//y5JKl++vC5fvmxENCDbFC1aVMnJyUbHAAyxd+9ezZ4922pZnTp1NGDAAIMSAdnrwoUL6t+/PyM0ke14xQEP6U7TR7p16yZJDLFEnuHn56c1a9aoXbt2lmVhYWGWOeNHjhxRkSJFjIoHZItOnTqpX79+euWVV1S4cGGrdZT7yO18fX21adMmNW/e3LJs7dq1KlGihIGpgOxTqVIlnThxQuXLlzc6CvIYplwBmXT27Fn5+fkZHQMwzI8//qg+ffqoQoUK8vX1VUREhI4eParp06ercOHC6tChg0aNGqWQkBCjowJZ5k5v4in3kRfs2LFDgwYNUpUqVeTj46Nz587p2LFjCg0NVWBgoNHxgCw3ZcoUffnll3ruueduKfX79+9vUCrkBRQ6QCbVrVtXW7du5boJyNPOnTunsLAwXbx4Ub6+vmrdurWKFSumixcvKiYmhutKIdej3Ede9/fff2vjxo26dOmSvL291bJlS44J5Bl3GrlvMpm0dOnSbE6DvIRCB8ikZs2aacaMGSpVqpTRUQAABqHcBwAA2Y1r6ACZVKZMGb344ouqVq2aihYtarVuwoQJBqUCss/x48f14Ycf6tSpU0pPT7dat2PHDoNSAdnLw8NDkZGRFDrIkzgPANJff/2lzz//XBcvXtTYsWP1zTffqFOnTkbHQi5HoQNkkpubm5o2bWp0DMAw77zzjlxdXdWzZ08+3QF5FuU+8jLOA8jr9uzZowEDBqhx48b68ccflZiYqFmzZik+Pl49e/Y0Oh5yMaZcAQAypXr16vrhhx8YmYA8beTIkXdcR6GD3I7zAPK6tm3bauDAgWrYsKFq1aqlffv26ddff9XgwYMZpYYsRYUOZFJycrLCwsIUGRlpGWackpKiY8eOac6cOQanA7Je0aJFlZycbHQMwFCUNsjLOA8grzt9+rQaNGggKeNCyJJUuXJlxcbGGhkLeQCFDpBJb731lnbt2iVPT0+lpKTIzc1Nx48fV5s2bYyOBmSLTp06qV+/fnrllVdu+ajOWrVqGZQKyH6ffvqpVq5cqfPnz6tIkSIKCQlRr169LG/ugdyK8wDyuuLFi+vAgQOqUaOGZdmvv/4qHx8fA1MhL6DQATJp165d+vzzzxUdHa3PP/9cH3/8sRYtWqTDhw8bHQ3IFuPGjZMkHTx40Gq5yWTSH3/8YUQkINt9+umnWrx4sXr27KnHHntMZ86c0YIFC2RnZ8f1E5DrcR5AXterVy/16dNHL7/8slJSUjR//nx99tlnGjp0qNHRkMtxDR0gk27Mk42OjlanTp20ceNGJSUl6emnn9bu3buNjgcAyAbPP/+8Pv74Y1WsWNGy7Pfff9eAAQO4fgIA5AHff/+9li9frvPnz8vb21svvviinn32WaNjIZdjhA6QSd7e3jp79qz8/PwUFRWl+Ph42dnZKS4uzuhoQJa6ePGivL29FRERccdtihcvno2JAONcunRJ5cuXt1pWvnx5Xb161ZhAQDbiPIC8buzYsRoyZIgaNmxodBTkMRQ6QCa1bNlSHTp00OrVq9WoUSP16dNHzs7OevLJJ42OBmSpZs2a6cCBAwoKCpLJZNKNAZ83/s5Qe+QlJUqU0LZt26z+N3bbtm0qUaKEgamA7HG788ANnAeQF4SFhd310w6BrMKUK+AR2LRpkxo2bKj09HRNnjxZ169f1+DBg+Xn52d0NCDLXLhwQT4+Pjp//vwdt/H19c3GRIBxtm/frsGDB6tJkyby8/PTmTNntGPHDk2fPl2NGzc2Oh6Qpf59HoiOjtaCBQv09NNPq1WrVgalArLPpEmTFBcXpxdeeEFFixa1KjUZpYasRKEDPEIxMTHy9PQ0OgaQrUaMGKG2bdvySSbI88LDw7Vu3TpduXJFvr6+CgkJUZUqVYyOBRji2rVreuGFF7R9+3ajowBZ7uYptzfKHEYrIzsw5QrIpOvXr2vixIkKCwtTcnKyXF1d9dJLL2nw4MFycnIyOh6Q5dzc3DRgwAC5u7vrhRdeUHBwsLy9vY2OBWS72rVrq3bt2kbHAHKMf/75x+gIQLbg4vcwCiN0gEx6++23dezYMQ0cOFA+Pj46e/aspk2bpsDAQA0fPtzoeEC2SElJ0c6dO7Vu3Trt2bNHtWrVUtu2bfXMM89QbCJPuHTpkmbNmqWzZ88qNTXVat3SpUsNSgVkj5kzZ1p9n5KSol27dqlw4cKaN2+eQakAIPej0AEyqX79+vr666/l5eVlWXbx4kWFhITwseXIk/773//q/fff1++//66CBQsqODhYffv2lbu7u9HRgCzTrVs3xcbG6qmnnpKjo6PVuv79+xuUCsgenTt3tvre3t5epUqVUq9evVS0aFGDUgFZr3r16jpw4IDKly9vdd2cmzHlClmJKVdAJrm6usre3t5qmZubm9LT0w1KBGS/y5cva8OGDfrqq6/0119/qWHDhurfv7+KFy+uTz75RH369NGyZcuMjglkmf/+97/64YcfKC6RJ3322WdGRwAMcWME2tKlS5WamioHBwelp6crKSlJx44dU9WqVQ1OiNyOQgd4SBEREZKkNm3aaMiQIRoxYoR8fX116dIlTZ48WV27djU2IJBNunfvrvDwcJUsWVLBwcFq3bq11Yi1oUOHqn379gYmBLKej4+P7OzsjI4BGGb79u1auXKlzp8/ryJFiigkJEQtW7Y0OhaQpWrWrCkp45qao0eP1o8//qjZs2crNDRUJpNJo0aNUkBAgMEpkZsx5Qp4SDeGVt58CHFVe+RF7777rtq2bXvHT/OJi4vTxYsXVapUqWxOBmS9G+X+119/rd9//119+vRRwYIFrbbhI2uR24WFhem9995T+/bt9dhjj+nMmTP68ssvNWLECLVr187oeECWa9eundq1a6eQkBDVr19fEyZMUKFChTRkyBBt27bN6HjIxSh0gId0/vz5e27j6+srKeOaOnzqD/KS1NRUHTt2TBUrVjQ6CpClKPcBqVWrVnrrrbesPuUtPDxc77//vjZu3GhgMiB7BAYGau/evfr999/VsWNH7du3Tw4ODvL399fBgweNjodcjClXwEO6Udbcj2bNmunAgQNZmAYwzvfff68xY8YoMjLS6pdaBwcH/frrrwYmA7Leg3xULeU+cquIiAgFBgZaLQsICNDFixcNSgRkL1dXV0VFRenbb79VjRo15ODgoKNHj8rT09PoaMjlKHSAbMBAOORmkydPVtOmTVWgQAH9+eefatGihWbNmqWQkBCjowFZjnIfkLy9vbVv3z6ra4Xs27eP6YbIM9q2bas2bdron3/+0fTp0/Xbb7+pR48eevXVV42OhlyOQgfIBnf6GEMgNzh79qyGDRumc+fOKTw8XE2bNlXJkiU1ZMiQWz7KFsjLKPeRW3Xp0kX9+vVT+/bt5efnpzNnzmjlypUaOXKk0dGAbDFgwAAFBATI2dlZ1apV04ULF/T++++radOmRkdDLkehAwDIFC8vL9nZ2al48eL666+/JEmlS5dmqD3wL5T7yK3atWsne3t7rV27Vtu3b5evr6/GjRun5557zuhoQLa5edqhj4+PfHx8DEyDvIJCBwCQKeXKldO0adPUr18/FSpUSN9//71cXFzk7OxsdDQAQDYYO3ashgwZouDgYKOjAECeYmd0AACAbRs2bJi2b9+uy5cva+DAgerbt6+6du2q7t27Gx0NAJANwsLC5OrqanQMAMhz+NhyIBtUr16dC2Eiz7h06ZLi4uL0xBNPGB0FyFE4FyC3mjRpkuLi4vTCCy+oaNGiVtMLuTAyAGQdplwB2cDJycnoCMAjt2/fvruuv3LlimrVqpVNaQAARlm8eLEk6csvv7SUOWazWSaTSX/88YeR0QAgV2OEDpBJ69evv+1yR0dHeXl5qVq1agxDRq5Uvnz5u67njTzykv3796t69eqys7vzbPbatWsrPDw8G1MB2eP8+fN3XOfr65uNSQAgb6HQATLp5Zdf1n//+18VKlRIvr6+unDhgi5fvixvb28lJCTIZDJp0aJFqlChgtFRAQBZJDAwUN999x0FPvKkiIiI2y53dHRUwYIFGakMAFmEKVdAJpUrV061atXS4MGDLf8zO3PmTMXGxmrUqFFatGiRJkyYoKVLlxqcFMg6J0+e1DfffKPLly/L19dXLVq04LoJyFP8/Pz066+/KiAgwOgoQLZr0qSJ0tPTJf1vqtUNdnZ2qlu3riZNmiQvLy+jIgJArsQIHSCT6tevr507d8rR0dGyLCUlRY0bN9bu3buVmpqq2rVra//+/QamBLLO9u3bNXjwYD355JMqXry4zp07p+PHj2v+/PmqWbOm0fGAbNG9e3eFh4frscceu+WisBT6yO2WLVumnTt36q233pKfn5/OnTunDz/8UE8++aSaNm2qOXPmyMHBQZMnTzY6KgDkKozQAR6Bs2fPqmTJkpbvz58/r9TUVElSYmKiVdkD5DZTp07VuHHj1KZNG8uy1atXa8KECVqzZo1xwYBs5O/vL39/f6NjAIb49NNPtWrVKnl4eEiSSpYsqUmTJqlt27bq37+/xo4dq6efftrYkACQC1HoAJkUEhKinj17qlevXipevLgiIiK0cOFCBQcHKyoqSm+++aYaNmxodEwgy0RERKhVq1ZWy1544QVNmDDBoERA9uvfv7/REQDDxMTEyN7e3mqZyWRSVFSUJMnV1dUyJQsA8OhQ6ACZNHDgQLm5uWnBggW6cOGCihcvrvbt26tLly767bffVLJkSQ0ePNjomECWqVKlirZu3arnnnvOsuznn39WtWrVjAsFZLOYmBh99tlnioyMtPzimpKSomPHjunrr782OB2QtZ566im9/vrrGjVqlOU/tyZPnqz69esrOTlZs2bNUqVKlYyOCQC5DtfQAQBkyqhRo7R+/Xo1atRIJUqUUGRkpLZv366aNWuqaNGilu0YsYPcrHfv3jp16pS8vLx0/fp1FS9eXLt371bHjh01cuRIo+MBWerq1at6/fXXtWfPHsv1oxo1aqTx48fr6NGjmjRpkqZMmaJSpUoZnBQAchcKHSCTzGazli5dqpUrV+r8+fMqUqSIQkJC1KtXL6uLYgK51f3+skqhg9ysRo0a2rhxoyIjIzVv3jzNnDlTX331lTZs2KD58+cbHQ/IFpGRkbp48aKKFy+uIkWKKDExUS4uLkbHAoBciylXQCYtXbpUixcvVs+ePfXYY4/pzJkzWrBggezs7NSzZ0+j4wFZ7n6KmjFjxmR9EMBADg4OKlasmFxdXfXnn39Kkpo3b64PP/zQ4GRA1lu6dKleeeUVFStWTMWKFZMk/fe//9Xw4cO1ZcsWg9MBQO5lZ3QAwNZ98cUXmj17tjp06KAGDRqoU6dOmj17tlauXGl0NCDH4BoiyO18fX3122+/qUCBAoqLi1N0dLTi4+OVmJhodDQgy82ZM0dr166VJKWmpmrKlCnq1KmT6tata3AyAMjdGKEDZNKlS5dUvnx5q2Xly5fX1atXjQkE5EDM7kVu16FDB3Xu3FnffPONWrRooS5dusjBwUG1atUyOhqQ5RYuXKju3bsrJiZGGzZs0D///KMFCxaodu3aRkcDgFyNETpAJpUoUULbtm2zWrZt2zaVKFHCoERAzsP1pJDbhYSEqG/fvrK3t9ewYcP07LPPKioqiilXyBMqVqyoBQsWaO7cufLw8NCGDRsocwAgGzBCB8ikvn37avDgwdq8ebP8/Px0+vRpffvtt5o+fbrR0QAA2WT69Olat26dmjRpIkdHR1WoUEGOjo768ssv1aNHD6PjAVli5syZVt9Xr15d4eHhmjt3rhwcMn7N6N+/vxHRACBP4FOugEdg7969Wrt2raKiouTr66u2bduqSpUqRscCcozq1avrwIEDRscAskyDBg20fPly+fn5WZadOXNGXbp00c6dOw1MBmSdzp0733W9yWTS0qVLsykNAOQ9jNABHlLnzp1vmUZiNpt18uRJffTRR5LEmxgAyCOuX78uHx8fq2U+Pj6Kj483KBGQ9T777DPL381ms9LT02Vvb6/Lly/Ly8tL9vb2BqYDgNyPa+gADykwMFABAQEqXry4fv/9d1WoUEHPPfecqlatqj///FNPPPGE0RGBHIPBoMjtKlWqpHnz5lktW7Ro0S0XzQdyo6NHjyooKEhHjhyRJC1YsEBNmzbVyZMnDU4GALkbU66ATOrQoYPeeOMNVa9e3bLst99+09tvv61169YZmAzIOZYsWaKuXbsaHQPIMkeOHNGrr74qV1dXeXt76+LFi0pNTdWCBQsodZDrde7cWbVq1VLfvn3l4OCg1NRUhYaG6sCBA1q0aJHR8QAg16LQATLJ399f+/fvtxpWnJKSooCAAB08eNDAZED2iIyM1Jw5c3Tq1Cmlp6dbrWPaIfKS2NhY7dy5U5cuXZKPj48aNWokd3d3o2MBWa5mzZrat2+f1VT0tLQ01a5dW/v27TMwGQDkblxDB8ikUqVKacmSJerevbtlWWhoKP8jizxj5MiRunLliho3bixHR0ej4wCGKViwoNq0aWN0DCDb5c+fXydPnlTJkiUty86ePasCBQoYmAoAcj9G6ACZdODAAfXu3Vtubm7y9vZWRESE0tPTtXDhQpUrV87oeECWq1WrlrZs2SIvLy+jowAADDBt2jRt3LhRPXr0UPHixRUREaGFCxeqZcuW6tevn9HxACDXYoQOkEnVq1fX1q1b9d133ykyMlLe3t4KCgpimD3yDHd3dzk5ORkdAwBgkP79+8vOzk6hoaG6fPmyfHx8FBwcrB49ehgdDQByNUboAAAyZfXq1fr+++/12muvqXDhwlbrihcvblAqAAAAIHej0AEAZMq/rxdlMplkNptlMpn0xx9/GJQKAJBdkpOTFRYWpsjISMvF8VNSUnTs2DHNmTPH4HQAkHsx5QoAkCk7duwwOgIAwEBvvfWWdu3aJU9PT6WkpMjNzU3Hjx/nIuEAkMXsjA4AALBtvr6+8vX1VWxsrI4cOaIiRYrIxcVFvr6+RkcDAGSDXbt26fPPP9e4ceNUrVo1hYWF6c0331RiYqLR0QAgV6PQAQBkSlRUlF566SW9+OKLGj58uM6ePatnnnlGBw8eNDoaACAbpKenq2TJkipZsqRlqm3Hjh21f/9+g5MBQO5GoQMAyJQPPvhAZcuW1b59++Tg4KBSpUqpZ8+e+vDDD42OBgDIBt7e3jp79qy8vLwUFRWl+Ph4mc1mxcXFGR0NAHI1rqEDAMiU8PBwbd++Xa6urjKZTJKkHj16aNGiRQYnAwBkh5YtW6pDhw5avXq1GjVqpD59+sjZ2VlPPvmk0dEAIFej0AEAZIqjo6MSExPl6uqqGx+cGBcXp3z58hmcDACQHXr27Ck/Pz/ly5dPgwcP1ty5c3X9+nW9/fbbRkcDgFyNKVcAgEwJCgrSsGHDdOrUKZlMJkVFRem9995Tw4YNjY4GAMgGcXFx2r17t+rVq6egoCB9/fXXKlKkiIoVK2Z0NADI1UzmG/+dCgDAQ4iLi9PIkSO1detWSZLJZFLDhg01efJkubu7G5wOAJDV3n77bR07dkwDBw6Uj4+Pzp49q2nTpikwMFDDhw83Oh4A5FoUOgCATNm/f7/8/f0VGxurc+fOydvbW0WLFjU6FgAgm9SvX19ff/21vLy8LMsuXryokJAQ7d6928BkAJC7MeUKAJAp/fr1U3Jysry8vFSlShXKHADIY1xdXWVvb2+1zM3NTenp6QYlAoC8gUIHAJApfn5++vXXX42OAQDIZhEREYqIiFCbNm00ZMgQHTt2THFxcTp58qRGjBihrl27Gh0RAHI1plwBADKle/fuCg8P12OPPaaiRYtaPrpckpYuXWpgMgBAVipfvrxMJpNu/nXixjnAbDbLZDLpjz/+MCoeAOR6fGw5ACBT/P395e/vb3QMAEA227Fjh9ERACBPY4QOAAAAAACAjWGEDgDgoYwcOfKe20yYMCEbkgAAAAB5DxdFBgBkSkxMjL7++mtdu3ZNHh4eSkpK0oYNG5ScnGx0NAAAACDXYsoVACBTevfurXbt2unpp5+2LNu9e7dCQ0O1bNkyA5MBAAAAuReFDgAgU/z9/fXLL7/Izu5/gz7T0tJUs2ZNHTx40MBkAAAAQO7FlCsAQKb4+vpq06ZNVsvWrl2rEiVKGJQIAAAAyP0YoQMAyJQdO3Zo0KBBqlKlinx8fHTu3DkdO3ZMoaGhCgwMNDoeAAAAkCtR6AAAMu3vv//Wxo0bdenSJXl7e6tly5by8/MzOhYAAACQa1HoAAAAAAAA2BgHowMAAGxTUFCQTCbTXbfZsWNHNqUBAAAA8hYKHQDAQ+nfv/89Cx0AAAAAWYMpVwAAAAAAADaGEToAgIfSs2dPzZs3T507d77jSJ2lS5dmcyoAAAAgb6DQAQA8lBo1akgSH00OAAAAGIApVwAAAAAAADaGEToAgEyJi4vT8uXLdfbsWaWmplqtmzBhgkGpAAAAgNzNzugAAADbNnLkSC1fvlzx8fFGRwEAAADyDKZcAQAyxd/fX1u2bFHRokWNjgIAAADkGYzQAQBkSpEiReTp6Wl0DAAAACBPodABAGTKSy+9pEmTJumff/4xOgoAAACQZzDlCgDwUMqXLy+TyaQbpxGTyXTLNn/88Ud2xwIAAADyBD7lCgDwUJYuXSpJMpvNOnXqlFxdXeXt7a0LFy4oKSlJjz/+uLEBAQAAgFyMKVcAgIcSEBCggIAA7d27V6GhoapSpYoCAgKUP39+zZ07V4cPHzY6IgAAAJBrMeUKAJApDRo00PLly+Xn52dZdubMGXXp0kU7d+40MBkAAACQezFCBwCQKdevX5ePj4/VMh8fH8XHxxuUCAAAAMj9KHQAAJlSqVIlzZs3z2rZokWLVL58eYMSAQAAALkfU64AAJly5MgRvfrqq5aLIl+8eFGpqalasGABpQ4AAACQRSh0AACZFhsbq507d+rSpUvy8fFRo0aN5O7ubnQsAAAAINei0AEAAAAAALAxXEMHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAJBF0tLSdPbsWaNjAACAXIhCBwAAGOrkyZMaPny4GjRoIH9/fz3zzDP66KOPFBcXJ0kqV66c9u7da3DKhzNkyBCtX7/ekPvev3+//P39M/1zZsyYoc6dOz+CRAAA4FGi0AEAAIY5cOCAXnjhBfn6+mr9+vU6ePCg5s+fr0OHDunVV19VWlqa0REzJSYmxrD7rlmzpg4ePGjY/QMAgKxFoQMAAAzzzjvvqE2bNho4cKC8vLwkSU888YSmTp2qQoUK3TJd6a+//lKvXr3UqFEjValSRc2aNdPOnTst62fMmKGGDRsqICBAbdu21Y4dOyRJqampGjNmjOrVq6fAwEB16NBBv/zyy31lTE1N1bRp09SwYUNVr15dHTt21NGjRyVJkZGRGjx4sIKCglS1alU9/fTTWr16tSRp1KhR2r9/v+bOnavevXtLks6cOaPevXsrMDBQjRs31tSpU5WcnGy5r2+++UbPPvusatasqe7du+vtt9/WiBEjJEnp6emaN2+ennnmGdWoUUMhISHatWuX5bZBQUF65513VK9ePbVp00Y//fSTypUrZ1l/5MgRde7cWf7+/qpfv76mTZsms9ksSVq9erWCg4MVGBgof39/9erVS9HR0ff1+AAAAGNQ6AAAAEOcOXNGx48fV4sWLW5ZV7hwYc2ePVuPP/641fIBAwaobNmy2rZtm/bv36/69etrzJgxkqTw8HCtXLlSq1at0t69e9WuXTuNGjVKKSkp+uqrr3Tw4EFt2rRJP/74o2rVqqX33nvvvnLOmTNHGzZs0MKFC7Vv3z4FBASoV69eSktL0+jRo+Xo6KhvvvlGBw4cUKdOnTR27FjFxcVp/Pjxqlmzpnr16qXQ0FDFx8era9euKlOmjH744QetWLFCP/74o2bMmCFJOnjwoIYPH67hw4crPDxcL730ktauXWvJMWvWLC1fvlzTpk3T3r179eqrr6pv3746fPiwZZvDhw9r06ZNWrp0qezs/vc27+rVq3r11VcVGBiovXv3asWKFVq7dq1Wrlypw4cPa9y4cRozZoz27t2rTZs26dSpU1q6dOn9PpUAAMAADkYHAAAAedONESCFCxe+79vMnTtXxYoVk9ls1vnz51WgQAFFRkZKkpydnRUbG6svv/xSjRs3Vrt27dS+fXuZTCa5uLjo3LlzWr16tRo0aKBBgwZpyJAh93Wf69atU69evVS6dGlJUp8+fdSwYUOZzWaNGzdO+fLlk6OjoyIiIpQvXz4lJiYqNjZW+fLls/o53333nZKTkzV06FCZTCb5+Pho0KBBGjhwoF5//XWtWbNGTZs2VVBQkCSpSZMmeuaZZyy3X7NmjXr27KlKlSpJkpo1a6YtW7Zo9erVqlKliiTp2WefVYECBW7Zh507d8rZ2Vn9+vWTyWTSf/7zHy1evFhubm7y8PDQhg0b9Nhjjyk2NlaXLl2Sl5eX5XEFAAA5E4UOAAAwRJEiRSRJly9fvmUkjiRduXLllrLn6NGj6tu3ry5fvqxSpUrJy8vLMm3I399fM2bM0GeffaYFCxbIxcVFnTt3Vp8+fdS8eXOlpKRo1apVmjJligoVKqTevXvr5ZdfvmfOy5cvq3jx4pbvnZycVK1aNUnS2bNn9eGHH+rUqVN6/PHHVaJECUkZ06P+7fz584qOjlatWrUsy8xms1JSUhQVFaULFy6oYsWKVrfx8/PTlStXLI+Hn5+f1frHHnvMMv1LkooWLXrHffDx8ZHJZLIsK1mypCQpOTlZS5cuVVhYmNzc3FSuXDldv37d8rgCAICciUIHAAAYwtfXV2XLltXGjRutSg5JioqKUuPGjTVhwgTLssjISA0aNEgzZ860jGLZsmWLtm7dKkmKiIhQoUKFtHDhQiUnJ+unn35S//79ValSJZUoUUKVKlVSmzZtlJiYqM2bN2v48OGqWbOmypQpc9ecPj4+unDhguX7lJQUTZ48Wd26dVOvXr00dOhQdejQQSaTSb/99pu+/vrr2/4cb29v/ec//9HmzZsty65fv66oqCh5eXnJ19dXERERVreJiIiQk5OT5fH69zWFzp49a1Xi3FzY/Pu+L1y4ILPZbNlm+/btun79ui5duqQ9e/YoLCzMUqDduOYPAADIubiGDgAAMMzbb7+tNWvWaObMmYqJiZHZbNYff/yh3r17q1KlSnr22Wct28bFxSktLU2urq6SpBMnTmjWrFmSMkaZ/Prrr+rRo4eOHj0qJycnFSpUSJLk6empnTt3qn///jp37pxcXFzk4eEhBwcHubu73zNjcHCwFi5cqJMnTyo1NVVz587V9u3blT9/fiUmJsrFxUUmk0kRERGaPHmypIzSR8oYzXPt2jVJUuPGjRUXF6cFCxYoOTlZ//zzj4YPH64hQ4bIZDKpXbt22rZtm3bt2qW0tDR9//33lrJKktq1a6d58+bpyJEjSktL06ZNm/Ttt9/qhRdeuOc+NGrUSKmpqQoNDVVycrLOnDmjDz74QElJSbp+/bocHBzk6Oio1NRUffXVV9q1a5dlHwAAQM7ECB0AAGCYgIAALVu2TKGhoWrevLkSEhJUuHBhPffcc+rVq5ccHR0t25YsWVJvvvmmhg0bpoSEBHl7e+vFF1/U5MmTdezYMT377LM6deqU+vTpo5iYGBUqVEhvvfWWqlatqkqVKikyMlIvvfSSrl+/Ll9fX02dOlXe3t73zNijRw+lpqaqe/fuio2NVeXKlTV//ny5u7vrgw8+0LRp0zRu3DgVKlRIL774ok6cOKFjx47piSeeUJs2bTRmzBj99ttvWrFihZYsWaKJEydqwYIFSk9PV2BgoObMmSNJqly5st577z2NGTNGMTExqlmzpurUqWN5DLp166b09HQNGTJEly9fVokSJTRlyhQFBATccx8KFCighQsXasKECVq8eLFcXV3VsWNHtW/fXlevXtWxY8fUuHFjOTs7q2LFiurQoYPCw8Mf8lkFAADZwWRmgjQAAIDhTp48qfT0dJUqVcqybMCAASpZsuR9X8AZAADkHUy5AgAAyAFOnDihLl266MyZM5KkvXv3ateuXWrYsKHByQAAQE7ECB0AAJBnLV68WNOnT7/j+pYtW+r999/Ptjxz5szRypUrFRsbK19fX/Xq1UstW7bMtvsHAAC2g0IHAAAAAADAxjDlCgAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxvwfQiGAdt1L2QAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1150.62x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analysis of the class balancing\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "gTitle = f'{nom_dataset} - Number of classes = ' + str(len(pd.Series(DB['Class_categorical']).unique()))\n",
    "g = sns.displot(DB,x='Class_categorical', hue='Class_categorical',height = 5, aspect = 2).set(title=gTitle)\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set_titles('Number of classes')\n",
    "\n",
    "# Retrieve the axes object from the plot\n",
    "axes = g.ax\n",
    "\n",
    "# Iterate over each bar in the plot\n",
    "for p in axes.patches:\n",
    "    # Get the coordinates of the bar\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    cord_x, cord_y = p.get_xy()\n",
    "    if height > 0:\n",
    "        axes.annotate(f'{height}', (cord_x + width/2, cord_y + height), ha='center')\n",
    "        \n",
    "g._legend.remove()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1-) Features original\n",
      "2-) Features augmented\n",
      "3-) Features augmented and windowed (US8K is only windowed)\n",
      "\n",
      "Select the dataset: 2\n"
     ]
    }
   ],
   "source": [
    "# Read the pkl file with the augmented features extracted\n",
    "\n",
    "opc = 0\n",
    "while str(opc) not in '123':\n",
    "    print()\n",
    "    print(\"1-) Features original\")\n",
    "    print(\"2-) Features augmented\")\n",
    "    print(\"3-) Features augmented and windowed (US8K is only windowed)\")\n",
    "\n",
    "    opc = input(\"\\nSelect the dataset: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "\n",
    "if opc == 1:\n",
    "    DB_from_pkl      = pd.read_pickle(os.path.join(path_models, pkl_features_CNN_2D))\n",
    "    model_surname    = '_original'\n",
    "\n",
    "elif opc == 2:\n",
    "    DB_from_pkl      = pd.read_pickle(os.path.join(path_models, pkl_aug_features_CNN_2D))\n",
    "    model_surname    = '_augmented'\n",
    "\n",
    "elif opc == 3:\n",
    "    DB_from_pkl      = pd.read_pickle(os.path.join(path_models, pkl_aug_wind_features_CNN_2D))\n",
    "    model_surname    = '_windowed'\n",
    "    \n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_categorical</th>\n",
       "      <th>Class_OHEV</th>\n",
       "      <th>Fold</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog_bark</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[-44.0467643737793], [-39.25644302368164], [-38.62413787841797], [-36.58848571777344], [-32.5598030090332], [-31.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog_bark</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[-47.09422302246094], [-42.41543197631836], [-42.184661865234375], [-40.20640182495117], [-38.634029388427734], [-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog_bark</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[-44.166175842285156], [-39.65951919555664], [-40.44279479980469], [-38.40540313720703], [-35.72234344482422], [-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog_bark</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[-42.92694854736328], [-39.34496307373047], [-38.55472183227539], [-35.95314025878906], [-33.04743194580078], [-33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dog_bark</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[-47.5416259765625], [-43.15168380737305], [-41.6463508605957], [-39.49897003173828], [-36.66865158081055], [-34.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26143</th>\n",
       "      <td>car_horn</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[-14.898265838623047], [-11.679378509521484], [-10.258830070495605], [-8.828937530517578], [-11.271302223205566], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26144</th>\n",
       "      <td>car_horn</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[-11.867830276489258], [-8.616534233093262], [-9.279485702514648], [-12.071174621582031], [-13.651904106140137], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26145</th>\n",
       "      <td>car_horn</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[-12.172089576721191], [-9.088859558105469], [-8.40767765045166], [-10.63945198059082], [-11.134468078613281], [-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26146</th>\n",
       "      <td>car_horn</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[-18.028657913208008], [-15.86125373840332], [-16.575408935546875], [-15.176151275634766], [-13.415931701660156], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26147</th>\n",
       "      <td>car_horn</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[-9.517300605773926], [-6.2735795974731445], [-5.663743495941162], [-6.405637264251709], [-10.28356647491455], [-7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26148 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class_categorical       Class_OHEV Fold                                                                                                                 features\n",
       "0              dog_bark  [0, 0, 0, 1, 0]    5  [[[-44.0467643737793], [-39.25644302368164], [-38.62413787841797], [-36.58848571777344], [-32.5598030090332], [-31.4...\n",
       "1              dog_bark  [0, 0, 0, 1, 0]    5  [[[-47.09422302246094], [-42.41543197631836], [-42.184661865234375], [-40.20640182495117], [-38.634029388427734], [-...\n",
       "2              dog_bark  [0, 0, 0, 1, 0]    5  [[[-44.166175842285156], [-39.65951919555664], [-40.44279479980469], [-38.40540313720703], [-35.72234344482422], [-3...\n",
       "3              dog_bark  [0, 0, 0, 1, 0]    5  [[[-42.92694854736328], [-39.34496307373047], [-38.55472183227539], [-35.95314025878906], [-33.04743194580078], [-33...\n",
       "4              dog_bark  [0, 0, 0, 1, 0]    5  [[[-47.5416259765625], [-43.15168380737305], [-41.6463508605957], [-39.49897003173828], [-36.66865158081055], [-34.1...\n",
       "...                 ...              ...  ...                                                                                                                      ...\n",
       "26143          car_horn  [0, 1, 0, 0, 0]    7  [[[-14.898265838623047], [-11.679378509521484], [-10.258830070495605], [-8.828937530517578], [-11.271302223205566], ...\n",
       "26144          car_horn  [0, 1, 0, 0, 0]    7  [[[-11.867830276489258], [-8.616534233093262], [-9.279485702514648], [-12.071174621582031], [-13.651904106140137], [...\n",
       "26145          car_horn  [0, 1, 0, 0, 0]    7  [[[-12.172089576721191], [-9.088859558105469], [-8.40767765045166], [-10.63945198059082], [-11.134468078613281], [-1...\n",
       "26146          car_horn  [0, 1, 0, 0, 0]    7  [[[-18.028657913208008], [-15.86125373840332], [-16.575408935546875], [-15.176151275634766], [-13.415931701660156], ...\n",
       "26147          car_horn  [0, 1, 0, 0, 0]    7  [[[-9.517300605773926], [-6.2735795974731445], [-5.663743495941162], [-6.405637264251709], [-10.28356647491455], [-7...\n",
       "\n",
       "[26148 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_from_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1150.62x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analysis of the class balancing\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "gTitle = f'{nom_dataset} - Number of classes = ' + str(len(pd.Series(DB_from_pkl['Class_categorical']).unique()))\n",
    "g = sns.displot(DB_from_pkl,x='Class_categorical', hue='Class_categorical',height = 5, aspect = 2).set(title=gTitle)\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set_titles('Number of classes')\n",
    "\n",
    "# Retrieve the axes object from the plot\n",
    "axes = g.ax\n",
    "\n",
    "# Iterate over each bar in the plot\n",
    "for p in axes.patches:\n",
    "    # Get the coordinates of the bar\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    cord_x, cord_y = p.get_xy()\n",
    "    if height > 0:\n",
    "        axes.annotate(f'{height}', (cord_x + width/2, cord_y + height), ha='center')\n",
    "        \n",
    "g._legend.remove()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation fold: 1\n",
      "dbComplete_VAL size: 2580\n",
      "dbComplete_TRN size: 23568\n",
      "\n",
      "Validation fold: 10\n",
      "dbComplete_VAL size: 2514\n",
      "dbComplete_TRN size: 23634\n",
      "\n",
      "Validation fold: 2\n",
      "dbComplete_VAL size: 2574\n",
      "dbComplete_TRN size: 23574\n",
      "\n",
      "Validation fold: 3\n",
      "dbComplete_VAL size: 2892\n",
      "dbComplete_TRN size: 23256\n",
      "\n",
      "Validation fold: 4\n",
      "dbComplete_VAL size: 3234\n",
      "dbComplete_TRN size: 22914\n",
      "\n",
      "Validation fold: 5\n",
      "dbComplete_VAL size: 2808\n",
      "dbComplete_TRN size: 23340\n",
      "\n",
      "Validation fold: 6\n",
      "dbComplete_VAL size: 2400\n",
      "dbComplete_TRN size: 23748\n",
      "\n",
      "Validation fold: 7\n",
      "dbComplete_VAL size: 2430\n",
      "dbComplete_TRN size: 23718\n",
      "\n",
      "Validation fold: 8\n",
      "dbComplete_VAL size: 2340\n",
      "dbComplete_TRN size: 23808\n",
      "\n",
      "Validation fold: 9\n",
      "dbComplete_VAL size: 2376\n",
      "dbComplete_TRN size: 23772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold in np.unique(DB_from_pkl['Fold']):\n",
    "    print(f\"Validation fold: {fold}\")\n",
    "    \n",
    "    valsize = len(DB_from_pkl[DB_from_pkl['Fold'] == fold])\n",
    "    trnsize = len(DB_from_pkl[DB_from_pkl['Fold'] != fold])\n",
    "    print(f'dbComplete_VAL size: {valsize}')\n",
    "    print(f'dbComplete_TRN size: {trnsize}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class_categorical    object\n",
       "Class_OHEV           object\n",
       "Fold                 object\n",
       "features             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_from_pkl.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_from_pkl['Class_OHEV'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26148,)\n",
      "(5,)\n",
      "(180, 173, 1)\n"
     ]
    }
   ],
   "source": [
    "print(DB_from_pkl['Fold'].shape)\n",
    "print(DB_from_pkl['Class_OHEV'][0].shape)\n",
    "print(DB_from_pkl['features'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'numpy.int32'>\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(DB_from_pkl['Fold'][0][0]))\n",
    "print(type(DB_from_pkl['Class_OHEV'][0][0]))\n",
    "print(type(DB_from_pkl['features'][0][0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class_categorical       \n",
      "background         2800     [1, 0, 0, 0, 0]\n",
      "car_horn           12950    [0, 1, 0, 0, 0]\n",
      "children_playing   10391    [0, 0, 1, 0, 0]\n",
      "dog_bark           25763    [0, 0, 0, 1, 0]\n",
      "siren              7919     [0, 0, 0, 0, 1]\n",
      "Name: Class_OHEV, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'background': array([1, 0, 0, 0, 0]),\n",
       " 'car_horn': array([0, 1, 0, 0, 0]),\n",
       " 'children_playing': array([0, 0, 1, 0, 0]),\n",
       " 'dog_bark': array([0, 0, 0, 1, 0]),\n",
       " 'siren': array([0, 0, 0, 0, 1])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by the class and get one random sample of each class\n",
    "k = DB_from_pkl.groupby('Class_categorical')['Class_OHEV'].apply(lambda s: s.sample(1))\n",
    "print(k)\n",
    "\n",
    "# Convert the pandas series into a dataframe\n",
    "temp_k_df = k.reset_index()\n",
    "\n",
    "# Delete the index from the grouppby result\n",
    "del temp_k_df['level_1']\n",
    "\n",
    "# Set the \"Class\" as the dataframe index\n",
    "temp_k_df.set_index(\"Class_categorical\", inplace=True)\n",
    "\n",
    "# Convert the dataframe to a dictionary (Class: Class_encoder)\n",
    "encoder_dict = temp_k_df[\"Class_OHEV\"].to_dict()\n",
    "encoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of classes in the dataset\n",
    "\n",
    "num_classes = len(encoder_dict.keys())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['background', 'car_horn', 'children_playing', 'dog_bark', 'siren']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name of the classes\n",
    "\n",
    "nom_classes = list(encoder_dict.keys())\n",
    "nom_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate 1 fold for validation and create a DB for the training / testing\n",
    "\n",
    "DB_from_pkl_VAL = DB_from_pkl[DB_from_pkl['Fold'] == fold].copy()\n",
    "DB_from_pkl_TRN = DB_from_pkl[DB_from_pkl['Fold'] != fold].copy()\n",
    "\n",
    "X      = DB_from_pkl_TRN['features'].to_numpy()\n",
    "y      = np.array(DB_from_pkl_TRN.Class_categorical.to_list())\n",
    "y_OHEV = np.array(DB_from_pkl_TRN.Class_OHEV.to_list())\n",
    "\n",
    "X_val      = DB_from_pkl_VAL['features'].to_numpy()\n",
    "y_val      = np.array(DB_from_pkl_VAL.Class_categorical.to_list())\n",
    "y_OHEV_val = np.array(DB_from_pkl_VAL.Class_OHEV.to_list())\n",
    "\n",
    "\n",
    "# Stackup and pass all values to float32\n",
    "X = np.stack(X)\n",
    "X = np.asarray(X).astype(np.float32)\n",
    "\n",
    "X_val = np.stack(X_val)\n",
    "X_val = np.asarray(X_val).astype(np.float32)\n",
    "\n",
    "y_OHEV     = np.asarray(y_OHEV).astype(np.float32)\n",
    "y_OHEV_val = np.asarray(y_OHEV_val).astype(np.float32)\n",
    "\n",
    "\n",
    "# Retrieve the indexes used for training the classifiers\n",
    "idx_trn = np.genfromtxt(os.path.join(path_models, '_idx_trn_' + nom_dataset + model_surname + '.csv'), delimiter=',', dtype = int)\n",
    "idx_tst = np.genfromtxt(os.path.join(path_models, '_idx_tst_' + nom_dataset + model_surname + '.csv'), delimiter=',', dtype = int)\n",
    "\n",
    "X_train      = X[idx_trn]\n",
    "X_test       = X[idx_tst]\n",
    "y_train      = y[idx_trn]\n",
    "y_test       = y[idx_tst]\n",
    "y_train_OHEV = y_OHEV[idx_trn]\n",
    "y_test_OHEV  = y_OHEV[idx_tst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21211, 180, 173, 1)\n",
      "y_train.........: (21211,)\n",
      "y_train_OHEV....: (21211, 5)\n",
      "\n",
      "==================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2357, 180, 173, 1)\n",
      "y_test..........: (2357,)\n",
      "y_test_OHEV.....: (2357, 5)\n",
      "\n",
      "==================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2376, 180, 173, 1)\n",
      "y_val...........: (2376,)\n",
      "y_OHEV_val......: (2376, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n==================================\")\n",
    "print(\"Training set\\n\")\n",
    "\n",
    "print(f'X_train.........: {np.shape(X_train)}')\n",
    "print(f'y_train.........: {np.shape(y_train)}')\n",
    "print(f'y_train_OHEV....: {np.shape(y_train_OHEV)}')\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Testing set\\n\")\n",
    "\n",
    "print(f'X_test..........: {np.shape(X_test)}')\n",
    "print(f'y_test..........: {np.shape(y_test)}')\n",
    "print(f'y_test_OHEV.....: {np.shape(y_test_OHEV)}')\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Validation set\\n\")\n",
    "\n",
    "print(f'X_val...........: {np.shape(X_val)}')\n",
    "print(f'y_val...........: {np.shape(y_val)}')\n",
    "print(f'y_OHEV_val......: {np.shape(y_OHEV_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple confusion matrix\n",
    "\n",
    "def simple_conf_matrix(y_true, y_pred, nom_classes, clf, acc):\n",
    "    \n",
    "    picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "    conf_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "    title = nom_dataset + model_surname + norm_type + ' - Classifier ' + clf + ' - Validation accuracy: '+ str(\"{:0.2f} %\".format(acc*100))\n",
    "\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sns.heatmap(conf_matrix, \n",
    "                annot=True, \n",
    "                fmt='g', \n",
    "                cmap=cmap_cm, \n",
    "                annot_kws={\"size\": 8}, \n",
    "                xticklabels=nom_classes, \n",
    "                yticklabels=nom_classes)\n",
    "    plt.title(title, fontsize = 12)\n",
    "    plt.savefig(os.path.join(path_pic, picture_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title, cmap, normalize):\n",
    "\n",
    "    if labels is not None:\n",
    "        tick_marks = np.arange(len(labels))\n",
    "        plt.xticks(tick_marks, labels, fontsize=10, rotation=45)\n",
    "        plt.yticks(tick_marks, labels, fontsize=10)\n",
    "   \n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 8)\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 8)\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title, fontsize=13)\n",
    "    plt.colorbar(shrink=1)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(None)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G41d4lWCSIXW"
   },
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Convolutional Neural Networks** (CNNs) are a class of deep learning algorithms specifically designed for processing grid-like data, such as images and videos. CNNs are highly effective in tasks related to computer vision, including image recognition, object detection, and image segmentation. They are characterized by their ability to automatically and adaptively learn spatial hierarchies of features from input data. CNNs consist of multiple layers, including convolutional layers, pooling layers, and fully connected layers. The convolutional layers apply convolution operations to the input data, enabling the network to automatically learn patterns and features from images, such as edges, textures, and more complex structures. The pooling layers downsample the spatial dimensions of the data, reducing computational complexity while retaining important features. Fully connected layers at the end of the network process the learned features and make predictions based on them. One of the significant advantages of CNNs is their ability to capture local patterns and spatial hierarchies of features. By using shared weights and biases in the convolutional layers, CNNs are capable of learning translation-invariant features, making them well-suited for tasks where the spatial arrangement of features in the input data is essential. Additionally, CNNs can automatically learn relevant features from raw pixel values, eliminating the need for manual feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 173, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputShape = X_train[0].shape\n",
    "inputShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjU1o2LPQ8Qi"
   },
   "outputs": [],
   "source": [
    "# Architecture based on Su et al. (2019)\n",
    "\n",
    "def basemodel_Su(model_name):\n",
    "       \n",
    "    model = Sequential(name = model_name)\n",
    "    \n",
    "    # Input is 44 x 180\n",
    "    # If we have N x N image size and F x F filter size, afer the convolution the result will be\n",
    "    # (N x N) * (F x F) = (N - F + 1) x (N - F + 1)\n",
    "    # (44 - 7 + 1) x (180 - 7 + 1) = (38 x 174)\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(inputShape), padding='same', strides=(2,2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), strides=(2,2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten(name='Flatten'))\n",
    "\n",
    "    model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    epochs  = 100\n",
    "    lrate   = 0.001\n",
    "    decay   = lrate/epochs\n",
    "    sgd     = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture based on Luz et al. (2021)\n",
    "\n",
    "def basemodel_Luz(model_name):\n",
    "       \n",
    "    model = Sequential(name = model_name)\n",
    "    \n",
    "    model.add(Conv2D(24, (5, 5), input_shape=(inputShape), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(48, (5, 5), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(48, (5, 5), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(48, (5, 5), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten(name='Flatten'))\n",
    "\n",
    "    model.add(Dense(64, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    epochs  = 100\n",
    "    lrate   = 0.001\n",
    "    decay   = lrate/epochs\n",
    "    sgd     = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-kw6vXfvbsx"
   },
   "outputs": [],
   "source": [
    "monitor = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=20, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "if not os.path.exists(path_models):\n",
    "    os.makedirs(path_models)\n",
    "\n",
    "filepath       = os.path.join(path_models, 'Model_CNN_2D_weights_0_best' + model_surname + '.hdf5')\n",
    "checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint, monitor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "lw99-PBBaMkh",
    "outputId": "ff226441-ccbe-4ee2-8392-728db38108c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1-) Architecture based on Su et al. (2019)\n",
      "2-) Architecture based on Luz et al. (2021)\n",
      "\n",
      "Select the model: 2\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Select the model\n",
    "\n",
    "opc = 0\n",
    "while str(opc) not in '12':\n",
    "    print()\n",
    "    print(\"1-) Architecture based on Su et al. (2019)\")\n",
    "    print(\"2-) Architecture based on Luz et al. (2021)\")\n",
    "\n",
    "    opc = input(\"\\nSelect the model: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "\n",
    "if opc == 1:\n",
    "    basemodel = basemodel_Su\n",
    "    surName = '_Su'\n",
    "\n",
    "elif opc == 2:\n",
    "    basemodel = basemodel_Luz\n",
    "    surName = '_Luz'\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n",
    "Model_CNN_2D = basemodel('Model_CNN_2D' + surName)\n",
    "print(Model_CNN_2D.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(Model_CNN_2D, to_file= os.path.join(path_models, 'Model_CNN_2D' + model_surname + '.png'), show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the column \"Param\":\n",
    "\n",
    "1. For `Conv1D` layer:\n",
    "   - The number of parameters for a `Conv1D` layer is calculated as `(kernel_size * input_channels + 1) * output_channels`, where `kernel_size` is the size of the convolutional kernel, `input_channels` is the number of input channels (1 in this case), and `output_channels` is the number of output channels.\n",
    "\n",
    "2. For `Dense` layer:\n",
    "   - The number of parameters for a `Dense` layer is calculated as `(input_units + 1) * output_units`, where `input_units` is the number of input units and `output_units` is the number of output units.\n",
    "   \n",
    "3. In the calculation of parameters for a convolutional layer, the term \"channels\" refers to the number of filters used in that layer.\n",
    "4. Params = (filter_height * filter_width * input_channels + 1) * number_of_filters\n",
    "\n",
    "\n",
    "- 624   parameters is the result of 24 filters * (5 kernels * 5 kernels * 1 channel + 1)\n",
    "- 28,848 parameters is the result of 48 filter * (5 kernels * 5 kernels * 24 channels + 1)\n",
    "- 57,648 parameters is the result of 48 filter * (5 kernels * 5 kernels * 48 channels + 1)\n",
    "- 57,648 parameters is the result of 48 filter * (5 kernels * 5 kernels * 48 channels + 1)\n",
    "- 67,648  parameters is the result of 64 neurons with 1,056 features + 64 bias values\n",
    "- 8,320  parameters is the result of 128 neurons with 64 features + 128 bias values\n",
    "- 645  parameters is the result of 5 neurons with 128 features + 5 bias values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cx0OsC7UNwui"
   },
   "source": [
    "### CNN 2D adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21211, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21211, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2357, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2357, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2376, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2376, 5) .............type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n========================================================================\")\n",
    "print(\"Training set\\n\")\n",
    "\n",
    "print(f'X_train.........: {np.shape(X_train)} ...type: {type(X_train[0][0][0][0])}')\n",
    "print(f'y_train_OHEV....: {np.shape(y_train_OHEV)} ............type: {type(y_train_OHEV[0][0])}')\n",
    "\n",
    "print(\"\\n========================================================================\")\n",
    "print(\"Testing set\\n\")\n",
    "\n",
    "print(f'X_test..........: {np.shape(X_test)} ....type: {type(X_test[0][0][0][0])}')\n",
    "print(f'y_test_OHEV.....: {np.shape(y_test_OHEV)} .............type: {type(y_test_OHEV[0][0])}')\n",
    "\n",
    "print(\"\\n========================================================================\")\n",
    "print(\"Validation set\\n\")\n",
    "\n",
    "print(f'X_val...........: {np.shape(X_val)} ....type: {type(X_val[0][0][0][0])}')\n",
    "print(f'y_OHEV_val......: {np.shape(y_OHEV_val)} .............type: {type(y_OHEV_val[0][0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/663 [..............................] - ETA: 20s - loss: 2.0570 - accuracy: 0.2500WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0219s vs `on_train_batch_end` time: 0.0409s). Check your callbacks.\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.9423 - accuracy: 0.6512\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.81502, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 43s 65ms/step - loss: 0.9423 - accuracy: 0.6512 - val_loss: 0.5881 - val_accuracy: 0.8150\n",
      "Epoch 2/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.5495 - accuracy: 0.8123\n",
      "Epoch 00002: val_accuracy improved from 0.81502 to 0.85872, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 42s 64ms/step - loss: 0.5495 - accuracy: 0.8123 - val_loss: 0.3930 - val_accuracy: 0.8587\n",
      "Epoch 3/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.3932 - accuracy: 0.8654\n",
      "Epoch 00003: val_accuracy improved from 0.85872 to 0.89436, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 44s 66ms/step - loss: 0.3932 - accuracy: 0.8654 - val_loss: 0.2865 - val_accuracy: 0.8944\n",
      "Epoch 4/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.3060 - accuracy: 0.8965\n",
      "Epoch 00004: val_accuracy improved from 0.89436 to 0.89860, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 45s 67ms/step - loss: 0.3060 - accuracy: 0.8965 - val_loss: 0.2737 - val_accuracy: 0.8986\n",
      "Epoch 5/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2454 - accuracy: 0.9174\n",
      "Epoch 00005: val_accuracy improved from 0.89860 to 0.95630, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 45s 68ms/step - loss: 0.2454 - accuracy: 0.9174 - val_loss: 0.1393 - val_accuracy: 0.9563\n",
      "Epoch 6/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1954 - accuracy: 0.9346\n",
      "Epoch 00006: val_accuracy did not improve from 0.95630\n",
      "663/663 [==============================] - 45s 68ms/step - loss: 0.1954 - accuracy: 0.9346 - val_loss: 0.1419 - val_accuracy: 0.9499\n",
      "Epoch 7/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 0.9434\n",
      "Epoch 00007: val_accuracy did not improve from 0.95630\n",
      "663/663 [==============================] - 42s 64ms/step - loss: 0.1639 - accuracy: 0.9434 - val_loss: 0.1394 - val_accuracy: 0.9491\n",
      "Epoch 8/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.9506\n",
      "Epoch 00008: val_accuracy did not improve from 0.95630\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.1472 - accuracy: 0.9506 - val_loss: 0.1840 - val_accuracy: 0.9389\n",
      "Epoch 9/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9587\n",
      "Epoch 00009: val_accuracy improved from 0.95630 to 0.96436, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.1166 - accuracy: 0.9587 - val_loss: 0.1164 - val_accuracy: 0.9644\n",
      "Epoch 10/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.9652\n",
      "Epoch 00010: val_accuracy improved from 0.96436 to 0.97285, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0996 - accuracy: 0.9652 - val_loss: 0.0944 - val_accuracy: 0.9728\n",
      "Epoch 11/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 0.9694\n",
      "Epoch 00011: val_accuracy improved from 0.97285 to 0.97454, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0899 - accuracy: 0.9694 - val_loss: 0.0931 - val_accuracy: 0.9745\n",
      "Epoch 12/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9732\n",
      "Epoch 00012: val_accuracy did not improve from 0.97454\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0786 - accuracy: 0.9732 - val_loss: 0.0952 - val_accuracy: 0.9699\n",
      "Epoch 13/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9747\n",
      "Epoch 00013: val_accuracy did not improve from 0.97454\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0727 - accuracy: 0.9747 - val_loss: 0.1257 - val_accuracy: 0.9614\n",
      "Epoch 14/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0617 - accuracy: 0.9799\n",
      "Epoch 00014: val_accuracy did not improve from 0.97454\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0617 - accuracy: 0.9799 - val_loss: 0.1109 - val_accuracy: 0.9661\n",
      "Epoch 15/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9827\n",
      "Epoch 00015: val_accuracy did not improve from 0.97454\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0489 - accuracy: 0.9827 - val_loss: 0.1074 - val_accuracy: 0.9686\n",
      "Epoch 16/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9850\n",
      "Epoch 00016: val_accuracy improved from 0.97454 to 0.97794, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0448 - accuracy: 0.9850 - val_loss: 0.0703 - val_accuracy: 0.9779\n",
      "Epoch 17/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 0.9869\n",
      "Epoch 00017: val_accuracy did not improve from 0.97794\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0398 - accuracy: 0.9869 - val_loss: 0.0656 - val_accuracy: 0.9775\n",
      "Epoch 18/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9844\n",
      "Epoch 00018: val_accuracy did not improve from 0.97794\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0474 - accuracy: 0.9844 - val_loss: 0.0973 - val_accuracy: 0.9741\n",
      "Epoch 19/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9889\n",
      "Epoch 00019: val_accuracy improved from 0.97794 to 0.98176, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0348 - accuracy: 0.9889 - val_loss: 0.0656 - val_accuracy: 0.9818\n",
      "Epoch 20/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9900\n",
      "Epoch 00020: val_accuracy did not improve from 0.98176\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0325 - accuracy: 0.9900 - val_loss: 0.0711 - val_accuracy: 0.9762\n",
      "Epoch 21/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9912\n",
      "Epoch 00021: val_accuracy improved from 0.98176 to 0.98260, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.0723 - val_accuracy: 0.9826\n",
      "Epoch 22/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9916\n",
      "Epoch 00022: val_accuracy did not improve from 0.98260\n",
      "663/663 [==============================] - 43s 64ms/step - loss: 0.0270 - accuracy: 0.9916 - val_loss: 0.1266 - val_accuracy: 0.9656\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663/663 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9922\n",
      "Epoch 00023: val_accuracy did not improve from 0.98260\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0243 - accuracy: 0.9922 - val_loss: 0.0945 - val_accuracy: 0.9750\n",
      "Epoch 24/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9910\n",
      "Epoch 00024: val_accuracy did not improve from 0.98260\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 0.2055 - val_accuracy: 0.9555\n",
      "Epoch 25/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9932\n",
      "Epoch 00025: val_accuracy did not improve from 0.98260\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0230 - accuracy: 0.9932 - val_loss: 0.0771 - val_accuracy: 0.9805\n",
      "Epoch 26/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9921\n",
      "Epoch 00026: val_accuracy did not improve from 0.98260\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.0745 - val_accuracy: 0.9826\n",
      "Epoch 27/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9908\n",
      "Epoch 00027: val_accuracy did not improve from 0.98260\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0265 - accuracy: 0.9908 - val_loss: 0.0976 - val_accuracy: 0.9762\n",
      "Epoch 28/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9937\n",
      "Epoch 00028: val_accuracy improved from 0.98260 to 0.98345, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.0771 - val_accuracy: 0.9835\n",
      "Epoch 29/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 0.9941\n",
      "Epoch 00029: val_accuracy improved from 0.98345 to 0.98473, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0196 - accuracy: 0.9941 - val_loss: 0.0750 - val_accuracy: 0.9847\n",
      "Epoch 30/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9934\n",
      "Epoch 00030: val_accuracy did not improve from 0.98473\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.0691 - val_accuracy: 0.9830\n",
      "Epoch 31/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9948\n",
      "Epoch 00031: val_accuracy improved from 0.98473 to 0.98557, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0700 - val_accuracy: 0.9856\n",
      "Epoch 32/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9953\n",
      "Epoch 00032: val_accuracy did not improve from 0.98557\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 0.1310 - val_accuracy: 0.9750\n",
      "Epoch 33/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9946\n",
      "Epoch 00033: val_accuracy did not improve from 0.98557\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.0736 - val_accuracy: 0.9835\n",
      "Epoch 34/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9954\n",
      "Epoch 00034: val_accuracy did not improve from 0.98557\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0128 - accuracy: 0.9954 - val_loss: 0.0944 - val_accuracy: 0.9762\n",
      "Epoch 35/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9955\n",
      "Epoch 00035: val_accuracy did not improve from 0.98557\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.1884 - val_accuracy: 0.9639\n",
      "Epoch 36/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9953\n",
      "Epoch 00036: val_accuracy did not improve from 0.98557\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0143 - accuracy: 0.9953 - val_loss: 0.1053 - val_accuracy: 0.9784\n",
      "Epoch 37/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9956\n",
      "Epoch 00037: val_accuracy did not improve from 0.98557\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0718 - val_accuracy: 0.9852\n",
      "Epoch 38/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9946\n",
      "Epoch 00038: val_accuracy did not improve from 0.98557\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.0694 - val_accuracy: 0.9856\n",
      "Epoch 39/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9968\n",
      "Epoch 00039: val_accuracy did not improve from 0.98557\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.1174 - val_accuracy: 0.9775\n",
      "Epoch 40/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9957\n",
      "Epoch 00040: val_accuracy did not improve from 0.98557\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.0740 - val_accuracy: 0.9856\n",
      "Epoch 41/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9950\n",
      "Epoch 00041: val_accuracy did not improve from 0.98557\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0195 - accuracy: 0.9950 - val_loss: 0.1028 - val_accuracy: 0.9775\n",
      "Epoch 42/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 0.9967\n",
      "Epoch 00042: val_accuracy improved from 0.98557 to 0.98685, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0725 - val_accuracy: 0.9868\n",
      "Epoch 43/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9969\n",
      "Epoch 00043: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0681 - val_accuracy: 0.9843\n",
      "Epoch 44/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9969\n",
      "Epoch 00044: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.1013 - val_accuracy: 0.9830\n",
      "Epoch 45/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9975\n",
      "Epoch 00045: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0776 - val_accuracy: 0.9843\n",
      "Epoch 46/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9978\n",
      "Epoch 00046: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0784 - val_accuracy: 0.9864\n",
      "Epoch 47/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9979\n",
      "Epoch 00047: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0059 - accuracy: 0.9979 - val_loss: 0.0745 - val_accuracy: 0.9860\n",
      "Epoch 48/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9973\n",
      "Epoch 00048: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0774 - val_accuracy: 0.9852\n",
      "Epoch 49/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9976\n",
      "Epoch 00049: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.0734 - val_accuracy: 0.9856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9975\n",
      "Epoch 00050: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0067 - accuracy: 0.9975 - val_loss: 0.1575 - val_accuracy: 0.9724\n",
      "Epoch 51/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9975\n",
      "Epoch 00051: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 44s 66ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.0833 - val_accuracy: 0.9839\n",
      "Epoch 52/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9975\n",
      "Epoch 00052: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.0855 - val_accuracy: 0.9868\n",
      "Epoch 53/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 00053: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1107 - val_accuracy: 0.9771\n",
      "Epoch 54/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9982\n",
      "Epoch 00054: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.1375 - val_accuracy: 0.9792\n",
      "Epoch 55/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 00055: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0935 - val_accuracy: 0.9835\n",
      "Epoch 56/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9969\n",
      "Epoch 00056: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0920 - val_accuracy: 0.9830\n",
      "Epoch 57/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9978\n",
      "Epoch 00057: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 43s 65ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0912 - val_accuracy: 0.9813\n",
      "Epoch 58/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 00058: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0724 - val_accuracy: 0.9864\n",
      "Epoch 59/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 00059: val_accuracy improved from 0.98685 to 0.99194, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0608 - val_accuracy: 0.9919\n",
      "Epoch 60/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9979\n",
      "Epoch 00060: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0931 - val_accuracy: 0.9822\n",
      "Epoch 61/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9977\n",
      "Epoch 00061: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.1710 - val_accuracy: 0.9699\n",
      "Epoch 62/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9963\n",
      "Epoch 00062: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.0801 - val_accuracy: 0.9847\n",
      "Epoch 63/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n",
      "Epoch 00063: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0658 - val_accuracy: 0.9881\n",
      "Epoch 64/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9991\n",
      "Epoch 00064: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0710 - val_accuracy: 0.9868\n",
      "Epoch 65/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 00065: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0609 - val_accuracy: 0.9885\n",
      "Epoch 66/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 00066: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.1330 - val_accuracy: 0.9775\n",
      "Epoch 67/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9978\n",
      "Epoch 00067: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0829 - val_accuracy: 0.9860\n",
      "Epoch 68/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9981\n",
      "Epoch 00068: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 0.0645 - val_accuracy: 0.9902\n",
      "Epoch 69/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9980\n",
      "Epoch 00069: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0922 - val_accuracy: 0.9847\n",
      "Epoch 70/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9978\n",
      "Epoch 00070: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0616 - val_accuracy: 0.9894\n",
      "Epoch 71/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9981\n",
      "Epoch 00071: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0964 - val_accuracy: 0.9822\n",
      "Epoch 72/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch 00072: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0666 - val_accuracy: 0.9873\n",
      "Epoch 73/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 00073: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0855 - val_accuracy: 0.9864\n",
      "Epoch 74/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 00074: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0897 - val_accuracy: 0.9864\n",
      "Epoch 75/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 00075: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0720 - val_accuracy: 0.9885\n",
      "Epoch 76/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 00076: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0937 - val_accuracy: 0.9856\n",
      "Epoch 77/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9985\n",
      "Epoch 00077: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0994 - val_accuracy: 0.9796\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663/663 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 00078: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0836 - val_accuracy: 0.9885\n",
      "Epoch 79/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00079: val_accuracy did not improve from 0.99194\n",
      "Restoring model weights from the end of the best epoch.\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0900 - val_accuracy: 0.9890\n",
      "Epoch 00079: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs     = 100\n",
    "history    = Model_CNN_2D.fit(X_train, y_train_OHEV,\n",
    "                              batch_size      = batch_size,\n",
    "                              epochs          = epochs,\n",
    "                              verbose         = 1,\n",
    "                              validation_data = (X_test, y_test_OHEV),\n",
    "                              steps_per_epoch=int(np.ceil(X_train.shape[0] / float(batch_size))),\n",
    "                              callbacks       = callbacks_list,\n",
    "                              use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 2s 23ms/step - loss: 0.6584 - accuracy: 0.9129\n",
      "Test loss: 0.6583688855171204\n",
      "Test accuracy: 0.9128788113594055\n"
     ]
    }
   ],
   "source": [
    "score_CNN_2D = Model_CNN_2D.evaluate(X_val, y_OHEV_val, verbose=1, batch_size = batch_size)\n",
    "print('Test loss:', score_CNN_2D[0])\n",
    "print('Test accuracy:', score_CNN_2D[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "fig.suptitle('CNN 2D - Training / Validation loss and accuracy')\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)\n",
    "fig.tight_layout()\n",
    "plt.savefig(os.path.join(path_pic, picture_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file (not the best model though)\n",
    "\n",
    "# Model_CNN_2D.save(path_models + \"Model_CNN_2D.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_CNN_2d = np.argmax(Model_CNN_2D.predict(X_val),axis=1)\n",
    "y_pred_CNN_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_enc = np.argmax(y_OHEV_val, axis=1)\n",
    "y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9128788113594055"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_CNN_2D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.88      0.91      0.90       492\n",
      "        car_horn       0.83      0.96      0.89       192\n",
      "children_playing       0.93      0.92      0.92       600\n",
      "        dog_bark       0.94      0.82      0.88       600\n",
      "           siren       0.93      1.00      0.96       492\n",
      "\n",
      "        accuracy                           0.91      2376\n",
      "       macro avg       0.90      0.92      0.91      2376\n",
      "    weighted avg       0.92      0.91      0.91      2376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_set_CNN_2D = classification_report(y_test_enc, y_pred_CNN_2d, target_names=nom_classes)\n",
    "print(metrics_set_CNN_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the model with the highest accuracy\n",
    "\n",
    "Model_CNN_2D_saved = load_model(os.path.join(path_models, 'Model_CNN_2D_weights_0_best' + model_surname + '.hdf5'))\n",
    "Model_CNN_2D_saved.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 2s 21ms/step - loss: 0.6584 - accuracy: 0.9129\n",
      "Test loss: 0.6583688855171204\n",
      "Test accuracy: 0.9128788113594055\n"
     ]
    }
   ],
   "source": [
    "score_CNN_2D_saved = Model_CNN_2D_saved.evaluate(X_val, y_OHEV_val, verbose=1, batch_size = batch_size)\n",
    "print('Test loss:', score_CNN_2D_saved[0])\n",
    "print('Test accuracy:', score_CNN_2D_saved[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_CNN_2D_saved = np.argmax(Model_CNN_2D_saved.predict(X_val),axis=1)\n",
    "y_pred_CNN_2D_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "prob = np.round(Model_CNN_2D_saved.predict(X_val)[7],6)\n",
    "for i in prob:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.88      0.91      0.90       492\n",
      "        car_horn       0.83      0.96      0.89       192\n",
      "children_playing       0.93      0.92      0.92       600\n",
      "        dog_bark       0.94      0.82      0.88       600\n",
      "           siren       0.93      1.00      0.96       492\n",
      "\n",
      "        accuracy                           0.91      2376\n",
      "       macro avg       0.90      0.92      0.91      2376\n",
      "    weighted avg       0.92      0.91      0.91      2376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_set_CNN_2D_saved = classification_report(y_test_enc, y_pred_CNN_2D_saved, target_names=nom_classes)\n",
    "print(metrics_set_CNN_2D_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple confusion matrix\n",
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "conf_matrix = metrics.confusion_matrix(y_test_enc, y_pred_CNN_2D_saved)\n",
    "title = nom_dataset + model_surname + ' - Classifier CNN 2D (best model) - Highest accuracy test: '+ str(\"{:0.2f}%\".format(score_CNN_2D_saved[1]*100))\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True, \n",
    "            fmt='g', \n",
    "            cmap=cmap_cm, \n",
    "            annot_kws={\"size\": 8}, \n",
    "            xticklabels=nom_classes, \n",
    "            yticklabels=nom_classes)\n",
    "plt.title(title, fontsize = 12)\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x1443aa5ce50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1443aa68640>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1443aa68730>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1443aa7f700>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1443aa8af70>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1443aa99070>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1443aa99e80>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1443aa5cd60>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1443aaad940>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1443aabb8e0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1443aac6b20>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1443aad11f0>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x1443aad90d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1443aad1b80>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1443aabb730>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1443aae7d00>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1443aae7ee0>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_CNN_2D_saved.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[[-0.02657928,  0.00122943, -0.18243383,  0.2185159 ,\n",
      "           0.10634892, -0.08355007, -0.06137769,  0.1308163 ,\n",
      "          -0.02245957,  0.09941851, -0.03203182,  0.00228082,\n",
      "           0.07220789,  0.20480445, -0.06005377, -0.03854817,\n",
      "          -0.18082549,  0.04825758,  0.02615472,  0.2022339 ,\n",
      "           0.09019198, -0.06378061,  0.03902486, -0.07371221]],\n",
      "\n",
      "        [[ 0.05374381, -0.00327912, -0.04069416,  0.11426854,\n",
      "           0.07265656, -0.07873468, -0.17127992,  0.13437788,\n",
      "          -0.10212824, -0.05266235, -0.07810523,  0.05502661,\n",
      "           0.03954656,  0.32891473,  0.02086445, -0.14420463,\n",
      "          -0.05467715,  0.03189955, -0.02522521,  0.1909754 ,\n",
      "           0.10673805, -0.04950684,  0.00736467, -0.04842993]],\n",
      "\n",
      "        [[-0.10616557,  0.00689328, -0.15853515,  0.13222328,\n",
      "           0.12632588,  0.06524009, -0.19887383,  0.1575999 ,\n",
      "          -0.12320626, -0.01787262, -0.02983307, -0.05335969,\n",
      "          -0.09386978,  0.09305962,  0.20009694, -0.15936247,\n",
      "          -0.09905002,  0.01400143, -0.05111485,  0.12561315,\n",
      "           0.10859331, -0.0458694 ,  0.05480118, -0.01749467]],\n",
      "\n",
      "        [[ 0.06964477, -0.02118137, -0.03377291,  0.11671682,\n",
      "           0.12214888, -0.08607139, -0.10353884,  0.03615759,\n",
      "          -0.05323133, -0.06058783, -0.10805263,  0.07120901,\n",
      "          -0.09454253,  0.05531101,  0.10686957, -0.10414912,\n",
      "          -0.15425144, -0.0248631 , -0.01731409,  0.13074364,\n",
      "           0.12458912,  0.08901432,  0.05491448, -0.11295147]],\n",
      "\n",
      "        [[-0.03134157,  0.05642946,  0.0267103 ,  0.11730821,\n",
      "           0.16892904, -0.05776972, -0.11083291,  0.0908886 ,\n",
      "           0.05739715, -0.11764791,  0.05757975, -0.03987483,\n",
      "          -0.05725313, -0.19217205,  0.05117152,  0.0391366 ,\n",
      "          -0.16461816, -0.02625407, -0.0201596 ,  0.03455062,\n",
      "           0.13107012,  0.12535252, -0.09723216, -0.02813535]]],\n",
      "\n",
      "\n",
      "       [[[ 0.01926947,  0.05759637, -0.08315696,  0.13429604,\n",
      "          -0.15600047,  0.03329714, -0.15753634, -0.05816466,\n",
      "          -0.10160018,  0.07442621, -0.06549395, -0.01723586,\n",
      "          -0.01812979, -0.05209769,  0.07242494,  0.04302917,\n",
      "           0.22920911, -0.07319061,  0.00352087,  0.09500419,\n",
      "           0.18370904, -0.0152711 ,  0.19898432,  0.08716469]],\n",
      "\n",
      "        [[-0.05736854, -0.00819127, -0.13155612, -0.01933751,\n",
      "          -0.17376822,  0.04721243, -0.17506638, -0.08173827,\n",
      "          -0.14014769,  0.01099735,  0.05952224,  0.10913223,\n",
      "          -0.03936584,  0.06279949,  0.12192169,  0.07906447,\n",
      "           0.25318018, -0.07039407, -0.09727715,  0.13963425,\n",
      "           0.08918154, -0.09459272,  0.19692522, -0.06754226]],\n",
      "\n",
      "        [[-0.00629997,  0.08406279, -0.07807475,  0.01112242,\n",
      "          -0.13366383, -0.08436428, -0.12133734,  0.01469296,\n",
      "           0.00932719, -0.10711139, -0.10708968,  0.04121812,\n",
      "          -0.03260483,  0.19863312,  0.21917737,  0.05865564,\n",
      "           0.3021133 , -0.02818973, -0.04595653,  0.14809933,\n",
      "           0.08063217, -0.02858226,  0.19017535, -0.00494143]],\n",
      "\n",
      "        [[-0.0935975 ,  0.08291209, -0.1627232 ,  0.12826721,\n",
      "          -0.06196174, -0.05319888, -0.00893591, -0.0091209 ,\n",
      "           0.06349307, -0.09729037, -0.05885429,  0.01180321,\n",
      "           0.03657423,  0.16513553,  0.09092207, -0.09944583,\n",
      "           0.2755633 , -0.08348714, -0.07649674,  0.11563296,\n",
      "           0.16558479, -0.07953171,  0.03752744, -0.05475849]],\n",
      "\n",
      "        [[-0.08800537,  0.05453135, -0.03683842,  0.09855095,\n",
      "          -0.07900473,  0.00735583, -0.08278095, -0.00740698,\n",
      "           0.07683987, -0.09317091,  0.03895408,  0.07969464,\n",
      "           0.022141  , -0.02052341, -0.16136281, -0.08807144,\n",
      "           0.28741956,  0.00549813,  0.06037386, -0.07736474,\n",
      "           0.01838141,  0.104717  ,  0.05619528, -0.03653608]]],\n",
      "\n",
      "\n",
      "       [[[ 0.0233928 , -0.04791746, -0.09872153, -0.12288284,\n",
      "          -0.11882652,  0.01677091,  0.05398149,  0.03213944,\n",
      "          -0.01748154,  0.429486  , -0.05394698,  0.08360191,\n",
      "          -0.07239211, -0.18122603,  0.22843699, -0.04943424,\n",
      "          -0.2547335 , -0.09881905,  0.03823423,  0.01991168,\n",
      "          -0.21924566, -0.03356941,  0.29645672,  0.04708077]],\n",
      "\n",
      "        [[ 0.01431222, -0.02182979,  0.05538413, -0.06013045,\n",
      "          -0.11426935,  0.04408305, -0.00955412, -0.06060344,\n",
      "          -0.1304095 ,  0.3646114 , -0.07965386,  0.06267723,\n",
      "          -0.05659341, -0.02458952,  0.30171207,  0.02203329,\n",
      "          -0.06657474, -0.05347069,  0.01159735,  0.11079426,\n",
      "          -0.16204849, -0.14535074,  0.20475008, -0.0860534 ]],\n",
      "\n",
      "        [[ 0.0173679 ,  0.0101341 ,  0.02435916, -0.03472472,\n",
      "          -0.17061429, -0.11793758,  0.00826761,  0.00351372,\n",
      "          -0.06352022,  0.40854463,  0.01830124,  0.123742  ,\n",
      "           0.03036174,  0.1115256 ,  0.05055597,  0.1025476 ,\n",
      "          -0.10226921, -0.11352965, -0.12051348,  0.11587973,\n",
      "          -0.15302615, -0.00597726,  0.26999   ,  0.0435999 ]],\n",
      "\n",
      "        [[ 0.05783287,  0.10083172,  0.02637067, -0.10342535,\n",
      "          -0.05807353, -0.04747818,  0.0626346 , -0.04339688,\n",
      "           0.10642067,  0.29079598, -0.09680708,  0.02820318,\n",
      "          -0.10003793,  0.14082819, -0.09818067, -0.06506582,\n",
      "          -0.12268576, -0.09451052,  0.08515088, -0.02778658,\n",
      "          -0.07868725,  0.02432338,  0.09722345,  0.05828624]],\n",
      "\n",
      "        [[-0.08446827,  0.06216278, -0.04244958, -0.01369485,\n",
      "           0.03026059, -0.05734725, -0.11388055, -0.04357738,\n",
      "           0.1635075 ,  0.32009926, -0.08449346,  0.06881347,\n",
      "          -0.11387921,  0.23284349,  0.00616113,  0.06106737,\n",
      "          -0.15965159, -0.09766254, -0.04672647, -0.02352803,\n",
      "          -0.07689033, -0.08242017,  0.10047168,  0.02980655]]],\n",
      "\n",
      "\n",
      "       [[[-0.08416342,  0.0249144 , -0.06930287, -0.10511206,\n",
      "          -0.08162759, -0.08337809, -0.01063947,  0.06336294,\n",
      "          -0.12281942, -0.46703604,  0.01424514,  0.10134306,\n",
      "           0.07124951, -0.08737978,  0.14045636,  0.0055664 ,\n",
      "          -0.10312437,  0.08410297,  0.07790136, -0.07781848,\n",
      "          -0.14452872, -0.08393708, -0.00678871,  0.00794621]],\n",
      "\n",
      "        [[ 0.02597942,  0.03711374, -0.00233289, -0.12018422,\n",
      "          -0.13690268, -0.08023982,  0.05743606,  0.16152757,\n",
      "          -0.1631118 , -0.4433312 ,  0.03566133,  0.01492746,\n",
      "           0.0429603 , -0.15169851, -0.02151438, -0.08586393,\n",
      "          -0.0563877 ,  0.06998317, -0.08216739, -0.17380366,\n",
      "          -0.1357861 ,  0.06149235, -0.09440754, -0.0091271 ]],\n",
      "\n",
      "        [[ 0.0107571 , -0.00616014,  0.1397103 , -0.1838689 ,\n",
      "           0.07277913, -0.02079078,  0.15305269,  0.06343074,\n",
      "           0.02638134, -0.4169786 ,  0.01009382,  0.05296871,\n",
      "          -0.03692785, -0.13877529, -0.18027113, -0.11306033,\n",
      "           0.00473266, -0.03941264, -0.04292443, -0.20140298,\n",
      "          -0.08054359, -0.10374262,  0.00287577, -0.07510187]],\n",
      "\n",
      "        [[-0.11095439,  0.01022555,  0.16981097, -0.12034458,\n",
      "           0.04527441, -0.03319679,  0.1440461 ,  0.09693035,\n",
      "           0.12590209, -0.44268072, -0.04092293,  0.04462318,\n",
      "          -0.0022534 ,  0.05728988, -0.15194283,  0.03399115,\n",
      "          -0.01010275, -0.03806918,  0.07130457, -0.09395233,\n",
      "          -0.10509686,  0.06908003, -0.15759805, -0.08861176]],\n",
      "\n",
      "        [[-0.10541148,  0.09529158,  0.15232667, -0.17513335,\n",
      "           0.07238998, -0.08751856,  0.18687882,  0.17050482,\n",
      "           0.20269357, -0.53447   , -0.02611729,  0.07757035,\n",
      "          -0.06943312,  0.04043645,  0.00991689, -0.09806818,\n",
      "          -0.15642971, -0.09506962, -0.01114978, -0.1271428 ,\n",
      "           0.08054393,  0.01477253, -0.16567151, -0.03528736]]],\n",
      "\n",
      "\n",
      "       [[[-0.12278302, -0.10343573,  0.0242697 , -0.06818082,\n",
      "           0.04867606, -0.0949284 ,  0.2230691 , -0.10018392,\n",
      "          -0.06038424,  0.24902585, -0.0550802 ,  0.08013498,\n",
      "          -0.03990711,  0.0357868 , -0.09477861,  0.07767469,\n",
      "           0.02646833,  0.03974387, -0.11596005, -0.16258162,\n",
      "           0.11550336, -0.02071443, -0.17855658, -0.04587854]],\n",
      "\n",
      "        [[-0.04790418, -0.02606326,  0.07895222,  0.07974617,\n",
      "           0.06695596, -0.04491889,  0.15748873, -0.04960502,\n",
      "          -0.04471673,  0.19830428, -0.06233085,  0.03684193,\n",
      "           0.05448724, -0.14334439, -0.16113625,  0.15374434,\n",
      "           0.15210931,  0.17905124,  0.05209414, -0.23329495,\n",
      "           0.20161366,  0.12338963, -0.22701913, -0.04910031]],\n",
      "\n",
      "        [[-0.07522225,  0.03753382,  0.04334941, -0.03009077,\n",
      "           0.08018406, -0.01957684, -0.01168036,  0.01715711,\n",
      "          -0.02845456,  0.18499891, -0.01026268,  0.01128533,\n",
      "           0.06721178, -0.08220214, -0.00827802,  0.07884792,\n",
      "           0.1643798 ,  0.16248645,  0.13650064, -0.20205857,\n",
      "           0.18568768, -0.04182939, -0.300218  , -0.05879034]],\n",
      "\n",
      "        [[-0.00255873,  0.13113655,  0.08384228,  0.0143342 ,\n",
      "           0.06878299, -0.00523463,  0.04934375,  0.02824507,\n",
      "           0.09681912,  0.15552926, -0.02135912,  0.12518679,\n",
      "           0.02673083, -0.14106296, -0.03000122, -0.01402246,\n",
      "           0.09522546,  0.05657593, -0.07053974, -0.07459105,\n",
      "           0.16887972,  0.13403304, -0.19381468,  0.0534346 ]],\n",
      "\n",
      "        [[-0.03783917,  0.00228745,  0.18901236, -0.07804392,\n",
      "           0.14506811,  0.06616881,  0.18081993, -0.03235378,\n",
      "           0.1272164 ,  0.04270063,  0.07604218,  0.00731337,\n",
      "           0.00277519,  0.0194435 , -0.09992282,  0.07548473,\n",
      "           0.10360454,  0.09714972,  0.08359816, -0.07457218,\n",
      "           0.06036257, -0.00215278, -0.32694176, -0.00276204]]]],\n",
      "      dtype=float32), array([-0.00204597,  0.23242788,  0.0087778 ,  0.01902936,  0.0056234 ,\n",
      "       -0.00614162,  0.0077826 ,  0.06099395,  0.00065666,  0.05169497,\n",
      "       -0.00105547,  0.04608398,  0.00179018, -0.06468948,  0.13449322,\n",
      "        0.02298943,  0.01466625,  0.00491247,  0.00181549,  0.02964113,\n",
      "        0.05166512,  0.01182108,  0.07862833, -0.00133702], dtype=float32)]\n",
      "[array([0.832572  , 1.0054733 , 0.97162783, 0.9786917 , 0.96602994,\n",
      "       0.83574986, 1.0210384 , 1.0101318 , 0.91810715, 1.3810521 ,\n",
      "       0.8641035 , 1.0551269 , 0.8484846 , 1.0947953 , 1.0786821 ,\n",
      "       0.8771814 , 1.0778766 , 0.91458166, 0.8577615 , 1.059264  ,\n",
      "       1.1204104 , 0.86894774, 1.238888  , 0.85458064], dtype=float32), array([ 0.11441954,  0.07661442,  0.04020507,  0.04248392,  0.05852927,\n",
      "       -0.00211241,  0.12972663,  0.1504991 ,  0.12462655,  0.05218178,\n",
      "        0.04623409,  0.08501816, -0.00648492, -0.0618402 , -0.04676002,\n",
      "        0.15289545,  0.08565688,  0.08654858,  0.05208106,  0.06186   ,\n",
      "        0.0954709 , -0.00474667,  0.0176079 ,  0.04415713], dtype=float32), array([6.396067  , 0.2938808 , 1.8752975 , 1.5839018 , 1.2848052 ,\n",
      "       7.002602  , 1.9830141 , 0.23523101, 1.7035854 , 1.771968  ,\n",
      "       5.770354  , 0.30196318, 3.042066  , 0.37407938, 0.43341964,\n",
      "       2.2944329 , 0.6393109 , 1.7147101 , 1.7811165 , 2.4424148 ,\n",
      "       0.37847322, 1.4468882 , 1.6571724 , 4.667953  ], dtype=float32), array([134.6167    ,   0.6156251 ,  35.170864  ,  14.495876  ,\n",
      "        12.436364  , 159.0932    ,  58.308422  ,   0.78251016,\n",
      "        15.654629  ,  27.454102  , 108.3526    ,   1.6019791 ,\n",
      "        31.67157   ,   2.2855709 ,   2.1501102 ,  22.65162   ,\n",
      "         9.663069  ,  20.050852  ,  11.171356  ,  28.138689  ,\n",
      "         2.346095  ,   8.9037    ,  20.252895  ,  70.071396  ],\n",
      "      dtype=float32)]\n",
      "[]\n",
      "[array([[[[ 4.93030883e-02, -9.48091969e-03, -2.03945972e-02, ...,\n",
      "          -1.72680337e-02,  5.26541611e-04, -1.94390304e-02],\n",
      "         [ 2.63143759e-02, -1.11856088e-02, -3.39667983e-02, ...,\n",
      "           2.80212285e-03,  4.17212211e-02,  2.59580202e-02],\n",
      "         [-2.73881610e-02,  4.52452712e-02, -5.32009127e-03, ...,\n",
      "          -1.75164156e-02, -3.10744159e-02,  2.02871487e-02],\n",
      "         ...,\n",
      "         [ 1.04004880e-02,  4.41719107e-02,  2.57557593e-02, ...,\n",
      "          -4.10912419e-03, -5.32648265e-02, -6.01227768e-03],\n",
      "         [ 2.85468008e-02, -3.40308920e-02,  2.94408239e-02, ...,\n",
      "          -4.43597324e-02, -2.61620246e-02,  6.12466736e-03],\n",
      "         [-4.97062244e-02,  5.60067482e-02, -2.68935319e-02, ...,\n",
      "          -6.98145572e-03,  3.03688161e-02, -4.62681726e-02]],\n",
      "\n",
      "        [[ 3.85320671e-02,  2.18185596e-02, -2.94530801e-02, ...,\n",
      "          -4.94375750e-02, -1.79412030e-02,  3.42433378e-02],\n",
      "         [-2.44183429e-02,  1.57968681e-02,  3.93069629e-03, ...,\n",
      "           3.81852221e-03, -1.46340830e-02, -2.02620272e-02],\n",
      "         [ 4.39580046e-02, -3.85448784e-02,  4.31985036e-02, ...,\n",
      "           2.14257892e-02, -4.31694351e-02,  3.69328000e-02],\n",
      "         ...,\n",
      "         [-9.42914467e-03, -4.12282050e-02, -2.68243775e-02, ...,\n",
      "          -4.73846048e-02,  3.65050808e-02,  4.29070974e-03],\n",
      "         [ 2.58815475e-02, -4.31169793e-02, -8.56667161e-02, ...,\n",
      "           2.19339114e-02, -8.57280102e-03,  2.01455150e-02],\n",
      "         [ 3.05945277e-02, -1.85878053e-02,  3.69256958e-02, ...,\n",
      "          -7.91189913e-03,  6.34471998e-02, -5.61043695e-02]],\n",
      "\n",
      "        [[-7.54614687e-03, -2.07038969e-02, -1.33679612e-02, ...,\n",
      "           2.35190224e-02,  1.36729637e-02, -7.09392279e-02],\n",
      "         [ 2.41495296e-02, -3.15697718e-04, -4.95749861e-02, ...,\n",
      "           4.64421213e-02,  6.90024570e-02,  5.20305708e-02],\n",
      "         [-3.48081579e-03, -2.04256475e-02,  5.53892255e-02, ...,\n",
      "          -4.86925766e-02,  3.83256525e-02, -5.42557687e-02],\n",
      "         ...,\n",
      "         [-1.65318139e-02,  5.66193312e-02, -3.52531448e-02, ...,\n",
      "           3.15669626e-02,  2.90524047e-02,  1.06189940e-02],\n",
      "         [ 6.09105341e-02,  9.81106641e-05, -4.24969196e-02, ...,\n",
      "          -4.59707379e-02,  2.59762513e-03, -4.37011309e-02],\n",
      "         [-1.43208150e-02,  2.04894431e-02, -9.41283349e-03, ...,\n",
      "           4.56101559e-02,  2.23751981e-02, -2.93340087e-02]],\n",
      "\n",
      "        [[-5.50330132e-02,  3.74587700e-02,  3.20711099e-02, ...,\n",
      "          -2.85468269e-02, -4.79480019e-03, -6.30958453e-02],\n",
      "         [-2.92868391e-02, -1.32260863e-02,  5.88191263e-02, ...,\n",
      "           4.04439978e-02,  5.06028719e-02,  3.79864052e-02],\n",
      "         [ 3.35285291e-02, -1.78438658e-03, -2.82724984e-02, ...,\n",
      "           1.79233383e-02, -4.50664572e-02, -5.34130298e-02],\n",
      "         ...,\n",
      "         [ 1.10697430e-02, -3.96927632e-03,  1.47929611e-02, ...,\n",
      "          -1.44705502e-02, -8.30476452e-03,  3.68581489e-02],\n",
      "         [ 5.67421913e-02,  1.67356078e-02, -7.08143786e-02, ...,\n",
      "          -1.78413689e-02, -3.35844085e-02, -9.16881021e-03],\n",
      "         [-1.03799049e-02,  4.73700017e-02, -1.00582158e-02, ...,\n",
      "           1.21393213e-02,  6.03099912e-02, -5.59764402e-03]],\n",
      "\n",
      "        [[ 1.22949826e-02, -1.86587442e-02,  3.15976404e-02, ...,\n",
      "          -3.51259969e-02,  4.84839715e-02, -6.40948564e-02],\n",
      "         [-1.33927362e-02,  9.04907100e-03,  3.00203469e-02, ...,\n",
      "           1.78146027e-02,  7.03256056e-02,  1.85251180e-02],\n",
      "         [-5.95186315e-02,  2.75742002e-02, -2.70590521e-02, ...,\n",
      "          -1.39433704e-03, -2.23824270e-02, -2.81408951e-02],\n",
      "         ...,\n",
      "         [ 1.36965569e-02, -2.07605083e-02,  1.15240365e-02, ...,\n",
      "          -4.38897684e-03,  2.46376544e-02, -3.78364325e-03],\n",
      "         [ 7.02637509e-02, -7.15146773e-04, -4.88661788e-02, ...,\n",
      "          -2.07673870e-02, -1.69337541e-02, -3.12205218e-02],\n",
      "         [ 4.00334522e-02,  7.98641145e-03,  4.98180203e-02, ...,\n",
      "           9.08465777e-03, -4.81816716e-02,  6.99354522e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 8.61152261e-03, -1.49970641e-02,  1.91237852e-02, ...,\n",
      "           3.55142020e-02,  4.99248654e-02,  7.06815161e-03],\n",
      "         [ 7.75603428e-02,  5.66252833e-03,  4.62262854e-02, ...,\n",
      "          -4.95182052e-02,  2.43238173e-02,  4.55977693e-02],\n",
      "         [-6.12957738e-02, -9.77847259e-04, -5.74940667e-02, ...,\n",
      "           5.86509658e-03, -5.58492839e-02,  2.14603506e-02],\n",
      "         ...,\n",
      "         [ 5.02577238e-02,  4.12890129e-02,  1.82657316e-02, ...,\n",
      "          -4.93019596e-02,  1.61031801e-02,  1.13321366e-02],\n",
      "         [ 4.33126353e-02,  8.31669196e-03,  6.32134378e-02, ...,\n",
      "          -2.63765436e-02, -3.19030732e-02, -8.15873407e-03],\n",
      "         [-6.88590156e-03, -1.32101104e-02, -1.10847550e-02, ...,\n",
      "           3.50011662e-02,  5.82087860e-02, -1.78418234e-02]],\n",
      "\n",
      "        [[ 3.51050124e-02,  3.64537798e-02, -9.87677276e-03, ...,\n",
      "           5.12071513e-02, -5.11725545e-02, -5.65963909e-02],\n",
      "         [-5.85370138e-03,  1.26825925e-02,  5.33506162e-02, ...,\n",
      "          -2.16112044e-02, -2.92967074e-03,  1.77555275e-03],\n",
      "         [ 2.58519314e-04, -3.48929167e-02, -2.00144481e-02, ...,\n",
      "           4.29066606e-02, -3.71202417e-02, -3.22616822e-03],\n",
      "         ...,\n",
      "         [ 2.45527161e-04, -4.60491255e-02, -4.86825034e-02, ...,\n",
      "           3.26024406e-02,  1.54097704e-03, -4.61317636e-02],\n",
      "         [ 8.23841766e-02, -2.55723260e-02, -4.51154396e-04, ...,\n",
      "           4.07141931e-02,  5.96538186e-03, -8.76746401e-02],\n",
      "         [-2.05801222e-02,  1.67501085e-02,  2.51360070e-02, ...,\n",
      "          -3.43253426e-02,  1.57209523e-02, -6.22672886e-02]],\n",
      "\n",
      "        [[-3.73589434e-02,  1.70442145e-02,  1.86526291e-02, ...,\n",
      "          -3.41083854e-02,  5.68446778e-02, -5.24116419e-02],\n",
      "         [-6.32291064e-02, -1.23220729e-02,  3.20554599e-02, ...,\n",
      "          -3.12570892e-02,  3.80389690e-02,  1.67064834e-02],\n",
      "         [-4.28357013e-02, -1.12511041e-02,  1.79937575e-02, ...,\n",
      "          -1.84267629e-02,  1.98642481e-02, -5.69684803e-02],\n",
      "         ...,\n",
      "         [-1.78777985e-02,  5.19223511e-02,  2.10093409e-02, ...,\n",
      "          -3.35977636e-02,  2.61087697e-02, -5.16345315e-02],\n",
      "         [ 9.54083353e-02, -6.00232333e-02,  5.21165244e-02, ...,\n",
      "           2.66082063e-02,  1.10693779e-02, -2.04510950e-02],\n",
      "         [ 5.15586473e-02, -1.39190303e-02, -2.21723225e-02, ...,\n",
      "           3.76982279e-02,  2.68241633e-02, -2.17294600e-02]],\n",
      "\n",
      "        [[-5.47955744e-02,  1.80958733e-02, -5.67855407e-03, ...,\n",
      "          -1.28359701e-02,  4.49803919e-02,  2.48401277e-02],\n",
      "         [ 2.92903767e-03, -3.36992331e-02,  7.55925551e-02, ...,\n",
      "           3.49640436e-02,  2.81246603e-02, -2.80912668e-02],\n",
      "         [ 5.75833209e-03, -5.69552518e-02,  3.65750939e-02, ...,\n",
      "          -2.19650585e-02, -5.74187525e-02, -2.16885433e-02],\n",
      "         ...,\n",
      "         [-5.66306477e-03,  4.36456874e-02,  2.17730887e-02, ...,\n",
      "           4.39623790e-03,  7.67803267e-02, -4.65880223e-02],\n",
      "         [ 4.42409292e-02, -5.12236506e-02,  3.76421474e-02, ...,\n",
      "           4.39241789e-02, -6.72326759e-02, -1.90169141e-02],\n",
      "         [ 1.36277592e-02, -2.08435077e-02, -4.29409295e-02, ...,\n",
      "           5.13958484e-02,  3.27246860e-02, -4.96409833e-02]],\n",
      "\n",
      "        [[-5.18171936e-02,  2.56699957e-02,  6.25233306e-03, ...,\n",
      "          -3.69917490e-02, -6.17890572e-03, -1.85581297e-02],\n",
      "         [-7.68898800e-02,  3.22995186e-02,  5.83983324e-02, ...,\n",
      "           1.72539009e-03,  3.06051951e-02,  3.98958363e-02],\n",
      "         [-3.11215082e-03,  2.76773982e-02,  2.15740968e-02, ...,\n",
      "           9.90044419e-03,  3.55843380e-02,  2.90037934e-02],\n",
      "         ...,\n",
      "         [ 6.12756982e-02,  1.30300224e-02, -5.13640307e-02, ...,\n",
      "           1.18843196e-02,  8.86625890e-03, -1.41461771e-02],\n",
      "         [-2.59053241e-02, -4.76772860e-02,  5.59391715e-02, ...,\n",
      "          -1.08928354e-02,  5.09558879e-02, -9.30297151e-02],\n",
      "         [-5.19519709e-02, -1.64262056e-02,  9.23907943e-03, ...,\n",
      "           2.58587617e-02,  1.01212077e-02, -1.99639667e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 8.43059830e-03, -5.20626903e-02, -3.16517688e-02, ...,\n",
      "          -2.81097507e-03, -1.75453536e-02,  1.47997290e-02],\n",
      "         [-4.91748489e-02,  5.42498333e-03, -3.19481045e-02, ...,\n",
      "           5.52938953e-02,  5.06818406e-02,  3.33893076e-02],\n",
      "         [ 1.98279019e-03,  1.74180865e-02, -5.78200370e-02, ...,\n",
      "           4.06249538e-02,  8.37021600e-03, -3.71063873e-02],\n",
      "         ...,\n",
      "         [ 1.75256319e-02, -4.31869105e-02,  5.94281964e-02, ...,\n",
      "           5.16786724e-02,  1.06704775e-02, -2.97352765e-02],\n",
      "         [-6.10371828e-02,  6.59796223e-02, -3.45712033e-04, ...,\n",
      "           2.93631852e-02, -2.46051960e-02,  7.67140975e-03],\n",
      "         [ 4.31834720e-02,  2.92876568e-02, -3.48989293e-02, ...,\n",
      "           4.11802728e-04,  2.04292461e-02, -4.28506434e-02]],\n",
      "\n",
      "        [[ 2.35809237e-02, -1.76953226e-02,  1.04129063e-02, ...,\n",
      "           1.63563229e-02, -6.22904021e-03,  1.35662090e-02],\n",
      "         [-2.19591316e-02, -4.98655438e-02,  4.65114340e-02, ...,\n",
      "          -4.66686450e-02,  2.55909637e-02, -5.49129071e-03],\n",
      "         [ 1.84806399e-02,  4.02247980e-02,  2.41838749e-02, ...,\n",
      "           4.40832339e-02, -4.35239859e-02, -4.61620279e-03],\n",
      "         ...,\n",
      "         [-2.53044837e-03,  3.11516505e-02,  4.95105647e-02, ...,\n",
      "           5.75083755e-02, -4.05784994e-02, -6.14281893e-02],\n",
      "         [-2.34534703e-02,  5.02340756e-02,  2.86756456e-02, ...,\n",
      "           1.49869667e-02, -4.81489784e-04,  8.08960348e-02],\n",
      "         [ 3.09292856e-03,  5.93068637e-02, -3.37718353e-02, ...,\n",
      "           3.79147939e-02,  5.54355793e-02,  1.02482014e-03]],\n",
      "\n",
      "        [[ 1.63689628e-02, -1.72345620e-02, -1.09158549e-02, ...,\n",
      "           1.82639826e-02, -5.29197864e-02, -6.76924139e-02],\n",
      "         [ 4.05049920e-02, -1.05826659e-02,  4.06118892e-02, ...,\n",
      "          -5.66577632e-03, -2.76460196e-03, -3.16599086e-02],\n",
      "         [-3.43146436e-02, -6.28259825e-03, -7.99147859e-02, ...,\n",
      "           5.17454036e-02, -1.54690519e-02, -4.86509539e-02],\n",
      "         ...,\n",
      "         [ 1.71434786e-02, -5.32365367e-02,  4.08016965e-02, ...,\n",
      "          -4.17158566e-03,  9.84451920e-03, -3.53974625e-02],\n",
      "         [-2.16318071e-02,  5.34973815e-02,  1.10741239e-02, ...,\n",
      "          -2.05908734e-02, -6.44229800e-02,  7.27338791e-02],\n",
      "         [ 2.38917000e-03, -2.84376778e-02,  4.42761136e-03, ...,\n",
      "           6.78634457e-03,  3.82133946e-02, -3.65817994e-02]],\n",
      "\n",
      "        [[ 4.38415259e-02, -1.99472159e-02, -5.93229905e-02, ...,\n",
      "          -2.88255271e-02,  5.53160161e-02, -1.10284379e-02],\n",
      "         [ 1.45254685e-02, -4.90075983e-02,  7.06562698e-02, ...,\n",
      "           7.40399212e-02, -3.05853654e-02,  2.05655620e-02],\n",
      "         [ 5.28916270e-02, -3.82188261e-02, -3.63226086e-02, ...,\n",
      "           1.91062819e-02,  4.91849370e-02, -6.69965968e-02],\n",
      "         ...,\n",
      "         [ 3.80762070e-02,  3.43592502e-02, -2.54083220e-02, ...,\n",
      "          -8.51130486e-03,  3.71486843e-02,  3.19248326e-02],\n",
      "         [-7.30781332e-02,  7.95652419e-02,  5.60518317e-02, ...,\n",
      "          -5.11111245e-02,  2.74821860e-03, -4.16132342e-03],\n",
      "         [ 1.97536666e-02,  3.05645959e-03,  3.71022671e-02, ...,\n",
      "           1.87623035e-02, -1.94486324e-02, -1.28213279e-02]],\n",
      "\n",
      "        [[-3.42733264e-02,  2.09217146e-02, -5.04785143e-02, ...,\n",
      "          -1.56479795e-02, -3.86089943e-02,  8.24736804e-03],\n",
      "         [ 1.24772359e-02, -4.13447879e-02,  1.20019428e-02, ...,\n",
      "           2.88540199e-02, -3.12614739e-02, -2.49557234e-02],\n",
      "         [ 1.93786379e-02, -4.72441651e-02, -7.51348510e-02, ...,\n",
      "          -4.14388962e-02, -2.63971742e-02, -6.04374520e-02],\n",
      "         ...,\n",
      "         [ 3.53707150e-02, -8.93804617e-03,  5.61463609e-02, ...,\n",
      "           1.93754099e-02,  3.36884446e-02,  4.39132117e-02],\n",
      "         [-3.88337411e-02,  6.55085593e-02,  5.95906787e-02, ...,\n",
      "           4.51079234e-02, -3.37411538e-02,  3.05387601e-02],\n",
      "         [ 4.28960249e-02,  4.86277007e-02,  3.94024327e-02, ...,\n",
      "           1.85950827e-02,  6.21777661e-02, -4.15212475e-02]]],\n",
      "\n",
      "\n",
      "       [[[-1.80563740e-02,  8.34745634e-03,  1.09021813e-02, ...,\n",
      "           4.36044186e-02,  2.13585119e-03,  1.48096038e-02],\n",
      "         [-6.16717972e-02, -5.31249605e-02, -1.97288711e-02, ...,\n",
      "          -4.52220142e-02,  2.23358423e-02,  4.74126488e-02],\n",
      "         [-6.28695590e-03,  2.66616922e-02,  6.32999688e-02, ...,\n",
      "           4.32860255e-02,  6.94178119e-02, -1.16570794e-03],\n",
      "         ...,\n",
      "         [ 7.35663285e-04, -5.68714272e-03, -1.91120431e-02, ...,\n",
      "           5.10085374e-02,  3.04122046e-02,  1.09564420e-02],\n",
      "         [-7.91669115e-02, -4.90237549e-02, -3.63709666e-02, ...,\n",
      "           5.41029833e-02, -1.07951537e-01,  8.20411071e-02],\n",
      "         [-5.46896495e-02, -1.80155057e-02,  5.02379835e-02, ...,\n",
      "           4.02126200e-02,  4.30043079e-02, -3.69142927e-02]],\n",
      "\n",
      "        [[ 3.84844430e-02, -1.81051798e-03, -3.80555466e-02, ...,\n",
      "           4.29202616e-02,  1.98859498e-02, -2.66067777e-02],\n",
      "         [-6.64617717e-02, -2.81459447e-02, -2.43434384e-02, ...,\n",
      "          -1.27874129e-02,  1.57745797e-02, -8.09787959e-02],\n",
      "         [ 4.97032143e-02,  4.32026535e-02, -1.20584411e-03, ...,\n",
      "           1.96355283e-02,  2.03141347e-02,  7.62282079e-03],\n",
      "         ...,\n",
      "         [-2.95324661e-02, -2.30366271e-02, -7.82346725e-03, ...,\n",
      "          -4.05838229e-02,  8.13529454e-03, -5.51544428e-02],\n",
      "         [-7.65751153e-02,  7.22280063e-04, -8.25487822e-02, ...,\n",
      "           2.44751554e-02, -4.73224483e-02,  9.20522735e-02],\n",
      "         [ 4.79182862e-02,  2.95633655e-02, -1.38644278e-02, ...,\n",
      "          -7.90577661e-03, -5.26349701e-04,  2.90906988e-03]],\n",
      "\n",
      "        [[-5.09477630e-02,  3.79605293e-02,  2.56590173e-02, ...,\n",
      "           1.80405136e-02,  3.47283557e-02, -2.58279918e-03],\n",
      "         [-5.08615822e-02,  3.28139290e-02, -4.46953401e-02, ...,\n",
      "           4.16649468e-02,  1.76973045e-02, -3.02475821e-02],\n",
      "         [-4.02569696e-02,  5.19918092e-02,  3.09021529e-02, ...,\n",
      "          -5.18191904e-02,  4.91286702e-02, -1.07795587e-02],\n",
      "         ...,\n",
      "         [-5.69434874e-02,  1.42435366e-02,  1.96505785e-02, ...,\n",
      "           1.22450208e-02,  2.16829889e-02,  1.86690558e-02],\n",
      "         [-6.98678568e-02,  1.21673383e-02, -7.81598166e-02, ...,\n",
      "          -3.80385220e-02,  7.16158014e-04,  7.22509772e-02],\n",
      "         [-7.58617045e-03,  9.89738619e-04, -2.94371750e-02, ...,\n",
      "           2.40571368e-02, -3.47912200e-02,  1.07175801e-02]],\n",
      "\n",
      "        [[-1.15647856e-02, -3.14328745e-02,  1.11029297e-02, ...,\n",
      "          -4.84548733e-02,  4.62581813e-02,  3.60082202e-02],\n",
      "         [ 3.39908004e-02,  1.81138683e-02,  5.54542542e-02, ...,\n",
      "           7.36982003e-02, -3.22080068e-02, -6.10194635e-03],\n",
      "         [-4.30783369e-02,  4.73298617e-02,  4.67205653e-03, ...,\n",
      "          -1.35748405e-02,  3.58955711e-02,  5.33058047e-02],\n",
      "         ...,\n",
      "         [ 1.73468273e-02,  5.85262012e-03, -1.36412354e-03, ...,\n",
      "           1.87975522e-02, -4.36759042e-03,  2.91153155e-02],\n",
      "         [-3.27547714e-02, -9.46827605e-03, -3.40766236e-02, ...,\n",
      "          -1.42062921e-03, -8.30746889e-02,  7.56605715e-03],\n",
      "         [-5.18652163e-02,  2.48332880e-02,  2.01513078e-02, ...,\n",
      "          -4.55313455e-03, -4.42540720e-02,  7.93823786e-03]],\n",
      "\n",
      "        [[-1.23792021e-02, -2.06547827e-02, -2.95492169e-02, ...,\n",
      "           3.55718024e-02, -6.69902340e-02,  2.80000400e-02],\n",
      "         [-1.70407631e-02,  4.36939374e-02, -3.14043090e-02, ...,\n",
      "           2.99475137e-02, -3.46614495e-02, -7.69614130e-02],\n",
      "         [ 3.00733037e-02,  2.57954095e-02,  4.23475690e-02, ...,\n",
      "          -2.64624506e-02,  1.35605196e-02, -3.92421298e-02],\n",
      "         ...,\n",
      "         [ 1.03526786e-02,  1.83658134e-02,  4.76892218e-02, ...,\n",
      "           6.01922423e-02,  4.67340127e-02, -2.30616536e-02],\n",
      "         [-8.25961027e-03,  5.50183989e-02,  1.39924176e-02, ...,\n",
      "           4.73222136e-02, -4.11787853e-02, -3.69195081e-02],\n",
      "         [ 3.81905548e-02,  3.14281732e-02,  1.84259526e-02, ...,\n",
      "          -5.35971895e-02, -3.05075757e-02,  3.79676148e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 4.04324122e-02, -7.40901392e-04, -2.50191670e-02, ...,\n",
      "           5.97855188e-02, -3.46601270e-02,  5.02388291e-02],\n",
      "         [-3.97299677e-02, -2.98588090e-02, -2.28769593e-02, ...,\n",
      "          -1.96383353e-02, -1.30008883e-03,  1.41522978e-02],\n",
      "         [-3.10525042e-03, -3.84966731e-02, -8.47484730e-03, ...,\n",
      "           4.13063131e-02,  5.30822016e-02,  6.35764971e-02],\n",
      "         ...,\n",
      "         [-1.26546836e-02,  5.31047657e-02,  2.93350704e-02, ...,\n",
      "          -4.79321964e-02,  6.84621045e-04, -9.18431953e-03],\n",
      "         [ 9.73318354e-04, -3.60484980e-02,  4.32476550e-02, ...,\n",
      "           2.67273355e-02,  5.15055731e-02,  8.89441222e-02],\n",
      "         [ 2.68726479e-02, -4.55364697e-02,  4.36490402e-02, ...,\n",
      "          -3.73400077e-02, -4.17559221e-02, -4.10114415e-02]],\n",
      "\n",
      "        [[-5.55638112e-02,  4.31772098e-02, -6.89929700e-04, ...,\n",
      "           4.14477400e-02,  7.00441934e-03,  5.95764723e-03],\n",
      "         [ 2.34352443e-02,  1.72137897e-02, -2.23239716e-02, ...,\n",
      "          -4.25644219e-02, -3.70886177e-03, -6.13713004e-02],\n",
      "         [ 1.18179424e-02, -2.39656996e-02, -5.21110892e-02, ...,\n",
      "          -4.34260592e-02,  1.75292697e-02,  5.90881407e-02],\n",
      "         ...,\n",
      "         [-3.70636880e-02, -2.56376411e-03,  4.56545055e-02, ...,\n",
      "          -8.08330812e-03, -2.01919843e-02,  5.63894631e-03],\n",
      "         [ 6.73071221e-02,  6.40049949e-03, -8.53516534e-03, ...,\n",
      "          -2.28055157e-02,  6.75857812e-02,  8.16138461e-02],\n",
      "         [-5.75556196e-02, -1.57073252e-02,  5.83191924e-02, ...,\n",
      "          -1.31685287e-02, -3.37553397e-02, -4.86921854e-02]],\n",
      "\n",
      "        [[-5.09936474e-02,  5.19602969e-02,  7.26490766e-02, ...,\n",
      "           5.58096450e-04, -6.31899238e-02,  1.75305456e-02],\n",
      "         [-3.62420343e-02,  4.54977043e-02,  5.42227328e-02, ...,\n",
      "           5.86967096e-02,  5.22997603e-02, -1.47058712e-02],\n",
      "         [ 3.12385112e-02,  1.23571521e-02,  2.56642085e-02, ...,\n",
      "           4.16196622e-02,  2.07793806e-02, -2.29316987e-02],\n",
      "         ...,\n",
      "         [ 5.46489318e-04, -1.10564996e-02,  2.46599782e-02, ...,\n",
      "           2.70656906e-02, -4.76290174e-02,  1.50553817e-02],\n",
      "         [ 4.13344577e-02,  3.05322884e-03,  5.15519343e-02, ...,\n",
      "          -6.44803094e-03,  2.87677143e-02,  5.56759909e-02],\n",
      "         [ 5.49194682e-03,  5.44220135e-02, -3.31674777e-02, ...,\n",
      "          -5.36676496e-02, -4.99325395e-02, -1.78063046e-02]],\n",
      "\n",
      "        [[-5.61448447e-02,  1.30946208e-02, -1.63820777e-02, ...,\n",
      "          -1.87226478e-02, -7.99592491e-03,  3.69073153e-02],\n",
      "         [ 9.36657283e-03,  3.10953055e-02, -1.98654383e-02, ...,\n",
      "           6.63726851e-02,  8.84696376e-03,  3.89703140e-02],\n",
      "         [ 3.71527597e-02,  1.49822058e-02, -6.30094185e-02, ...,\n",
      "           3.50002386e-02,  2.48327572e-02,  1.03871236e-02],\n",
      "         ...,\n",
      "         [-5.53442612e-02,  1.42383194e-02,  1.98960137e-02, ...,\n",
      "           1.56111261e-02, -4.93339077e-02, -3.07140090e-02],\n",
      "         [-2.78579034e-02,  8.49802233e-03,  2.01317146e-02, ...,\n",
      "          -6.77052885e-02, -1.10806357e-02, -1.83143932e-02],\n",
      "         [ 4.46349494e-02,  1.90059878e-02,  5.98470457e-02, ...,\n",
      "          -5.02473377e-02, -2.37117149e-02, -4.90216278e-02]],\n",
      "\n",
      "        [[ 3.17190997e-02,  1.32789640e-02,  2.23528892e-02, ...,\n",
      "          -2.83141043e-02, -3.59239206e-02,  5.03953844e-02],\n",
      "         [-1.07151344e-02,  3.02760005e-02, -1.57777127e-02, ...,\n",
      "           4.34674881e-02, -6.87135532e-02, -2.62429975e-02],\n",
      "         [ 5.97053533e-03, -2.89684511e-03,  2.82290932e-02, ...,\n",
      "           5.11855334e-02, -4.87702489e-02,  1.95506401e-02],\n",
      "         ...,\n",
      "         [ 2.18297187e-02,  4.83773760e-02,  3.54452319e-02, ...,\n",
      "           5.01292348e-02, -6.39676079e-02,  4.06434946e-02],\n",
      "         [-1.22874863e-02,  1.92412850e-03, -4.58054431e-02, ...,\n",
      "          -3.50060128e-02,  7.06568509e-02,  6.75918907e-02],\n",
      "         [-3.26602161e-02,  6.64813146e-02,  4.04517073e-03, ...,\n",
      "          -5.02351262e-02, -2.36082189e-02,  5.73474467e-02]]]],\n",
      "      dtype=float32), array([-0.05442264, -0.05014568, -0.00517566,  0.01986779, -0.01996096,\n",
      "       -0.09445161, -0.00163942,  0.00129741,  0.01122335, -0.00488098,\n",
      "       -0.01740403, -0.02418933, -0.02923536, -0.0561109 , -0.0234213 ,\n",
      "       -0.03301935, -0.00924599, -0.01553622, -0.01469134, -0.02821122,\n",
      "       -0.02928333, -0.04110225, -0.01308686,  0.00859774, -0.00805922,\n",
      "       -0.01443585,  0.02941306, -0.03179546, -0.05892841, -0.00254637,\n",
      "       -0.05213488, -0.0625029 , -0.04776402,  0.01911706, -0.01656617,\n",
      "       -0.0301586 , -0.0356855 , -0.01415609, -0.01429593, -0.02182847,\n",
      "        0.00119653,  0.02114574, -0.02011375, -0.00366745, -0.01925847,\n",
      "       -0.03248381, -0.03482032, -0.05671948], dtype=float32)]\n",
      "[array([1.0131726 , 0.9664961 , 1.0296737 , 1.1288902 , 1.010856  ,\n",
      "       1.0622255 , 0.9617012 , 1.0821639 , 1.0486593 , 1.0245701 ,\n",
      "       0.9565802 , 1.0262501 , 0.9585549 , 1.033399  , 0.99243236,\n",
      "       0.9311814 , 0.9314938 , 0.9337735 , 1.0133679 , 0.9376832 ,\n",
      "       0.97337097, 0.94509935, 1.0661618 , 0.99667144, 0.98701847,\n",
      "       0.94067097, 1.1017789 , 0.9637034 , 1.0267428 , 0.94786906,\n",
      "       1.0232394 , 1.0528177 , 0.9778558 , 0.9897853 , 0.95055753,\n",
      "       0.9693163 , 0.96785617, 1.0423585 , 0.92715895, 0.97187746,\n",
      "       1.1034502 , 1.0020902 , 0.97243726, 0.9640222 , 0.99770296,\n",
      "       0.9350878 , 1.018049  , 1.0397617 ], dtype=float32), array([ 0.04128768,  0.03988652,  0.05225827, -0.01211041, -0.00767714,\n",
      "       -0.01076113,  0.02294127,  0.04398314, -0.03336981,  0.01631436,\n",
      "        0.05067732,  0.05383431,  0.08358869, -0.03344603,  0.0383741 ,\n",
      "        0.05826426,  0.07966629,  0.05802633,  0.02439164,  0.07407779,\n",
      "        0.08869746,  0.0844088 ,  0.04960524,  0.07475556,  0.05935   ,\n",
      "        0.0266299 ,  0.02140487,  0.07674641,  0.01099916,  0.09743619,\n",
      "        0.02491755, -0.03325413,  0.02083492,  0.02684231,  0.02462302,\n",
      "        0.04665547,  0.1033006 ,  0.00813995,  0.04615764,  0.05730141,\n",
      "        0.01634768,  0.02233754,  0.04821953,  0.06341372,  0.02444951,\n",
      "        0.04311102,  0.09854643, -0.01375798], dtype=float32), array([0.22794408, 0.8214007 , 0.37598115, 0.48211586, 0.5084391 ,\n",
      "       0.30295718, 0.2265053 , 0.41192806, 0.48721576, 0.48835075,\n",
      "       0.44725743, 0.35976735, 0.25494868, 0.2404571 , 0.2719894 ,\n",
      "       0.49777454, 0.84879214, 0.48034543, 0.6879579 , 0.9571121 ,\n",
      "       0.6977924 , 0.4103513 , 0.32073873, 0.4283497 , 0.39761305,\n",
      "       0.5601767 , 0.5217641 , 0.5819548 , 0.4177296 , 0.46460134,\n",
      "       0.25919208, 0.6263789 , 0.4676552 , 0.5536028 , 0.58528495,\n",
      "       0.8334401 , 0.50388545, 0.6608512 , 0.44721705, 0.32050115,\n",
      "       0.4784798 , 0.47118843, 0.53296036, 0.41340846, 0.2928158 ,\n",
      "       0.8477023 , 0.2249547 , 0.47159046], dtype=float32), array([0.20262232, 2.9119585 , 0.7341911 , 0.6185063 , 0.31541985,\n",
      "       0.38760936, 0.21928947, 0.5646731 , 0.31262943, 0.4952294 ,\n",
      "       1.0492598 , 0.4483361 , 0.5736961 , 0.16514364, 0.6182683 ,\n",
      "       0.83455515, 2.6153958 , 0.77593344, 0.9006643 , 3.6425042 ,\n",
      "       2.154408  , 1.0184288 , 0.46102306, 0.6884129 , 0.51543885,\n",
      "       0.7340511 , 0.5963355 , 1.7507329 , 0.47073075, 1.5118877 ,\n",
      "       0.3640763 , 0.43445262, 0.31189063, 0.49844816, 0.6548946 ,\n",
      "       0.7488852 , 1.3958021 , 1.1043558 , 1.1566185 , 0.97519445,\n",
      "       0.6839532 , 0.53405446, 1.039773  , 0.3886461 , 0.5553464 ,\n",
      "       2.7160125 , 0.576302  , 0.38235778], dtype=float32)]\n",
      "[]\n",
      "[array([[[[ 0.04568725, -0.01752752,  0.0102566 , ..., -0.0259991 ,\n",
      "           0.02178613, -0.01475997],\n",
      "         [ 0.00138047,  0.04350843, -0.02101834, ..., -0.04847689,\n",
      "          -0.03717156, -0.00382869],\n",
      "         [-0.03724899, -0.01173964, -0.00664492, ...,  0.02736016,\n",
      "          -0.05046729, -0.02116811],\n",
      "         ...,\n",
      "         [-0.01191356, -0.03928368, -0.02247334, ..., -0.0458001 ,\n",
      "           0.00547271, -0.03075661],\n",
      "         [-0.03016405, -0.0371253 ,  0.01786753, ..., -0.05924527,\n",
      "          -0.01617395, -0.02955254],\n",
      "         [ 0.01355847, -0.03197216,  0.01354152, ..., -0.01858972,\n",
      "           0.057446  ,  0.01640312]],\n",
      "\n",
      "        [[ 0.05005364, -0.00760204,  0.02894898, ..., -0.03119693,\n",
      "          -0.06936764,  0.04757475],\n",
      "         [ 0.0239959 , -0.02826459, -0.00395067, ...,  0.0344848 ,\n",
      "           0.01582768, -0.05314392],\n",
      "         [ 0.06212234,  0.0140181 ,  0.00539869, ...,  0.01097425,\n",
      "          -0.03862008, -0.0242788 ],\n",
      "         ...,\n",
      "         [-0.00693065, -0.01812239, -0.05765427, ..., -0.02139265,\n",
      "           0.03316512, -0.0019613 ],\n",
      "         [-0.01535548, -0.0340132 , -0.00884793, ...,  0.02974132,\n",
      "           0.01763218, -0.00694231],\n",
      "         [ 0.02017111,  0.05189217,  0.02093216, ..., -0.01670322,\n",
      "           0.01883115,  0.00817482]],\n",
      "\n",
      "        [[ 0.06204439,  0.00136416, -0.01044758, ..., -0.01223759,\n",
      "          -0.0459493 , -0.00781657],\n",
      "         [ 0.02231618, -0.0407462 , -0.04381255, ..., -0.00214703,\n",
      "          -0.02963687,  0.04031173],\n",
      "         [ 0.03440671,  0.01073789, -0.02660754, ...,  0.00328516,\n",
      "          -0.00168412,  0.02235232],\n",
      "         ...,\n",
      "         [ 0.02583731,  0.03779208, -0.01281618, ..., -0.05031585,\n",
      "           0.03333232,  0.04263682],\n",
      "         [ 0.01653675,  0.00159037, -0.03125103, ...,  0.01911527,\n",
      "           0.024482  ,  0.0091518 ],\n",
      "         [ 0.03660351,  0.04388193, -0.02585055, ..., -0.01260693,\n",
      "           0.01293748, -0.04168425]],\n",
      "\n",
      "        [[ 0.04098801,  0.06223216,  0.01871269, ..., -0.03682561,\n",
      "          -0.01668737, -0.02538934],\n",
      "         [ 0.03566653, -0.03681339, -0.03788699, ..., -0.04314735,\n",
      "           0.03584346,  0.02817367],\n",
      "         [ 0.07927882, -0.00334697,  0.01445981, ..., -0.02635247,\n",
      "          -0.05917034,  0.04779014],\n",
      "         ...,\n",
      "         [-0.03818631,  0.00187004, -0.01646285, ..., -0.03125937,\n",
      "           0.03363681,  0.03912743],\n",
      "         [-0.0364315 , -0.01888089, -0.0290387 , ...,  0.01525068,\n",
      "          -0.01479513,  0.01165333],\n",
      "         [-0.0214779 , -0.01257196, -0.04060119, ..., -0.0003881 ,\n",
      "           0.0209997 , -0.05676678]],\n",
      "\n",
      "        [[-0.05292033, -0.00877951,  0.04254884, ..., -0.03581918,\n",
      "          -0.03389508,  0.03600321],\n",
      "         [ 0.01787825, -0.03440769, -0.00972499, ..., -0.04791811,\n",
      "          -0.03963723,  0.02276838],\n",
      "         [-0.01003306, -0.06721046, -0.02028614, ..., -0.04959149,\n",
      "           0.01533152,  0.00232697],\n",
      "         ...,\n",
      "         [-0.03612881, -0.04783092, -0.00719828, ..., -0.00970146,\n",
      "           0.00566716,  0.00316964],\n",
      "         [ 0.02497883, -0.00362201, -0.03727651, ..., -0.06257764,\n",
      "           0.04180681, -0.02064594],\n",
      "         [-0.0507516 , -0.03794421,  0.03682593, ..., -0.04985438,\n",
      "          -0.00178718, -0.00665709]]],\n",
      "\n",
      "\n",
      "       [[[ 0.01727568,  0.01317608, -0.03356816, ...,  0.00976414,\n",
      "           0.02095249,  0.02674573],\n",
      "         [-0.05430773,  0.02024448,  0.00968155, ..., -0.05899953,\n",
      "          -0.04659681,  0.04010935],\n",
      "         [ 0.00493416, -0.02970789,  0.02499741, ...,  0.00482172,\n",
      "           0.01786749, -0.05100377],\n",
      "         ...,\n",
      "         [ 0.0140687 ,  0.00447916, -0.02168668, ..., -0.01217292,\n",
      "           0.00251901, -0.03506613],\n",
      "         [ 0.01033123, -0.01429547,  0.02460366, ..., -0.08210037,\n",
      "           0.03040355, -0.0181068 ],\n",
      "         [ 0.0419198 , -0.0006487 ,  0.04921878, ..., -0.08974964,\n",
      "          -0.04882147, -0.00588018]],\n",
      "\n",
      "        [[ 0.01270281, -0.00038604,  0.04311493, ..., -0.06302144,\n",
      "           0.03328981,  0.00052198],\n",
      "         [ 0.04539461, -0.03850196, -0.03394752, ...,  0.00888634,\n",
      "           0.00600295, -0.00254425],\n",
      "         [-0.00649044, -0.0450761 , -0.01617811, ...,  0.04347517,\n",
      "           0.02360381, -0.05085847],\n",
      "         ...,\n",
      "         [-0.00296353, -0.02152514, -0.00899262, ..., -0.02832385,\n",
      "          -0.00211553,  0.02480761],\n",
      "         [-0.03300491,  0.06649032,  0.01277127, ..., -0.06530575,\n",
      "           0.05562168, -0.03689557],\n",
      "         [ 0.00078361, -0.02448696,  0.01438533, ..., -0.08104914,\n",
      "           0.03287745, -0.01428656]],\n",
      "\n",
      "        [[ 0.03385048,  0.00847566, -0.00558916, ...,  0.0283665 ,\n",
      "          -0.0121334 , -0.04411991],\n",
      "         [-0.02687882, -0.0270124 , -0.00138944, ...,  0.00091952,\n",
      "          -0.04258037,  0.00043481],\n",
      "         [ 0.03132173, -0.02957752, -0.02128652, ..., -0.02590568,\n",
      "           0.00837323, -0.01794256],\n",
      "         ...,\n",
      "         [ 0.03704017, -0.01792498,  0.02372259, ..., -0.02374484,\n",
      "           0.01978427,  0.03776611],\n",
      "         [ 0.0001716 , -0.02595696,  0.02122569, ..., -0.00976614,\n",
      "          -0.01495243,  0.00161578],\n",
      "         [-0.0256472 , -0.051455  ,  0.00994213, ..., -0.03439068,\n",
      "          -0.0052782 , -0.06223246]],\n",
      "\n",
      "        [[ 0.05076404,  0.05998325,  0.0702123 , ...,  0.07936276,\n",
      "           0.00691051, -0.02922171],\n",
      "         [ 0.01847579, -0.0201168 , -0.00733616, ...,  0.02829279,\n",
      "          -0.04205402, -0.01803174],\n",
      "         [ 0.01243546,  0.02500545, -0.03399065, ..., -0.00361157,\n",
      "           0.01925569, -0.00374   ],\n",
      "         ...,\n",
      "         [-0.02295374,  0.01134469,  0.04320984, ..., -0.05418798,\n",
      "           0.00984974, -0.03709592],\n",
      "         [-0.01116834,  0.02688081, -0.01205743, ...,  0.01375502,\n",
      "           0.03652388, -0.00069441],\n",
      "         [ 0.03162566, -0.02885929,  0.02714435, ...,  0.01179089,\n",
      "           0.02223215, -0.04432341]],\n",
      "\n",
      "        [[ 0.05212156, -0.01076711,  0.07868646, ...,  0.02724543,\n",
      "          -0.01238243,  0.01659968],\n",
      "         [-0.02788536,  0.00312286,  0.00312236, ..., -0.01976139,\n",
      "          -0.04909647, -0.00633103],\n",
      "         [-0.00238715, -0.00721641, -0.00883489, ...,  0.01727922,\n",
      "           0.04195125, -0.03908387],\n",
      "         ...,\n",
      "         [-0.02995341, -0.00431384, -0.02752495, ..., -0.05282635,\n",
      "          -0.00087991, -0.0464407 ],\n",
      "         [-0.00039176,  0.01235624, -0.05020672, ..., -0.07596243,\n",
      "           0.02435627,  0.02501123],\n",
      "         [ 0.02682021,  0.00393902,  0.02453573, ...,  0.00274444,\n",
      "          -0.04303924,  0.02677752]]],\n",
      "\n",
      "\n",
      "       [[[ 0.0321793 ,  0.01094129,  0.03639083, ...,  0.01430765,\n",
      "          -0.02030223,  0.02655931],\n",
      "         [-0.01837105,  0.03980251, -0.00230579, ..., -0.0131712 ,\n",
      "          -0.02903078, -0.02800764],\n",
      "         [-0.0111374 ,  0.01745245,  0.02633413, ..., -0.02174428,\n",
      "           0.07430556,  0.02303295],\n",
      "         ...,\n",
      "         [-0.01489828,  0.03402444, -0.05721166, ...,  0.01243245,\n",
      "          -0.01563274, -0.04346637],\n",
      "         [ 0.0054564 , -0.00495502, -0.03081794, ..., -0.0494069 ,\n",
      "           0.00342235, -0.01248481],\n",
      "         [ 0.00955915,  0.02157062,  0.03103198, ..., -0.05124899,\n",
      "           0.0065834 ,  0.03455389]],\n",
      "\n",
      "        [[ 0.0109041 ,  0.05632297,  0.03135079, ..., -0.0516804 ,\n",
      "           0.01925858, -0.03078576],\n",
      "         [-0.02239027, -0.00969315, -0.00160393, ..., -0.00456393,\n",
      "           0.02747297,  0.03930579],\n",
      "         [-0.03840031, -0.06417699,  0.00810901, ...,  0.01420839,\n",
      "           0.06031652, -0.00513056],\n",
      "         ...,\n",
      "         [-0.0051598 , -0.02446412, -0.05305059, ..., -0.02865534,\n",
      "           0.03357293,  0.04350755],\n",
      "         [ 0.02453834,  0.0055161 , -0.00984378, ..., -0.02015661,\n",
      "          -0.04942649,  0.02240465],\n",
      "         [ 0.01560334, -0.01111501, -0.01260544, ..., -0.01646343,\n",
      "           0.01215183,  0.00513705]],\n",
      "\n",
      "        [[-0.05079731,  0.01111149, -0.04389409, ..., -0.01107861,\n",
      "          -0.0306973 , -0.03252834],\n",
      "         [ 0.00775775, -0.02684043,  0.01114057, ..., -0.01542597,\n",
      "          -0.01594044,  0.02443442],\n",
      "         [-0.0114034 , -0.06021088, -0.06603777, ..., -0.03198956,\n",
      "           0.02600333, -0.03991938],\n",
      "         ...,\n",
      "         [-0.02879965, -0.04885906, -0.02794242, ...,  0.03650275,\n",
      "          -0.03417609, -0.02457157],\n",
      "         [-0.00191895,  0.04892004,  0.02343668, ...,  0.01903879,\n",
      "          -0.00876398, -0.01611813],\n",
      "         [ 0.03704889, -0.00060526,  0.01386673, ..., -0.00734404,\n",
      "           0.010047  ,  0.0067376 ]],\n",
      "\n",
      "        [[-0.06603451,  0.05451148, -0.01380735, ...,  0.03896846,\n",
      "          -0.02033002, -0.00879857],\n",
      "         [ 0.02962874, -0.01809215,  0.01845043, ..., -0.01491364,\n",
      "           0.04984633,  0.01724304],\n",
      "         [-0.02517026, -0.04025347, -0.05237691, ...,  0.01505637,\n",
      "           0.02890164,  0.00572668],\n",
      "         ...,\n",
      "         [-0.02393802, -0.01972128,  0.01940838, ..., -0.0275807 ,\n",
      "           0.02456248, -0.01565219],\n",
      "         [ 0.02796177,  0.0441994 , -0.0449972 , ..., -0.01193288,\n",
      "          -0.00231381, -0.01148765],\n",
      "         [ 0.00399783,  0.01368485, -0.02291686, ...,  0.03896271,\n",
      "          -0.02596476,  0.02953297]],\n",
      "\n",
      "        [[-0.0289627 ,  0.03559822, -0.03368529, ...,  0.04331907,\n",
      "          -0.03087739,  0.00346251],\n",
      "         [-0.05111328,  0.00433821, -0.03269862, ..., -0.04962961,\n",
      "           0.02511516, -0.00759385],\n",
      "         [ 0.04201253, -0.06498206, -0.022694  , ..., -0.04910557,\n",
      "          -0.04022144, -0.04821849],\n",
      "         ...,\n",
      "         [ 0.03459106, -0.02385172, -0.0548097 , ...,  0.00020863,\n",
      "           0.00851073,  0.02201781],\n",
      "         [ 0.01200988,  0.05083095, -0.03124154, ..., -0.01874016,\n",
      "          -0.04621153, -0.00118257],\n",
      "         [-0.02005715, -0.05886372,  0.07358466, ..., -0.0534806 ,\n",
      "           0.0127929 ,  0.04347281]]],\n",
      "\n",
      "\n",
      "       [[[-0.00574159, -0.03524106,  0.03162326, ...,  0.02430055,\n",
      "          -0.0339177 ,  0.01323203],\n",
      "         [ 0.018765  , -0.02846339,  0.00294138, ..., -0.02166273,\n",
      "           0.02334513, -0.01511049],\n",
      "         [-0.03339563, -0.00074751,  0.01687127, ..., -0.04677396,\n",
      "          -0.03152075, -0.03673118],\n",
      "         ...,\n",
      "         [-0.04823276, -0.00732771, -0.03858969, ...,  0.01809752,\n",
      "          -0.00370112,  0.00937872],\n",
      "         [-0.04014101,  0.00999747, -0.03190433, ..., -0.06260409,\n",
      "          -0.05180617, -0.03952111],\n",
      "         [-0.0515109 , -0.01699364, -0.0183805 , ..., -0.03853104,\n",
      "           0.04161279,  0.0164703 ]],\n",
      "\n",
      "        [[ 0.00911276,  0.04286766,  0.01894371, ...,  0.02568715,\n",
      "           0.04239194, -0.0236591 ],\n",
      "         [ 0.00251973,  0.00824188, -0.00975271, ..., -0.00941531,\n",
      "           0.0552487 , -0.02876359],\n",
      "         [-0.01769082, -0.02374942,  0.04199176, ..., -0.00098729,\n",
      "           0.01438907,  0.01527352],\n",
      "         ...,\n",
      "         [-0.0533765 , -0.05381009, -0.01092054, ...,  0.02133526,\n",
      "          -0.0136384 ,  0.00993663],\n",
      "         [ 0.04237365, -0.0311419 ,  0.01856547, ..., -0.01158421,\n",
      "          -0.04305353, -0.01045332],\n",
      "         [ 0.01248474, -0.0161396 ,  0.00422529, ..., -0.02563783,\n",
      "           0.04200298,  0.03959637]],\n",
      "\n",
      "        [[-0.033067  ,  0.01723836,  0.01578584, ..., -0.02639563,\n",
      "          -0.0247949 , -0.02079173],\n",
      "         [ 0.00801715, -0.03317032,  0.02332863, ...,  0.02446245,\n",
      "           0.04542861, -0.02486651],\n",
      "         [ 0.01633088,  0.0390262 , -0.01667015, ..., -0.05040338,\n",
      "           0.04704094, -0.04029395],\n",
      "         ...,\n",
      "         [-0.02003695, -0.01532362,  0.04787072, ...,  0.02585702,\n",
      "          -0.03549249,  0.04289559],\n",
      "         [-0.05925588,  0.0410966 ,  0.00102613, ..., -0.07177767,\n",
      "          -0.01105215, -0.05328716],\n",
      "         [-0.02323418,  0.03961345,  0.03896252, ..., -0.02925543,\n",
      "           0.02921734, -0.03983151]],\n",
      "\n",
      "        [[-0.03940965,  0.04182931,  0.06683718, ...,  0.01284051,\n",
      "          -0.05864573, -0.02763691],\n",
      "         [-0.05980442, -0.02178643,  0.01157795, ..., -0.01602582,\n",
      "           0.0154341 , -0.03885492],\n",
      "         [-0.0500493 , -0.0232221 , -0.01574692, ..., -0.05201825,\n",
      "           0.00808761,  0.0179966 ],\n",
      "         ...,\n",
      "         [ 0.01775431, -0.03055658, -0.01149948, ..., -0.00828189,\n",
      "          -0.0066702 , -0.02775955],\n",
      "         [ 0.01258763, -0.03472383, -0.00356549, ..., -0.00010467,\n",
      "           0.01055252, -0.01653245],\n",
      "         [-0.04301527,  0.01873381,  0.02036319, ..., -0.04504551,\n",
      "          -0.06362863,  0.02628812]],\n",
      "\n",
      "        [[-0.04921762, -0.04048578,  0.003158  , ..., -0.06488923,\n",
      "          -0.01788766, -0.03518536],\n",
      "         [ 0.03426261, -0.00463165, -0.00032675, ...,  0.01565985,\n",
      "           0.0522686 ,  0.00762969],\n",
      "         [ 0.04123455,  0.01907695, -0.03019395, ..., -0.05421219,\n",
      "          -0.00557306, -0.00256615],\n",
      "         ...,\n",
      "         [-0.02212009,  0.04087339,  0.04994198, ..., -0.02273099,\n",
      "           0.01013869,  0.0150645 ],\n",
      "         [ 0.03603949, -0.01858189,  0.01576092, ...,  0.02866322,\n",
      "          -0.00687921, -0.04253998],\n",
      "         [-0.00141838, -0.01852494,  0.02282293, ..., -0.00859581,\n",
      "          -0.02974867,  0.03352566]]],\n",
      "\n",
      "\n",
      "       [[[-0.00294691, -0.05560258, -0.03174888, ...,  0.03265762,\n",
      "          -0.02343938,  0.02691304],\n",
      "         [ 0.01923583,  0.00399719,  0.02782583, ..., -0.03118934,\n",
      "           0.01613458, -0.03276462],\n",
      "         [ 0.05110655,  0.06114466, -0.02828924, ..., -0.01709878,\n",
      "          -0.04340955,  0.0103822 ],\n",
      "         ...,\n",
      "         [-0.05118517,  0.00037111, -0.02845478, ..., -0.04116948,\n",
      "           0.05385679,  0.01176807],\n",
      "         [ 0.03059145,  0.00214207, -0.02441603, ...,  0.02863654,\n",
      "          -0.02442066,  0.01737659],\n",
      "         [ 0.02874591,  0.01750888, -0.02935907, ...,  0.01885601,\n",
      "          -0.02853188,  0.02037568]],\n",
      "\n",
      "        [[ 0.01479261, -0.05094714, -0.04222865, ...,  0.0112954 ,\n",
      "          -0.02747484,  0.02990256],\n",
      "         [-0.07324094, -0.03664906,  0.02316137, ..., -0.02053868,\n",
      "          -0.02367529,  0.01866128],\n",
      "         [-0.03690374, -0.03054242,  0.00561698, ...,  0.0196819 ,\n",
      "           0.03456646,  0.04830733],\n",
      "         ...,\n",
      "         [-0.0259666 , -0.03327582,  0.00361985, ..., -0.0479352 ,\n",
      "          -0.00637679, -0.02057115],\n",
      "         [ 0.03473433, -0.0212071 , -0.00105576, ...,  0.02003785,\n",
      "          -0.03627726,  0.02714591],\n",
      "         [-0.0167504 ,  0.00799417, -0.01336442, ...,  0.05368063,\n",
      "          -0.00909542, -0.04839503]],\n",
      "\n",
      "        [[-0.02109449,  0.01635933,  0.01079344, ..., -0.0091002 ,\n",
      "          -0.01694697, -0.03673345],\n",
      "         [-0.04768437, -0.03174777,  0.01548151, ..., -0.0478253 ,\n",
      "           0.03525816, -0.04829966],\n",
      "         [ 0.00323647,  0.05861695,  0.02657911, ...,  0.00296431,\n",
      "           0.02838709,  0.03968223],\n",
      "         ...,\n",
      "         [ 0.02799324, -0.03385928, -0.00903083, ...,  0.02020427,\n",
      "           0.03622871,  0.01625377],\n",
      "         [-0.04169516, -0.00918535, -0.05392005, ..., -0.0174867 ,\n",
      "          -0.00880745,  0.03534254],\n",
      "         [ 0.03820754,  0.05321179,  0.02286619, ...,  0.04461302,\n",
      "           0.01264712, -0.0050534 ]],\n",
      "\n",
      "        [[ 0.03020727, -0.06795702,  0.00234927, ..., -0.06811309,\n",
      "          -0.02774272,  0.02306596],\n",
      "         [-0.02733293,  0.00171535,  0.05655936, ...,  0.00490635,\n",
      "          -0.02723398, -0.03592813],\n",
      "         [ 0.02699636,  0.05832538, -0.04069311, ..., -0.01553293,\n",
      "           0.00190376, -0.03706374],\n",
      "         ...,\n",
      "         [ 0.00624888, -0.02043744,  0.04710994, ..., -0.06530829,\n",
      "          -0.03023357, -0.04354563],\n",
      "         [ 0.0433594 , -0.05184852, -0.03419195, ...,  0.04655004,\n",
      "          -0.03239934,  0.04830356],\n",
      "         [-0.00635096,  0.05993466,  0.04057217, ..., -0.03193944,\n",
      "           0.03095152,  0.03331426]],\n",
      "\n",
      "        [[ 0.01922515, -0.01899555, -0.04604064, ..., -0.02896031,\n",
      "           0.04513796, -0.01041437],\n",
      "         [-0.01187556,  0.00869134,  0.01639085, ..., -0.05361436,\n",
      "           0.02838308, -0.02469212],\n",
      "         [-0.01430477,  0.06488609, -0.03360462, ..., -0.00086708,\n",
      "           0.02981293, -0.03920942],\n",
      "         ...,\n",
      "         [-0.01246277, -0.03572026,  0.02795504, ..., -0.05528985,\n",
      "          -0.03716959,  0.04000973],\n",
      "         [-0.01915633, -0.04148411,  0.03647679, ...,  0.08014713,\n",
      "          -0.04850477, -0.01842145],\n",
      "         [-0.0262942 ,  0.00643269, -0.00963905, ..., -0.00987776,\n",
      "           0.02147698,  0.01623652]]]], dtype=float32), array([-0.00519345, -0.01631474, -0.00913599, -0.0248892 , -0.01446629,\n",
      "       -0.01553032, -0.03044582,  0.00676325, -0.05849779,  0.00901829,\n",
      "       -0.00480606, -0.03331483, -0.01542045, -0.00681604, -0.01480416,\n",
      "       -0.04536713, -0.00797613, -0.04318567, -0.02883827, -0.01206208,\n",
      "        0.00464177, -0.00850015, -0.00588683, -0.02984579, -0.02786414,\n",
      "       -0.02099974,  0.00566705, -0.002824  , -0.02046904, -0.00474691,\n",
      "        0.01223297, -0.00644735, -0.0016711 , -0.00865906, -0.0310106 ,\n",
      "       -0.00540512, -0.02498251, -0.00437878, -0.00461655, -0.01241948,\n",
      "       -0.02243594, -0.00584154, -0.01402353, -0.0050634 , -0.02071208,\n",
      "        0.00128302, -0.00028448,  0.00179586], dtype=float32)]\n",
      "[array([1.016391  , 0.9751989 , 0.9606534 , 0.9945854 , 0.9873057 ,\n",
      "       0.950937  , 1.0111698 , 0.98350394, 1.0603663 , 0.9590398 ,\n",
      "       0.9603089 , 1.0407332 , 1.0280666 , 1.018105  , 0.9589201 ,\n",
      "       1.0582125 , 0.99206597, 0.9898603 , 0.9954861 , 0.94855464,\n",
      "       1.0003419 , 1.0058763 , 1.0003983 , 0.99502593, 1.0070567 ,\n",
      "       1.0470995 , 0.9739641 , 0.97956896, 1.0052631 , 1.0079552 ,\n",
      "       0.99700284, 0.9500038 , 0.9617624 , 1.0028362 , 1.0183326 ,\n",
      "       1.0103573 , 1.0868121 , 0.9867954 , 1.0470288 , 0.9671104 ,\n",
      "       1.0246515 , 0.93163544, 0.9983675 , 1.0328603 , 1.0193422 ,\n",
      "       1.0924917 , 0.97232896, 0.940991  ], dtype=float32), array([ 0.04693951,  0.06600649,  0.00687004,  0.00395375, -0.02362559,\n",
      "       -0.00720879,  0.01806329,  0.07133931, -0.00443032,  0.06632842,\n",
      "        0.02273452,  0.00517746, -0.01680924,  0.01815086,  0.06648511,\n",
      "       -0.07999168,  0.00842536,  0.04094087, -0.0132464 ,  0.04284273,\n",
      "        0.04540298,  0.04527289, -0.03237766,  0.00050447, -0.01048812,\n",
      "       -0.03998292,  0.02345271,  0.03533477,  0.01417449,  0.00928777,\n",
      "        0.03055159,  0.05249862,  0.0543615 ,  0.05340802,  0.01810156,\n",
      "        0.05884532,  0.0139197 ,  0.01418209,  0.01552548,  0.06555438,\n",
      "        0.03880376,  0.03763093,  0.0461564 , -0.03567972, -0.0029716 ,\n",
      "        0.03009243,  0.04781   ,  0.01194112], dtype=float32), array([0.7266479 , 0.7208571 , 0.8738909 , 0.41760814, 0.70399684,\n",
      "       0.45709598, 0.31021896, 0.40917036, 0.14664577, 0.10282531,\n",
      "       0.18383223, 0.39002797, 0.2413597 , 0.29537123, 0.3634106 ,\n",
      "       0.46915573, 0.35387513, 0.19174917, 0.24104199, 0.48266655,\n",
      "       1.298568  , 0.59058714, 0.1418902 , 0.32583016, 0.52745306,\n",
      "       0.19004665, 0.17083672, 0.622673  , 0.08026495, 0.08379551,\n",
      "       0.40354407, 0.6034321 , 0.44270363, 0.4452337 , 0.1815118 ,\n",
      "       0.79675317, 0.70707434, 0.6433514 , 0.2404082 , 0.56035084,\n",
      "       0.21754827, 0.5015152 , 0.2568326 , 0.50791943, 0.47269276,\n",
      "       0.18858224, 0.6489253 , 0.8392005 ], dtype=float32), array([1.168313  , 1.0868664 , 1.248316  , 1.2228155 , 1.145272  ,\n",
      "       0.55880225, 0.8144577 , 0.83098495, 0.280681  , 0.25458062,\n",
      "       0.1774729 , 0.8546553 , 0.40541652, 0.75233215, 1.0136564 ,\n",
      "       0.6917946 , 0.70912504, 0.4276217 , 0.3946702 , 1.4151399 ,\n",
      "       3.2778046 , 1.1559851 , 0.2667099 , 0.35642877, 0.7119978 ,\n",
      "       0.340038  , 0.4097971 , 1.2289277 , 0.18675269, 0.11609118,\n",
      "       0.7934197 , 1.7755728 , 1.3822836 , 1.3956263 , 0.35193425,\n",
      "       1.3586059 , 1.0029355 , 0.93536013, 0.55624145, 1.4703505 ,\n",
      "       0.4581061 , 1.6910484 , 0.7651829 , 0.7426258 , 0.6880816 ,\n",
      "       0.46880257, 1.4490278 , 1.722141  ], dtype=float32)]\n",
      "[]\n",
      "[array([[[[-6.99610785e-02, -3.92627269e-02,  3.09473872e-02, ...,\n",
      "           4.12773006e-02,  6.53275624e-02,  8.93525500e-03],\n",
      "         [ 2.68517788e-02,  4.99007441e-02, -7.60256033e-03, ...,\n",
      "          -2.21936442e-02, -2.56100558e-02, -3.73741239e-02],\n",
      "         [ 1.62230767e-02, -5.01479069e-03,  1.45272817e-02, ...,\n",
      "          -5.01430482e-02,  1.65449809e-02,  3.84861901e-02],\n",
      "         ...,\n",
      "         [-5.89458793e-02, -3.68850958e-03, -4.98395599e-02, ...,\n",
      "           3.29663418e-02, -5.45219425e-03,  2.75421925e-02],\n",
      "         [ 1.91463251e-02,  2.18628310e-02,  2.80197132e-02, ...,\n",
      "           1.02914749e-02,  5.91458455e-02,  2.35343650e-02],\n",
      "         [-5.01690656e-02,  1.24380866e-04,  2.83659436e-02, ...,\n",
      "           4.05857563e-02, -1.00190723e-02, -3.71275805e-02]],\n",
      "\n",
      "        [[ 1.56400409e-02, -3.48021537e-02,  7.09305331e-03, ...,\n",
      "          -2.58504022e-02,  2.51640775e-03,  7.51446411e-02],\n",
      "         [-2.55374610e-02,  5.34466766e-02,  3.74475494e-02, ...,\n",
      "           3.57560664e-02,  2.89788023e-02,  4.28113788e-02],\n",
      "         [ 7.48668506e-04,  2.34488845e-02, -5.54727875e-02, ...,\n",
      "           4.22196137e-03, -1.88219063e-02, -3.77540551e-02],\n",
      "         ...,\n",
      "         [-3.62766087e-02, -7.05647841e-03,  3.51582915e-02, ...,\n",
      "          -1.16233472e-02,  1.77435651e-02, -8.93596932e-03],\n",
      "         [ 2.79184431e-02,  3.09608970e-02,  1.08009931e-02, ...,\n",
      "          -3.22140846e-03,  1.14954617e-02,  5.46447672e-02],\n",
      "         [ 1.34861600e-02,  5.63699603e-02,  1.05291400e-02, ...,\n",
      "          -8.73885304e-03, -2.69903410e-02,  1.14853000e-02]],\n",
      "\n",
      "        [[ 1.59255769e-02,  2.70374231e-02,  4.74697426e-02, ...,\n",
      "          -4.63254116e-02,  3.22291255e-02,  6.71472475e-02],\n",
      "         [ 3.50570269e-02,  7.87705407e-02,  3.45279574e-02, ...,\n",
      "           5.44151058e-03,  4.85511962e-03, -6.96279993e-03],\n",
      "         [-3.68537381e-02,  4.94259782e-03,  1.62656233e-02, ...,\n",
      "          -6.37329593e-02, -7.60528222e-02,  6.55429531e-03],\n",
      "         ...,\n",
      "         [-4.19976655e-03, -2.09845286e-02,  4.31815237e-02, ...,\n",
      "          -4.74151671e-02, -2.00210586e-02, -5.11127636e-02],\n",
      "         [-3.56812477e-02, -4.45386618e-02,  3.89920361e-02, ...,\n",
      "          -4.67497334e-02, -2.38853246e-02,  1.06665231e-02],\n",
      "         [-4.04852070e-02,  8.10393170e-02, -4.66934629e-02, ...,\n",
      "          -6.64494559e-02,  2.24204492e-02,  2.62173661e-03]],\n",
      "\n",
      "        [[-3.70754227e-02,  4.02677692e-02, -2.52696164e-02, ...,\n",
      "           5.49624208e-03,  4.87750173e-02,  5.24547026e-02],\n",
      "         [-5.95410448e-03,  3.30360793e-02,  5.52384220e-02, ...,\n",
      "           1.88212134e-02, -3.30454274e-03,  2.60200026e-03],\n",
      "         [-4.57006805e-02, -2.35653706e-02, -1.28988838e-02, ...,\n",
      "           2.45720763e-02, -3.10176443e-02,  3.54981795e-02],\n",
      "         ...,\n",
      "         [ 1.83702465e-02, -8.77254922e-03,  5.91086671e-02, ...,\n",
      "           6.43190136e-03,  1.24053825e-02,  3.15655507e-02],\n",
      "         [ 3.85601223e-02,  1.41542079e-02, -1.58511382e-02, ...,\n",
      "          -2.10120976e-02,  2.23289169e-02, -2.73585692e-03],\n",
      "         [ 1.91037096e-02,  2.45246701e-02,  3.85395922e-02, ...,\n",
      "          -3.85542810e-02, -2.77093705e-02, -3.55160050e-02]],\n",
      "\n",
      "        [[-2.17265878e-02,  5.49909985e-03,  3.04803699e-02, ...,\n",
      "           1.52819725e-02, -1.79012138e-02,  1.44967185e-02],\n",
      "         [ 1.15030073e-02,  6.20616898e-02, -2.65064556e-02, ...,\n",
      "           1.25436662e-02, -1.44731356e-02,  2.37571243e-02],\n",
      "         [-4.45793122e-02,  1.99945197e-02,  3.73515077e-02, ...,\n",
      "           2.04289183e-02, -4.90893573e-02, -9.60614998e-03],\n",
      "         ...,\n",
      "         [-6.76867738e-03,  3.05299107e-02,  4.15217690e-02, ...,\n",
      "          -1.19430367e-02, -2.98989248e-02,  2.62240507e-03],\n",
      "         [-3.16471383e-02,  1.63374394e-02,  1.32457800e-02, ...,\n",
      "          -3.06561217e-02,  7.10598333e-03,  3.64110209e-02],\n",
      "         [-4.06292873e-03,  2.76738685e-02, -2.99176499e-02, ...,\n",
      "          -5.30918613e-02, -5.37070557e-02,  8.56789015e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 2.74795834e-02,  5.20279184e-02, -3.49464417e-02, ...,\n",
      "          -3.43402214e-02, -5.41353412e-02, -1.78399533e-02],\n",
      "         [-6.56285658e-02,  1.26882019e-02,  1.35967880e-02, ...,\n",
      "          -6.46608882e-04, -1.30031386e-03,  1.58718955e-02],\n",
      "         [-1.74394026e-02,  2.72185896e-02,  3.38774845e-02, ...,\n",
      "          -8.75098724e-03, -5.58742546e-02,  7.22885085e-03],\n",
      "         ...,\n",
      "         [-2.78907679e-02,  4.52089123e-02,  2.01104060e-02, ...,\n",
      "          -5.12421771e-04,  3.48951370e-02, -1.00175980e-02],\n",
      "         [ 1.89193022e-02, -9.24813841e-03,  5.31230588e-03, ...,\n",
      "           2.69289166e-02, -3.40641886e-02, -4.64526229e-02],\n",
      "         [-5.27490675e-02,  1.28849214e-02, -7.38251302e-03, ...,\n",
      "          -3.71024758e-03,  5.85524365e-02,  4.00365219e-02]],\n",
      "\n",
      "        [[-4.16676663e-02,  1.42863793e-02,  4.63736802e-03, ...,\n",
      "          -2.81116962e-02,  1.98284537e-02,  3.99935283e-02],\n",
      "         [-9.67473630e-03,  1.02307070e-02,  1.00368168e-02, ...,\n",
      "          -5.62988073e-02, -4.49951291e-02, -2.46800929e-02],\n",
      "         [ 2.85568330e-02,  1.63487382e-02, -1.74894184e-03, ...,\n",
      "          -5.47908917e-02,  7.18273269e-03, -6.21941825e-03],\n",
      "         ...,\n",
      "         [-3.02074733e-03,  1.29960589e-02, -7.17339991e-03, ...,\n",
      "           3.78233008e-02,  5.17129712e-02,  4.39964198e-02],\n",
      "         [ 8.94666463e-03, -6.39231279e-02, -1.89933609e-02, ...,\n",
      "           2.93309726e-02, -3.69279347e-02,  1.54997676e-03],\n",
      "         [ 3.05269994e-02, -4.05900367e-02, -4.63617295e-02, ...,\n",
      "          -2.01278646e-03,  3.06401365e-02,  4.90353629e-02]],\n",
      "\n",
      "        [[-3.28795128e-02,  1.37075689e-02,  1.01592038e-02, ...,\n",
      "          -3.92487943e-02,  2.70626834e-03, -8.15542240e-04],\n",
      "         [-2.59120632e-02, -5.40511012e-02,  2.59902887e-02, ...,\n",
      "          -6.70224503e-02, -5.16572734e-03,  1.78818963e-02],\n",
      "         [-1.67188235e-02, -7.11588264e-02,  3.44592403e-03, ...,\n",
      "          -4.27618111e-03,  4.67596315e-02, -1.15047023e-03],\n",
      "         ...,\n",
      "         [-6.92350790e-04, -5.24031557e-02, -5.58831729e-02, ...,\n",
      "          -7.80381868e-03,  5.21706454e-02, -3.71417254e-02],\n",
      "         [-5.45009680e-04, -2.37500877e-03, -2.49116328e-02, ...,\n",
      "           5.27958162e-02,  1.14997262e-02, -1.30369943e-02],\n",
      "         [-4.85110562e-03,  3.45033333e-02, -3.31231877e-02, ...,\n",
      "          -1.96345150e-02, -1.25327986e-02, -3.91430669e-02]],\n",
      "\n",
      "        [[-1.44675653e-02, -4.38550934e-02, -1.94978956e-02, ...,\n",
      "          -6.20604232e-02, -3.30137983e-02,  4.15757634e-02],\n",
      "         [-6.68765008e-02, -5.76226711e-02, -1.36104226e-02, ...,\n",
      "           3.11886426e-02,  3.36815529e-02, -4.03813384e-02],\n",
      "         [-1.34273767e-02, -8.91806837e-03, -2.86632497e-02, ...,\n",
      "           8.59895721e-03, -2.97952536e-02, -6.21606670e-02],\n",
      "         ...,\n",
      "         [-3.10117695e-02,  3.30362320e-02, -6.66677486e-03, ...,\n",
      "          -3.30168083e-02, -3.50407586e-02, -8.39019660e-03],\n",
      "         [ 1.22991325e-02, -2.85430700e-02, -3.52979004e-02, ...,\n",
      "           5.64005971e-02, -2.31746621e-02,  2.42085792e-02],\n",
      "         [ 1.39267016e-02, -2.27079671e-02, -2.27021966e-02, ...,\n",
      "           3.38364914e-02, -3.54262590e-02, -2.96043567e-02]],\n",
      "\n",
      "        [[-4.68218029e-02,  2.27568354e-02,  6.59675747e-02, ...,\n",
      "          -1.92927923e-02, -1.32580325e-02, -8.79624044e-04],\n",
      "         [ 9.51865222e-03, -1.32096475e-02, -4.17286567e-02, ...,\n",
      "           1.44829117e-02,  1.20154256e-02, -2.00270768e-02],\n",
      "         [ 3.56159098e-02, -1.19332513e-02, -5.70735568e-03, ...,\n",
      "           1.86957978e-02,  5.21348417e-02, -2.78670806e-02],\n",
      "         ...,\n",
      "         [-5.22537269e-02,  4.78887185e-02, -4.78822878e-03, ...,\n",
      "          -3.87426168e-02,  6.99312100e-03,  2.67645922e-02],\n",
      "         [ 1.74358487e-02,  2.82761771e-02,  2.84192357e-02, ...,\n",
      "           7.14625884e-03, -2.53974777e-02, -4.53972593e-02],\n",
      "         [ 1.95323993e-02, -1.59885846e-02, -1.82648059e-02, ...,\n",
      "          -5.10010757e-02, -1.49612641e-02,  1.34671871e-02]]],\n",
      "\n",
      "\n",
      "       [[[-5.45477271e-02,  2.85735317e-02, -3.22219729e-02, ...,\n",
      "           1.03182402e-02,  2.22160053e-02,  3.24235298e-03],\n",
      "         [ 8.12330376e-03, -3.61016393e-02, -3.45979109e-02, ...,\n",
      "          -1.79399289e-02, -8.87328945e-03,  3.95917036e-02],\n",
      "         [ 2.40843911e-02, -3.77061181e-02, -1.37361428e-02, ...,\n",
      "           8.54138937e-03, -4.31856364e-02, -4.07642014e-02],\n",
      "         ...,\n",
      "         [-1.02067748e-02,  2.48599239e-02,  5.79335447e-03, ...,\n",
      "          -1.94455460e-02, -3.08197662e-02, -1.27714267e-02],\n",
      "         [ 6.75973133e-04,  1.36364466e-02, -3.97932976e-02, ...,\n",
      "           2.74609588e-03, -1.67351440e-02, -1.17805758e-02],\n",
      "         [-2.92052701e-02,  7.37791834e-03, -7.68222788e-04, ...,\n",
      "          -3.91884111e-02, -3.11188698e-02, -4.33815643e-02]],\n",
      "\n",
      "        [[-5.20272702e-02,  2.00825129e-02,  1.32925259e-02, ...,\n",
      "           4.23454829e-02, -3.30778398e-02, -9.09232721e-03],\n",
      "         [-4.38621081e-02,  1.25560667e-02,  3.26836519e-02, ...,\n",
      "          -4.12826017e-02, -7.37098679e-02,  2.77129910e-03],\n",
      "         [-1.66577455e-02,  5.75222932e-02, -1.54545913e-02, ...,\n",
      "           7.14836866e-02, -2.60511283e-02, -4.52635363e-02],\n",
      "         ...,\n",
      "         [-4.00483273e-02, -3.41164111e-03, -1.98726580e-02, ...,\n",
      "          -1.69238243e-02,  9.22947936e-03, -3.45041044e-02],\n",
      "         [ 1.48555553e-02, -2.23533586e-02, -5.80963753e-02, ...,\n",
      "          -8.24722182e-03,  1.03170956e-02,  3.95716317e-02],\n",
      "         [ 1.34183941e-02, -4.01799567e-02, -2.13862956e-02, ...,\n",
      "           3.25173475e-02, -1.43482788e-02, -3.90608460e-02]],\n",
      "\n",
      "        [[ 3.53107303e-02,  7.92243343e-04, -2.43971460e-02, ...,\n",
      "           7.08938166e-02,  2.11698487e-02, -2.34184973e-02],\n",
      "         [-1.98057201e-03,  3.70980725e-02,  6.97445031e-03, ...,\n",
      "          -5.38180880e-02, -1.28237400e-02, -1.28743313e-02],\n",
      "         [ 3.63344811e-02, -2.95047518e-02,  2.33724918e-02, ...,\n",
      "           3.43278311e-02, -7.26473425e-03, -1.96086075e-02],\n",
      "         ...,\n",
      "         [ 2.72143586e-03, -3.69288363e-02, -3.57424170e-02, ...,\n",
      "           5.34013472e-03,  1.70627143e-02, -2.62758583e-02],\n",
      "         [ 1.91817936e-02, -1.89694879e-03, -4.50659469e-02, ...,\n",
      "          -4.07532528e-02, -2.39240788e-02, -1.37010897e-02],\n",
      "         [ 1.35970796e-02, -3.12354695e-02,  6.33108988e-02, ...,\n",
      "           3.07796299e-02, -2.75520068e-02, -1.91651210e-02]],\n",
      "\n",
      "        [[-3.29523608e-02, -5.38035817e-02,  6.17107516e-03, ...,\n",
      "           2.03155950e-02,  2.41911523e-02, -5.71013205e-02],\n",
      "         [-4.05743644e-02,  1.92173533e-02, -3.26246917e-02, ...,\n",
      "           1.38901630e-02, -4.26131450e-02, -5.19626550e-02],\n",
      "         [ 1.08230058e-02, -4.79951389e-02,  3.59039418e-02, ...,\n",
      "          -2.66555790e-02, -1.73972063e-02,  2.49210000e-02],\n",
      "         ...,\n",
      "         [-3.63874435e-02,  1.05023775e-02, -1.83677413e-02, ...,\n",
      "          -2.69120000e-02, -1.05329100e-02,  2.09816843e-02],\n",
      "         [-5.37187755e-02,  3.07678021e-02,  3.48512940e-02, ...,\n",
      "          -1.36829540e-02,  3.26696858e-02,  1.51625769e-02],\n",
      "         [-3.92448604e-02,  6.08484447e-03, -5.08613046e-03, ...,\n",
      "          -2.34155674e-02,  1.22229075e-02,  1.60019193e-02]],\n",
      "\n",
      "        [[-5.70284240e-02, -6.65517747e-02,  1.99852753e-02, ...,\n",
      "           1.29208891e-02,  3.52670550e-02,  2.89351251e-02],\n",
      "         [-2.49132654e-03, -9.95986816e-03, -2.56168991e-02, ...,\n",
      "          -2.06741150e-02, -3.68848108e-02, -2.16096863e-02],\n",
      "         [-5.53309880e-02, -9.29920748e-03,  1.43014742e-02, ...,\n",
      "           5.49472403e-03,  2.14491002e-02,  3.67018245e-02],\n",
      "         ...,\n",
      "         [-4.48604561e-02,  1.43941920e-02, -5.98367676e-02, ...,\n",
      "           1.26937404e-02, -1.06417853e-03, -9.75244492e-03],\n",
      "         [ 4.53536026e-03,  1.97324008e-02, -2.77762134e-02, ...,\n",
      "          -7.80476630e-03, -4.74234391e-03,  3.27344127e-02],\n",
      "         [-2.73508690e-02, -3.49628553e-02,  1.51278004e-02, ...,\n",
      "          -3.89024504e-02, -2.63909008e-02, -2.20867731e-02]]],\n",
      "\n",
      "\n",
      "       [[[-4.63653076e-03,  4.18649651e-02, -3.70430574e-02, ...,\n",
      "          -2.48069521e-02,  7.73168809e-04, -4.76331562e-02],\n",
      "         [ 7.17745395e-04, -6.28226921e-02,  3.31457555e-02, ...,\n",
      "          -6.02343911e-03, -4.24973816e-02, -1.25176841e-02],\n",
      "         [-5.76750701e-03,  5.42856939e-02, -2.55987570e-02, ...,\n",
      "          -2.54060095e-03,  1.74871609e-02,  2.39621177e-02],\n",
      "         ...,\n",
      "         [ 3.15631554e-02, -6.00721277e-02,  4.67709545e-03, ...,\n",
      "           5.37482463e-02,  5.55209955e-03,  2.05892287e-02],\n",
      "         [-1.04996953e-02, -6.72999546e-02, -4.88141850e-02, ...,\n",
      "           4.54483274e-03, -1.28793782e-02,  3.07215322e-02],\n",
      "         [-2.85681654e-02,  1.25858914e-02, -6.44866703e-03, ...,\n",
      "          -1.93198100e-02, -1.42125711e-02,  3.92405726e-02]],\n",
      "\n",
      "        [[-2.83934642e-02, -5.68139972e-03,  2.18004882e-02, ...,\n",
      "           2.76445393e-02, -8.65181722e-03, -3.69249620e-02],\n",
      "         [-1.54865542e-02, -3.95286381e-02, -3.57018597e-02, ...,\n",
      "          -2.64928918e-02, -2.87840087e-02, -2.42388505e-03],\n",
      "         [-7.16473535e-03,  3.36619690e-02,  1.64592322e-02, ...,\n",
      "           6.93538561e-02,  3.81589644e-02,  2.35745441e-02],\n",
      "         ...,\n",
      "         [ 5.07000722e-02, -4.39805761e-02, -6.68613426e-03, ...,\n",
      "           5.97439185e-02, -3.15430015e-02,  5.96262813e-02],\n",
      "         [-1.06919417e-02, -5.23655629e-03, -1.53467981e-02, ...,\n",
      "          -3.20386328e-02, -2.43237242e-02, -1.37951141e-02],\n",
      "         [ 2.09987517e-02, -1.05310995e-02, -3.64868343e-02, ...,\n",
      "           4.92611229e-02, -7.80365616e-03,  3.29645276e-02]],\n",
      "\n",
      "        [[ 5.21180369e-02, -2.88624335e-02,  2.25778669e-02, ...,\n",
      "           8.15427396e-03,  2.51326673e-02,  4.64491695e-02],\n",
      "         [-3.16111604e-04, -1.33418459e-02, -1.03598787e-02, ...,\n",
      "           3.50287668e-02, -4.79071774e-02, -5.42958751e-02],\n",
      "         [ 1.88277271e-02,  6.40121102e-03, -4.86841276e-02, ...,\n",
      "           5.03845587e-02,  4.39745095e-03, -1.39718205e-02],\n",
      "         ...,\n",
      "         [ 3.16046402e-02, -4.35079932e-02, -1.83802973e-02, ...,\n",
      "           5.13129868e-02,  2.82734986e-02, -5.96470432e-03],\n",
      "         [-4.64888057e-03,  3.81454565e-02, -2.03276295e-02, ...,\n",
      "           5.99471168e-05,  3.09965033e-02,  1.27280345e-02],\n",
      "         [-7.61710387e-03, -4.49412912e-02,  2.50727236e-02, ...,\n",
      "           4.72586229e-02,  5.04687391e-02, -1.53056663e-02]],\n",
      "\n",
      "        [[-3.91311832e-02, -8.87913350e-03,  1.58957206e-02, ...,\n",
      "           2.71572024e-02, -3.30328792e-02, -2.53488887e-02],\n",
      "         [-3.90298329e-02,  5.00741787e-03,  5.17879464e-02, ...,\n",
      "          -3.85278501e-02,  3.19811180e-02,  2.53428463e-02],\n",
      "         [ 1.66983008e-02, -1.68190897e-02, -4.07298133e-02, ...,\n",
      "          -1.59300789e-02, -5.98838599e-03,  9.73764621e-03],\n",
      "         ...,\n",
      "         [ 1.79255009e-03, -5.12641110e-02,  3.78840690e-04, ...,\n",
      "          -4.96601388e-02, -1.62581746e-02, -3.14481109e-02],\n",
      "         [-1.79017391e-02,  5.92720928e-03,  2.14172453e-02, ...,\n",
      "           4.88688704e-03,  2.81883255e-02,  6.43399032e-03],\n",
      "         [ 1.73961222e-02, -1.77502539e-02,  3.17355469e-02, ...,\n",
      "           2.00298596e-02,  2.98859254e-02,  3.36082913e-02]],\n",
      "\n",
      "        [[-4.93640825e-03,  4.46385890e-02, -4.74120752e-04, ...,\n",
      "           3.12186517e-02, -6.03714201e-04, -3.62979621e-02],\n",
      "         [-1.19669903e-02,  1.93877034e-02,  1.72373781e-03, ...,\n",
      "          -3.01297475e-02,  1.11334296e-02, -1.50724417e-02],\n",
      "         [ 2.16071419e-02, -4.49204408e-02, -2.68400908e-02, ...,\n",
      "           5.49094826e-02,  3.98866832e-02,  4.55878442e-03],\n",
      "         ...,\n",
      "         [ 4.34106924e-02, -5.03062941e-02,  8.73113342e-04, ...,\n",
      "          -1.81157738e-02, -3.68454643e-02, -6.16721995e-03],\n",
      "         [ 2.41815522e-02, -3.58045511e-02,  1.69087225e-03, ...,\n",
      "          -1.48920286e-02,  2.45945863e-02, -2.67464835e-02],\n",
      "         [-2.60292348e-02, -3.02360114e-03,  1.88751593e-02, ...,\n",
      "           5.62174022e-02, -3.77107561e-02,  1.12586538e-03]]],\n",
      "\n",
      "\n",
      "       [[[ 2.96000129e-04,  2.73497626e-02,  3.90613377e-02, ...,\n",
      "           3.41646932e-02, -1.69945080e-02,  1.90827996e-03],\n",
      "         [ 4.03991491e-02, -4.55251560e-02, -1.41170342e-02, ...,\n",
      "          -3.24047878e-02, -7.87914824e-03, -1.04902370e-03],\n",
      "         [-1.30010145e-02, -2.69503314e-02,  2.13437434e-02, ...,\n",
      "          -4.94089089e-02,  1.60545809e-03,  4.53482084e-02],\n",
      "         ...,\n",
      "         [-1.55457482e-02, -6.00617640e-02, -1.17427204e-02, ...,\n",
      "          -3.07245329e-02,  8.48143175e-03,  2.18491219e-02],\n",
      "         [-7.13560078e-03, -3.47152017e-02,  1.99414231e-03, ...,\n",
      "          -4.43701521e-02, -5.94238378e-02, -2.11268887e-02],\n",
      "         [-9.49166156e-03, -1.60776004e-02, -1.36043373e-02, ...,\n",
      "           6.82628524e-05,  1.27862794e-02,  2.89542470e-02]],\n",
      "\n",
      "        [[-3.97996902e-02,  2.91498285e-02, -1.03136739e-02, ...,\n",
      "          -6.00724742e-02, -5.61276544e-03, -2.79872604e-02],\n",
      "         [ 1.88481342e-02, -2.08263360e-02,  4.72859740e-02, ...,\n",
      "          -3.77840619e-03, -2.59109288e-02, -2.20958814e-02],\n",
      "         [-2.33576931e-02,  1.69091169e-02, -4.50470410e-02, ...,\n",
      "           2.19148528e-02,  2.76431628e-02,  5.11820652e-02],\n",
      "         ...,\n",
      "         [-3.28048691e-02,  3.72925997e-02, -5.03791571e-02, ...,\n",
      "           6.96816714e-03,  3.05273657e-04, -3.01021691e-02],\n",
      "         [-3.95049937e-02, -3.92362475e-02,  4.46187742e-02, ...,\n",
      "           1.50565114e-02, -5.87081723e-03,  5.05037531e-02],\n",
      "         [ 3.42512466e-02,  5.49690006e-03,  3.65964347e-03, ...,\n",
      "           2.12368625e-03, -1.54690603e-02,  1.32312328e-02]],\n",
      "\n",
      "        [[ 4.29104753e-02, -2.42919158e-02,  3.38494293e-02, ...,\n",
      "          -1.74487531e-02,  1.88243650e-02, -3.29777710e-02],\n",
      "         [ 3.77078094e-02,  1.71226580e-02, -2.15255991e-02, ...,\n",
      "          -3.90447788e-02, -4.88173701e-02,  1.27530079e-02],\n",
      "         [-1.91971511e-02,  2.98226289e-02, -4.86240089e-02, ...,\n",
      "          -4.10489105e-02,  5.41665852e-02,  4.23350707e-02],\n",
      "         ...,\n",
      "         [-2.23074425e-02, -5.83382137e-02,  3.64841782e-02, ...,\n",
      "          -2.25585103e-02,  1.77039276e-03,  1.81070447e-03],\n",
      "         [-1.80097602e-04, -3.88609469e-02, -4.37440127e-02, ...,\n",
      "          -6.08831048e-02,  2.29304265e-02,  3.04064788e-02],\n",
      "         [-2.31020804e-02,  3.96453291e-02, -1.01653142e-02, ...,\n",
      "          -5.23264892e-02, -3.32933082e-03,  5.07459464e-03]],\n",
      "\n",
      "        [[ 4.45480049e-02, -1.11985661e-03, -1.98925659e-02, ...,\n",
      "           4.53121141e-02, -3.05186063e-02, -1.63293127e-02],\n",
      "         [ 1.70255378e-02, -3.86181772e-02, -8.40415829e-04, ...,\n",
      "          -8.29094741e-03,  1.74471941e-02, -3.37187760e-02],\n",
      "         [ 3.43796983e-02, -5.38423322e-02, -5.24341874e-03, ...,\n",
      "           1.72981638e-02,  9.47483163e-03, -6.06475910e-03],\n",
      "         ...,\n",
      "         [-3.75663824e-02,  1.12436693e-02, -5.05235717e-02, ...,\n",
      "          -3.64899859e-02,  1.60833579e-02, -4.94868867e-02],\n",
      "         [-1.38122146e-03,  1.28657976e-02,  2.72781365e-02, ...,\n",
      "          -5.09183146e-02,  9.69225448e-03,  4.38580066e-02],\n",
      "         [ 3.44094634e-02,  3.35261598e-02, -2.08228678e-02, ...,\n",
      "          -3.39448750e-02,  1.97721124e-02, -6.26801932e-03]],\n",
      "\n",
      "        [[ 4.60686572e-02,  6.52019866e-03,  5.09668998e-02, ...,\n",
      "          -2.30754651e-02, -5.89202829e-02,  2.97070704e-02],\n",
      "         [ 1.50695061e-02,  1.68054905e-02, -1.75201911e-02, ...,\n",
      "          -4.67605479e-02, -2.73896405e-03,  2.52101757e-02],\n",
      "         [-2.24132966e-02, -5.94846867e-02, -2.68001892e-02, ...,\n",
      "           3.33557464e-02,  1.87317301e-02,  2.11167801e-02],\n",
      "         ...,\n",
      "         [-7.15024769e-02,  2.62362622e-02, -1.63955539e-02, ...,\n",
      "          -3.26710753e-02, -4.78943326e-02,  3.18793915e-02],\n",
      "         [ 2.28177179e-02,  2.01456659e-02, -2.62905341e-02, ...,\n",
      "          -4.18613330e-02, -3.50033701e-03,  2.23360467e-03],\n",
      "         [-5.23646958e-02, -5.35950512e-02,  7.11938459e-03, ...,\n",
      "          -5.20087071e-02, -1.30896466e-02,  2.93511227e-02]]]],\n",
      "      dtype=float32), array([-0.02353609, -0.02569739, -0.00455816, -0.00918178, -0.01472873,\n",
      "       -0.04421351, -0.01081746, -0.01084797, -0.0083541 , -0.01786542,\n",
      "       -0.02511856, -0.01377759, -0.01307869, -0.00738659, -0.01696442,\n",
      "       -0.01128265, -0.01116654, -0.01231695, -0.00896361, -0.01768807,\n",
      "       -0.00740603, -0.01553703, -0.00479036, -0.01345041, -0.01919964,\n",
      "       -0.02438545, -0.02481694, -0.00659319, -0.01654488, -0.04581998,\n",
      "        0.00297955, -0.03865314, -0.0137231 , -0.01169132, -0.0110848 ,\n",
      "       -0.00700962, -0.00347263, -0.01668983, -0.0049943 , -0.00932962,\n",
      "       -0.01768608, -0.01307986, -0.00468837, -0.02014798, -0.06786325,\n",
      "       -0.01695167, -0.01858773, -0.0109665 ], dtype=float32)]\n",
      "[array([1.0065175 , 1.0810347 , 0.9622944 , 1.018094  , 0.93867195,\n",
      "       1.1237103 , 0.9827796 , 1.1233197 , 0.9640098 , 0.99537736,\n",
      "       1.0873984 , 0.9667069 , 0.9836423 , 0.9430918 , 1.0129061 ,\n",
      "       0.97504616, 1.0624499 , 1.0599852 , 1.0298818 , 1.0355701 ,\n",
      "       0.9387013 , 1.0071846 , 0.9311647 , 0.98058075, 1.0518073 ,\n",
      "       1.0247611 , 1.0600342 , 1.0601428 , 1.1198416 , 1.0559413 ,\n",
      "       0.97541046, 1.09912   , 0.99740833, 1.001661  , 0.9558436 ,\n",
      "       0.9610228 , 0.9539406 , 1.0411366 , 0.9443508 , 0.9656385 ,\n",
      "       0.9865918 , 1.002165  , 1.0082431 , 0.9608369 , 1.165922  ,\n",
      "       1.0201638 , 1.0268604 , 0.9267961 ], dtype=float32), array([-0.05077438, -0.01265103, -0.05268569, -0.05765668, -0.04572969,\n",
      "       -0.09166654, -0.06233389, -0.08634577, -0.05419973, -0.06283458,\n",
      "       -0.02427206, -0.04366712, -0.08361857, -0.02542992, -0.04231375,\n",
      "       -0.06158971, -0.04904068, -0.05497625, -0.0454662 , -0.05318881,\n",
      "       -0.03051923, -0.02785341, -0.02335694, -0.0472734 , -0.03716702,\n",
      "       -0.06328341, -0.04014955, -0.03271311, -0.01920588, -0.04464887,\n",
      "       -0.0307558 , -0.02641483, -0.03239619, -0.02557893, -0.03966452,\n",
      "       -0.04903264, -0.0369714 , -0.04440924, -0.02965959, -0.03223085,\n",
      "       -0.05436971, -0.00959579, -0.0452273 , -0.03520083, -0.08910023,\n",
      "       -0.05776714, -0.06986164, -0.02339511], dtype=float32), array([0.20518471, 0.12173695, 0.72309834, 0.21343803, 0.40140697,\n",
      "       0.14027475, 0.5124935 , 0.4028985 , 0.42459399, 0.22460826,\n",
      "       0.11001592, 0.5371554 , 0.5755191 , 0.5611292 , 0.22923502,\n",
      "       0.6318035 , 0.33954677, 0.0845264 , 0.61184365, 0.18692562,\n",
      "       1.2009727 , 0.10615729, 1.1450074 , 0.25262064, 0.14107256,\n",
      "       0.16726755, 0.1716655 , 0.22623463, 0.09538011, 0.21443462,\n",
      "       0.15839778, 0.11344301, 0.11243388, 0.19801646, 0.22165729,\n",
      "       0.51576537, 0.71438104, 0.13015965, 0.4331019 , 0.3482941 ,\n",
      "       0.36447325, 0.21854153, 0.56778806, 0.14657494, 0.09677742,\n",
      "       0.19217582, 0.2768075 , 0.43991226], dtype=float32), array([0.22285196, 0.25468093, 1.1713966 , 0.46323574, 0.83847654,\n",
      "       0.28363597, 0.66396946, 0.9597865 , 0.51698095, 0.631284  ,\n",
      "       0.3050898 , 0.8575946 , 0.8502367 , 0.72867817, 0.43985555,\n",
      "       1.3159182 , 0.50246793, 0.11259352, 0.8585281 , 0.39923537,\n",
      "       3.120886  , 0.21804053, 2.5126588 , 0.4593222 , 0.3599881 ,\n",
      "       0.29296032, 0.49758413, 0.4178838 , 0.21018492, 0.4450441 ,\n",
      "       0.40080374, 0.3682857 , 0.2422794 , 0.32866246, 0.32319763,\n",
      "       0.61904836, 1.224868  , 0.29231155, 1.4897201 , 0.5866182 ,\n",
      "       0.6885368 , 0.60441315, 0.82755554, 0.36051956, 0.24292597,\n",
      "       0.33615386, 0.56000346, 1.0645834 ], dtype=float32)]\n",
      "[]\n",
      "[]\n",
      "[array([[ 0.01371628,  0.02598301, -0.0150319 , ..., -0.03712562,\n",
      "        -0.00307484, -0.00179032],\n",
      "       [ 0.00666498,  0.01747597,  0.03017553, ...,  0.02900821,\n",
      "        -0.02076818, -0.01943608],\n",
      "       [-0.01797759,  0.03597405, -0.02349428, ..., -0.02038906,\n",
      "        -0.00811799, -0.00367941],\n",
      "       ...,\n",
      "       [ 0.02193427,  0.0028955 , -0.02731336, ...,  0.03002696,\n",
      "        -0.00926207,  0.00510872],\n",
      "       [-0.01517669,  0.02268287,  0.01982398, ...,  0.00121011,\n",
      "         0.03415929, -0.02124461],\n",
      "       [ 0.03110803,  0.02469838,  0.00908418, ...,  0.02390342,\n",
      "        -0.01339405, -0.02425058]], dtype=float32), array([-1.7447753e-03, -3.9993436e-03,  2.2492744e-03, -1.3337580e-03,\n",
      "       -1.5083206e-03,  5.9390063e-03,  5.1198974e-03,  2.4676346e-03,\n",
      "       -3.3414983e-03,  5.9295623e-03, -2.0540187e-03, -2.5224646e-03,\n",
      "       -2.7989310e-03, -2.8974270e-03,  2.8183169e-03, -5.7879202e-03,\n",
      "       -2.3570396e-03, -2.7913614e-03, -1.1113071e-03,  1.3106740e-03,\n",
      "       -3.5875188e-03,  4.3923996e-04,  2.4710773e-03,  1.1152271e-03,\n",
      "       -7.1287778e-04, -4.1146656e-03, -9.0763774e-03,  3.3167377e-03,\n",
      "       -3.1976318e-03, -4.2319810e-03, -2.3147434e-03, -2.4095664e-03,\n",
      "       -1.4588896e-03,  2.7124695e-03, -7.7243433e-03, -1.4929911e-03,\n",
      "        3.5381133e-03, -9.3968178e-04,  3.2735895e-04, -1.4413395e-03,\n",
      "       -9.5639564e-04, -4.7299569e-03,  3.0760725e-03, -2.6613264e-03,\n",
      "        2.3457864e-03, -1.6013537e-05, -1.1756662e-03, -2.3472381e-03,\n",
      "       -1.6334894e-04,  2.3598861e-04, -1.2746539e-04,  4.1244049e-03,\n",
      "       -2.1161179e-03,  4.0949169e-03,  2.0708453e-03, -1.2390104e-03,\n",
      "       -1.9576328e-03, -2.6208628e-03, -1.3437796e-03, -3.9481781e-03,\n",
      "        4.6010269e-03, -3.1582846e-03,  4.9576722e-03, -2.6423705e-03],\n",
      "      dtype=float32)]\n",
      "[]\n",
      "[array([[ 0.09871162,  0.02107837,  0.03403564, ...,  0.0681347 ,\n",
      "        -0.16252165, -0.11462077],\n",
      "       [-0.01666211, -0.12586623, -0.07562706, ...,  0.08209931,\n",
      "         0.09195325,  0.00729537],\n",
      "       [ 0.05459423, -0.00794343, -0.07977588, ..., -0.05303666,\n",
      "         0.19349895, -0.16621737],\n",
      "       ...,\n",
      "       [-0.00643848,  0.04451058,  0.07387013, ...,  0.01387274,\n",
      "         0.1627397 , -0.11520352],\n",
      "       [-0.13892564,  0.11285029,  0.11246834, ..., -0.06349139,\n",
      "         0.17710893, -0.07742479],\n",
      "       [-0.13293001,  0.09068945,  0.02755734, ..., -0.16347936,\n",
      "         0.08200872, -0.026589  ]], dtype=float32), array([-0.0106664 ,  0.02271707,  0.00524962,  0.00010381,  0.02300615,\n",
      "        0.00339129,  0.04767423,  0.01950046,  0.00452339, -0.00626758,\n",
      "        0.00692365, -0.02136006,  0.03812331, -0.00139804,  0.01259132,\n",
      "        0.00493631,  0.02650844, -0.01186646,  0.05702965,  0.00121301,\n",
      "        0.01345556,  0.01575854, -0.00119781,  0.03263782,  0.04265986,\n",
      "        0.03653492, -0.01334658,  0.01226458,  0.03248037,  0.06873124,\n",
      "        0.01736094,  0.04104399,  0.00887801, -0.00400843,  0.02810433,\n",
      "        0.00855047, -0.00512359,  0.02204769, -0.00087711,  0.0254359 ,\n",
      "       -0.00504147,  0.00707049,  0.00215676,  0.07203303, -0.00396642,\n",
      "        0.00152546,  0.02079211,  0.00703505,  0.01084014,  0.0150936 ,\n",
      "        0.00298427,  0.00999253, -0.01494846,  0.01815332, -0.00912022,\n",
      "        0.01911454,  0.08152143,  0.03239142,  0.0581205 ,  0.00045364,\n",
      "       -0.00992323, -0.00872892, -0.00605378, -0.01774197,  0.00388786,\n",
      "        0.01630184, -0.00582669, -0.00464446,  0.04288714, -0.00130225,\n",
      "       -0.01076366,  0.00744297,  0.03356882,  0.00681175,  0.04269454,\n",
      "        0.01461962,  0.01767767,  0.00898562,  0.00616688,  0.06692801,\n",
      "        0.01536222, -0.0357523 , -0.00637554,  0.02547078,  0.00442599,\n",
      "        0.00074558,  0.00310635, -0.01031463,  0.00797295,  0.00299635,\n",
      "        0.03629433,  0.02925211,  0.01403439,  0.0212786 ,  0.01285544,\n",
      "       -0.01235041,  0.00666388,  0.02484706, -0.00552248, -0.00987048,\n",
      "       -0.01321696,  0.03394341, -0.00316574,  0.01025664,  0.02940914,\n",
      "       -0.00067885,  0.0380701 ,  0.0018084 , -0.00065189,  0.02503758,\n",
      "       -0.01501264, -0.0170481 ,  0.00789985, -0.01536995, -0.02304447,\n",
      "        0.03398026,  0.00165709,  0.00576952,  0.01570459,  0.06377688,\n",
      "        0.00957327,  0.04886685, -0.00527283, -0.00588596,  0.01618072,\n",
      "       -0.00098088,  0.01398086,  0.00770296], dtype=float32)]\n",
      "[array([[-9.51483995e-02,  6.71759546e-02, -1.80677280e-01,\n",
      "        -4.52316999e-02,  5.92582338e-02],\n",
      "       [ 1.72119752e-01, -2.76133977e-02,  2.97288317e-02,\n",
      "        -2.05468431e-01,  2.95249391e-02],\n",
      "       [-2.73497161e-02, -1.14021450e-01, -1.87616497e-02,\n",
      "        -8.28516409e-02,  3.91817577e-02],\n",
      "       [-1.88163426e-02, -2.74615139e-02, -4.88828914e-03,\n",
      "        -2.34504063e-02, -7.62554109e-02],\n",
      "       [ 2.54238188e-01,  1.43659607e-01,  2.42248527e-03,\n",
      "        -6.27427697e-02, -8.01467523e-02],\n",
      "       [ 1.03572503e-01,  1.86068863e-01, -2.32402347e-02,\n",
      "         1.09339535e-01, -1.91846006e-02],\n",
      "       [ 2.75412619e-01, -1.00716822e-01,  1.18688889e-01,\n",
      "        -1.13603696e-02, -1.15457170e-01],\n",
      "       [ 4.73380126e-02, -7.63111189e-02, -1.62972420e-01,\n",
      "        -4.54908013e-02,  1.41185731e-01],\n",
      "       [-8.37121978e-02,  1.01593278e-01,  1.37628987e-01,\n",
      "         7.93810785e-02,  1.37841627e-01],\n",
      "       [-1.30148679e-01,  1.48865819e-01, -1.14736497e-01,\n",
      "         8.68285894e-02,  1.04293905e-01],\n",
      "       [-1.44400075e-01, -1.88856628e-02,  7.96786025e-02,\n",
      "         1.32257074e-01,  1.44108385e-01],\n",
      "       [-1.55881777e-01, -2.35893279e-02, -2.71341562e-01,\n",
      "         1.18860759e-01, -5.50451986e-02],\n",
      "       [ 1.90323561e-01,  6.48852438e-02,  2.54536986e-01,\n",
      "        -1.40655518e-01,  5.80127202e-02],\n",
      "       [-2.40322500e-02,  1.77077875e-01,  9.02400017e-02,\n",
      "        -1.72914222e-01,  1.67685539e-01],\n",
      "       [ 7.35453796e-03, -9.08003673e-02,  1.21904187e-01,\n",
      "         1.53160870e-01,  1.00668646e-01],\n",
      "       [-6.55819476e-02, -1.94786236e-01, -5.94139993e-02,\n",
      "         9.00809318e-02,  8.64574537e-02],\n",
      "       [-4.89244126e-02, -3.62932794e-02,  1.65418535e-01,\n",
      "        -1.40185207e-01, -1.63470566e-01],\n",
      "       [ 2.35842630e-01,  1.50034264e-01, -2.10221604e-01,\n",
      "        -3.55951721e-03, -1.09232619e-01],\n",
      "       [ 7.15387166e-02, -1.47714272e-01,  1.42935857e-01,\n",
      "         1.88667789e-01, -2.05293968e-01],\n",
      "       [ 5.14959469e-02,  9.83334333e-02, -1.27028987e-01,\n",
      "        -4.55608703e-02,  6.53286502e-02],\n",
      "       [ 1.71882927e-01,  1.17828086e-01,  2.07246155e-01,\n",
      "         5.56251965e-02, -9.67135504e-02],\n",
      "       [-1.49362653e-01,  1.07667193e-01,  1.08720452e-01,\n",
      "         2.43817449e-01, -2.16383282e-02],\n",
      "       [-2.79429164e-02,  5.51685728e-02,  1.20356299e-01,\n",
      "        -8.44039693e-02,  2.01114893e-01],\n",
      "       [ 5.88508211e-02, -9.39859375e-02,  1.11988463e-01,\n",
      "        -8.69412646e-02,  6.81133792e-02],\n",
      "       [ 1.82184979e-01, -2.13561058e-01, -2.22979277e-01,\n",
      "        -1.84090972e-01,  2.01282665e-01],\n",
      "       [ 4.35280800e-02, -2.50951320e-01,  5.78798056e-02,\n",
      "         1.58370048e-01, -1.49892673e-01],\n",
      "       [-1.41780302e-01, -8.91221166e-02, -1.36986673e-01,\n",
      "         1.11312874e-01, -1.19053565e-01],\n",
      "       [ 5.71829528e-02, -6.57681525e-02, -2.17355251e-01,\n",
      "         9.29601118e-02, -8.18902999e-02],\n",
      "       [-2.66462918e-02, -1.14818387e-01, -1.19792521e-02,\n",
      "         1.89571619e-01, -2.45979518e-01],\n",
      "       [ 3.25600535e-01, -4.20282111e-02, -2.34391883e-01,\n",
      "        -1.55973852e-01, -1.48721591e-01],\n",
      "       [-1.32547036e-01, -2.03769594e-01, -1.43768206e-01,\n",
      "         5.90890795e-02,  2.21178725e-01],\n",
      "       [ 2.36655369e-01, -4.33157571e-02,  1.25841439e-01,\n",
      "        -1.49711847e-01,  1.20774776e-01],\n",
      "       [ 1.06851637e-01,  1.90555692e-01, -7.14352168e-03,\n",
      "        -5.16303144e-02, -1.26772329e-01],\n",
      "       [ 5.33793941e-02,  1.85727209e-01,  2.78101899e-02,\n",
      "         2.32454747e-01,  1.69496655e-01],\n",
      "       [-1.04890846e-01, -1.01223281e-02,  2.42449924e-01,\n",
      "        -7.34006688e-02,  1.61698982e-01],\n",
      "       [-1.34057477e-01, -7.98023790e-02,  1.74452513e-01,\n",
      "         6.26761327e-03,  8.29561502e-02],\n",
      "       [-1.14452854e-01,  9.11804438e-02, -2.02927560e-01,\n",
      "        -3.30522074e-03, -2.33825251e-01],\n",
      "       [-1.15158811e-01,  5.48333898e-02,  2.48551890e-01,\n",
      "         4.52079857e-03,  3.42530373e-04],\n",
      "       [-1.26372620e-01, -4.30050343e-02,  4.35276069e-02,\n",
      "         2.10923642e-01,  4.46636118e-02],\n",
      "       [-1.94028497e-01, -1.26485407e-01,  5.09025529e-02,\n",
      "         1.33656070e-01, -4.55752686e-02],\n",
      "       [-1.65606156e-01,  1.85145989e-01,  1.56494126e-01,\n",
      "        -8.86410922e-02, -9.63583738e-02],\n",
      "       [ 3.31602357e-02, -1.62592202e-01,  1.09283822e-02,\n",
      "         8.09603631e-02, -1.99378673e-02],\n",
      "       [ 2.18797773e-02, -5.19423224e-02, -2.51268804e-01,\n",
      "        -6.79637417e-02,  1.44741973e-02],\n",
      "       [-3.02501678e-01, -2.59581447e-01,  2.63618678e-01,\n",
      "         1.11031726e-01,  2.37959668e-01],\n",
      "       [-1.62907876e-02,  2.61126906e-01, -1.10066101e-01,\n",
      "         7.75410607e-02, -1.79226119e-02],\n",
      "       [-5.50093129e-02,  3.92321460e-02, -6.19326122e-02,\n",
      "        -1.80628151e-01, -4.66215611e-02],\n",
      "       [-1.35538056e-01, -1.69483826e-01, -1.03095528e-02,\n",
      "         2.61676490e-01, -1.03389688e-01],\n",
      "       [ 5.56492731e-02, -8.04215819e-02,  1.16688654e-01,\n",
      "         9.87006277e-02,  7.71091655e-02],\n",
      "       [ 2.19505996e-01,  9.75632742e-02, -1.43961847e-01,\n",
      "         2.41630360e-01, -1.63418472e-01],\n",
      "       [ 1.16587095e-01, -1.52604669e-01,  1.70283452e-01,\n",
      "         4.36883196e-02, -6.15650974e-02],\n",
      "       [-6.81740791e-02, -1.20923951e-01, -3.10498513e-02,\n",
      "         1.07241221e-01, -6.78358898e-02],\n",
      "       [-9.65577140e-02,  3.20350528e-02,  8.90171230e-02,\n",
      "        -2.58058816e-01, -6.91539794e-02],\n",
      "       [ 9.84319672e-02,  2.39607453e-01, -1.81390159e-02,\n",
      "         7.76904076e-02,  2.91425106e-03],\n",
      "       [ 1.08014487e-01,  1.60006970e-01,  1.81899995e-01,\n",
      "        -1.78218275e-01, -9.47839543e-02],\n",
      "       [-2.19580293e-01,  2.11735711e-01,  1.91118731e-03,\n",
      "         1.10653609e-01, -4.18549068e-02],\n",
      "       [-6.77126423e-02, -1.66074917e-01, -1.63494989e-01,\n",
      "        -3.87563109e-02,  2.35123828e-01],\n",
      "       [ 1.33059874e-01, -2.38570854e-01,  3.29723597e-01,\n",
      "        -1.25607908e-01,  2.03500420e-01],\n",
      "       [ 1.91709042e-01, -2.43724305e-02,  1.54996186e-01,\n",
      "        -1.60493180e-01, -3.77546586e-02],\n",
      "       [ 5.79437464e-02, -2.05451086e-01,  1.66521117e-01,\n",
      "        -1.53753802e-01, -9.11671743e-02],\n",
      "       [-2.40516379e-01, -1.76560968e-01, -1.60964280e-01,\n",
      "        -8.78018811e-02, -1.04276061e-01],\n",
      "       [-8.17609504e-02, -1.45257920e-01, -1.07041940e-01,\n",
      "         3.22685800e-02,  1.69586539e-01],\n",
      "       [-1.08881511e-01,  7.97290578e-02, -9.45196897e-02,\n",
      "        -2.11163133e-01, -1.35429114e-01],\n",
      "       [-8.88480991e-02,  2.09896475e-01, -9.30381566e-02,\n",
      "        -1.60247371e-01,  3.14282402e-02],\n",
      "       [-1.52108237e-01,  6.01341650e-02, -1.74252138e-01,\n",
      "        -7.57874697e-02, -2.64150221e-02],\n",
      "       [-7.61284381e-02, -9.35906172e-02, -1.72226161e-01,\n",
      "        -2.19283745e-01, -1.59917787e-01],\n",
      "       [-9.89596099e-02,  8.54838341e-02,  5.67467622e-02,\n",
      "         2.38344342e-01, -2.41720080e-01],\n",
      "       [ 1.15366839e-01,  1.50585398e-01, -8.54706168e-02,\n",
      "         1.95949413e-02,  2.27277860e-01],\n",
      "       [-2.15870291e-02,  2.78679654e-02, -1.51025563e-01,\n",
      "        -8.45761746e-02, -1.48195773e-01],\n",
      "       [-2.32710987e-01, -2.18730271e-01,  4.28184457e-02,\n",
      "         1.08322091e-01,  2.16915250e-01],\n",
      "       [-1.99971586e-01, -7.65959397e-02, -1.31410167e-01,\n",
      "        -1.54713288e-01,  2.85546929e-01],\n",
      "       [-2.55610228e-01, -6.31963909e-02, -1.29403666e-01,\n",
      "        -8.75138864e-02, -2.12106273e-01],\n",
      "       [-1.86879247e-01, -1.45133957e-01, -1.98559001e-01,\n",
      "         1.80683881e-01,  1.24722585e-01],\n",
      "       [ 1.74352989e-01, -9.80478376e-02, -7.22093806e-02,\n",
      "        -1.25955835e-01, -9.10680834e-03],\n",
      "       [-6.64920807e-02, -1.54848143e-01, -5.34065217e-02,\n",
      "         5.77892251e-02,  1.50567591e-01],\n",
      "       [-1.44985661e-01, -2.14906454e-01,  1.55760005e-01,\n",
      "        -1.34990886e-01, -4.28860039e-02],\n",
      "       [-1.05302334e-01,  2.17913231e-03, -2.11634606e-01,\n",
      "        -2.15819776e-01,  2.62761712e-01],\n",
      "       [ 1.43070713e-01, -1.74626336e-01, -7.29805157e-02,\n",
      "        -4.70593870e-02, -8.91089588e-02],\n",
      "       [ 1.15905084e-01,  4.80453260e-02, -1.09258257e-01,\n",
      "         2.32556704e-02,  1.18859075e-01],\n",
      "       [ 1.34714633e-01, -2.55433246e-02, -5.60708717e-03,\n",
      "         1.16897367e-01,  1.53900227e-02],\n",
      "       [ 8.66237655e-02, -1.48150012e-01,  2.26832226e-01,\n",
      "        -1.11673616e-01, -1.80748016e-01],\n",
      "       [ 5.54198362e-02,  1.13462396e-01,  2.14262500e-01,\n",
      "         8.35067332e-02, -2.20390454e-01],\n",
      "       [-1.84006199e-01,  2.10860178e-01, -1.06796529e-02,\n",
      "        -6.11595297e-03, -3.81896421e-02],\n",
      "       [-2.23818328e-02,  1.24687506e-02, -1.23105809e-01,\n",
      "        -9.24362317e-02, -1.73605695e-01],\n",
      "       [ 5.31627908e-02, -6.78531080e-02,  2.14208961e-01,\n",
      "         1.52398124e-02, -1.01816036e-01],\n",
      "       [-2.71247067e-02,  2.32599199e-01, -2.35824034e-01,\n",
      "        -1.89163789e-01,  7.12868199e-02],\n",
      "       [-4.94537130e-02,  1.82940409e-01,  1.36988625e-01,\n",
      "        -9.83299166e-02, -1.89237669e-01],\n",
      "       [ 3.64450701e-02,  2.40417182e-01, -1.45419285e-01,\n",
      "        -1.48673594e-01, -1.67212099e-01],\n",
      "       [ 9.72169489e-02,  3.94757517e-04, -6.27324730e-02,\n",
      "         1.31481707e-01,  8.45171213e-02],\n",
      "       [-7.03917667e-02, -4.67248522e-02, -9.60346311e-02,\n",
      "         8.74363724e-03,  2.09802657e-01],\n",
      "       [-3.54036503e-02,  9.40776095e-02,  8.61609131e-02,\n",
      "         1.15736090e-01, -1.28364563e-01],\n",
      "       [ 8.19679201e-02, -2.26852417e-01, -3.46598513e-02,\n",
      "        -6.73290044e-02, -1.67788401e-01],\n",
      "       [ 1.41092539e-01, -1.35294646e-01,  1.49127683e-02,\n",
      "        -9.70963854e-03,  1.66361853e-02],\n",
      "       [ 1.82605967e-01,  1.04992777e-01,  1.58020303e-01,\n",
      "         1.65303677e-01, -1.06455036e-01],\n",
      "       [ 5.82132442e-03, -1.39459044e-01, -2.52123833e-01,\n",
      "         2.06598997e-01,  1.05192745e-02],\n",
      "       [-2.32385576e-01, -3.93031947e-02,  2.60653105e-02,\n",
      "        -1.93114281e-02, -6.79400489e-02],\n",
      "       [-9.45759565e-02,  1.00197718e-01,  6.92369649e-03,\n",
      "        -3.78716253e-02, -8.00496861e-02],\n",
      "       [ 5.39665967e-02,  9.84504670e-02, -7.52775520e-02,\n",
      "        -2.18862295e-01,  3.67363542e-02],\n",
      "       [ 1.41190082e-01, -1.59892634e-01, -5.88944852e-02,\n",
      "         1.44316822e-01, -1.38893705e-02],\n",
      "       [-1.28793046e-02,  8.21657330e-02, -1.69641927e-01,\n",
      "         2.41416603e-01,  3.07704564e-02],\n",
      "       [-1.33315191e-01,  1.37683615e-01, -2.15684786e-01,\n",
      "         2.44700294e-02,  6.21607676e-02],\n",
      "       [-1.39270619e-01,  2.28704866e-02, -8.47134888e-02,\n",
      "        -6.65218979e-02,  1.02927744e-01],\n",
      "       [ 2.11327329e-01, -8.22031125e-02, -7.20794592e-03,\n",
      "         2.35605627e-01, -4.87577543e-03],\n",
      "       [-1.49216801e-01, -2.48614736e-02, -1.34993285e-01,\n",
      "        -2.69295722e-01,  1.38765693e-01],\n",
      "       [ 8.60763565e-02, -3.57723497e-02, -1.07078001e-01,\n",
      "         1.33815885e-01,  1.54405102e-01],\n",
      "       [ 2.34619021e-01,  2.02166602e-01,  8.09474960e-02,\n",
      "        -2.05938041e-01, -2.22024053e-01],\n",
      "       [-1.17457323e-01,  2.12765887e-01,  1.67544976e-01,\n",
      "         2.94686686e-02, -1.03410112e-03],\n",
      "       [ 1.62096675e-02, -4.14024107e-02,  3.58772993e-01,\n",
      "         8.77451077e-02, -6.48909211e-02],\n",
      "       [-6.85661612e-03, -1.71289533e-01, -1.06323004e-01,\n",
      "        -1.61436177e-03,  1.12023495e-01],\n",
      "       [ 9.46110711e-02,  1.11863889e-01,  3.71507928e-02,\n",
      "        -3.30080576e-02, -4.92676869e-02],\n",
      "       [ 1.55490413e-01, -1.69951003e-02,  2.51709700e-01,\n",
      "         8.03618357e-02,  8.82753655e-02],\n",
      "       [-2.42355779e-01,  1.47053063e-01, -5.01301438e-02,\n",
      "        -5.93360998e-02, -2.22107843e-01],\n",
      "       [ 1.27957314e-02,  1.27202466e-01, -7.88724422e-02,\n",
      "        -5.60514405e-02,  1.17064267e-01],\n",
      "       [ 1.22008473e-01, -1.02663845e-01,  5.77991940e-02,\n",
      "         3.38537470e-02,  1.59256175e-01],\n",
      "       [ 6.06501848e-02,  1.43778801e-01, -1.13419957e-01,\n",
      "        -2.62588859e-02, -1.65269017e-01],\n",
      "       [-1.41063586e-01,  1.26227483e-01, -1.44607410e-01,\n",
      "         1.71208233e-01,  9.21066776e-02],\n",
      "       [ 7.91070461e-02, -1.84043869e-01,  7.23660141e-02,\n",
      "        -1.91336676e-01,  1.98473677e-01],\n",
      "       [ 6.23563267e-02, -1.78685352e-01,  8.32783338e-03,\n",
      "        -3.86344679e-02, -1.76521316e-01],\n",
      "       [ 1.22720726e-01,  2.26787060e-01,  4.63561602e-02,\n",
      "        -4.15072218e-02, -1.45832002e-01],\n",
      "       [ 1.93209529e-01, -1.72014702e-02, -9.57623422e-02,\n",
      "         1.12708427e-01,  1.04563750e-01],\n",
      "       [ 2.96792388e-02, -1.55304328e-01,  1.86062783e-01,\n",
      "        -3.75841036e-02, -2.31243774e-01],\n",
      "       [ 4.29763570e-02,  4.96743880e-02, -2.30147764e-01,\n",
      "        -3.56308632e-02, -2.22625658e-01],\n",
      "       [ 5.56247868e-02, -1.06059685e-01,  2.59405911e-01,\n",
      "        -1.44036263e-02, -9.91251990e-02],\n",
      "       [-3.97626758e-02, -1.04324847e-01, -2.13643968e-01,\n",
      "         5.47414757e-02, -5.45086786e-02],\n",
      "       [-1.20968610e-01, -7.87757859e-02, -1.61140680e-01,\n",
      "        -1.76959321e-01, -1.45279214e-01],\n",
      "       [-1.49999335e-01,  5.32036535e-02,  2.19443813e-02,\n",
      "         2.30744109e-01,  1.92385316e-02],\n",
      "       [-9.64101478e-02, -1.67209759e-01, -3.16806734e-02,\n",
      "         2.61844769e-02, -9.80934054e-02],\n",
      "       [ 2.07590654e-01,  1.11645371e-01, -1.52569860e-01,\n",
      "         1.22113235e-01,  3.25446427e-02],\n",
      "       [ 8.61077756e-02,  1.48880288e-01, -3.27302627e-02,\n",
      "        -3.96721205e-03, -2.23060817e-01]], dtype=float32), array([ 0.13944052, -0.17835277,  0.12428623, -0.04089573, -0.0444776 ],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in Model_CNN_2D_saved.layers:\n",
    "    print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 13652
    },
    "colab_type": "code",
    "id": "fIDuoBKNFu9Q",
    "outputId": "5329416e-8b59-4453-ac94-c4dd6247960f"
   },
   "source": [
    "## Metrics for the classifiers\n",
    "\n",
    "\n",
    "1. Accuracy: Accuracy is a measure of how many correct predictions a model makes overall, i.e., the ratio of correct predictions to the total number of predictions. It's a commonly used metric for evaluating models, but it may not be suitable in certain situations.\n",
    "\n",
    "2. Precision: Precision measures the ratio of true positives (correctly predicted positive instances) to all instances predicted as positive. It focuses on the accuracy of positive predictions.\n",
    "\n",
    "3. Recall: Recall, also known as sensitivity or true positive rate, measures the ratio of true positives to all actual positive instances. It focuses on how well a model captures all the positive instances.\n",
    "\n",
    "4. F1 Score: The F1 score is the harmonic mean of precision and recall. It provides a balanced measure that takes into account both false positives and false negatives. The F1 score is especially useful when you want to strike a balance between precision and recall.\n",
    "\n",
    "\n",
    "The F1 score is a metric that combines precision and recall, and it is particularly useful in situations where class imbalance or unequal misclassification costs are present. In such contexts, the F1 score can be more informative and meaningful than accuracy.\n",
    "\n",
    "A context where considering the F1 score makes more sense than accuracy:\n",
    "\n",
    "**Medical Diagnosis:**\n",
    "\n",
    "Imagine you're developing a model to diagnose a rare disease, and only 5% of the population has this disease. In this case, you have a significant class imbalance, where the majority of cases are negative (non-disease) and only a small fraction are positive (disease). If you were to use accuracy as the evaluation metric, the model could achieve a high accuracy by simply predicting \"negative\" for every case, because it would be correct 95% of the time due to the class imbalance. However, this would be entirely useless for detecting the actual disease.\n",
    "\n",
    "In this scenario, you'd be more interested in the F1 score. The F1 score considers both precision and recall, helping you find a balance between correctly identifying the disease (high recall) and not making too many false positive predictions (high precision). A high F1 score in this context indicates that your model is effective at correctly identifying the disease while minimizing false alarms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['Model_CNN_2D_Su', 'Model_CNN_2D_Luz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to run the classifiers and their metrics\n",
    "\n",
    "def model_classifiers(classifiers:list, db: pd.DataFrame):\n",
    "    \n",
    "    # Clear the session to start a new training\n",
    "    K.clear_session()\n",
    "                      \n",
    "    monitor = EarlyStopping(monitor='val_accuracy', \n",
    "                        min_delta = 0.0001, \n",
    "                        patience = 20, \n",
    "                        verbose = 1, \n",
    "                        mode = 'auto', \n",
    "                        restore_best_weights = True)\n",
    "                      \n",
    "    count       = 1\n",
    "    verbose     = True\n",
    "    models      = []\n",
    "    acc_set     = pd.DataFrame(index=None, columns=['Model',\n",
    "                                                    'Fold',\n",
    "                                                    'Accuracy(Train)',\n",
    "                                                    'Accuracy(Val)',\n",
    "                                                    'F1(Train)',\n",
    "                                                    'F1(Val)', \n",
    "                                                    'Precision(Train)',\n",
    "                                                    'Precision(Val)', \n",
    "                                                    'Recall(Train)',\n",
    "                                                    'Recall(Val)', \n",
    "                                                    'Conf_M',\n",
    "                                                    'Process_time',                                                     \n",
    "                                                    'Class_report(Val)'])\n",
    "                      \n",
    "    for fold in np.unique(db['Fold']):\n",
    "        print(f\"\\nValidation fold: {fold}\")\n",
    "\n",
    "        DB_VAL = db[db['Fold'] == fold]\n",
    "        DB_TRN = db[db['Fold'] != fold]\n",
    "\n",
    "        X      = DB_TRN['features'].to_numpy()\n",
    "        y      = np.array(DB_TRN.Class_categorical.to_list())\n",
    "        y_OHEV = np.array(DB_TRN.Class_OHEV.to_list())\n",
    "\n",
    "        X_val      = DB_VAL['features'].to_numpy()\n",
    "        y_val      = np.array(DB_VAL.Class_categorical.to_list())\n",
    "        y_OHEV_val = np.array(DB_VAL.Class_OHEV.to_list())\n",
    "\n",
    "\n",
    "        # Stackup and pass all values to float32\n",
    "        X = np.stack(X)\n",
    "        X = np.asarray(X).astype(np.float32)\n",
    "\n",
    "        X_val = np.stack(X_val)\n",
    "        X_val = np.asarray(X_val).astype(np.float32)\n",
    "\n",
    "        y_OHEV     = np.asarray(y_OHEV).astype(np.float32)\n",
    "        y_OHEV_val = np.asarray(y_OHEV_val).astype(np.float32)\n",
    "\n",
    "        X_train_final, X_test, y_train_final, y_test = train_test_split(X,\n",
    "                                                                        y_OHEV, \n",
    "                                                                        test_size = 0.1, \n",
    "                                                                        random_state = 100, \n",
    "                                                                        stratify = y_OHEV)\n",
    "        \n",
    "        print(\"\\n========================================================================\")\n",
    "        print(\"Training set\\n\")\n",
    "\n",
    "        print(f'X_train.........: {np.shape(X_train_final)} ...type: {type(X_train_final[0][0][0][0])}')\n",
    "        print(f'y_train_OHEV....: {np.shape(y_train_final)} ............type: {type(y_train_final[0][0])}')\n",
    "\n",
    "        print(\"\\n========================================================================\")\n",
    "        print(\"Testing set\\n\")\n",
    "\n",
    "        print(f'X_test..........: {np.shape(X_test)} ....type: {type(X_test[0][0][0][0])}')\n",
    "        print(f'y_test_OHEV.....: {np.shape(y_test)} .............type: {type(y_test[0][0])}')\n",
    "\n",
    "        print(\"\\n========================================================================\")\n",
    "        print(\"Validation set\\n\")\n",
    "\n",
    "        print(f'X_val...........: {np.shape(X_val)} ....type: {type(X_val[0][0][0][0])}')\n",
    "        print(f'y_OHEV_val......: {np.shape(y_OHEV_val)} .............type: {type(y_OHEV_val[0][0])}')\n",
    "        print()\n",
    "\n",
    "        \n",
    "        for i in tqdm(range(len(classifiers))):\n",
    "            \n",
    "            name         = classifiers[i]\n",
    "            model_name   = (classifiers[i] + '_' + str(count))\n",
    "            count        = count + 1\n",
    "            \n",
    "            if not os.path.exists(path_models):\n",
    "                os.makedirs(path_models)\n",
    "\n",
    "            filepath       = os.path.join(path_models, classifiers[i] + '_weights_0_best' + model_surname + '.hdf5')\n",
    "            checkpoint     = ModelCheckpoint(filepath, \n",
    "                                             monitor = 'val_accuracy', \n",
    "                                             verbose = 1, \n",
    "                                             save_best_only = True, \n",
    "                                             mode = 'max')\n",
    "            callbacks_list = [checkpoint, monitor]\n",
    "\n",
    "            if classifiers[i] == 'Model_CNN_2D_Su':\n",
    "                model = basemodel_Su(classifiers[i])\n",
    "                model.summary()\n",
    "                print(model_name)\n",
    "            \n",
    "            elif classifiers[i] == 'Model_CNN_2D_Luz':\n",
    "                model = basemodel_Luz(classifiers[i])\n",
    "                model.summary()\n",
    "                print(model_name)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "            model.fit(X_train_final, \n",
    "                      y_train_final,\n",
    "                      batch_size          = batch_size,\n",
    "                      epochs              = epochs,\n",
    "                      verbose             = 1,\n",
    "                      validation_data     = (X_test, y_test),\n",
    "                      steps_per_epoch     = int(np.ceil(X_train_final.shape[0] / float(batch_size))),\n",
    "                      callbacks           = callbacks_list,\n",
    "                      use_multiprocessing = True)\n",
    "                      \n",
    "            # Get the model predictions\n",
    "            y_train_enc = np.argmax(y_train_final, axis=1)\n",
    "            y_val_enc   = np.argmax(y_OHEV_val, axis=1)\n",
    "\n",
    "            y_train_predicted = np.argmax(model.predict(X_train_final), axis=1)\n",
    "\n",
    "            t_srt             = time.process_time_ns()\n",
    "            y_val_predicted   = np.argmax(model.predict(X_val), axis=1)\n",
    "            t_end             = time.process_time_ns()\n",
    "            proc_time         = ((t_end - t_srt) / 1000000)   \n",
    "            \n",
    "            # Compute the classifier metrics\n",
    "            accuracy_train = metrics.accuracy_score(y_train_enc, y_train_predicted)\n",
    "            accuracy_val   = metrics.accuracy_score(y_val_enc,  y_val_predicted)\n",
    "\n",
    "            f1_Score_train = metrics.f1_score(y_train_enc, y_train_predicted, average = 'weighted')\n",
    "            f1_Score_val   = metrics.f1_score(y_val_enc,  y_val_predicted,  average = 'weighted')\n",
    "\n",
    "            precision_score_train = metrics.precision_score(y_train_enc, y_train_predicted, average = 'weighted')\n",
    "            precision_score_val   = metrics.precision_score(y_val_enc,  y_val_predicted,  average = 'weighted')\n",
    "\n",
    "            recall_score_train = metrics.recall_score(y_train_enc, y_train_predicted, average = 'weighted')\n",
    "            recall_score_val   = metrics.recall_score(y_val_enc,  y_val_predicted,  average = 'weighted')\n",
    "\n",
    "            class_report_val = classification_report(y_val_enc, y_val_predicted, target_names = nom_classes)\n",
    "            print(class_report_val)\n",
    "            \n",
    "            # Compute the confusion matrix\n",
    "            CM = metrics.confusion_matrix(y_val_enc, y_val_predicted)\n",
    "            y_val_enc       = []\n",
    "            y_val_predicted = []\n",
    "\n",
    "            # Store the name, test accuracy results and model\n",
    "            models.append((name, accuracy_val, model))\n",
    "            \n",
    "            K.clear_session()\n",
    "            del model\n",
    "                    \n",
    "            acc_set = pd.concat([acc_set, pd.DataFrame({'Model': [name],\n",
    "                                                        'Fold': [fold],\n",
    "                                                        'Accuracy(Train)': [accuracy_train],\n",
    "                                                        'Accuracy(Val)': [accuracy_val],\n",
    "                                                        'F1(Train)': [f1_Score_train],\n",
    "                                                        'F1(Val)': [f1_Score_val],\n",
    "                                                        'Precision(Train)': [precision_score_train],\n",
    "                                                        'Precision(Val)': [precision_score_val],\n",
    "                                                        'Recall(Train)': [recall_score_train],\n",
    "                                                        'Recall(Val)': [recall_score_val],\n",
    "                                                        'Conf_M': [CM],\n",
    "                                                        'Process_time': [proc_time],\n",
    "                                                        'Class_report(Val)': class_report_val})], ignore_index = True)\n",
    "                   \n",
    "    return acc_set, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation fold: 1\n",
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21211, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21211, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2357, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2357, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2580, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2580, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_1\n",
      "Epoch 1/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 1.2225 - accuracy: 0.6021\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69453, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 17s 25ms/step - loss: 1.2225 - accuracy: 0.6021 - val_loss: 0.8207 - val_accuracy: 0.6945\n",
      "Epoch 2/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.7504 - accuracy: 0.7313\n",
      "Epoch 00002: val_accuracy improved from 0.69453 to 0.76623, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.7505 - accuracy: 0.7313 - val_loss: 0.6139 - val_accuracy: 0.7662\n",
      "Epoch 3/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.6281 - accuracy: 0.7750\n",
      "Epoch 00003: val_accuracy improved from 0.76623 to 0.78871, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.6280 - accuracy: 0.7751 - val_loss: 0.6104 - val_accuracy: 0.7887\n",
      "Epoch 4/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.8059\n",
      "Epoch 00004: val_accuracy improved from 0.78871 to 0.79126, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.5468 - accuracy: 0.8059 - val_loss: 0.6640 - val_accuracy: 0.7913\n",
      "Epoch 5/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.4958 - accuracy: 0.8229\n",
      "Epoch 00005: val_accuracy improved from 0.79126 to 0.83029, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.4957 - accuracy: 0.8230 - val_loss: 0.4973 - val_accuracy: 0.8303\n",
      "Epoch 6/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.8414\n",
      "Epoch 00006: val_accuracy improved from 0.83029 to 0.88333, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.4357 - accuracy: 0.8414 - val_loss: 0.3567 - val_accuracy: 0.8833\n",
      "Epoch 7/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.3932 - accuracy: 0.8572\n",
      "Epoch 00007: val_accuracy did not improve from 0.88333\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.3931 - accuracy: 0.8572 - val_loss: 0.4648 - val_accuracy: 0.8553\n",
      "Epoch 8/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.3629 - accuracy: 0.8706\n",
      "Epoch 00008: val_accuracy improved from 0.88333 to 0.89733, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.3629 - accuracy: 0.8706 - val_loss: 0.3083 - val_accuracy: 0.8973\n",
      "Epoch 9/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.3409 - accuracy: 0.8788\n",
      "Epoch 00009: val_accuracy did not improve from 0.89733\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.3409 - accuracy: 0.8788 - val_loss: 0.3440 - val_accuracy: 0.8905\n",
      "Epoch 10/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.3088 - accuracy: 0.8871\n",
      "Epoch 00010: val_accuracy improved from 0.89733 to 0.90412, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.3087 - accuracy: 0.8872 - val_loss: 0.2836 - val_accuracy: 0.9041\n",
      "Epoch 11/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.2865 - accuracy: 0.8968\n",
      "Epoch 00011: val_accuracy improved from 0.90412 to 0.91260, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.2863 - accuracy: 0.8969 - val_loss: 0.2602 - val_accuracy: 0.9126\n",
      "Epoch 12/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2720 - accuracy: 0.9018\n",
      "Epoch 00012: val_accuracy improved from 0.91260 to 0.91854, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.2721 - accuracy: 0.9017 - val_loss: 0.2583 - val_accuracy: 0.9185\n",
      "Epoch 13/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.2504 - accuracy: 0.9090\n",
      "Epoch 00013: val_accuracy did not improve from 0.91854\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.2503 - accuracy: 0.9090 - val_loss: 0.3124 - val_accuracy: 0.8990\n",
      "Epoch 14/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2403 - accuracy: 0.9144\n",
      "Epoch 00014: val_accuracy improved from 0.91854 to 0.93636, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.2403 - accuracy: 0.9144 - val_loss: 0.1943 - val_accuracy: 0.9364\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662/663 [============================>.] - ETA: 0s - loss: 0.2225 - accuracy: 0.9211\n",
      "Epoch 00015: val_accuracy improved from 0.93636 to 0.94951, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.2224 - accuracy: 0.9211 - val_loss: 0.1624 - val_accuracy: 0.9495\n",
      "Epoch 16/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2106 - accuracy: 0.9232\n",
      "Epoch 00016: val_accuracy did not improve from 0.94951\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.2104 - accuracy: 0.9232 - val_loss: 0.1955 - val_accuracy: 0.9393\n",
      "Epoch 17/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2024 - accuracy: 0.9287\n",
      "Epoch 00017: val_accuracy did not improve from 0.94951\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.2021 - accuracy: 0.9288 - val_loss: 0.2049 - val_accuracy: 0.9368\n",
      "Epoch 18/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.1852 - accuracy: 0.9333\n",
      "Epoch 00018: val_accuracy did not improve from 0.94951\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1851 - accuracy: 0.9333 - val_loss: 0.1628 - val_accuracy: 0.9474\n",
      "Epoch 19/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1765 - accuracy: 0.9360\n",
      "Epoch 00019: val_accuracy improved from 0.94951 to 0.95291, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1766 - accuracy: 0.9360 - val_loss: 0.1493 - val_accuracy: 0.9529\n",
      "Epoch 20/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1711 - accuracy: 0.9375\n",
      "Epoch 00020: val_accuracy improved from 0.95291 to 0.95460, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1714 - accuracy: 0.9375 - val_loss: 0.1518 - val_accuracy: 0.9546\n",
      "Epoch 21/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1661 - accuracy: 0.9389\n",
      "Epoch 00021: val_accuracy did not improve from 0.95460\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1661 - accuracy: 0.9389 - val_loss: 0.2148 - val_accuracy: 0.9334\n",
      "Epoch 22/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.1546 - accuracy: 0.9434\n",
      "Epoch 00022: val_accuracy improved from 0.95460 to 0.96182, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1546 - accuracy: 0.9434 - val_loss: 0.1234 - val_accuracy: 0.9618\n",
      "Epoch 23/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1440 - accuracy: 0.9476\n",
      "Epoch 00023: val_accuracy did not improve from 0.96182\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1440 - accuracy: 0.9476 - val_loss: 0.2352 - val_accuracy: 0.9308\n",
      "Epoch 24/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9484\n",
      "Epoch 00024: val_accuracy did not improve from 0.96182\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1423 - accuracy: 0.9484 - val_loss: 0.1351 - val_accuracy: 0.9605\n",
      "Epoch 25/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1324 - accuracy: 0.9518\n",
      "Epoch 00025: val_accuracy improved from 0.96182 to 0.96266, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1324 - accuracy: 0.9518 - val_loss: 0.1328 - val_accuracy: 0.9627\n",
      "Epoch 26/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1284 - accuracy: 0.9547\n",
      "Epoch 00026: val_accuracy did not improve from 0.96266\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1285 - accuracy: 0.9548 - val_loss: 0.1464 - val_accuracy: 0.9542\n",
      "Epoch 27/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1200 - accuracy: 0.9565\n",
      "Epoch 00027: val_accuracy did not improve from 0.96266\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1200 - accuracy: 0.9564 - val_loss: 0.1383 - val_accuracy: 0.9571\n",
      "Epoch 28/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9574\n",
      "Epoch 00028: val_accuracy improved from 0.96266 to 0.96436, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1164 - accuracy: 0.9574 - val_loss: 0.1226 - val_accuracy: 0.9644\n",
      "Epoch 29/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9597\n",
      "Epoch 00029: val_accuracy did not improve from 0.96436\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1110 - accuracy: 0.9597 - val_loss: 0.1407 - val_accuracy: 0.9597\n",
      "Epoch 30/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1072 - accuracy: 0.9615\n",
      "Epoch 00030: val_accuracy improved from 0.96436 to 0.97242, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1071 - accuracy: 0.9615 - val_loss: 0.0956 - val_accuracy: 0.9724\n",
      "Epoch 31/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1085 - accuracy: 0.9606\n",
      "Epoch 00031: val_accuracy did not improve from 0.97242\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1086 - accuracy: 0.9605 - val_loss: 0.1149 - val_accuracy: 0.9678\n",
      "Epoch 32/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9628\n",
      "Epoch 00032: val_accuracy improved from 0.97242 to 0.97667, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1021 - accuracy: 0.9628 - val_loss: 0.0943 - val_accuracy: 0.9767\n",
      "Epoch 33/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9648\n",
      "Epoch 00033: val_accuracy did not improve from 0.97667\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0966 - accuracy: 0.9648 - val_loss: 0.1232 - val_accuracy: 0.9699\n",
      "Epoch 34/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0881 - accuracy: 0.9673\n",
      "Epoch 00034: val_accuracy improved from 0.97667 to 0.98006, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0881 - accuracy: 0.9673 - val_loss: 0.0917 - val_accuracy: 0.9801\n",
      "Epoch 35/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0881 - accuracy: 0.9678\n",
      "Epoch 00035: val_accuracy did not improve from 0.98006\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0879 - accuracy: 0.9679 - val_loss: 0.1074 - val_accuracy: 0.9690\n",
      "Epoch 36/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0825 - accuracy: 0.9705\n",
      "Epoch 00036: val_accuracy did not improve from 0.98006\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0824 - accuracy: 0.9705 - val_loss: 0.1054 - val_accuracy: 0.9699\n",
      "Epoch 37/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9704\n",
      "Epoch 00037: val_accuracy improved from 0.98006 to 0.98345, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0825 - accuracy: 0.9704 - val_loss: 0.0720 - val_accuracy: 0.9835\n",
      "Epoch 38/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 0.9701\n",
      "Epoch 00038: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0809 - accuracy: 0.9701 - val_loss: 0.0996 - val_accuracy: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9732\n",
      "Epoch 00039: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0748 - accuracy: 0.9732 - val_loss: 0.0900 - val_accuracy: 0.9784\n",
      "Epoch 40/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0731 - accuracy: 0.9737\n",
      "Epoch 00040: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0732 - accuracy: 0.9736 - val_loss: 0.0754 - val_accuracy: 0.9830\n",
      "Epoch 41/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0751 - accuracy: 0.9737\n",
      "Epoch 00041: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0752 - accuracy: 0.9736 - val_loss: 0.0921 - val_accuracy: 0.9762\n",
      "Epoch 42/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9759\n",
      "Epoch 00042: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0689 - accuracy: 0.9759 - val_loss: 0.0732 - val_accuracy: 0.9826\n",
      "Epoch 43/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9755\n",
      "Epoch 00043: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0692 - accuracy: 0.9755 - val_loss: 0.0858 - val_accuracy: 0.9805\n",
      "Epoch 44/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9761\n",
      "Epoch 00044: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0677 - accuracy: 0.9761 - val_loss: 0.0784 - val_accuracy: 0.9801\n",
      "Epoch 45/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9780\n",
      "Epoch 00045: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0633 - accuracy: 0.9780 - val_loss: 0.0835 - val_accuracy: 0.9796\n",
      "Epoch 46/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9786\n",
      "Epoch 00046: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0630 - accuracy: 0.9785 - val_loss: 0.0819 - val_accuracy: 0.9818\n",
      "Epoch 47/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9771\n",
      "Epoch 00047: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0644 - accuracy: 0.9771 - val_loss: 0.0801 - val_accuracy: 0.9771\n",
      "Epoch 48/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9795\n",
      "Epoch 00048: val_accuracy improved from 0.98345 to 0.98812, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0598 - accuracy: 0.9795 - val_loss: 0.0683 - val_accuracy: 0.9881\n",
      "Epoch 49/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.9800\n",
      "Epoch 00049: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0565 - accuracy: 0.9800 - val_loss: 0.0734 - val_accuracy: 0.9818\n",
      "Epoch 50/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 0.9792\n",
      "Epoch 00050: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 17s 25ms/step - loss: 0.0599 - accuracy: 0.9792 - val_loss: 0.0647 - val_accuracy: 0.9852\n",
      "Epoch 51/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9812\n",
      "Epoch 00051: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 17s 25ms/step - loss: 0.0537 - accuracy: 0.9811 - val_loss: 0.0717 - val_accuracy: 0.9826\n",
      "Epoch 52/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9797\n",
      "Epoch 00052: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0581 - accuracy: 0.9797 - val_loss: 0.0630 - val_accuracy: 0.9864\n",
      "Epoch 53/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9813\n",
      "Epoch 00053: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0525 - accuracy: 0.9812 - val_loss: 0.0712 - val_accuracy: 0.9839\n",
      "Epoch 54/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9809\n",
      "Epoch 00054: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0513 - accuracy: 0.9809 - val_loss: 0.0717 - val_accuracy: 0.9843\n",
      "Epoch 55/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9823\n",
      "Epoch 00055: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0498 - accuracy: 0.9823 - val_loss: 0.0711 - val_accuracy: 0.9860\n",
      "Epoch 56/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.9822\n",
      "Epoch 00056: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0499 - accuracy: 0.9822 - val_loss: 0.0786 - val_accuracy: 0.9822\n",
      "Epoch 57/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9833\n",
      "Epoch 00057: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0477 - accuracy: 0.9833 - val_loss: 0.0660 - val_accuracy: 0.9873\n",
      "Epoch 58/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0455 - accuracy: 0.9836\n",
      "Epoch 00058: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0455 - accuracy: 0.9836 - val_loss: 0.0638 - val_accuracy: 0.9868\n",
      "Epoch 59/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0419 - accuracy: 0.9848\n",
      "Epoch 00059: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0420 - accuracy: 0.9847 - val_loss: 0.0756 - val_accuracy: 0.9813\n",
      "Epoch 60/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9845\n",
      "Epoch 00060: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0460 - accuracy: 0.9845 - val_loss: 0.0777 - val_accuracy: 0.9830\n",
      "Epoch 61/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 0.9863\n",
      "Epoch 00061: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0435 - accuracy: 0.9862 - val_loss: 0.0902 - val_accuracy: 0.9758\n",
      "Epoch 62/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9855\n",
      "Epoch 00062: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0429 - accuracy: 0.9855 - val_loss: 0.0763 - val_accuracy: 0.9818\n",
      "Epoch 63/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9864\n",
      "Epoch 00063: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0379 - accuracy: 0.9863 - val_loss: 0.0684 - val_accuracy: 0.9835\n",
      "Epoch 64/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9852\n",
      "Epoch 00064: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0403 - accuracy: 0.9852 - val_loss: 0.0745 - val_accuracy: 0.9847\n",
      "Epoch 65/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9866\n",
      "Epoch 00065: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0388 - accuracy: 0.9866 - val_loss: 0.0716 - val_accuracy: 0.9847\n",
      "Epoch 66/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9856\n",
      "Epoch 00066: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0383 - accuracy: 0.9856 - val_loss: 0.0643 - val_accuracy: 0.9873\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "662/663 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.9866\n",
      "Epoch 00067: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0375 - accuracy: 0.9866 - val_loss: 0.0655 - val_accuracy: 0.9852\n",
      "Epoch 68/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9864\n",
      "Epoch 00068: val_accuracy did not improve from 0.98812\n",
      "Restoring model weights from the end of the best epoch.\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0388 - accuracy: 0.9864 - val_loss: 0.0574 - val_accuracy: 0.9881\n",
      "Epoch 00068: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [18:32<18:32, 1112.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.92      0.86      0.89       648\n",
      "        car_horn       0.92      0.92      0.92       216\n",
      "children_playing       0.77      0.91      0.83       600\n",
      "        dog_bark       0.89      0.86      0.87       600\n",
      "           siren       0.93      0.84      0.88       516\n",
      "\n",
      "        accuracy                           0.87      2580\n",
      "       macro avg       0.88      0.88      0.88      2580\n",
      "    weighted avg       0.88      0.87      0.87      2580\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_2\n",
      "Epoch 1/100\n",
      "  2/663 [..............................] - ETA: 22s - loss: 1.9557 - accuracy: 0.2344WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0241s vs `on_train_batch_end` time: 0.0437s). Check your callbacks.\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.9451 - accuracy: 0.6451\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80441, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.9451 - accuracy: 0.6451 - val_loss: 0.5418 - val_accuracy: 0.8044\n",
      "Epoch 2/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.5576 - accuracy: 0.8035\n",
      "Epoch 00002: val_accuracy improved from 0.80441 to 0.88417, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.5576 - accuracy: 0.8035 - val_loss: 0.3475 - val_accuracy: 0.8842\n",
      "Epoch 3/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.8590\n",
      "Epoch 00003: val_accuracy improved from 0.88417 to 0.91387, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.4051 - accuracy: 0.8590 - val_loss: 0.2694 - val_accuracy: 0.9139\n",
      "Epoch 4/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.8908\n",
      "Epoch 00004: val_accuracy did not improve from 0.91387\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.3072 - accuracy: 0.8908 - val_loss: 0.2377 - val_accuracy: 0.9079\n",
      "Epoch 5/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2575 - accuracy: 0.9109\n",
      "Epoch 00005: val_accuracy did not improve from 0.91387\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.2575 - accuracy: 0.9109 - val_loss: 0.3472 - val_accuracy: 0.8787\n",
      "Epoch 6/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9300\n",
      "Epoch 00006: val_accuracy improved from 0.91387 to 0.95206, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.2016 - accuracy: 0.9300 - val_loss: 0.1489 - val_accuracy: 0.9521\n",
      "Epoch 7/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.9383\n",
      "Epoch 00007: val_accuracy improved from 0.95206 to 0.95418, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.1785 - accuracy: 0.9383 - val_loss: 0.1321 - val_accuracy: 0.9542\n",
      "Epoch 8/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.9480\n",
      "Epoch 00008: val_accuracy did not improve from 0.95418\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.1522 - accuracy: 0.9480 - val_loss: 0.1705 - val_accuracy: 0.9482\n",
      "Epoch 9/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.9552\n",
      "Epoch 00009: val_accuracy did not improve from 0.95418\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.1252 - accuracy: 0.9552 - val_loss: 0.1469 - val_accuracy: 0.9504\n",
      "Epoch 10/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9638\n",
      "Epoch 00010: val_accuracy improved from 0.95418 to 0.96054, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.1068 - accuracy: 0.9638 - val_loss: 0.1194 - val_accuracy: 0.9605\n",
      "Epoch 11/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9659\n",
      "Epoch 00011: val_accuracy improved from 0.96054 to 0.97497, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0983 - accuracy: 0.9659 - val_loss: 0.0705 - val_accuracy: 0.9750\n",
      "Epoch 12/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9728\n",
      "Epoch 00012: val_accuracy did not improve from 0.97497\n",
      "663/663 [==============================] - 44s 67ms/step - loss: 0.0795 - accuracy: 0.9728 - val_loss: 0.1132 - val_accuracy: 0.9597\n",
      "Epoch 13/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9741\n",
      "Epoch 00013: val_accuracy did not improve from 0.97497\n",
      "663/663 [==============================] - 44s 67ms/step - loss: 0.0734 - accuracy: 0.9741 - val_loss: 0.1244 - val_accuracy: 0.9593\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663/663 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9779\n",
      "Epoch 00014: val_accuracy did not improve from 0.97497\n",
      "663/663 [==============================] - 42s 64ms/step - loss: 0.0668 - accuracy: 0.9779 - val_loss: 0.1134 - val_accuracy: 0.9665\n",
      "Epoch 15/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9806\n",
      "Epoch 00015: val_accuracy improved from 0.97497 to 0.98345, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 42s 64ms/step - loss: 0.0568 - accuracy: 0.9806 - val_loss: 0.0586 - val_accuracy: 0.9835\n",
      "Epoch 16/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9824\n",
      "Epoch 00016: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 43s 65ms/step - loss: 0.0512 - accuracy: 0.9824 - val_loss: 0.0766 - val_accuracy: 0.9762\n",
      "Epoch 17/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9818\n",
      "Epoch 00017: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0531 - accuracy: 0.9818 - val_loss: 0.0530 - val_accuracy: 0.9822\n",
      "Epoch 18/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9854\n",
      "Epoch 00018: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0448 - accuracy: 0.9854 - val_loss: 0.0783 - val_accuracy: 0.9784\n",
      "Epoch 19/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9845\n",
      "Epoch 00019: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0449 - accuracy: 0.9845 - val_loss: 0.0646 - val_accuracy: 0.9809\n",
      "Epoch 20/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9877\n",
      "Epoch 00020: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0379 - accuracy: 0.9877 - val_loss: 0.0844 - val_accuracy: 0.9767\n",
      "Epoch 21/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9891\n",
      "Epoch 00021: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.0710 - val_accuracy: 0.9775\n",
      "Epoch 22/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9909\n",
      "Epoch 00022: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0268 - accuracy: 0.9909 - val_loss: 0.0779 - val_accuracy: 0.9835\n",
      "Epoch 23/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9903\n",
      "Epoch 00023: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 0.0839 - val_accuracy: 0.9809\n",
      "Epoch 24/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9917\n",
      "Epoch 00024: val_accuracy improved from 0.98345 to 0.98473, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.0679 - val_accuracy: 0.9847\n",
      "Epoch 25/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9916\n",
      "Epoch 00025: val_accuracy did not improve from 0.98473\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.1120 - val_accuracy: 0.9711\n",
      "Epoch 26/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9926\n",
      "Epoch 00026: val_accuracy did not improve from 0.98473\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0813 - val_accuracy: 0.9801\n",
      "Epoch 27/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9917\n",
      "Epoch 00027: val_accuracy improved from 0.98473 to 0.98515, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0525 - val_accuracy: 0.9852\n",
      "Epoch 28/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9940\n",
      "Epoch 00028: val_accuracy did not improve from 0.98515\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.3735 - val_accuracy: 0.9317\n",
      "Epoch 29/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9933\n",
      "Epoch 00029: val_accuracy did not improve from 0.98515\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0737 - val_accuracy: 0.9826\n",
      "Epoch 30/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9949\n",
      "Epoch 00030: val_accuracy did not improve from 0.98515\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0663 - val_accuracy: 0.9839\n",
      "Epoch 31/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9949\n",
      "Epoch 00031: val_accuracy improved from 0.98515 to 0.98685, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0551 - val_accuracy: 0.9868\n",
      "Epoch 32/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9956\n",
      "Epoch 00032: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0543 - val_accuracy: 0.9860\n",
      "Epoch 33/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9969\n",
      "Epoch 00033: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.1217 - val_accuracy: 0.9758\n",
      "Epoch 34/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9958\n",
      "Epoch 00034: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.0642 - val_accuracy: 0.9847\n",
      "Epoch 35/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9951\n",
      "Epoch 00035: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.1502 - val_accuracy: 0.9716\n",
      "Epoch 36/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9965\n",
      "Epoch 00036: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0702 - val_accuracy: 0.9860\n",
      "Epoch 37/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9953\n",
      "Epoch 00037: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.0676 - val_accuracy: 0.9835\n",
      "Epoch 38/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9968\n",
      "Epoch 00038: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.1001 - val_accuracy: 0.9835\n",
      "Epoch 39/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9958\n",
      "Epoch 00039: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.1063 - val_accuracy: 0.9767\n",
      "Epoch 40/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9963\n",
      "Epoch 00040: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0691 - val_accuracy: 0.9864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9969\n",
      "Epoch 00041: val_accuracy improved from 0.98685 to 0.98939, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0521 - val_accuracy: 0.9894\n",
      "Epoch 42/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9971\n",
      "Epoch 00042: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.0491 - val_accuracy: 0.9860\n",
      "Epoch 43/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9969\n",
      "Epoch 00043: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0616 - val_accuracy: 0.9873\n",
      "Epoch 44/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9972\n",
      "Epoch 00044: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 0.0624 - val_accuracy: 0.9868\n",
      "Epoch 45/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9966\n",
      "Epoch 00045: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0525 - val_accuracy: 0.9873\n",
      "Epoch 46/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9975\n",
      "Epoch 00046: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0067 - accuracy: 0.9975 - val_loss: 0.0943 - val_accuracy: 0.9835\n",
      "Epoch 47/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 00047: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0971 - val_accuracy: 0.9809\n",
      "Epoch 48/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 00048: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.1108 - val_accuracy: 0.9796\n",
      "Epoch 49/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9966\n",
      "Epoch 00049: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.0928 - val_accuracy: 0.9843\n",
      "Epoch 50/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9971\n",
      "Epoch 00050: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0926 - val_accuracy: 0.9835\n",
      "Epoch 51/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9969\n",
      "Epoch 00051: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0656 - val_accuracy: 0.9890\n",
      "Epoch 52/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9973\n",
      "Epoch 00052: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0604 - val_accuracy: 0.9856\n",
      "Epoch 53/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 00053: val_accuracy improved from 0.98939 to 0.99024, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0608 - val_accuracy: 0.9902\n",
      "Epoch 54/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 00054: val_accuracy did not improve from 0.99024\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0572 - val_accuracy: 0.9881\n",
      "Epoch 55/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 00055: val_accuracy did not improve from 0.99024\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0664 - val_accuracy: 0.9885\n",
      "Epoch 56/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 00056: val_accuracy did not improve from 0.99024\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0585 - val_accuracy: 0.9902\n",
      "Epoch 57/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980\n",
      "Epoch 00057: val_accuracy did not improve from 0.99024\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0596 - val_accuracy: 0.9898\n",
      "Epoch 58/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9982\n",
      "Epoch 00058: val_accuracy did not improve from 0.99024\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0556 - val_accuracy: 0.9873\n",
      "Epoch 59/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9983\n",
      "Epoch 00059: val_accuracy improved from 0.99024 to 0.99109, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0435 - val_accuracy: 0.9911\n",
      "Epoch 60/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9979\n",
      "Epoch 00060: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.0467 - val_accuracy: 0.9890\n",
      "Epoch 61/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 00061: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0530 - val_accuracy: 0.9894\n",
      "Epoch 62/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9975\n",
      "Epoch 00062: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0564 - val_accuracy: 0.9885\n",
      "Epoch 63/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9980\n",
      "Epoch 00063: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1835 - val_accuracy: 0.9699\n",
      "Epoch 64/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 00064: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0383 - val_accuracy: 0.9902\n",
      "Epoch 65/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9985\n",
      "Epoch 00065: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.0727 - val_accuracy: 0.9843\n",
      "Epoch 66/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 00066: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0489 - val_accuracy: 0.9907\n",
      "Epoch 67/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 00067: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0531 - val_accuracy: 0.9898\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663/663 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 00068: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0852 - val_accuracy: 0.9881\n",
      "Epoch 69/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9978\n",
      "Epoch 00069: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0545 - val_accuracy: 0.9902\n",
      "Epoch 70/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9987\n",
      "Epoch 00070: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0612 - val_accuracy: 0.9864\n",
      "Epoch 71/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 00071: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0823 - val_accuracy: 0.9860\n",
      "Epoch 72/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9983\n",
      "Epoch 00072: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0541 - val_accuracy: 0.9907\n",
      "Epoch 73/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9988\n",
      "Epoch 00073: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0454 - val_accuracy: 0.9907\n",
      "Epoch 74/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 00074: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0727 - val_accuracy: 0.9881\n",
      "Epoch 75/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 00075: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0531 - val_accuracy: 0.9902\n",
      "Epoch 76/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 00076: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0622 - val_accuracy: 0.9877\n",
      "Epoch 77/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9980\n",
      "Epoch 00077: val_accuracy improved from 0.99109 to 0.99236, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0438 - val_accuracy: 0.9924\n",
      "Epoch 78/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9988\n",
      "Epoch 00078: val_accuracy did not improve from 0.99236\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0525 - val_accuracy: 0.9911\n",
      "Epoch 79/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch 00079: val_accuracy did not improve from 0.99236\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0804 - val_accuracy: 0.9852\n",
      "Epoch 80/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 00080: val_accuracy did not improve from 0.99236\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0632 - val_accuracy: 0.9877\n",
      "Epoch 81/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00081: val_accuracy did not improve from 0.99236\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0479 - val_accuracy: 0.9924\n",
      "Epoch 82/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00082: val_accuracy did not improve from 0.99236\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0500 - val_accuracy: 0.9919\n",
      "Epoch 83/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 00083: val_accuracy improved from 0.99236 to 0.99279, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0469 - val_accuracy: 0.9928\n",
      "Epoch 84/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 00084: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0672 - val_accuracy: 0.9890\n",
      "Epoch 85/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 00085: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0576 - val_accuracy: 0.9902\n",
      "Epoch 86/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 00086: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0543 - val_accuracy: 0.9898\n",
      "Epoch 87/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 00087: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0483 - val_accuracy: 0.9894\n",
      "Epoch 88/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00088: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0528 - val_accuracy: 0.9902\n",
      "Epoch 89/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 00089: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0560 - val_accuracy: 0.9885\n",
      "Epoch 90/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9985\n",
      "Epoch 00090: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0641 - val_accuracy: 0.9881\n",
      "Epoch 91/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 00091: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0603 - val_accuracy: 0.9890\n",
      "Epoch 92/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00092: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0526 - val_accuracy: 0.9898\n",
      "Epoch 93/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00093: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0676 - val_accuracy: 0.9902\n",
      "Epoch 94/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00094: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0572 - val_accuracy: 0.9902\n",
      "Epoch 95/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00095: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0692 - val_accuracy: 0.9915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00096: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0988 - val_accuracy: 0.9830\n",
      "Epoch 97/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 00097: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0707 - val_accuracy: 0.9911\n",
      "Epoch 98/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00098: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0613 - val_accuracy: 0.9911\n",
      "Epoch 99/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9990\n",
      "Epoch 00099: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0668 - val_accuracy: 0.9915\n",
      "Epoch 100/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 00100: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0555 - val_accuracy: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:28:47<00:00, 2663.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.89      0.86      0.87       648\n",
      "        car_horn       0.99      0.85      0.91       216\n",
      "children_playing       0.86      0.93      0.89       600\n",
      "        dog_bark       0.89      0.95      0.92       600\n",
      "           siren       0.94      0.86      0.90       516\n",
      "\n",
      "        accuracy                           0.90      2580\n",
      "       macro avg       0.91      0.89      0.90      2580\n",
      "    weighted avg       0.90      0.90      0.90      2580\n",
      "\n",
      "\n",
      "Validation fold: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21270, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21270, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2364, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2364, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2514, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2514, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_3\n",
      "Epoch 1/100\n",
      "  1/665 [..............................] - ETA: 0s - loss: 5.0364 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0093s vs `on_train_batch_end` time: 0.0140s). Check your callbacks.\n",
      "665/665 [==============================] - ETA: 0s - loss: 1.1992 - accuracy: 0.6101\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76438, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 1.1992 - accuracy: 0.6101 - val_loss: 0.6803 - val_accuracy: 0.7644\n",
      "Epoch 2/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.7183 - accuracy: 0.7414\n",
      "Epoch 00002: val_accuracy improved from 0.76438 to 0.79695, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.7179 - accuracy: 0.7415 - val_loss: 0.5719 - val_accuracy: 0.7970\n",
      "Epoch 3/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.6108 - accuracy: 0.7794\n",
      "Epoch 00003: val_accuracy did not improve from 0.79695\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.6112 - accuracy: 0.7793 - val_loss: 0.6360 - val_accuracy: 0.7851\n",
      "Epoch 4/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.5406 - accuracy: 0.8026\n",
      "Epoch 00004: val_accuracy improved from 0.79695 to 0.85998, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.5405 - accuracy: 0.8026 - val_loss: 0.3966 - val_accuracy: 0.8600\n",
      "Epoch 5/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.4825 - accuracy: 0.8245\n",
      "Epoch 00005: val_accuracy improved from 0.85998 to 0.87606, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.4831 - accuracy: 0.8244 - val_loss: 0.3365 - val_accuracy: 0.8761\n",
      "Epoch 6/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.4452 - accuracy: 0.8391\n",
      "Epoch 00006: val_accuracy did not improve from 0.87606\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.4449 - accuracy: 0.8392 - val_loss: 0.3868 - val_accuracy: 0.8723\n",
      "Epoch 7/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.4081 - accuracy: 0.8518\n",
      "Epoch 00007: val_accuracy did not improve from 0.87606\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.4085 - accuracy: 0.8517 - val_loss: 0.3424 - val_accuracy: 0.8761\n",
      "Epoch 8/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.3671 - accuracy: 0.8675\n",
      "Epoch 00008: val_accuracy improved from 0.87606 to 0.90863, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.3669 - accuracy: 0.8676 - val_loss: 0.2472 - val_accuracy: 0.9086\n",
      "Epoch 9/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.3472 - accuracy: 0.8740\n",
      "Epoch 00009: val_accuracy improved from 0.90863 to 0.92090, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.3474 - accuracy: 0.8739 - val_loss: 0.2229 - val_accuracy: 0.9209\n",
      "Epoch 10/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.3252 - accuracy: 0.8819\n",
      "Epoch 00010: val_accuracy improved from 0.92090 to 0.92724, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.3250 - accuracy: 0.8820 - val_loss: 0.2135 - val_accuracy: 0.9272\n",
      "Epoch 11/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2979 - accuracy: 0.8906\n",
      "Epoch 00011: val_accuracy did not improve from 0.92724\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.2979 - accuracy: 0.8906 - val_loss: 0.3484 - val_accuracy: 0.8875\n",
      "Epoch 12/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2783 - accuracy: 0.8992\n",
      "Epoch 00012: val_accuracy improved from 0.92724 to 0.92936, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.2785 - accuracy: 0.8992 - val_loss: 0.1977 - val_accuracy: 0.9294\n",
      "Epoch 13/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2631 - accuracy: 0.9026\n",
      "Epoch 00013: val_accuracy improved from 0.92936 to 0.93697, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.2632 - accuracy: 0.9026 - val_loss: 0.1966 - val_accuracy: 0.9370\n",
      "Epoch 14/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2558 - accuracy: 0.9070\n",
      "Epoch 00014: val_accuracy did not improve from 0.93697\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.2556 - accuracy: 0.9071 - val_loss: 0.2625 - val_accuracy: 0.9192\n",
      "Epoch 15/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.2399 - accuracy: 0.9145\n",
      "Epoch 00015: val_accuracy did not improve from 0.93697\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.2397 - accuracy: 0.9145 - val_loss: 0.4134 - val_accuracy: 0.8761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2257 - accuracy: 0.9153\n",
      "Epoch 00016: val_accuracy did not improve from 0.93697\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.2256 - accuracy: 0.9154 - val_loss: 0.2120 - val_accuracy: 0.9272\n",
      "Epoch 17/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.9235\n",
      "Epoch 00017: val_accuracy did not improve from 0.93697\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.2119 - accuracy: 0.9235 - val_loss: 0.1901 - val_accuracy: 0.9349\n",
      "Epoch 18/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2065 - accuracy: 0.9262\n",
      "Epoch 00018: val_accuracy improved from 0.93697 to 0.95008, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.2065 - accuracy: 0.9261 - val_loss: 0.1416 - val_accuracy: 0.9501\n",
      "Epoch 19/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.1889 - accuracy: 0.9315\n",
      "Epoch 00019: val_accuracy improved from 0.95008 to 0.95601, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1889 - accuracy: 0.9315 - val_loss: 0.1285 - val_accuracy: 0.9560\n",
      "Epoch 20/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.1805 - accuracy: 0.9341\n",
      "Epoch 00020: val_accuracy improved from 0.95601 to 0.96066, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1809 - accuracy: 0.9340 - val_loss: 0.1185 - val_accuracy: 0.9607\n",
      "Epoch 21/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.9354\n",
      "Epoch 00021: val_accuracy did not improve from 0.96066\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1769 - accuracy: 0.9354 - val_loss: 0.2663 - val_accuracy: 0.9192\n",
      "Epoch 22/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1648 - accuracy: 0.9407\n",
      "Epoch 00022: val_accuracy did not improve from 0.96066\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1647 - accuracy: 0.9407 - val_loss: 0.1592 - val_accuracy: 0.9514\n",
      "Epoch 23/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1657 - accuracy: 0.9403\n",
      "Epoch 00023: val_accuracy improved from 0.96066 to 0.96954, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1657 - accuracy: 0.9403 - val_loss: 0.0977 - val_accuracy: 0.9695\n",
      "Epoch 24/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1584 - accuracy: 0.9432\n",
      "Epoch 00024: val_accuracy did not improve from 0.96954\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1585 - accuracy: 0.9431 - val_loss: 0.0991 - val_accuracy: 0.9670\n",
      "Epoch 25/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1466 - accuracy: 0.9479\n",
      "Epoch 00025: val_accuracy did not improve from 0.96954\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1464 - accuracy: 0.9480 - val_loss: 0.1055 - val_accuracy: 0.9640\n",
      "Epoch 26/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1445 - accuracy: 0.9475\n",
      "Epoch 00026: val_accuracy improved from 0.96954 to 0.97208, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 16s 23ms/step - loss: 0.1444 - accuracy: 0.9475 - val_loss: 0.0997 - val_accuracy: 0.9721\n",
      "Epoch 27/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.9525\n",
      "Epoch 00027: val_accuracy did not improve from 0.97208\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1359 - accuracy: 0.9525 - val_loss: 0.0968 - val_accuracy: 0.9674\n",
      "Epoch 28/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1255 - accuracy: 0.9550\n",
      "Epoch 00028: val_accuracy did not improve from 0.97208\n",
      "665/665 [==============================] - 16s 24ms/step - loss: 0.1255 - accuracy: 0.9550 - val_loss: 0.1138 - val_accuracy: 0.9615\n",
      "Epoch 29/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.1302 - accuracy: 0.9527\n",
      "Epoch 00029: val_accuracy did not improve from 0.97208\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1303 - accuracy: 0.9527 - val_loss: 0.1524 - val_accuracy: 0.9514\n",
      "Epoch 30/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.1224 - accuracy: 0.9553\n",
      "Epoch 00030: val_accuracy did not improve from 0.97208\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1224 - accuracy: 0.9554 - val_loss: 0.0996 - val_accuracy: 0.9691\n",
      "Epoch 31/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.1228 - accuracy: 0.9554\n",
      "Epoch 00031: val_accuracy did not improve from 0.97208\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1229 - accuracy: 0.9552 - val_loss: 0.0877 - val_accuracy: 0.9712\n",
      "Epoch 32/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9588\n",
      "Epoch 00032: val_accuracy improved from 0.97208 to 0.97462, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 16s 23ms/step - loss: 0.1175 - accuracy: 0.9588 - val_loss: 0.0768 - val_accuracy: 0.9746\n",
      "Epoch 33/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.9588\n",
      "Epoch 00033: val_accuracy did not improve from 0.97462\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1131 - accuracy: 0.9588 - val_loss: 0.0810 - val_accuracy: 0.9734\n",
      "Epoch 34/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1074 - accuracy: 0.9617\n",
      "Epoch 00034: val_accuracy did not improve from 0.97462\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1075 - accuracy: 0.9617 - val_loss: 0.0811 - val_accuracy: 0.9746\n",
      "Epoch 35/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.9641\n",
      "Epoch 00035: val_accuracy improved from 0.97462 to 0.97758, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1011 - accuracy: 0.9642 - val_loss: 0.0740 - val_accuracy: 0.9776\n",
      "Epoch 36/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.9658\n",
      "Epoch 00036: val_accuracy did not improve from 0.97758\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0962 - accuracy: 0.9658 - val_loss: 0.0836 - val_accuracy: 0.9763\n",
      "Epoch 37/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0912 - accuracy: 0.9673\n",
      "Epoch 00037: val_accuracy did not improve from 0.97758\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0912 - accuracy: 0.9673 - val_loss: 0.0723 - val_accuracy: 0.9759\n",
      "Epoch 38/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9652\n",
      "Epoch 00038: val_accuracy improved from 0.97758 to 0.98181, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 16s 24ms/step - loss: 0.0956 - accuracy: 0.9652 - val_loss: 0.0621 - val_accuracy: 0.9818\n",
      "Epoch 39/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9690\n",
      "Epoch 00039: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 16s 24ms/step - loss: 0.0872 - accuracy: 0.9690 - val_loss: 0.1144 - val_accuracy: 0.9624\n",
      "Epoch 40/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9688\n",
      "Epoch 00040: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0846 - accuracy: 0.9688 - val_loss: 0.0841 - val_accuracy: 0.9750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0851 - accuracy: 0.9704\n",
      "Epoch 00041: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0851 - accuracy: 0.9704 - val_loss: 0.0651 - val_accuracy: 0.9788\n",
      "Epoch 42/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9705\n",
      "Epoch 00042: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0803 - accuracy: 0.9705 - val_loss: 0.0842 - val_accuracy: 0.9725\n",
      "Epoch 43/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 0.9702\n",
      "Epoch 00043: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.0821 - accuracy: 0.9702 - val_loss: 0.0564 - val_accuracy: 0.9818\n",
      "Epoch 44/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 0.9702\n",
      "Epoch 00044: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0812 - accuracy: 0.9701 - val_loss: 0.0715 - val_accuracy: 0.9793\n",
      "Epoch 45/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0775 - accuracy: 0.9729\n",
      "Epoch 00045: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0774 - accuracy: 0.9730 - val_loss: 0.0641 - val_accuracy: 0.9776\n",
      "Epoch 46/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9735\n",
      "Epoch 00046: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 17s 25ms/step - loss: 0.0736 - accuracy: 0.9735 - val_loss: 0.0673 - val_accuracy: 0.9801\n",
      "Epoch 47/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9741\n",
      "Epoch 00047: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0746 - accuracy: 0.9741 - val_loss: 0.0870 - val_accuracy: 0.9725\n",
      "Epoch 48/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 0.9752\n",
      "Epoch 00048: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0691 - accuracy: 0.9752 - val_loss: 0.0689 - val_accuracy: 0.9801\n",
      "Epoch 49/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9757\n",
      "Epoch 00049: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0692 - accuracy: 0.9758 - val_loss: 0.0592 - val_accuracy: 0.9810\n",
      "Epoch 50/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 0.9775\n",
      "Epoch 00050: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0630 - accuracy: 0.9775 - val_loss: 0.1168 - val_accuracy: 0.9653\n",
      "Epoch 51/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9769\n",
      "Epoch 00051: val_accuracy improved from 0.98181 to 0.98393, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0643 - accuracy: 0.9770 - val_loss: 0.0536 - val_accuracy: 0.9839\n",
      "Epoch 52/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0637 - accuracy: 0.9777\n",
      "Epoch 00052: val_accuracy did not improve from 0.98393\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0637 - accuracy: 0.9777 - val_loss: 0.0633 - val_accuracy: 0.9810\n",
      "Epoch 53/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0634 - accuracy: 0.9778\n",
      "Epoch 00053: val_accuracy did not improve from 0.98393\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0635 - accuracy: 0.9779 - val_loss: 0.0714 - val_accuracy: 0.9776\n",
      "Epoch 54/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9787\n",
      "Epoch 00054: val_accuracy did not improve from 0.98393\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0589 - accuracy: 0.9787 - val_loss: 0.0654 - val_accuracy: 0.9818\n",
      "Epoch 55/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9778\n",
      "Epoch 00055: val_accuracy did not improve from 0.98393\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0626 - accuracy: 0.9779 - val_loss: 0.0532 - val_accuracy: 0.9835\n",
      "Epoch 56/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0607 - accuracy: 0.9780\n",
      "Epoch 00056: val_accuracy improved from 0.98393 to 0.98562, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0607 - accuracy: 0.9780 - val_loss: 0.0498 - val_accuracy: 0.9856\n",
      "Epoch 57/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9812\n",
      "Epoch 00057: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0539 - accuracy: 0.9812 - val_loss: 0.0473 - val_accuracy: 0.9848\n",
      "Epoch 58/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9788\n",
      "Epoch 00058: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0578 - accuracy: 0.9787 - val_loss: 0.0555 - val_accuracy: 0.9827\n",
      "Epoch 59/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9802\n",
      "Epoch 00059: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0556 - accuracy: 0.9803 - val_loss: 0.0491 - val_accuracy: 0.9852\n",
      "Epoch 60/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0525 - accuracy: 0.9814\n",
      "Epoch 00060: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0525 - accuracy: 0.9814 - val_loss: 0.0471 - val_accuracy: 0.9856\n",
      "Epoch 61/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0504 - accuracy: 0.9826\n",
      "Epoch 00061: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0504 - accuracy: 0.9826 - val_loss: 0.0561 - val_accuracy: 0.9835\n",
      "Epoch 62/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0560 - accuracy: 0.9806\n",
      "Epoch 00062: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0560 - accuracy: 0.9806 - val_loss: 0.0448 - val_accuracy: 0.9835\n",
      "Epoch 63/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9820\n",
      "Epoch 00063: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0511 - accuracy: 0.9819 - val_loss: 0.0606 - val_accuracy: 0.9810\n",
      "Epoch 64/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 0.9828\n",
      "Epoch 00064: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0505 - accuracy: 0.9828 - val_loss: 0.0432 - val_accuracy: 0.9856\n",
      "Epoch 65/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9828\n",
      "Epoch 00065: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0472 - accuracy: 0.9828 - val_loss: 0.0534 - val_accuracy: 0.9843\n",
      "Epoch 66/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9848\n",
      "Epoch 00066: val_accuracy improved from 0.98562 to 0.98773, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0424 - accuracy: 0.9849 - val_loss: 0.0392 - val_accuracy: 0.9877\n",
      "Epoch 67/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9833\n",
      "Epoch 00067: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0464 - accuracy: 0.9833 - val_loss: 0.0521 - val_accuracy: 0.9865\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/665 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9837\n",
      "Epoch 00068: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0463 - accuracy: 0.9836 - val_loss: 0.0411 - val_accuracy: 0.9869\n",
      "Epoch 69/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9850\n",
      "Epoch 00069: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0418 - accuracy: 0.9850 - val_loss: 0.0442 - val_accuracy: 0.9865\n",
      "Epoch 70/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9839\n",
      "Epoch 00070: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0451 - accuracy: 0.9838 - val_loss: 0.0672 - val_accuracy: 0.9818\n",
      "Epoch 71/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9838\n",
      "Epoch 00071: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0471 - accuracy: 0.9836 - val_loss: 0.0549 - val_accuracy: 0.9835\n",
      "Epoch 72/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9852\n",
      "Epoch 00072: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0428 - accuracy: 0.9852 - val_loss: 0.0435 - val_accuracy: 0.9852\n",
      "Epoch 73/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0453 - accuracy: 0.9842\n",
      "Epoch 00073: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0452 - accuracy: 0.9843 - val_loss: 0.0550 - val_accuracy: 0.9822\n",
      "Epoch 74/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9861\n",
      "Epoch 00074: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0403 - accuracy: 0.9861 - val_loss: 0.0495 - val_accuracy: 0.9860\n",
      "Epoch 75/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 0.9865\n",
      "Epoch 00075: val_accuracy improved from 0.98773 to 0.98816, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0389 - accuracy: 0.9865 - val_loss: 0.0393 - val_accuracy: 0.9882\n",
      "Epoch 76/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0413 - accuracy: 0.9854\n",
      "Epoch 00076: val_accuracy did not improve from 0.98816\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0414 - accuracy: 0.9854 - val_loss: 0.0421 - val_accuracy: 0.9882\n",
      "Epoch 77/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9859\n",
      "Epoch 00077: val_accuracy did not improve from 0.98816\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0411 - accuracy: 0.9859 - val_loss: 0.0525 - val_accuracy: 0.9848\n",
      "Epoch 78/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0384 - accuracy: 0.9875\n",
      "Epoch 00078: val_accuracy improved from 0.98816 to 0.99069, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0384 - accuracy: 0.9875 - val_loss: 0.0419 - val_accuracy: 0.9907\n",
      "Epoch 79/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9888\n",
      "Epoch 00079: val_accuracy did not improve from 0.99069\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0343 - accuracy: 0.9888 - val_loss: 0.0393 - val_accuracy: 0.9890\n",
      "Epoch 80/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9882\n",
      "Epoch 00080: val_accuracy improved from 0.99069 to 0.99112, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0340 - accuracy: 0.9882 - val_loss: 0.0365 - val_accuracy: 0.9911\n",
      "Epoch 81/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9884\n",
      "Epoch 00081: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 0.0430 - val_accuracy: 0.9886\n",
      "Epoch 82/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9885\n",
      "Epoch 00082: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 0.0385 - val_accuracy: 0.9886\n",
      "Epoch 83/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9881\n",
      "Epoch 00083: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0353 - accuracy: 0.9882 - val_loss: 0.0471 - val_accuracy: 0.9869\n",
      "Epoch 84/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9875\n",
      "Epoch 00084: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0352 - accuracy: 0.9874 - val_loss: 0.0463 - val_accuracy: 0.9865\n",
      "Epoch 85/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9884\n",
      "Epoch 00085: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.0355 - val_accuracy: 0.9911\n",
      "Epoch 86/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9885\n",
      "Epoch 00086: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0329 - accuracy: 0.9885 - val_loss: 0.0377 - val_accuracy: 0.9907\n",
      "Epoch 87/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9882\n",
      "Epoch 00087: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.0360 - val_accuracy: 0.9894\n",
      "Epoch 88/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0336 - accuracy: 0.9888\n",
      "Epoch 00088: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0336 - accuracy: 0.9888 - val_loss: 0.0421 - val_accuracy: 0.9877\n",
      "Epoch 89/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9883\n",
      "Epoch 00089: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0334 - accuracy: 0.9883 - val_loss: 0.0466 - val_accuracy: 0.9873\n",
      "Epoch 90/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9906\n",
      "Epoch 00090: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 0.0372 - val_accuracy: 0.9882\n",
      "Epoch 91/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.9904\n",
      "Epoch 00091: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0304 - accuracy: 0.9904 - val_loss: 0.0399 - val_accuracy: 0.9882\n",
      "Epoch 92/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9893\n",
      "Epoch 00092: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0323 - accuracy: 0.9893 - val_loss: 0.0419 - val_accuracy: 0.9877\n",
      "Epoch 93/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9886\n",
      "Epoch 00093: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0315 - accuracy: 0.9886 - val_loss: 0.0414 - val_accuracy: 0.9877\n",
      "Epoch 94/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9895\n",
      "Epoch 00094: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0300 - accuracy: 0.9894 - val_loss: 0.0374 - val_accuracy: 0.9894\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/665 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9898\n",
      "Epoch 00095: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0291 - accuracy: 0.9898 - val_loss: 0.0416 - val_accuracy: 0.9865\n",
      "Epoch 96/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9902\n",
      "Epoch 00096: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0281 - accuracy: 0.9902 - val_loss: 0.0381 - val_accuracy: 0.9894\n",
      "Epoch 97/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9912\n",
      "Epoch 00097: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0263 - accuracy: 0.9913 - val_loss: 0.0378 - val_accuracy: 0.9898\n",
      "Epoch 98/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9904\n",
      "Epoch 00098: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0259 - accuracy: 0.9904 - val_loss: 0.0357 - val_accuracy: 0.9898\n",
      "Epoch 99/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9913\n",
      "Epoch 00099: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0248 - accuracy: 0.9913 - val_loss: 0.0302 - val_accuracy: 0.9907\n",
      "Epoch 100/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9909\n",
      "Epoch 00100: val_accuracy did not improve from 0.99112\n",
      "Restoring model weights from the end of the best epoch.\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.0429 - val_accuracy: 0.9869\n",
      "Epoch 00100: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [25:27<25:27, 1527.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.84      0.91      0.88       618\n",
      "        car_horn       0.86      0.93      0.90       198\n",
      "children_playing       0.75      0.90      0.82       600\n",
      "        dog_bark       0.77      0.79      0.78       600\n",
      "           siren       0.91      0.56      0.69       498\n",
      "\n",
      "        accuracy                           0.81      2514\n",
      "       macro avg       0.83      0.82      0.81      2514\n",
      "    weighted avg       0.82      0.81      0.80      2514\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_4\n",
      "Epoch 1/100\n",
      "  2/665 [..............................] - ETA: 20s - loss: 2.1798 - accuracy: 0.1719WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0219s vs `on_train_batch_end` time: 0.0399s). Check your callbacks.\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.9484 - accuracy: 0.6404\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79653, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 43s 65ms/step - loss: 0.9484 - accuracy: 0.6404 - val_loss: 0.5621 - val_accuracy: 0.7965\n",
      "Epoch 2/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.5603 - accuracy: 0.7998\n",
      "Epoch 00002: val_accuracy improved from 0.79653 to 0.79865, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 42s 63ms/step - loss: 0.5605 - accuracy: 0.7997 - val_loss: 0.5843 - val_accuracy: 0.7986\n",
      "Epoch 3/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.3974 - accuracy: 0.8586\n",
      "Epoch 00003: val_accuracy improved from 0.79865 to 0.82149, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 42s 63ms/step - loss: 0.3971 - accuracy: 0.8588 - val_loss: 0.4691 - val_accuracy: 0.8215\n",
      "Epoch 4/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.3111 - accuracy: 0.8913\n",
      "Epoch 00004: val_accuracy improved from 0.82149 to 0.87775, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 42s 64ms/step - loss: 0.3110 - accuracy: 0.8914 - val_loss: 0.3458 - val_accuracy: 0.8777\n",
      "Epoch 5/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2490 - accuracy: 0.9156\n",
      "Epoch 00005: val_accuracy improved from 0.87775 to 0.92682, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 42s 63ms/step - loss: 0.2491 - accuracy: 0.9156 - val_loss: 0.2224 - val_accuracy: 0.9268\n",
      "Epoch 6/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1919 - accuracy: 0.9347\n",
      "Epoch 00006: val_accuracy improved from 0.92682 to 0.95770, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 42s 62ms/step - loss: 0.1919 - accuracy: 0.9346 - val_loss: 0.1379 - val_accuracy: 0.9577\n",
      "Epoch 7/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1667 - accuracy: 0.9427\n",
      "Epoch 00007: val_accuracy did not improve from 0.95770\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.1666 - accuracy: 0.9428 - val_loss: 0.1734 - val_accuracy: 0.9425\n",
      "Epoch 8/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1376 - accuracy: 0.9512\n",
      "Epoch 00008: val_accuracy improved from 0.95770 to 0.95939, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.1377 - accuracy: 0.9511 - val_loss: 0.1267 - val_accuracy: 0.9594\n",
      "Epoch 9/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1192 - accuracy: 0.9599\n",
      "Epoch 00009: val_accuracy improved from 0.95939 to 0.96108, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.1192 - accuracy: 0.9598 - val_loss: 0.1180 - val_accuracy: 0.9611\n",
      "Epoch 10/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.9647\n",
      "Epoch 00010: val_accuracy improved from 0.96108 to 0.96362, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.1011 - accuracy: 0.9648 - val_loss: 0.1212 - val_accuracy: 0.9636\n",
      "Epoch 11/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0924 - accuracy: 0.9683\n",
      "Epoch 00011: val_accuracy did not improve from 0.96362\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0923 - accuracy: 0.9684 - val_loss: 0.1375 - val_accuracy: 0.9581\n",
      "Epoch 12/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 0.9744\n",
      "Epoch 00012: val_accuracy improved from 0.96362 to 0.96447, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0760 - accuracy: 0.9744 - val_loss: 0.1138 - val_accuracy: 0.9645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0655 - accuracy: 0.9779\n",
      "Epoch 00013: val_accuracy improved from 0.96447 to 0.97885, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0655 - accuracy: 0.9779 - val_loss: 0.0656 - val_accuracy: 0.9788\n",
      "Epoch 14/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9804\n",
      "Epoch 00014: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 42s 63ms/step - loss: 0.0589 - accuracy: 0.9804 - val_loss: 0.1003 - val_accuracy: 0.9691\n",
      "Epoch 15/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0559 - accuracy: 0.9812\n",
      "Epoch 00015: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0559 - accuracy: 0.9812 - val_loss: 0.0944 - val_accuracy: 0.9700\n",
      "Epoch 16/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9848\n",
      "Epoch 00016: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0466 - accuracy: 0.9849 - val_loss: 0.0780 - val_accuracy: 0.9780\n",
      "Epoch 17/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 0.9860\n",
      "Epoch 00017: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0442 - accuracy: 0.9860 - val_loss: 0.0794 - val_accuracy: 0.9750\n",
      "Epoch 18/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 0.9864\n",
      "Epoch 00018: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0389 - accuracy: 0.9863 - val_loss: 0.0828 - val_accuracy: 0.9772\n",
      "Epoch 19/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9905\n",
      "Epoch 00019: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0300 - accuracy: 0.9906 - val_loss: 0.0766 - val_accuracy: 0.9780\n",
      "Epoch 20/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9903\n",
      "Epoch 00020: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0291 - accuracy: 0.9903 - val_loss: 0.1505 - val_accuracy: 0.9636\n",
      "Epoch 21/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9890\n",
      "Epoch 00021: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0316 - accuracy: 0.9890 - val_loss: 0.0976 - val_accuracy: 0.9763\n",
      "Epoch 22/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9906\n",
      "Epoch 00022: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 42s 64ms/step - loss: 0.0280 - accuracy: 0.9906 - val_loss: 0.2378 - val_accuracy: 0.9564\n",
      "Epoch 23/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9920\n",
      "Epoch 00023: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.0810 - val_accuracy: 0.9784\n",
      "Epoch 24/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9911\n",
      "Epoch 00024: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 0.0716 - val_accuracy: 0.9780\n",
      "Epoch 25/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9916\n",
      "Epoch 00025: val_accuracy improved from 0.97885 to 0.98012, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.0916 - val_accuracy: 0.9801\n",
      "Epoch 26/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9928\n",
      "Epoch 00026: val_accuracy improved from 0.98012 to 0.98096, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.0677 - val_accuracy: 0.9810\n",
      "Epoch 27/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9924\n",
      "Epoch 00027: val_accuracy did not improve from 0.98096\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.0723 - val_accuracy: 0.9810\n",
      "Epoch 28/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9947\n",
      "Epoch 00028: val_accuracy did not improve from 0.98096\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.1165 - val_accuracy: 0.9717\n",
      "Epoch 29/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9933\n",
      "Epoch 00029: val_accuracy improved from 0.98096 to 0.98858, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.0499 - val_accuracy: 0.9886\n",
      "Epoch 30/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9947\n",
      "Epoch 00030: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 42s 64ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0618 - val_accuracy: 0.9860\n",
      "Epoch 31/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9933\n",
      "Epoch 00031: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 0.0793 - val_accuracy: 0.9805\n",
      "Epoch 32/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9962\n",
      "Epoch 00032: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.0589 - val_accuracy: 0.9865\n",
      "Epoch 33/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9933\n",
      "Epoch 00033: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.0877 - val_accuracy: 0.9827\n",
      "Epoch 34/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9950\n",
      "Epoch 00034: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.2457 - val_accuracy: 0.9475\n",
      "Epoch 35/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9944\n",
      "Epoch 00035: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 42s 64ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.0907 - val_accuracy: 0.9814\n",
      "Epoch 36/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9963\n",
      "Epoch 00036: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 42s 64ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0585 - val_accuracy: 0.9856\n",
      "Epoch 37/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9971\n",
      "Epoch 00037: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0818 - val_accuracy: 0.9839\n",
      "Epoch 38/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9962\n",
      "Epoch 00038: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.1121 - val_accuracy: 0.9759\n",
      "Epoch 39/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9961\n",
      "Epoch 00039: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0466 - val_accuracy: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 00040: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0744 - val_accuracy: 0.9805\n",
      "Epoch 41/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9976\n",
      "Epoch 00041: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0585 - val_accuracy: 0.9860\n",
      "Epoch 42/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9963\n",
      "Epoch 00042: val_accuracy improved from 0.98858 to 0.98900, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0482 - val_accuracy: 0.9890\n",
      "Epoch 43/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9970\n",
      "Epoch 00043: val_accuracy did not improve from 0.98900\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.0573 - val_accuracy: 0.9852\n",
      "Epoch 44/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 00044: val_accuracy did not improve from 0.98900\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.0946 - val_accuracy: 0.9831\n",
      "Epoch 45/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9978\n",
      "Epoch 00045: val_accuracy did not improve from 0.98900\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0644 - val_accuracy: 0.9869\n",
      "Epoch 46/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9972\n",
      "Epoch 00046: val_accuracy did not improve from 0.98900\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.1069 - val_accuracy: 0.9772\n",
      "Epoch 47/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9973\n",
      "Epoch 00047: val_accuracy improved from 0.98900 to 0.98942, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0477 - val_accuracy: 0.9894\n",
      "Epoch 48/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 00048: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1111 - val_accuracy: 0.9793\n",
      "Epoch 49/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9960\n",
      "Epoch 00049: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.1171 - val_accuracy: 0.9759\n",
      "Epoch 50/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9961\n",
      "Epoch 00050: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 0.1910 - val_accuracy: 0.9662\n",
      "Epoch 51/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9964\n",
      "Epoch 00051: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0495 - val_accuracy: 0.9856\n",
      "Epoch 52/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 00052: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0553 - val_accuracy: 0.9860\n",
      "Epoch 53/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9969\n",
      "Epoch 00053: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0468 - val_accuracy: 0.9873\n",
      "Epoch 54/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9979\n",
      "Epoch 00054: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0645 - val_accuracy: 0.9839\n",
      "Epoch 55/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9975\n",
      "Epoch 00055: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.1327 - val_accuracy: 0.9755\n",
      "Epoch 56/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 00056: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0642 - val_accuracy: 0.9869\n",
      "Epoch 57/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch 00057: val_accuracy improved from 0.98942 to 0.99112, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0468 - val_accuracy: 0.9911\n",
      "Epoch 58/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9984\n",
      "Epoch 00058: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0580 - val_accuracy: 0.9894\n",
      "Epoch 59/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9983\n",
      "Epoch 00059: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0535 - val_accuracy: 0.9898\n",
      "Epoch 60/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 00060: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0614 - val_accuracy: 0.9873\n",
      "Epoch 61/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 00061: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0660 - val_accuracy: 0.9890\n",
      "Epoch 62/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 00062: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 42s 62ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0686 - val_accuracy: 0.9869\n",
      "Epoch 63/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 00063: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0578 - val_accuracy: 0.9882\n",
      "Epoch 64/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 00064: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0657 - val_accuracy: 0.9877\n",
      "Epoch 65/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 00065: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.1094 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00066: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0660 - val_accuracy: 0.9886\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/665 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 00067: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1791 - val_accuracy: 0.9712\n",
      "Epoch 68/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 00068: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0702 - val_accuracy: 0.9890\n",
      "Epoch 69/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 00069: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0690 - val_accuracy: 0.9869\n",
      "Epoch 70/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00070: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0502 - val_accuracy: 0.9903\n",
      "Epoch 71/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 00071: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0577 - val_accuracy: 0.9882\n",
      "Epoch 72/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 00072: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0654 - val_accuracy: 0.9877\n",
      "Epoch 73/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00073: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0612 - val_accuracy: 0.9890\n",
      "Epoch 74/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9982\n",
      "Epoch 00074: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0714 - val_accuracy: 0.9860\n",
      "Epoch 75/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 00075: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0586 - val_accuracy: 0.9882\n",
      "Epoch 76/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 00076: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0758 - val_accuracy: 0.9843\n",
      "Epoch 77/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 00077: val_accuracy did not improve from 0.99112\n",
      "Restoring model weights from the end of the best epoch.\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0630 - val_accuracy: 0.9882\n",
      "Epoch 00077: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:19:26<00:00, 2383.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.89      0.88      0.88       618\n",
      "        car_horn       0.84      0.95      0.89       198\n",
      "children_playing       0.90      0.91      0.90       600\n",
      "        dog_bark       0.74      0.89      0.81       600\n",
      "           siren       0.91      0.63      0.75       498\n",
      "\n",
      "        accuracy                           0.85      2514\n",
      "       macro avg       0.85      0.85      0.85      2514\n",
      "    weighted avg       0.85      0.85      0.84      2514\n",
      "\n",
      "\n",
      "Validation fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21216, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21216, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2358, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2358, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2574, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2574, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_5\n",
      "Epoch 1/100\n",
      "  1/663 [..............................] - ETA: 0s - loss: 4.3012 - accuracy: 0.3125WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0040s vs `on_train_batch_end` time: 0.0190s). Check your callbacks.\n",
      "661/663 [============================>.] - ETA: 0s - loss: 1.1228 - accuracy: 0.6314\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74258, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 1.1216 - accuracy: 0.6316 - val_loss: 0.7131 - val_accuracy: 0.7426\n",
      "Epoch 2/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.7025 - accuracy: 0.7508\n",
      "Epoch 00002: val_accuracy improved from 0.74258 to 0.76845, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.7035 - accuracy: 0.7504 - val_loss: 0.6438 - val_accuracy: 0.7684\n",
      "Epoch 3/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.5925 - accuracy: 0.7850\n",
      "Epoch 00003: val_accuracy improved from 0.76845 to 0.78456, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.5923 - accuracy: 0.7850 - val_loss: 0.5791 - val_accuracy: 0.7846\n",
      "Epoch 4/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.5153 - accuracy: 0.8141\n",
      "Epoch 00004: val_accuracy improved from 0.78456 to 0.83673, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.5147 - accuracy: 0.8143 - val_loss: 0.4892 - val_accuracy: 0.8367\n",
      "Epoch 5/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.4656 - accuracy: 0.8306\n",
      "Epoch 00005: val_accuracy improved from 0.83673 to 0.88592, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.4653 - accuracy: 0.8308 - val_loss: 0.3171 - val_accuracy: 0.8859\n",
      "Epoch 6/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.4257 - accuracy: 0.8450\n",
      "Epoch 00006: val_accuracy improved from 0.88592 to 0.88762, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.4253 - accuracy: 0.8452 - val_loss: 0.3238 - val_accuracy: 0.8876\n",
      "Epoch 7/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.3766 - accuracy: 0.8637\n",
      "Epoch 00007: val_accuracy improved from 0.88762 to 0.89355, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.3765 - accuracy: 0.8636 - val_loss: 0.2958 - val_accuracy: 0.8936\n",
      "Epoch 8/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.8741\n",
      "Epoch 00008: val_accuracy did not improve from 0.89355\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.3533 - accuracy: 0.8739 - val_loss: 0.2949 - val_accuracy: 0.8927\n",
      "Epoch 9/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.8829\n",
      "Epoch 00009: val_accuracy improved from 0.89355 to 0.90119, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.3300 - accuracy: 0.8826 - val_loss: 0.2829 - val_accuracy: 0.9012\n",
      "Epoch 10/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.3015 - accuracy: 0.8913\n",
      "Epoch 00010: val_accuracy improved from 0.90119 to 0.90840, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.3016 - accuracy: 0.8912 - val_loss: 0.2588 - val_accuracy: 0.9084\n",
      "Epoch 11/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2848 - accuracy: 0.8978\n",
      "Epoch 00011: val_accuracy improved from 0.90840 to 0.92791, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.2849 - accuracy: 0.8978 - val_loss: 0.2163 - val_accuracy: 0.9279\n",
      "Epoch 12/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.9028\n",
      "Epoch 00012: val_accuracy did not improve from 0.92791\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.2656 - accuracy: 0.9029 - val_loss: 0.2080 - val_accuracy: 0.9271\n",
      "Epoch 13/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9103\n",
      "Epoch 00013: val_accuracy did not improve from 0.92791\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.2463 - accuracy: 0.9101 - val_loss: 0.2243 - val_accuracy: 0.9211\n",
      "Epoch 14/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2303 - accuracy: 0.9162\n",
      "Epoch 00014: val_accuracy improved from 0.92791 to 0.93299, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.2303 - accuracy: 0.9162 - val_loss: 0.1929 - val_accuracy: 0.9330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9221\n",
      "Epoch 00015: val_accuracy improved from 0.93299 to 0.95759, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.2195 - accuracy: 0.9220 - val_loss: 0.1287 - val_accuracy: 0.9576\n",
      "Epoch 16/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2042 - accuracy: 0.9248\n",
      "Epoch 00016: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.2040 - accuracy: 0.9249 - val_loss: 0.1999 - val_accuracy: 0.9288\n",
      "Epoch 17/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1993 - accuracy: 0.9258\n",
      "Epoch 00017: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1988 - accuracy: 0.9260 - val_loss: 0.1394 - val_accuracy: 0.9542\n",
      "Epoch 18/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1873 - accuracy: 0.9317\n",
      "Epoch 00018: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1874 - accuracy: 0.9317 - val_loss: 0.2049 - val_accuracy: 0.9326\n",
      "Epoch 19/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1761 - accuracy: 0.9366\n",
      "Epoch 00019: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1764 - accuracy: 0.9365 - val_loss: 0.1320 - val_accuracy: 0.9559\n",
      "Epoch 20/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9375\n",
      "Epoch 00020: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1714 - accuracy: 0.9376 - val_loss: 0.1520 - val_accuracy: 0.9449\n",
      "Epoch 21/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1572 - accuracy: 0.9433\n",
      "Epoch 00021: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1571 - accuracy: 0.9434 - val_loss: 0.2149 - val_accuracy: 0.9173\n",
      "Epoch 22/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1498 - accuracy: 0.9461\n",
      "Epoch 00022: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1497 - accuracy: 0.9461 - val_loss: 0.1461 - val_accuracy: 0.9512\n",
      "Epoch 23/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1453 - accuracy: 0.9477\n",
      "Epoch 00023: val_accuracy improved from 0.95759 to 0.96480, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1451 - accuracy: 0.9477 - val_loss: 0.1089 - val_accuracy: 0.9648\n",
      "Epoch 24/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 0.9516\n",
      "Epoch 00024: val_accuracy did not improve from 0.96480\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1298 - accuracy: 0.9517 - val_loss: 0.1038 - val_accuracy: 0.9648\n",
      "Epoch 25/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1330 - accuracy: 0.9522\n",
      "Epoch 00025: val_accuracy did not improve from 0.96480\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1330 - accuracy: 0.9522 - val_loss: 0.1074 - val_accuracy: 0.9635\n",
      "Epoch 26/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1281 - accuracy: 0.9536\n",
      "Epoch 00026: val_accuracy did not improve from 0.96480\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1282 - accuracy: 0.9536 - val_loss: 0.1022 - val_accuracy: 0.9631\n",
      "Epoch 27/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 0.9543\n",
      "Epoch 00027: val_accuracy did not improve from 0.96480\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1270 - accuracy: 0.9544 - val_loss: 0.1094 - val_accuracy: 0.9606\n",
      "Epoch 28/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 0.9596\n",
      "Epoch 00028: val_accuracy did not improve from 0.96480\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1158 - accuracy: 0.9597 - val_loss: 0.1149 - val_accuracy: 0.9606\n",
      "Epoch 29/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1169 - accuracy: 0.9570\n",
      "Epoch 00029: val_accuracy improved from 0.96480 to 0.97243, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1167 - accuracy: 0.9571 - val_loss: 0.0760 - val_accuracy: 0.9724\n",
      "Epoch 30/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1053 - accuracy: 0.9621\n",
      "Epoch 00030: val_accuracy improved from 0.97243 to 0.97540, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1054 - accuracy: 0.9620 - val_loss: 0.0885 - val_accuracy: 0.9754\n",
      "Epoch 31/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1032 - accuracy: 0.9633\n",
      "Epoch 00031: val_accuracy improved from 0.97540 to 0.97668, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1030 - accuracy: 0.9634 - val_loss: 0.0715 - val_accuracy: 0.9767\n",
      "Epoch 32/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1036 - accuracy: 0.9624\n",
      "Epoch 00032: val_accuracy did not improve from 0.97668\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1035 - accuracy: 0.9625 - val_loss: 0.1393 - val_accuracy: 0.9559\n",
      "Epoch 33/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1004 - accuracy: 0.9651\n",
      "Epoch 00033: val_accuracy did not improve from 0.97668\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1006 - accuracy: 0.9650 - val_loss: 0.2678 - val_accuracy: 0.9279\n",
      "Epoch 34/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.9652\n",
      "Epoch 00034: val_accuracy did not improve from 0.97668\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0943 - accuracy: 0.9652 - val_loss: 0.1152 - val_accuracy: 0.9635\n",
      "Epoch 35/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0898 - accuracy: 0.9673\n",
      "Epoch 00035: val_accuracy improved from 0.97668 to 0.97795, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0897 - accuracy: 0.9673 - val_loss: 0.0674 - val_accuracy: 0.9779\n",
      "Epoch 36/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0919 - accuracy: 0.9663\n",
      "Epoch 00036: val_accuracy did not improve from 0.97795\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0922 - accuracy: 0.9663 - val_loss: 0.0921 - val_accuracy: 0.9656\n",
      "Epoch 37/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0854 - accuracy: 0.9707\n",
      "Epoch 00037: val_accuracy improved from 0.97795 to 0.98092, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0858 - accuracy: 0.9706 - val_loss: 0.0613 - val_accuracy: 0.9809\n",
      "Epoch 38/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0807 - accuracy: 0.9721\n",
      "Epoch 00038: val_accuracy did not improve from 0.98092\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0808 - accuracy: 0.9720 - val_loss: 0.0639 - val_accuracy: 0.9801\n",
      "Epoch 39/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0784 - accuracy: 0.9728\n",
      "Epoch 00039: val_accuracy improved from 0.98092 to 0.98176, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0788 - accuracy: 0.9728 - val_loss: 0.0578 - val_accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9726\n",
      "Epoch 00040: val_accuracy did not improve from 0.98176\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0778 - accuracy: 0.9726 - val_loss: 0.0791 - val_accuracy: 0.9716\n",
      "Epoch 41/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0787 - accuracy: 0.9729\n",
      "Epoch 00041: val_accuracy improved from 0.98176 to 0.98388, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0788 - accuracy: 0.9729 - val_loss: 0.0587 - val_accuracy: 0.9839\n",
      "Epoch 42/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0742 - accuracy: 0.9732\n",
      "Epoch 00042: val_accuracy improved from 0.98388 to 0.98728, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0747 - accuracy: 0.9731 - val_loss: 0.0520 - val_accuracy: 0.9873\n",
      "Epoch 43/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9755\n",
      "Epoch 00043: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0677 - accuracy: 0.9755 - val_loss: 0.0619 - val_accuracy: 0.9771\n",
      "Epoch 44/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 0.9761\n",
      "Epoch 00044: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0691 - accuracy: 0.9761 - val_loss: 0.0576 - val_accuracy: 0.9843\n",
      "Epoch 45/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9749\n",
      "Epoch 00045: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 14s 22ms/step - loss: 0.0701 - accuracy: 0.9749 - val_loss: 0.0486 - val_accuracy: 0.9869\n",
      "Epoch 46/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9766\n",
      "Epoch 00046: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0628 - accuracy: 0.9764 - val_loss: 0.0457 - val_accuracy: 0.9873\n",
      "Epoch 47/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9782\n",
      "Epoch 00047: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0614 - accuracy: 0.9782 - val_loss: 0.0970 - val_accuracy: 0.9678\n",
      "Epoch 48/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9792\n",
      "Epoch 00048: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0578 - accuracy: 0.9793 - val_loss: 0.0648 - val_accuracy: 0.9813\n",
      "Epoch 49/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9767\n",
      "Epoch 00049: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0660 - accuracy: 0.9767 - val_loss: 0.0560 - val_accuracy: 0.9822\n",
      "Epoch 50/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 0.9792\n",
      "Epoch 00050: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0592 - accuracy: 0.9793 - val_loss: 0.0771 - val_accuracy: 0.9746\n",
      "Epoch 51/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0598 - accuracy: 0.9789\n",
      "Epoch 00051: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0597 - accuracy: 0.9790 - val_loss: 0.0467 - val_accuracy: 0.9856\n",
      "Epoch 52/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9798\n",
      "Epoch 00052: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0556 - accuracy: 0.9798 - val_loss: 0.0524 - val_accuracy: 0.9843\n",
      "Epoch 53/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.9812\n",
      "Epoch 00053: val_accuracy improved from 0.98728 to 0.98897, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0531 - accuracy: 0.9812 - val_loss: 0.0343 - val_accuracy: 0.9890\n",
      "Epoch 54/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0528 - accuracy: 0.9817\n",
      "Epoch 00054: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0528 - accuracy: 0.9817 - val_loss: 0.0483 - val_accuracy: 0.9835\n",
      "Epoch 55/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0554 - accuracy: 0.9810\n",
      "Epoch 00055: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0554 - accuracy: 0.9809 - val_loss: 0.0381 - val_accuracy: 0.9881\n",
      "Epoch 56/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9824\n",
      "Epoch 00056: val_accuracy improved from 0.98897 to 0.99109, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0493 - accuracy: 0.9824 - val_loss: 0.0331 - val_accuracy: 0.9911\n",
      "Epoch 57/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9836\n",
      "Epoch 00057: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0467 - accuracy: 0.9836 - val_loss: 0.0447 - val_accuracy: 0.9869\n",
      "Epoch 58/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9831\n",
      "Epoch 00058: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 0.0368 - val_accuracy: 0.9885\n",
      "Epoch 59/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9836\n",
      "Epoch 00059: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0473 - accuracy: 0.9837 - val_loss: 0.0520 - val_accuracy: 0.9839\n",
      "Epoch 60/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0454 - accuracy: 0.9839\n",
      "Epoch 00060: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0453 - accuracy: 0.9839 - val_loss: 0.0471 - val_accuracy: 0.9835\n",
      "Epoch 61/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 0.9850\n",
      "Epoch 00061: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0441 - accuracy: 0.9851 - val_loss: 0.0333 - val_accuracy: 0.9898\n",
      "Epoch 62/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9844\n",
      "Epoch 00062: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0463 - accuracy: 0.9844 - val_loss: 0.0479 - val_accuracy: 0.9852\n",
      "Epoch 63/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9864\n",
      "Epoch 00063: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0400 - accuracy: 0.9864 - val_loss: 0.0371 - val_accuracy: 0.9898\n",
      "Epoch 64/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9835\n",
      "Epoch 00064: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0456 - accuracy: 0.9835 - val_loss: 0.0332 - val_accuracy: 0.9907\n",
      "Epoch 65/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0427 - accuracy: 0.9854\n",
      "Epoch 00065: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0426 - accuracy: 0.9854 - val_loss: 0.0402 - val_accuracy: 0.9881\n",
      "Epoch 66/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9851\n",
      "Epoch 00066: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0398 - accuracy: 0.9852 - val_loss: 0.0375 - val_accuracy: 0.9894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9859\n",
      "Epoch 00067: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0413 - accuracy: 0.9859 - val_loss: 0.0658 - val_accuracy: 0.9754\n",
      "Epoch 68/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9871\n",
      "Epoch 00068: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 14s 22ms/step - loss: 0.0379 - accuracy: 0.9870 - val_loss: 0.0411 - val_accuracy: 0.9860\n",
      "Epoch 69/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9880\n",
      "Epoch 00069: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 14s 22ms/step - loss: 0.0349 - accuracy: 0.9880 - val_loss: 0.0388 - val_accuracy: 0.9885\n",
      "Epoch 70/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9876\n",
      "Epoch 00070: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0367 - accuracy: 0.9876 - val_loss: 0.0467 - val_accuracy: 0.9839\n",
      "Epoch 71/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9878\n",
      "Epoch 00071: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0374 - accuracy: 0.9879 - val_loss: 0.0368 - val_accuracy: 0.9881\n",
      "Epoch 72/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.9862\n",
      "Epoch 00072: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0376 - accuracy: 0.9862 - val_loss: 0.0370 - val_accuracy: 0.9873\n",
      "Epoch 73/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9878\n",
      "Epoch 00073: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0351 - accuracy: 0.9877 - val_loss: 0.0305 - val_accuracy: 0.9890\n",
      "Epoch 74/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9904\n",
      "Epoch 00074: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.0347 - val_accuracy: 0.9894\n",
      "Epoch 75/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0364 - accuracy: 0.9868\n",
      "Epoch 00075: val_accuracy improved from 0.99109 to 0.99152, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0366 - accuracy: 0.9867 - val_loss: 0.0280 - val_accuracy: 0.9915\n",
      "Epoch 76/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9883\n",
      "Epoch 00076: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 14s 22ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 0.0281 - val_accuracy: 0.9915\n",
      "Epoch 77/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9883\n",
      "Epoch 00077: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0343 - accuracy: 0.9883 - val_loss: 0.0379 - val_accuracy: 0.9877\n",
      "Epoch 78/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9878\n",
      "Epoch 00078: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.0382 - val_accuracy: 0.9885\n",
      "Epoch 79/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9884\n",
      "Epoch 00079: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0329 - accuracy: 0.9884 - val_loss: 0.0294 - val_accuracy: 0.9898\n",
      "Epoch 80/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.9889\n",
      "Epoch 00080: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0320 - accuracy: 0.9889 - val_loss: 0.0241 - val_accuracy: 0.9915\n",
      "Epoch 81/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9889\n",
      "Epoch 00081: val_accuracy improved from 0.99152 to 0.99194, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0323 - accuracy: 0.9889 - val_loss: 0.0245 - val_accuracy: 0.9919\n",
      "Epoch 82/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9896\n",
      "Epoch 00082: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0288 - accuracy: 0.9896 - val_loss: 0.0380 - val_accuracy: 0.9864\n",
      "Epoch 83/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9899\n",
      "Epoch 00083: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0319 - accuracy: 0.9899 - val_loss: 0.0288 - val_accuracy: 0.9907\n",
      "Epoch 84/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9896\n",
      "Epoch 00084: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0302 - accuracy: 0.9895 - val_loss: 0.0409 - val_accuracy: 0.9860\n",
      "Epoch 85/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 0.9894\n",
      "Epoch 00085: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0296 - accuracy: 0.9893 - val_loss: 0.0398 - val_accuracy: 0.9881\n",
      "Epoch 86/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9892\n",
      "Epoch 00086: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 14s 22ms/step - loss: 0.0295 - accuracy: 0.9892 - val_loss: 0.0288 - val_accuracy: 0.9894\n",
      "Epoch 87/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9902\n",
      "Epoch 00087: val_accuracy improved from 0.99194 to 0.99237, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.0274 - val_accuracy: 0.9924\n",
      "Epoch 88/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9902\n",
      "Epoch 00088: val_accuracy did not improve from 0.99237\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0265 - accuracy: 0.9902 - val_loss: 0.0294 - val_accuracy: 0.9915\n",
      "Epoch 89/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9899\n",
      "Epoch 00089: val_accuracy did not improve from 0.99237\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0282 - accuracy: 0.9899 - val_loss: 0.0280 - val_accuracy: 0.9898\n",
      "Epoch 90/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9903\n",
      "Epoch 00090: val_accuracy did not improve from 0.99237\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 0.0461 - val_accuracy: 0.9864\n",
      "Epoch 91/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9908\n",
      "Epoch 00091: val_accuracy did not improve from 0.99237\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.0293 - val_accuracy: 0.9898\n",
      "Epoch 92/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9904\n",
      "Epoch 00092: val_accuracy did not improve from 0.99237\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0286 - accuracy: 0.9903 - val_loss: 0.0328 - val_accuracy: 0.9898\n",
      "Epoch 93/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9919\n",
      "Epoch 00093: val_accuracy did not improve from 0.99237\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0381 - val_accuracy: 0.9864\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661/663 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9901\n",
      "Epoch 00094: val_accuracy improved from 0.99237 to 0.99279, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0273 - accuracy: 0.9901 - val_loss: 0.0282 - val_accuracy: 0.9928\n",
      "Epoch 95/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9902\n",
      "Epoch 00095: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0276 - accuracy: 0.9902 - val_loss: 0.0249 - val_accuracy: 0.9924\n",
      "Epoch 96/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9908\n",
      "Epoch 00096: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0255 - accuracy: 0.9908 - val_loss: 0.0654 - val_accuracy: 0.9792\n",
      "Epoch 97/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9907\n",
      "Epoch 00097: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0345 - val_accuracy: 0.9885\n",
      "Epoch 98/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.9923\n",
      "Epoch 00098: val_accuracy improved from 0.99279 to 0.99364, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.0214 - val_accuracy: 0.9936\n",
      "Epoch 99/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9917\n",
      "Epoch 00099: val_accuracy did not improve from 0.99364\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.0212 - val_accuracy: 0.9932\n",
      "Epoch 100/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9922\n",
      "Epoch 00100: val_accuracy did not improve from 0.99364\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.0297 - val_accuracy: 0.9885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [24:23<24:23, 1463.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.78      0.92      0.84       576\n",
      "        car_horn       0.93      0.80      0.86       252\n",
      "children_playing       0.87      0.89      0.88       600\n",
      "        dog_bark       0.91      0.91      0.91       600\n",
      "           siren       0.96      0.79      0.87       546\n",
      "\n",
      "        accuracy                           0.87      2574\n",
      "       macro avg       0.89      0.86      0.87      2574\n",
      "    weighted avg       0.88      0.87      0.87      2574\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_6\n",
      "Epoch 1/100\n",
      "  2/663 [..............................] - ETA: 19s - loss: 2.4419 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0040s vs `on_train_batch_end` time: 0.0548s). Check your callbacks.\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.9050 - accuracy: 0.6623\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76081, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.9050 - accuracy: 0.6623 - val_loss: 0.6431 - val_accuracy: 0.7608\n",
      "Epoch 2/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.5370 - accuracy: 0.8138\n",
      "Epoch 00002: val_accuracy improved from 0.76081 to 0.77311, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.5370 - accuracy: 0.8138 - val_loss: 0.6772 - val_accuracy: 0.7731\n",
      "Epoch 3/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.4093 - accuracy: 0.8596\n",
      "Epoch 00003: val_accuracy improved from 0.77311 to 0.89822, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.4093 - accuracy: 0.8596 - val_loss: 0.2938 - val_accuracy: 0.8982\n",
      "Epoch 4/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.8889\n",
      "Epoch 00004: val_accuracy did not improve from 0.89822\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.3148 - accuracy: 0.8889 - val_loss: 0.3539 - val_accuracy: 0.8757\n",
      "Epoch 5/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.9097\n",
      "Epoch 00005: val_accuracy did not improve from 0.89822\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.2611 - accuracy: 0.9097 - val_loss: 0.6664 - val_accuracy: 0.8126\n",
      "Epoch 6/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.9262\n",
      "Epoch 00006: val_accuracy did not improve from 0.89822\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.2154 - accuracy: 0.9262 - val_loss: 0.3883 - val_accuracy: 0.8685\n",
      "Epoch 7/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.9398\n",
      "Epoch 00007: val_accuracy improved from 0.89822 to 0.95038, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.1785 - accuracy: 0.9398 - val_loss: 0.1401 - val_accuracy: 0.9504\n",
      "Epoch 8/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9460\n",
      "Epoch 00008: val_accuracy did not improve from 0.95038\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.1557 - accuracy: 0.9460 - val_loss: 0.2771 - val_accuracy: 0.9037\n",
      "Epoch 9/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9581\n",
      "Epoch 00009: val_accuracy did not improve from 0.95038\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.1269 - accuracy: 0.9581 - val_loss: 0.2098 - val_accuracy: 0.9300\n",
      "Epoch 10/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1158 - accuracy: 0.9615\n",
      "Epoch 00010: val_accuracy did not improve from 0.95038\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.1158 - accuracy: 0.9615 - val_loss: 0.3369 - val_accuracy: 0.8893\n",
      "Epoch 11/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9676\n",
      "Epoch 00011: val_accuracy improved from 0.95038 to 0.95335, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0953 - accuracy: 0.9676 - val_loss: 0.1508 - val_accuracy: 0.9534\n",
      "Epoch 12/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9686\n",
      "Epoch 00012: val_accuracy did not improve from 0.95335\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0909 - accuracy: 0.9686 - val_loss: 1.1129 - val_accuracy: 0.7897\n",
      "Epoch 13/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9730\n",
      "Epoch 00013: val_accuracy did not improve from 0.95335\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0823 - accuracy: 0.9730 - val_loss: 0.2177 - val_accuracy: 0.9406\n",
      "Epoch 14/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.9759\n",
      "Epoch 00014: val_accuracy improved from 0.95335 to 0.97583, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0716 - accuracy: 0.9759 - val_loss: 0.0620 - val_accuracy: 0.9758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9815\n",
      "Epoch 00015: val_accuracy did not improve from 0.97583\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0544 - accuracy: 0.9815 - val_loss: 0.0832 - val_accuracy: 0.9737\n",
      "Epoch 16/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9825\n",
      "Epoch 00016: val_accuracy did not improve from 0.97583\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0549 - accuracy: 0.9825 - val_loss: 0.0980 - val_accuracy: 0.9699\n",
      "Epoch 17/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9833\n",
      "Epoch 00017: val_accuracy did not improve from 0.97583\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0496 - accuracy: 0.9833 - val_loss: 0.1420 - val_accuracy: 0.9589\n",
      "Epoch 18/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9835\n",
      "Epoch 00018: val_accuracy improved from 0.97583 to 0.97837, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0515 - accuracy: 0.9835 - val_loss: 0.0722 - val_accuracy: 0.9784\n",
      "Epoch 19/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9866\n",
      "Epoch 00019: val_accuracy did not improve from 0.97837\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 0.0917 - val_accuracy: 0.9724\n",
      "Epoch 20/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9874\n",
      "Epoch 00020: val_accuracy did not improve from 0.97837\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0409 - accuracy: 0.9874 - val_loss: 0.0798 - val_accuracy: 0.9763\n",
      "Epoch 21/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9894\n",
      "Epoch 00021: val_accuracy improved from 0.97837 to 0.97964, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0324 - accuracy: 0.9894 - val_loss: 0.0649 - val_accuracy: 0.9796\n",
      "Epoch 22/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9914\n",
      "Epoch 00022: val_accuracy improved from 0.97964 to 0.98388, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 0.0429 - val_accuracy: 0.9839\n",
      "Epoch 23/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9897\n",
      "Epoch 00023: val_accuracy did not improve from 0.98388\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0327 - accuracy: 0.9897 - val_loss: 0.0805 - val_accuracy: 0.9746\n",
      "Epoch 24/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9927\n",
      "Epoch 00024: val_accuracy did not improve from 0.98388\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.0748 - val_accuracy: 0.9796\n",
      "Epoch 25/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9924\n",
      "Epoch 00025: val_accuracy did not improve from 0.98388\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0541 - val_accuracy: 0.9835\n",
      "Epoch 26/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9919\n",
      "Epoch 00026: val_accuracy did not improve from 0.98388\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 0.0732 - val_accuracy: 0.9822\n",
      "Epoch 27/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9917\n",
      "Epoch 00027: val_accuracy did not improve from 0.98388\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.0940 - val_accuracy: 0.9750\n",
      "Epoch 28/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9926\n",
      "Epoch 00028: val_accuracy did not improve from 0.98388\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.0850 - val_accuracy: 0.9801\n",
      "Epoch 29/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9931\n",
      "Epoch 00029: val_accuracy improved from 0.98388 to 0.98473, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.0610 - val_accuracy: 0.9847\n",
      "Epoch 30/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9929\n",
      "Epoch 00030: val_accuracy did not improve from 0.98473\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.2120 - val_accuracy: 0.9474\n",
      "Epoch 31/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9942\n",
      "Epoch 00031: val_accuracy improved from 0.98473 to 0.98516, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0547 - val_accuracy: 0.9852\n",
      "Epoch 32/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9942\n",
      "Epoch 00032: val_accuracy did not improve from 0.98516\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.1153 - val_accuracy: 0.9669\n",
      "Epoch 33/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9939\n",
      "Epoch 00033: val_accuracy did not improve from 0.98516\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0657 - val_accuracy: 0.9818\n",
      "Epoch 34/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9932\n",
      "Epoch 00034: val_accuracy did not improve from 0.98516\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.1637 - val_accuracy: 0.9640\n",
      "Epoch 35/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9959\n",
      "Epoch 00035: val_accuracy did not improve from 0.98516\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0983 - val_accuracy: 0.9792\n",
      "Epoch 36/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9957\n",
      "Epoch 00036: val_accuracy did not improve from 0.98516\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.1146 - val_accuracy: 0.9746\n",
      "Epoch 37/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9970\n",
      "Epoch 00037: val_accuracy improved from 0.98516 to 0.98601, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0774 - val_accuracy: 0.9860\n",
      "Epoch 38/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9968\n",
      "Epoch 00038: val_accuracy did not improve from 0.98601\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.0836 - val_accuracy: 0.9813\n",
      "Epoch 39/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9948\n",
      "Epoch 00039: val_accuracy did not improve from 0.98601\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.0837 - val_accuracy: 0.9796\n",
      "Epoch 40/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9940\n",
      "Epoch 00040: val_accuracy did not improve from 0.98601\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.0624 - val_accuracy: 0.9860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9966\n",
      "Epoch 00041: val_accuracy improved from 0.98601 to 0.98855, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0497 - val_accuracy: 0.9885\n",
      "Epoch 42/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9971\n",
      "Epoch 00042: val_accuracy improved from 0.98855 to 0.98897, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.0536 - val_accuracy: 0.9890\n",
      "Epoch 43/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9953\n",
      "Epoch 00043: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0695 - val_accuracy: 0.9856\n",
      "Epoch 44/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9970\n",
      "Epoch 00044: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0588 - val_accuracy: 0.9873\n",
      "Epoch 45/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9960\n",
      "Epoch 00045: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0468 - val_accuracy: 0.9869\n",
      "Epoch 46/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 00046: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.0500 - val_accuracy: 0.9877\n",
      "Epoch 47/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9959\n",
      "Epoch 00047: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0747 - val_accuracy: 0.9830\n",
      "Epoch 48/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9964\n",
      "Epoch 00048: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0709 - val_accuracy: 0.9843\n",
      "Epoch 49/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9951\n",
      "Epoch 00049: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.0753 - val_accuracy: 0.9801\n",
      "Epoch 50/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9970\n",
      "Epoch 00050: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0825 - val_accuracy: 0.9818\n",
      "Epoch 51/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 00051: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.1011 - val_accuracy: 0.9775\n",
      "Epoch 52/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9973\n",
      "Epoch 00052: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.1867 - val_accuracy: 0.9606\n",
      "Epoch 53/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9957\n",
      "Epoch 00053: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0433 - val_accuracy: 0.9890\n",
      "Epoch 54/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9978\n",
      "Epoch 00054: val_accuracy improved from 0.98897 to 0.98940, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0415 - val_accuracy: 0.9894\n",
      "Epoch 55/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9981\n",
      "Epoch 00055: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0600 - val_accuracy: 0.9860\n",
      "Epoch 56/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 00056: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0541 - val_accuracy: 0.9864\n",
      "Epoch 57/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9978\n",
      "Epoch 00057: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0565 - val_accuracy: 0.9860\n",
      "Epoch 58/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9973\n",
      "Epoch 00058: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0556 - val_accuracy: 0.9885\n",
      "Epoch 59/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9976\n",
      "Epoch 00059: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0618 - val_accuracy: 0.9869\n",
      "Epoch 60/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9975\n",
      "Epoch 00060: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0569 - val_accuracy: 0.9864\n",
      "Epoch 61/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 00061: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0569 - val_accuracy: 0.9881\n",
      "Epoch 62/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 00062: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0514 - val_accuracy: 0.9894\n",
      "Epoch 63/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 00063: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0884 - val_accuracy: 0.9822\n",
      "Epoch 64/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 00064: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0516 - val_accuracy: 0.9860\n",
      "Epoch 65/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch 00065: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0564 - val_accuracy: 0.9843\n",
      "Epoch 66/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9985\n",
      "Epoch 00066: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0408 - val_accuracy: 0.9881\n",
      "Epoch 67/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 00067: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0557 - val_accuracy: 0.9856\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663/663 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9990\n",
      "Epoch 00068: val_accuracy improved from 0.98940 to 0.99152, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0429 - val_accuracy: 0.9915\n",
      "Epoch 69/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982\n",
      "Epoch 00069: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0988 - val_accuracy: 0.9796\n",
      "Epoch 70/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9978\n",
      "Epoch 00070: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.0717 - val_accuracy: 0.9852\n",
      "Epoch 71/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9983\n",
      "Epoch 00071: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0588 - val_accuracy: 0.9852\n",
      "Epoch 72/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9982\n",
      "Epoch 00072: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0539 - val_accuracy: 0.9860\n",
      "Epoch 73/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 00073: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0623 - val_accuracy: 0.9869\n",
      "Epoch 74/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 00074: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
      "Epoch 75/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 00075: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 0.0820 - val_accuracy: 0.9826\n",
      "Epoch 76/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 00076: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0452 - val_accuracy: 0.9885\n",
      "Epoch 77/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 00077: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0616 - val_accuracy: 0.9894\n",
      "Epoch 78/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 00078: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0635 - val_accuracy: 0.9877\n",
      "Epoch 79/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 00079: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0439 - val_accuracy: 0.9907\n",
      "Epoch 80/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00080: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0466 - val_accuracy: 0.9877\n",
      "Epoch 81/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9988\n",
      "Epoch 00081: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0479 - val_accuracy: 0.9860\n",
      "Epoch 82/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 00082: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0472 - val_accuracy: 0.9864\n",
      "Epoch 83/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00083: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 61ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0699 - val_accuracy: 0.9852\n",
      "Epoch 84/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 00084: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1095 - val_accuracy: 0.9809\n",
      "Epoch 85/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 00085: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0404 - val_accuracy: 0.9907\n",
      "Epoch 86/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00086: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0539 - val_accuracy: 0.9885\n",
      "Epoch 87/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 00087: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0466 - val_accuracy: 0.9885\n",
      "Epoch 88/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 00088: val_accuracy did not improve from 0.99152\n",
      "Restoring model weights from the end of the best epoch.\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0536 - val_accuracy: 0.9881\n",
      "Epoch 00088: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:24:38<00:00, 2539.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.91      0.88      0.89       576\n",
      "        car_horn       0.84      0.78      0.81       252\n",
      "children_playing       0.83      0.95      0.89       600\n",
      "        dog_bark       0.93      0.95      0.94       600\n",
      "           siren       1.00      0.89      0.94       546\n",
      "\n",
      "        accuracy                           0.90      2574\n",
      "       macro avg       0.90      0.89      0.89      2574\n",
      "    weighted avg       0.91      0.90      0.90      2574\n",
      "\n",
      "\n",
      "Validation fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (20930, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (20930, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2326, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2326, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2892, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2892, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_7\n",
      "Epoch 1/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 1.1723 - accuracy: 0.6122\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73431, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 23ms/step - loss: 1.1723 - accuracy: 0.6122 - val_loss: 0.7568 - val_accuracy: 0.7343\n",
      "Epoch 2/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.7315 - accuracy: 0.7369\n",
      "Epoch 00002: val_accuracy improved from 0.73431 to 0.81126, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.7315 - accuracy: 0.7369 - val_loss: 0.5454 - val_accuracy: 0.8113\n",
      "Epoch 3/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.7781\n",
      "Epoch 00003: val_accuracy improved from 0.81126 to 0.84996, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.6173 - accuracy: 0.7785 - val_loss: 0.4158 - val_accuracy: 0.8500\n",
      "Epoch 4/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.8084\n",
      "Epoch 00004: val_accuracy did not improve from 0.84996\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.5312 - accuracy: 0.8084 - val_loss: 0.4500 - val_accuracy: 0.8353\n",
      "Epoch 5/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.5081 - accuracy: 0.8160\n",
      "Epoch 00005: val_accuracy did not improve from 0.84996\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.5075 - accuracy: 0.8161 - val_loss: 0.5080 - val_accuracy: 0.8121\n",
      "Epoch 6/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.8413\n",
      "Epoch 00006: val_accuracy did not improve from 0.84996\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.4316 - accuracy: 0.8413 - val_loss: 0.4500 - val_accuracy: 0.8285\n",
      "Epoch 7/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.8563\n",
      "Epoch 00007: val_accuracy improved from 0.84996 to 0.85082, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.3914 - accuracy: 0.8563 - val_loss: 0.4203 - val_accuracy: 0.8508\n",
      "Epoch 8/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.8724\n",
      "Epoch 00008: val_accuracy improved from 0.85082 to 0.90843, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.3511 - accuracy: 0.8724 - val_loss: 0.2514 - val_accuracy: 0.9084\n",
      "Epoch 9/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.8812\n",
      "Epoch 00009: val_accuracy improved from 0.90843 to 0.91788, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.3330 - accuracy: 0.8813 - val_loss: 0.2110 - val_accuracy: 0.9179\n",
      "Epoch 10/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.8904\n",
      "Epoch 00010: val_accuracy did not improve from 0.91788\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.3064 - accuracy: 0.8904 - val_loss: 0.4517 - val_accuracy: 0.8362\n",
      "Epoch 11/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.2917 - accuracy: 0.8919\n",
      "Epoch 00011: val_accuracy did not improve from 0.91788\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.2917 - accuracy: 0.8919 - val_loss: 0.2010 - val_accuracy: 0.9175\n",
      "Epoch 12/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.2626 - accuracy: 0.9028\n",
      "Epoch 00012: val_accuracy did not improve from 0.91788\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.2629 - accuracy: 0.9027 - val_loss: 0.2678 - val_accuracy: 0.9127\n",
      "Epoch 13/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.9102\n",
      "Epoch 00013: val_accuracy did not improve from 0.91788\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.2460 - accuracy: 0.9102 - val_loss: 0.2167 - val_accuracy: 0.9170\n",
      "Epoch 14/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.9105\n",
      "Epoch 00014: val_accuracy improved from 0.91788 to 0.93981, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.2390 - accuracy: 0.9105 - val_loss: 0.1535 - val_accuracy: 0.9398\n",
      "Epoch 15/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.9212\n",
      "Epoch 00015: val_accuracy improved from 0.93981 to 0.95099, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.2177 - accuracy: 0.9212 - val_loss: 0.1387 - val_accuracy: 0.9510\n",
      "Epoch 16/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.1963 - accuracy: 0.9292\n",
      "Epoch 00016: val_accuracy did not improve from 0.95099\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1963 - accuracy: 0.9292 - val_loss: 0.1271 - val_accuracy: 0.9497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.1919 - accuracy: 0.9301\n",
      "Epoch 00017: val_accuracy did not improve from 0.95099\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1918 - accuracy: 0.9302 - val_loss: 0.1572 - val_accuracy: 0.9411\n",
      "Epoch 18/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.1840 - accuracy: 0.9336\n",
      "Epoch 00018: val_accuracy improved from 0.95099 to 0.96733, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1839 - accuracy: 0.9335 - val_loss: 0.0976 - val_accuracy: 0.9673\n",
      "Epoch 19/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 0.9379\n",
      "Epoch 00019: val_accuracy did not improve from 0.96733\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1681 - accuracy: 0.9379 - val_loss: 0.1472 - val_accuracy: 0.9475\n",
      "Epoch 20/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.9358\n",
      "Epoch 00020: val_accuracy improved from 0.96733 to 0.96819, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1745 - accuracy: 0.9358 - val_loss: 0.0846 - val_accuracy: 0.9682\n",
      "Epoch 21/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1556 - accuracy: 0.9438\n",
      "Epoch 00021: val_accuracy did not improve from 0.96819\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1556 - accuracy: 0.9438 - val_loss: 0.1863 - val_accuracy: 0.9347\n",
      "Epoch 22/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9467\n",
      "Epoch 00022: val_accuracy did not improve from 0.96819\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1510 - accuracy: 0.9465 - val_loss: 0.2663 - val_accuracy: 0.9175\n",
      "Epoch 23/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9495\n",
      "Epoch 00023: val_accuracy did not improve from 0.96819\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1466 - accuracy: 0.9495 - val_loss: 0.1093 - val_accuracy: 0.9596\n",
      "Epoch 24/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.9502\n",
      "Epoch 00024: val_accuracy improved from 0.96819 to 0.96991, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1361 - accuracy: 0.9503 - val_loss: 0.0820 - val_accuracy: 0.9699\n",
      "Epoch 25/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9519\n",
      "Epoch 00025: val_accuracy improved from 0.96991 to 0.97377, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1294 - accuracy: 0.9519 - val_loss: 0.0692 - val_accuracy: 0.9738\n",
      "Epoch 26/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9556\n",
      "Epoch 00026: val_accuracy did not improve from 0.97377\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.1226 - accuracy: 0.9556 - val_loss: 0.1391 - val_accuracy: 0.9523\n",
      "Epoch 27/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9575\n",
      "Epoch 00027: val_accuracy improved from 0.97377 to 0.97678, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1127 - accuracy: 0.9575 - val_loss: 0.0613 - val_accuracy: 0.9768\n",
      "Epoch 28/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9566\n",
      "Epoch 00028: val_accuracy improved from 0.97678 to 0.97807, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1195 - accuracy: 0.9566 - val_loss: 0.0606 - val_accuracy: 0.9781\n",
      "Epoch 29/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.9613\n",
      "Epoch 00029: val_accuracy did not improve from 0.97807\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.1092 - accuracy: 0.9613 - val_loss: 0.0702 - val_accuracy: 0.9725\n",
      "Epoch 30/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9625\n",
      "Epoch 00030: val_accuracy improved from 0.97807 to 0.97893, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1041 - accuracy: 0.9625 - val_loss: 0.0633 - val_accuracy: 0.9789\n",
      "Epoch 31/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9634\n",
      "Epoch 00031: val_accuracy improved from 0.97893 to 0.98022, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1007 - accuracy: 0.9634 - val_loss: 0.0577 - val_accuracy: 0.9802\n",
      "Epoch 32/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9623\n",
      "Epoch 00032: val_accuracy did not improve from 0.98022\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1035 - accuracy: 0.9623 - val_loss: 0.0514 - val_accuracy: 0.9802\n",
      "Epoch 33/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9661\n",
      "Epoch 00033: val_accuracy did not improve from 0.98022\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.0951 - accuracy: 0.9661 - val_loss: 0.0653 - val_accuracy: 0.9759\n",
      "Epoch 34/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0910 - accuracy: 0.9675\n",
      "Epoch 00034: val_accuracy did not improve from 0.98022\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0908 - accuracy: 0.9675 - val_loss: 0.0578 - val_accuracy: 0.9785\n",
      "Epoch 35/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9700\n",
      "Epoch 00035: val_accuracy improved from 0.98022 to 0.98280, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0841 - accuracy: 0.9700 - val_loss: 0.0492 - val_accuracy: 0.9828\n",
      "Epoch 36/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9690\n",
      "Epoch 00036: val_accuracy did not improve from 0.98280\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0863 - accuracy: 0.9690 - val_loss: 0.0597 - val_accuracy: 0.9785\n",
      "Epoch 37/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0841 - accuracy: 0.9704\n",
      "Epoch 00037: val_accuracy did not improve from 0.98280\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.0842 - accuracy: 0.9703 - val_loss: 0.0609 - val_accuracy: 0.9768\n",
      "Epoch 38/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0766 - accuracy: 0.9727\n",
      "Epoch 00038: val_accuracy improved from 0.98280 to 0.98495, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0766 - accuracy: 0.9727 - val_loss: 0.0447 - val_accuracy: 0.9850\n",
      "Epoch 39/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9736\n",
      "Epoch 00039: val_accuracy did not improve from 0.98495\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0749 - accuracy: 0.9736 - val_loss: 0.1395 - val_accuracy: 0.9557\n",
      "Epoch 40/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0855 - accuracy: 0.9703\n",
      "Epoch 00040: val_accuracy did not improve from 0.98495\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0853 - accuracy: 0.9704 - val_loss: 0.0474 - val_accuracy: 0.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9750\n",
      "Epoch 00041: val_accuracy did not improve from 0.98495\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.0735 - accuracy: 0.9750 - val_loss: 0.2209 - val_accuracy: 0.9338\n",
      "Epoch 42/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9684\n",
      "Epoch 00042: val_accuracy improved from 0.98495 to 0.98538, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0923 - accuracy: 0.9684 - val_loss: 0.0406 - val_accuracy: 0.9854\n",
      "Epoch 43/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9737\n",
      "Epoch 00043: val_accuracy improved from 0.98538 to 0.98624, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0723 - accuracy: 0.9737 - val_loss: 0.0459 - val_accuracy: 0.9862\n",
      "Epoch 44/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9752\n",
      "Epoch 00044: val_accuracy improved from 0.98624 to 0.98667, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0686 - accuracy: 0.9752 - val_loss: 0.0465 - val_accuracy: 0.9867\n",
      "Epoch 45/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9774\n",
      "Epoch 00045: val_accuracy did not improve from 0.98667\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.0651 - accuracy: 0.9774 - val_loss: 0.0651 - val_accuracy: 0.9785\n",
      "Epoch 46/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9770\n",
      "Epoch 00046: val_accuracy did not improve from 0.98667\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.0667 - accuracy: 0.9770 - val_loss: 0.0805 - val_accuracy: 0.9742\n",
      "Epoch 47/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9785\n",
      "Epoch 00047: val_accuracy did not improve from 0.98667\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0643 - accuracy: 0.9785 - val_loss: 0.0423 - val_accuracy: 0.9862\n",
      "Epoch 48/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9780\n",
      "Epoch 00048: val_accuracy did not improve from 0.98667\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0625 - accuracy: 0.9780 - val_loss: 0.0388 - val_accuracy: 0.9862\n",
      "Epoch 49/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9808\n",
      "Epoch 00049: val_accuracy did not improve from 0.98667\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0559 - accuracy: 0.9808 - val_loss: 0.0474 - val_accuracy: 0.9828\n",
      "Epoch 50/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0572 - accuracy: 0.9802\n",
      "Epoch 00050: val_accuracy improved from 0.98667 to 0.98968, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0572 - accuracy: 0.9802 - val_loss: 0.0290 - val_accuracy: 0.9897\n",
      "Epoch 51/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9810\n",
      "Epoch 00051: val_accuracy improved from 0.98968 to 0.99097, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0565 - accuracy: 0.9810 - val_loss: 0.0331 - val_accuracy: 0.9910\n",
      "Epoch 52/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0505 - accuracy: 0.9828\n",
      "Epoch 00052: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0504 - accuracy: 0.9828 - val_loss: 0.0318 - val_accuracy: 0.9897\n",
      "Epoch 53/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9811\n",
      "Epoch 00053: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0518 - accuracy: 0.9812 - val_loss: 0.0361 - val_accuracy: 0.9880\n",
      "Epoch 54/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9823\n",
      "Epoch 00054: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0514 - accuracy: 0.9823 - val_loss: 0.0447 - val_accuracy: 0.9828\n",
      "Epoch 55/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9834\n",
      "Epoch 00055: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0464 - accuracy: 0.9834 - val_loss: 0.0302 - val_accuracy: 0.9905\n",
      "Epoch 56/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9823\n",
      "Epoch 00056: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0511 - accuracy: 0.9823 - val_loss: 0.0329 - val_accuracy: 0.9884\n",
      "Epoch 57/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0532 - accuracy: 0.9819\n",
      "Epoch 00057: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0536 - accuracy: 0.9818 - val_loss: 0.0496 - val_accuracy: 0.9841\n",
      "Epoch 58/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9755\n",
      "Epoch 00058: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0680 - accuracy: 0.9755 - val_loss: 0.0347 - val_accuracy: 0.9875\n",
      "Epoch 59/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0530 - accuracy: 0.9813\n",
      "Epoch 00059: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0532 - accuracy: 0.9812 - val_loss: 0.0381 - val_accuracy: 0.9862\n",
      "Epoch 60/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9826\n",
      "Epoch 00060: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0501 - accuracy: 0.9827 - val_loss: 0.0369 - val_accuracy: 0.9884\n",
      "Epoch 61/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9844\n",
      "Epoch 00061: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0459 - accuracy: 0.9844 - val_loss: 0.0407 - val_accuracy: 0.9850\n",
      "Epoch 62/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9840\n",
      "Epoch 00062: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0469 - accuracy: 0.9840 - val_loss: 0.0536 - val_accuracy: 0.9832\n",
      "Epoch 63/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9828\n",
      "Epoch 00063: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0476 - accuracy: 0.9828 - val_loss: 0.1008 - val_accuracy: 0.9699\n",
      "Epoch 64/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9839\n",
      "Epoch 00064: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0428 - accuracy: 0.9839 - val_loss: 0.0450 - val_accuracy: 0.9867\n",
      "Epoch 65/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9849\n",
      "Epoch 00065: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0416 - accuracy: 0.9849 - val_loss: 0.0283 - val_accuracy: 0.9910\n",
      "Epoch 66/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9842\n",
      "Epoch 00066: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0442 - accuracy: 0.9842 - val_loss: 0.0271 - val_accuracy: 0.9910\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655/655 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9855\n",
      "Epoch 00067: val_accuracy improved from 0.99097 to 0.99140, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0411 - accuracy: 0.9855 - val_loss: 0.0253 - val_accuracy: 0.9914\n",
      "Epoch 68/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9847\n",
      "Epoch 00068: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0431 - accuracy: 0.9847 - val_loss: 0.0319 - val_accuracy: 0.9893\n",
      "Epoch 69/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9880\n",
      "Epoch 00069: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0368 - accuracy: 0.9881 - val_loss: 0.0361 - val_accuracy: 0.9884\n",
      "Epoch 70/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9860\n",
      "Epoch 00070: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0391 - accuracy: 0.9860 - val_loss: 0.0560 - val_accuracy: 0.9828\n",
      "Epoch 71/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9864\n",
      "Epoch 00071: val_accuracy improved from 0.99140 to 0.99312, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0356 - accuracy: 0.9864 - val_loss: 0.0228 - val_accuracy: 0.9931\n",
      "Epoch 72/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9882\n",
      "Epoch 00072: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 0.0210 - val_accuracy: 0.9931\n",
      "Epoch 73/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9879\n",
      "Epoch 00073: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0365 - accuracy: 0.9879 - val_loss: 0.0211 - val_accuracy: 0.9931\n",
      "Epoch 74/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9889\n",
      "Epoch 00074: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 0.0250 - val_accuracy: 0.9914\n",
      "Epoch 75/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9883\n",
      "Epoch 00075: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0339 - accuracy: 0.9883 - val_loss: 0.0316 - val_accuracy: 0.9875\n",
      "Epoch 76/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9896\n",
      "Epoch 00076: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.0309 - val_accuracy: 0.9910\n",
      "Epoch 77/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9879\n",
      "Epoch 00077: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0349 - accuracy: 0.9879 - val_loss: 0.0292 - val_accuracy: 0.9888\n",
      "Epoch 78/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9874\n",
      "Epoch 00078: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 0.0213 - val_accuracy: 0.9927\n",
      "Epoch 79/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9878\n",
      "Epoch 00079: val_accuracy improved from 0.99312 to 0.99484, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0339 - accuracy: 0.9878 - val_loss: 0.0202 - val_accuracy: 0.9948\n",
      "Epoch 80/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9899\n",
      "Epoch 00080: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.0165 - val_accuracy: 0.9944\n",
      "Epoch 81/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9890\n",
      "Epoch 00081: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.0203 - val_accuracy: 0.9936\n",
      "Epoch 82/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9900\n",
      "Epoch 00082: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.0209 - val_accuracy: 0.9931\n",
      "Epoch 83/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9888\n",
      "Epoch 00083: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0303 - accuracy: 0.9888 - val_loss: 0.0227 - val_accuracy: 0.9936\n",
      "Epoch 84/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9893\n",
      "Epoch 00084: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 0.0232 - val_accuracy: 0.9927\n",
      "Epoch 85/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9894\n",
      "Epoch 00085: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.0332 - val_accuracy: 0.9901\n",
      "Epoch 86/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9898\n",
      "Epoch 00086: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0306 - accuracy: 0.9898 - val_loss: 0.0307 - val_accuracy: 0.9918\n",
      "Epoch 87/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9899\n",
      "Epoch 00087: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0293 - accuracy: 0.9899 - val_loss: 0.0294 - val_accuracy: 0.9914\n",
      "Epoch 88/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9910\n",
      "Epoch 00088: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.0217 - val_accuracy: 0.9940\n",
      "Epoch 89/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9912\n",
      "Epoch 00089: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 0.0225 - val_accuracy: 0.9936\n",
      "Epoch 90/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9905\n",
      "Epoch 00090: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0263 - accuracy: 0.9905 - val_loss: 0.0225 - val_accuracy: 0.9940\n",
      "Epoch 91/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9910\n",
      "Epoch 00091: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0256 - accuracy: 0.9909 - val_loss: 0.0223 - val_accuracy: 0.9948\n",
      "Epoch 92/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9898\n",
      "Epoch 00092: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0302 - accuracy: 0.9898 - val_loss: 0.0577 - val_accuracy: 0.9858\n",
      "Epoch 93/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9902\n",
      "Epoch 00093: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0276 - accuracy: 0.9902 - val_loss: 0.0225 - val_accuracy: 0.9936\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655/655 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9917\n",
      "Epoch 00094: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.0241 - val_accuracy: 0.9914\n",
      "Epoch 95/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9913\n",
      "Epoch 00095: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0250 - accuracy: 0.9913 - val_loss: 0.0244 - val_accuracy: 0.9944\n",
      "Epoch 96/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9914\n",
      "Epoch 00096: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.0192 - val_accuracy: 0.9948\n",
      "Epoch 97/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9909\n",
      "Epoch 00097: val_accuracy improved from 0.99484 to 0.99527, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.0237 - val_accuracy: 0.9953\n",
      "Epoch 98/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9915\n",
      "Epoch 00098: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.0187 - val_accuracy: 0.9944\n",
      "Epoch 99/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9925\n",
      "Epoch 00099: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.0228 - val_accuracy: 0.9931\n",
      "Epoch 100/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9926\n",
      "Epoch 00100: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0192 - val_accuracy: 0.9953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [24:25<24:25, 1465.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.77      0.85      0.81       720\n",
      "        car_horn       0.76      1.00      0.86       258\n",
      "children_playing       0.89      0.89      0.89       600\n",
      "        dog_bark       0.90      0.83      0.86       600\n",
      "           siren       0.95      0.81      0.87       714\n",
      "\n",
      "        accuracy                           0.86      2892\n",
      "       macro avg       0.85      0.87      0.86      2892\n",
      "    weighted avg       0.86      0.86      0.86      2892\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_8\n",
      "Epoch 1/100\n",
      "  2/655 [..............................] - ETA: 19s - loss: 2.0967 - accuracy: 0.2656WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0209s vs `on_train_batch_end` time: 0.0390s). Check your callbacks.\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.9256 - accuracy: 0.6535\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73775, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.9256 - accuracy: 0.6535 - val_loss: 0.6589 - val_accuracy: 0.7377\n",
      "Epoch 2/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.8101\n",
      "Epoch 00002: val_accuracy improved from 0.73775 to 0.84351, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.5580 - accuracy: 0.8101 - val_loss: 0.4540 - val_accuracy: 0.8435\n",
      "Epoch 3/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.3949 - accuracy: 0.8659\n",
      "Epoch 00003: val_accuracy improved from 0.84351 to 0.86242, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.3951 - accuracy: 0.8658 - val_loss: 0.4197 - val_accuracy: 0.8624\n",
      "Epoch 4/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.3082 - accuracy: 0.8964\n",
      "Epoch 00004: val_accuracy improved from 0.86242 to 0.88822, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.3081 - accuracy: 0.8964 - val_loss: 0.3262 - val_accuracy: 0.8882\n",
      "Epoch 5/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.9216\n",
      "Epoch 00005: val_accuracy improved from 0.88822 to 0.91702, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.2358 - accuracy: 0.9215 - val_loss: 0.2431 - val_accuracy: 0.9170\n",
      "Epoch 6/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.9187\n",
      "Epoch 00006: val_accuracy did not improve from 0.91702\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.2416 - accuracy: 0.9186 - val_loss: 0.7839 - val_accuracy: 0.7605\n",
      "Epoch 7/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.2008 - accuracy: 0.9319\n",
      "Epoch 00007: val_accuracy improved from 0.91702 to 0.94798, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.2008 - accuracy: 0.9319 - val_loss: 0.1471 - val_accuracy: 0.9480\n",
      "Epoch 8/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1379 - accuracy: 0.9521\n",
      "Epoch 00008: val_accuracy did not improve from 0.94798\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.1381 - accuracy: 0.9521 - val_loss: 0.2681 - val_accuracy: 0.9153\n",
      "Epoch 9/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1297 - accuracy: 0.9559\n",
      "Epoch 00009: val_accuracy improved from 0.94798 to 0.96217, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.1297 - accuracy: 0.9559 - val_loss: 0.1123 - val_accuracy: 0.9622\n",
      "Epoch 10/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 0.9644\n",
      "Epoch 00010: val_accuracy did not improve from 0.96217\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.1081 - accuracy: 0.9645 - val_loss: 0.1136 - val_accuracy: 0.9596\n",
      "Epoch 11/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0872 - accuracy: 0.9695\n",
      "Epoch 00011: val_accuracy did not improve from 0.96217\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0872 - accuracy: 0.9695 - val_loss: 0.1523 - val_accuracy: 0.9501\n",
      "Epoch 12/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9744\n",
      "Epoch 00012: val_accuracy did not improve from 0.96217\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0755 - accuracy: 0.9744 - val_loss: 0.1393 - val_accuracy: 0.9531\n",
      "Epoch 13/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 0.9741\n",
      "Epoch 00013: val_accuracy improved from 0.96217 to 0.96389, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0749 - accuracy: 0.9742 - val_loss: 0.1096 - val_accuracy: 0.9639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 0.9812\n",
      "Epoch 00014: val_accuracy did not improve from 0.96389\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0567 - accuracy: 0.9812 - val_loss: 0.1470 - val_accuracy: 0.9570\n",
      "Epoch 15/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9818\n",
      "Epoch 00015: val_accuracy did not improve from 0.96389\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0536 - accuracy: 0.9818 - val_loss: 0.2255 - val_accuracy: 0.9372\n",
      "Epoch 16/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.9682\n",
      "Epoch 00016: val_accuracy improved from 0.96389 to 0.97206, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.1012 - accuracy: 0.9682 - val_loss: 0.0878 - val_accuracy: 0.9721\n",
      "Epoch 17/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.9836\n",
      "Epoch 00017: val_accuracy improved from 0.97206 to 0.97463, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0523 - accuracy: 0.9836 - val_loss: 0.0973 - val_accuracy: 0.9746\n",
      "Epoch 18/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0417 - accuracy: 0.9867\n",
      "Epoch 00018: val_accuracy did not improve from 0.97463\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0419 - accuracy: 0.9866 - val_loss: 0.1027 - val_accuracy: 0.9682\n",
      "Epoch 19/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 0.9688\n",
      "Epoch 00019: val_accuracy improved from 0.97463 to 0.98022, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0968 - accuracy: 0.9688 - val_loss: 0.0679 - val_accuracy: 0.9802\n",
      "Epoch 20/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9864\n",
      "Epoch 00020: val_accuracy improved from 0.98022 to 0.98495, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0422 - accuracy: 0.9864 - val_loss: 0.0542 - val_accuracy: 0.9850\n",
      "Epoch 21/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9875\n",
      "Epoch 00021: val_accuracy did not improve from 0.98495\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.6719 - val_accuracy: 0.8624\n",
      "Epoch 22/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1332 - accuracy: 0.9562\n",
      "Epoch 00022: val_accuracy did not improve from 0.98495\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.1332 - accuracy: 0.9562 - val_loss: 0.1315 - val_accuracy: 0.9669\n",
      "Epoch 23/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0487 - accuracy: 0.9830\n",
      "Epoch 00023: val_accuracy did not improve from 0.98495\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0487 - accuracy: 0.9830 - val_loss: 0.6522 - val_accuracy: 0.8551\n",
      "Epoch 24/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9881\n",
      "Epoch 00024: val_accuracy improved from 0.98495 to 0.98796, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0355 - accuracy: 0.9882 - val_loss: 0.0463 - val_accuracy: 0.9880\n",
      "Epoch 25/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9883\n",
      "Epoch 00025: val_accuracy did not improve from 0.98796\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0352 - accuracy: 0.9883 - val_loss: 0.0456 - val_accuracy: 0.9858\n",
      "Epoch 26/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9893\n",
      "Epoch 00026: val_accuracy did not improve from 0.98796\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.0821 - val_accuracy: 0.9802\n",
      "Epoch 27/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9936\n",
      "Epoch 00027: val_accuracy did not improve from 0.98796\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.0627 - val_accuracy: 0.9815\n",
      "Epoch 28/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9921\n",
      "Epoch 00028: val_accuracy improved from 0.98796 to 0.98925, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 0.0409 - val_accuracy: 0.9893\n",
      "Epoch 29/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9945\n",
      "Epoch 00029: val_accuracy did not improve from 0.98925\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.0553 - val_accuracy: 0.9845\n",
      "Epoch 30/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9946\n",
      "Epoch 00030: val_accuracy did not improve from 0.98925\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.0616 - val_accuracy: 0.9850\n",
      "Epoch 31/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9925\n",
      "Epoch 00031: val_accuracy improved from 0.98925 to 0.98968, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.0416 - val_accuracy: 0.9897\n",
      "Epoch 32/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9950\n",
      "Epoch 00032: val_accuracy did not improve from 0.98968\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.0502 - val_accuracy: 0.9854\n",
      "Epoch 33/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9948\n",
      "Epoch 00033: val_accuracy did not improve from 0.98968\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0659 - val_accuracy: 0.9858\n",
      "Epoch 34/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9953\n",
      "Epoch 00034: val_accuracy improved from 0.98968 to 0.99011, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.0451 - val_accuracy: 0.9901\n",
      "Epoch 35/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9962\n",
      "Epoch 00035: val_accuracy did not improve from 0.99011\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.1212 - val_accuracy: 0.9729\n",
      "Epoch 36/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9953\n",
      "Epoch 00036: val_accuracy did not improve from 0.99011\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.0898 - val_accuracy: 0.9789\n",
      "Epoch 37/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9945\n",
      "Epoch 00037: val_accuracy improved from 0.99011 to 0.99140, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.0349 - val_accuracy: 0.9914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9964\n",
      "Epoch 00038: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1030 - val_accuracy: 0.9772\n",
      "Epoch 39/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9920\n",
      "Epoch 00039: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0266 - accuracy: 0.9920 - val_loss: 0.0863 - val_accuracy: 0.9824\n",
      "Epoch 40/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9952\n",
      "Epoch 00040: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0642 - val_accuracy: 0.9858\n",
      "Epoch 41/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9968\n",
      "Epoch 00041: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0439 - val_accuracy: 0.9893\n",
      "Epoch 42/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0674 - accuracy: 0.9794\n",
      "Epoch 00042: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0674 - accuracy: 0.9794 - val_loss: 0.0626 - val_accuracy: 0.9841\n",
      "Epoch 43/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9931\n",
      "Epoch 00043: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.0411 - val_accuracy: 0.9897\n",
      "Epoch 44/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9950\n",
      "Epoch 00044: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.0732 - val_accuracy: 0.9828\n",
      "Epoch 45/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9958\n",
      "Epoch 00045: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.1534 - val_accuracy: 0.9652\n",
      "Epoch 46/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1015 - accuracy: 0.9693\n",
      "Epoch 00046: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.1015 - accuracy: 0.9693 - val_loss: 0.0626 - val_accuracy: 0.9794\n",
      "Epoch 47/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9912\n",
      "Epoch 00047: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 48/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9939\n",
      "Epoch 00048: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.0553 - val_accuracy: 0.9858\n",
      "Epoch 49/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9958\n",
      "Epoch 00049: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0443 - val_accuracy: 0.9893\n",
      "Epoch 50/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 00050: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0424 - val_accuracy: 0.9893\n",
      "Epoch 51/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9959\n",
      "Epoch 00051: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.1779 - val_accuracy: 0.9643\n",
      "Epoch 52/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9957\n",
      "Epoch 00052: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.0389 - val_accuracy: 0.9893\n",
      "Epoch 53/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9964\n",
      "Epoch 00053: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0406 - val_accuracy: 0.9897\n",
      "Epoch 54/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9971\n",
      "Epoch 00054: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0416 - val_accuracy: 0.9893\n",
      "Epoch 55/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9974\n",
      "Epoch 00055: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0583 - val_accuracy: 0.9884\n",
      "Epoch 56/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 00056: val_accuracy improved from 0.99140 to 0.99269, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0322 - val_accuracy: 0.9927\n",
      "Epoch 57/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9976\n",
      "Epoch 00057: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.0730 - val_accuracy: 0.9841\n",
      "Epoch 58/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9892\n",
      "Epoch 00058: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0403 - accuracy: 0.9892 - val_loss: 0.0439 - val_accuracy: 0.9884\n",
      "Epoch 59/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9963\n",
      "Epoch 00059: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0421 - val_accuracy: 0.9897\n",
      "Epoch 60/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9976\n",
      "Epoch 00060: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.0443 - val_accuracy: 0.9905\n",
      "Epoch 61/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9980\n",
      "Epoch 00061: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0467 - val_accuracy: 0.9914\n",
      "Epoch 62/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9978\n",
      "Epoch 00062: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.0429 - val_accuracy: 0.9897\n",
      "Epoch 63/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 00063: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0414 - val_accuracy: 0.9910\n",
      "Epoch 64/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9974\n",
      "Epoch 00064: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.0402 - val_accuracy: 0.9893\n",
      "Epoch 65/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch 00065: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0365 - val_accuracy: 0.9910\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654/655 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9988\n",
      "Epoch 00066: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0574 - val_accuracy: 0.9828\n",
      "Epoch 67/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 00067: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0450 - val_accuracy: 0.9905\n",
      "Epoch 68/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9989\n",
      "Epoch 00068: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0434 - val_accuracy: 0.9914\n",
      "Epoch 69/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982\n",
      "Epoch 00069: val_accuracy improved from 0.99269 to 0.99355, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0370 - val_accuracy: 0.9936\n",
      "Epoch 70/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9982\n",
      "Epoch 00070: val_accuracy did not improve from 0.99355\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.0455 - val_accuracy: 0.9888\n",
      "Epoch 71/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9979\n",
      "Epoch 00071: val_accuracy did not improve from 0.99355\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0366 - val_accuracy: 0.9927\n",
      "Epoch 72/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00072: val_accuracy improved from 0.99355 to 0.99527, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0278 - val_accuracy: 0.9953\n",
      "Epoch 73/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 00073: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0314 - val_accuracy: 0.9944\n",
      "Epoch 74/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 00074: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0318 - val_accuracy: 0.9940\n",
      "Epoch 75/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 00075: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0321 - val_accuracy: 0.9948\n",
      "Epoch 76/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 00076: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0419 - val_accuracy: 0.9914\n",
      "Epoch 77/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 00077: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1995 - val_accuracy: 0.9635\n",
      "Epoch 78/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9906\n",
      "Epoch 00078: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0347 - accuracy: 0.9906 - val_loss: 0.0435 - val_accuracy: 0.9893\n",
      "Epoch 79/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9983\n",
      "Epoch 00079: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0413 - val_accuracy: 0.9918\n",
      "Epoch 80/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 00080: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0307 - val_accuracy: 0.9931\n",
      "Epoch 81/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9983\n",
      "Epoch 00081: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0332 - val_accuracy: 0.9927\n",
      "Epoch 82/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 00082: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0399 - val_accuracy: 0.9918\n",
      "Epoch 83/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 00083: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0380 - val_accuracy: 0.9914\n",
      "Epoch 84/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 00084: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0353 - val_accuracy: 0.9936\n",
      "Epoch 85/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 00085: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0358 - val_accuracy: 0.9927\n",
      "Epoch 86/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 00086: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0373 - val_accuracy: 0.9931\n",
      "Epoch 87/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 00087: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 0.0495 - val_accuracy: 0.9910\n",
      "Epoch 88/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00088: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0348 - val_accuracy: 0.9931\n",
      "Epoch 89/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 00089: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0387 - val_accuracy: 0.9931\n",
      "Epoch 90/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9991\n",
      "Epoch 00090: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0559 - val_accuracy: 0.9893\n",
      "Epoch 91/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 00091: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0413 - val_accuracy: 0.9931\n",
      "Epoch 92/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 00092: val_accuracy did not improve from 0.99527\n",
      "Restoring model weights from the end of the best epoch.\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0546 - val_accuracy: 0.9880\n",
      "Epoch 00092: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:27:00<00:00, 2610.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.80      0.91      0.85       720\n",
      "        car_horn       0.93      0.98      0.95       258\n",
      "children_playing       0.91      0.84      0.87       600\n",
      "        dog_bark       0.89      0.92      0.90       600\n",
      "           siren       0.98      0.87      0.92       714\n",
      "\n",
      "        accuracy                           0.89      2892\n",
      "       macro avg       0.90      0.90      0.90      2892\n",
      "    weighted avg       0.90      0.89      0.89      2892\n",
      "\n",
      "\n",
      "Validation fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (20622, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (20622, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2292, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2292, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (3234, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (3234, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_9\n",
      "Epoch 1/100\n",
      "645/645 [==============================] - ETA: 0s - loss: 1.2299 - accuracy: 0.5786\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65314, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 1.2299 - accuracy: 0.5786 - val_loss: 0.8969 - val_accuracy: 0.6531\n",
      "Epoch 2/100\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.7735 - accuracy: 0.7166\n",
      "Epoch 00002: val_accuracy improved from 0.65314 to 0.66449, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.7735 - accuracy: 0.7166 - val_loss: 0.9292 - val_accuracy: 0.6645\n",
      "Epoch 3/100\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.6401 - accuracy: 0.7658\n",
      "Epoch 00003: val_accuracy improved from 0.66449 to 0.79799, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.6401 - accuracy: 0.7658 - val_loss: 0.5326 - val_accuracy: 0.7980\n",
      "Epoch 4/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.5653 - accuracy: 0.7949\n",
      "Epoch 00004: val_accuracy improved from 0.79799 to 0.80977, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.5650 - accuracy: 0.7951 - val_loss: 0.5199 - val_accuracy: 0.8098\n",
      "Epoch 5/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.5082 - accuracy: 0.8154\n",
      "Epoch 00005: val_accuracy improved from 0.80977 to 0.84468, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.5079 - accuracy: 0.8154 - val_loss: 0.4258 - val_accuracy: 0.8447\n",
      "Epoch 6/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.4577 - accuracy: 0.8361\n",
      "Epoch 00006: val_accuracy did not improve from 0.84468\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.4574 - accuracy: 0.8362 - val_loss: 0.7110 - val_accuracy: 0.7901\n",
      "Epoch 7/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.4117 - accuracy: 0.8524\n",
      "Epoch 00007: val_accuracy improved from 0.84468 to 0.88307, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.4117 - accuracy: 0.8524 - val_loss: 0.3243 - val_accuracy: 0.8831\n",
      "Epoch 8/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8623\n",
      "Epoch 00008: val_accuracy did not improve from 0.88307\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.3795 - accuracy: 0.8624 - val_loss: 0.4702 - val_accuracy: 0.8360\n",
      "Epoch 9/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3428 - accuracy: 0.8774\n",
      "Epoch 00009: val_accuracy did not improve from 0.88307\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.3434 - accuracy: 0.8774 - val_loss: 0.7325 - val_accuracy: 0.7818\n",
      "Epoch 10/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3209 - accuracy: 0.8850\n",
      "Epoch 00010: val_accuracy did not improve from 0.88307\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.3206 - accuracy: 0.8851 - val_loss: 0.4385 - val_accuracy: 0.8543\n",
      "Epoch 11/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2961 - accuracy: 0.8905\n",
      "Epoch 00011: val_accuracy did not improve from 0.88307\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.2962 - accuracy: 0.8905 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
      "Epoch 12/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2787 - accuracy: 0.8995\n",
      "Epoch 00012: val_accuracy did not improve from 0.88307\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.2784 - accuracy: 0.8996 - val_loss: 0.5613 - val_accuracy: 0.7849\n",
      "Epoch 13/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2634 - accuracy: 0.9058\n",
      "Epoch 00013: val_accuracy improved from 0.88307 to 0.92888, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.2632 - accuracy: 0.9058 - val_loss: 0.2054 - val_accuracy: 0.9289\n",
      "Epoch 14/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2426 - accuracy: 0.9127\n",
      "Epoch 00014: val_accuracy did not improve from 0.92888\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.2426 - accuracy: 0.9128 - val_loss: 0.1964 - val_accuracy: 0.9271\n",
      "Epoch 15/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2258 - accuracy: 0.9215\n",
      "Epoch 00015: val_accuracy improved from 0.92888 to 0.94241, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.2255 - accuracy: 0.9216 - val_loss: 0.1607 - val_accuracy: 0.9424\n",
      "Epoch 16/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2159 - accuracy: 0.9220\n",
      "Epoch 00016: val_accuracy did not improve from 0.94241\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.2158 - accuracy: 0.9221 - val_loss: 0.3006 - val_accuracy: 0.8953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2010 - accuracy: 0.9268\n",
      "Epoch 00017: val_accuracy did not improve from 0.94241\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.2010 - accuracy: 0.9268 - val_loss: 0.1592 - val_accuracy: 0.9415\n",
      "Epoch 18/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9309\n",
      "Epoch 00018: val_accuracy improved from 0.94241 to 0.95070, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.1930 - accuracy: 0.9310 - val_loss: 0.1357 - val_accuracy: 0.9507\n",
      "Epoch 19/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.9341\n",
      "Epoch 00019: val_accuracy did not improve from 0.95070\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1813 - accuracy: 0.9341 - val_loss: 0.1621 - val_accuracy: 0.9367\n",
      "Epoch 20/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1712 - accuracy: 0.9362\n",
      "Epoch 00020: val_accuracy improved from 0.95070 to 0.96161, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.1714 - accuracy: 0.9361 - val_loss: 0.1067 - val_accuracy: 0.9616\n",
      "Epoch 21/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9416\n",
      "Epoch 00021: val_accuracy did not improve from 0.96161\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1667 - accuracy: 0.9415 - val_loss: 0.1726 - val_accuracy: 0.9433\n",
      "Epoch 22/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9436\n",
      "Epoch 00022: val_accuracy did not improve from 0.96161\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1546 - accuracy: 0.9436 - val_loss: 0.1345 - val_accuracy: 0.9516\n",
      "Epoch 23/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1437 - accuracy: 0.9492\n",
      "Epoch 00023: val_accuracy improved from 0.96161 to 0.96990, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.1436 - accuracy: 0.9492 - val_loss: 0.0881 - val_accuracy: 0.9699\n",
      "Epoch 24/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1423 - accuracy: 0.9468\n",
      "Epoch 00024: val_accuracy did not improve from 0.96990\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1421 - accuracy: 0.9469 - val_loss: 0.1021 - val_accuracy: 0.9642\n",
      "Epoch 25/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1394 - accuracy: 0.9498\n",
      "Epoch 00025: val_accuracy did not improve from 0.96990\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1395 - accuracy: 0.9498 - val_loss: 0.0912 - val_accuracy: 0.9682\n",
      "Epoch 26/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1281 - accuracy: 0.9548\n",
      "Epoch 00026: val_accuracy did not improve from 0.96990\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1281 - accuracy: 0.9547 - val_loss: 0.1181 - val_accuracy: 0.9625\n",
      "Epoch 27/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 0.9551\n",
      "Epoch 00027: val_accuracy improved from 0.96990 to 0.97251, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.1226 - accuracy: 0.9551 - val_loss: 0.0795 - val_accuracy: 0.9725\n",
      "Epoch 28/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9581\n",
      "Epoch 00028: val_accuracy did not improve from 0.97251\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1163 - accuracy: 0.9581 - val_loss: 0.0818 - val_accuracy: 0.9716\n",
      "Epoch 29/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9583\n",
      "Epoch 00029: val_accuracy did not improve from 0.97251\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1139 - accuracy: 0.9582 - val_loss: 0.1191 - val_accuracy: 0.9638\n",
      "Epoch 30/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1065 - accuracy: 0.9613\n",
      "Epoch 00030: val_accuracy improved from 0.97251 to 0.97295, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.1067 - accuracy: 0.9613 - val_loss: 0.0772 - val_accuracy: 0.9729\n",
      "Epoch 31/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1102 - accuracy: 0.9610\n",
      "Epoch 00031: val_accuracy improved from 0.97295 to 0.97949, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.1100 - accuracy: 0.9611 - val_loss: 0.0626 - val_accuracy: 0.9795\n",
      "Epoch 32/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1030 - accuracy: 0.9627\n",
      "Epoch 00032: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1030 - accuracy: 0.9627 - val_loss: 0.0853 - val_accuracy: 0.9708\n",
      "Epoch 33/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.9653\n",
      "Epoch 00033: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0991 - accuracy: 0.9654 - val_loss: 0.1304 - val_accuracy: 0.9603\n",
      "Epoch 34/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9660\n",
      "Epoch 00034: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0942 - accuracy: 0.9660 - val_loss: 0.0832 - val_accuracy: 0.9725\n",
      "Epoch 35/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0887 - accuracy: 0.9679\n",
      "Epoch 00035: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0885 - accuracy: 0.9679 - val_loss: 0.1079 - val_accuracy: 0.9677\n",
      "Epoch 36/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0926 - accuracy: 0.9666\n",
      "Epoch 00036: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0924 - accuracy: 0.9666 - val_loss: 0.0971 - val_accuracy: 0.9725\n",
      "Epoch 37/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9680\n",
      "Epoch 00037: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0860 - accuracy: 0.9681 - val_loss: 0.1084 - val_accuracy: 0.9642\n",
      "Epoch 38/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0841 - accuracy: 0.9698\n",
      "Epoch 00038: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0841 - accuracy: 0.9699 - val_loss: 0.0654 - val_accuracy: 0.9782\n",
      "Epoch 39/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0787 - accuracy: 0.9711\n",
      "Epoch 00039: val_accuracy improved from 0.97949 to 0.98473, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.0786 - accuracy: 0.9711 - val_loss: 0.0580 - val_accuracy: 0.9847\n",
      "Epoch 40/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9738\n",
      "Epoch 00040: val_accuracy did not improve from 0.98473\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0747 - accuracy: 0.9738 - val_loss: 0.1057 - val_accuracy: 0.9664\n",
      "Epoch 41/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0745 - accuracy: 0.9730\n",
      "Epoch 00041: val_accuracy did not improve from 0.98473\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0744 - accuracy: 0.9730 - val_loss: 0.0566 - val_accuracy: 0.9817\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643/645 [============================>.] - ETA: 0s - loss: 0.0707 - accuracy: 0.9746\n",
      "Epoch 00042: val_accuracy did not improve from 0.98473\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0706 - accuracy: 0.9746 - val_loss: 0.1027 - val_accuracy: 0.9673\n",
      "Epoch 43/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 0.9750\n",
      "Epoch 00043: val_accuracy did not improve from 0.98473\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0691 - accuracy: 0.9750 - val_loss: 0.0701 - val_accuracy: 0.9786\n",
      "Epoch 44/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0720 - accuracy: 0.9747\n",
      "Epoch 00044: val_accuracy did not improve from 0.98473\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0719 - accuracy: 0.9747 - val_loss: 0.0621 - val_accuracy: 0.9812\n",
      "Epoch 45/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9768\n",
      "Epoch 00045: val_accuracy did not improve from 0.98473\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0684 - accuracy: 0.9767 - val_loss: 0.0919 - val_accuracy: 0.9703\n",
      "Epoch 46/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0674 - accuracy: 0.9754\n",
      "Epoch 00046: val_accuracy improved from 0.98473 to 0.98735, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.0674 - accuracy: 0.9754 - val_loss: 0.0435 - val_accuracy: 0.9873\n",
      "Epoch 47/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0636 - accuracy: 0.9774\n",
      "Epoch 00047: val_accuracy did not improve from 0.98735\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0635 - accuracy: 0.9774 - val_loss: 0.0750 - val_accuracy: 0.9773\n",
      "Epoch 48/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9787\n",
      "Epoch 00048: val_accuracy did not improve from 0.98735\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0617 - accuracy: 0.9787 - val_loss: 0.0422 - val_accuracy: 0.9852\n",
      "Epoch 49/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9780\n",
      "Epoch 00049: val_accuracy improved from 0.98735 to 0.98778, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.0599 - accuracy: 0.9780 - val_loss: 0.0433 - val_accuracy: 0.9878\n",
      "Epoch 50/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 0.9804\n",
      "Epoch 00050: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0574 - accuracy: 0.9804 - val_loss: 0.0471 - val_accuracy: 0.9860\n",
      "Epoch 51/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9809\n",
      "Epoch 00051: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0538 - accuracy: 0.9809 - val_loss: 0.0537 - val_accuracy: 0.9830\n",
      "Epoch 52/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9805\n",
      "Epoch 00052: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0532 - accuracy: 0.9805 - val_loss: 0.0476 - val_accuracy: 0.9869\n",
      "Epoch 53/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9813\n",
      "Epoch 00053: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0512 - accuracy: 0.9813 - val_loss: 0.0624 - val_accuracy: 0.9843\n",
      "Epoch 54/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0535 - accuracy: 0.9807\n",
      "Epoch 00054: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0534 - accuracy: 0.9807 - val_loss: 0.0591 - val_accuracy: 0.9821\n",
      "Epoch 55/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9827\n",
      "Epoch 00055: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0508 - accuracy: 0.9827 - val_loss: 0.0623 - val_accuracy: 0.9843\n",
      "Epoch 56/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9825\n",
      "Epoch 00056: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0484 - accuracy: 0.9825 - val_loss: 0.0943 - val_accuracy: 0.9729\n",
      "Epoch 57/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9830\n",
      "Epoch 00057: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0491 - accuracy: 0.9830 - val_loss: 0.0446 - val_accuracy: 0.9856\n",
      "Epoch 58/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9834\n",
      "Epoch 00058: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0474 - accuracy: 0.9834 - val_loss: 0.0487 - val_accuracy: 0.9830\n",
      "Epoch 59/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0505 - accuracy: 0.9819\n",
      "Epoch 00059: val_accuracy improved from 0.98778 to 0.98822, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.0504 - accuracy: 0.9820 - val_loss: 0.0473 - val_accuracy: 0.9882\n",
      "Epoch 60/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9839\n",
      "Epoch 00060: val_accuracy improved from 0.98822 to 0.98997, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 0.0371 - val_accuracy: 0.9900\n",
      "Epoch 61/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9840\n",
      "Epoch 00061: val_accuracy did not improve from 0.98997\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0448 - accuracy: 0.9840 - val_loss: 0.0538 - val_accuracy: 0.9812\n",
      "Epoch 62/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9835\n",
      "Epoch 00062: val_accuracy did not improve from 0.98997\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0468 - accuracy: 0.9835 - val_loss: 0.0582 - val_accuracy: 0.9830\n",
      "Epoch 63/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9832\n",
      "Epoch 00063: val_accuracy did not improve from 0.98997\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0475 - accuracy: 0.9832 - val_loss: 0.0535 - val_accuracy: 0.9830\n",
      "Epoch 64/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9856\n",
      "Epoch 00064: val_accuracy improved from 0.98997 to 0.99084, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.0421 - accuracy: 0.9856 - val_loss: 0.0307 - val_accuracy: 0.9908\n",
      "Epoch 65/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9855\n",
      "Epoch 00065: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0420 - accuracy: 0.9855 - val_loss: 0.0578 - val_accuracy: 0.9817\n",
      "Epoch 66/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.9865\n",
      "Epoch 00066: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0387 - accuracy: 0.9866 - val_loss: 0.0599 - val_accuracy: 0.9847\n",
      "Epoch 67/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9853\n",
      "Epoch 00067: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0399 - accuracy: 0.9853 - val_loss: 0.0337 - val_accuracy: 0.9882\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643/645 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9867\n",
      "Epoch 00068: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0390 - accuracy: 0.9867 - val_loss: 0.0496 - val_accuracy: 0.9865\n",
      "Epoch 69/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9861\n",
      "Epoch 00069: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0391 - accuracy: 0.9861 - val_loss: 0.0415 - val_accuracy: 0.9873\n",
      "Epoch 70/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 0.9864\n",
      "Epoch 00070: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0389 - accuracy: 0.9864 - val_loss: 0.0340 - val_accuracy: 0.9904\n",
      "Epoch 71/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9866\n",
      "Epoch 00071: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0370 - accuracy: 0.9866 - val_loss: 0.0341 - val_accuracy: 0.9900\n",
      "Epoch 72/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9878\n",
      "Epoch 00072: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0363 - accuracy: 0.9878 - val_loss: 0.0329 - val_accuracy: 0.9900\n",
      "Epoch 73/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9889\n",
      "Epoch 00073: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0317 - accuracy: 0.9889 - val_loss: 0.0358 - val_accuracy: 0.9887\n",
      "Epoch 74/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9866\n",
      "Epoch 00074: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 0.0444 - val_accuracy: 0.9860\n",
      "Epoch 75/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9870\n",
      "Epoch 00075: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0364 - accuracy: 0.9871 - val_loss: 0.0668 - val_accuracy: 0.9825\n",
      "Epoch 76/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9878\n",
      "Epoch 00076: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 0.0359 - val_accuracy: 0.9895\n",
      "Epoch 77/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9895\n",
      "Epoch 00077: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 0.0359 - val_accuracy: 0.9904\n",
      "Epoch 78/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9893\n",
      "Epoch 00078: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0325 - accuracy: 0.9892 - val_loss: 0.0296 - val_accuracy: 0.9908\n",
      "Epoch 79/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9888\n",
      "Epoch 00079: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0346 - accuracy: 0.9888 - val_loss: 0.0351 - val_accuracy: 0.9900\n",
      "Epoch 80/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9899\n",
      "Epoch 00080: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0287 - accuracy: 0.9899 - val_loss: 0.0335 - val_accuracy: 0.9908\n",
      "Epoch 81/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9875\n",
      "Epoch 00081: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0330 - accuracy: 0.9875 - val_loss: 0.0444 - val_accuracy: 0.9878\n",
      "Epoch 82/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9905\n",
      "Epoch 00082: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 0.0349 - val_accuracy: 0.9900\n",
      "Epoch 83/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9909\n",
      "Epoch 00083: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.0337 - val_accuracy: 0.9891\n",
      "Epoch 84/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9889\n",
      "Epoch 00084: val_accuracy did not improve from 0.99084\n",
      "Restoring model weights from the end of the best epoch.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0323 - accuracy: 0.9888 - val_loss: 0.0388 - val_accuracy: 0.9904\n",
      "Epoch 00084: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [20:23<20:23, 1223.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.72      0.86      0.78       684\n",
      "        car_horn       0.93      0.69      0.80       354\n",
      "children_playing       0.73      0.76      0.74       600\n",
      "        dog_bark       0.87      0.88      0.87       600\n",
      "           siren       0.94      0.87      0.91       996\n",
      "\n",
      "        accuracy                           0.83      3234\n",
      "       macro avg       0.84      0.81      0.82      3234\n",
      "    weighted avg       0.84      0.83      0.83      3234\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_10\n",
      "Epoch 1/100\n",
      "  2/645 [..............................] - ETA: 19s - loss: 2.2981 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0229s vs `on_train_batch_end` time: 0.0379s). Check your callbacks.\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.9244 - accuracy: 0.6568\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79145, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 63ms/step - loss: 0.9244 - accuracy: 0.6568 - val_loss: 0.5658 - val_accuracy: 0.7914\n",
      "Epoch 2/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5679 - accuracy: 0.7966\n",
      "Epoch 00002: val_accuracy did not improve from 0.79145\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.5677 - accuracy: 0.7966 - val_loss: 0.8435 - val_accuracy: 0.7417\n",
      "Epoch 3/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4173 - accuracy: 0.8561\n",
      "Epoch 00003: val_accuracy improved from 0.79145 to 0.85689, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.4172 - accuracy: 0.8561 - val_loss: 0.3759 - val_accuracy: 0.8569\n",
      "Epoch 4/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.8902\n",
      "Epoch 00004: val_accuracy improved from 0.85689 to 0.90794, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 41s 63ms/step - loss: 0.3232 - accuracy: 0.8902 - val_loss: 0.2575 - val_accuracy: 0.9079\n",
      "Epoch 5/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2451 - accuracy: 0.9136\n",
      "Epoch 00005: val_accuracy improved from 0.90794 to 0.92845, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.2453 - accuracy: 0.9136 - val_loss: 0.2020 - val_accuracy: 0.9284\n",
      "Epoch 6/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2022 - accuracy: 0.9312\n",
      "Epoch 00006: val_accuracy improved from 0.92845 to 0.93979, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.2021 - accuracy: 0.9312 - val_loss: 0.1787 - val_accuracy: 0.9398\n",
      "Epoch 7/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.1714 - accuracy: 0.9421\n",
      "Epoch 00007: val_accuracy did not improve from 0.93979\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.1713 - accuracy: 0.9421 - val_loss: 0.6428 - val_accuracy: 0.8259\n",
      "Epoch 8/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.1437 - accuracy: 0.9512\n",
      "Epoch 00008: val_accuracy improved from 0.93979 to 0.94503, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.1437 - accuracy: 0.9512 - val_loss: 0.1647 - val_accuracy: 0.9450\n",
      "Epoch 9/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.1196 - accuracy: 0.9593\n",
      "Epoch 00009: val_accuracy did not improve from 0.94503\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.1197 - accuracy: 0.9594 - val_loss: 0.2831 - val_accuracy: 0.9158\n",
      "Epoch 10/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9631\n",
      "Epoch 00010: val_accuracy improved from 0.94503 to 0.96073, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.1111 - accuracy: 0.9630 - val_loss: 0.1291 - val_accuracy: 0.9607\n",
      "Epoch 11/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9678\n",
      "Epoch 00011: val_accuracy did not improve from 0.96073\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0930 - accuracy: 0.9678 - val_loss: 0.1341 - val_accuracy: 0.9529\n",
      "Epoch 12/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0811 - accuracy: 0.9727\n",
      "Epoch 00012: val_accuracy did not improve from 0.96073\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0810 - accuracy: 0.9727 - val_loss: 0.1648 - val_accuracy: 0.9568\n",
      "Epoch 13/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9769\n",
      "Epoch 00013: val_accuracy improved from 0.96073 to 0.96117, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0652 - accuracy: 0.9769 - val_loss: 0.1308 - val_accuracy: 0.9612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.9795\n",
      "Epoch 00014: val_accuracy improved from 0.96117 to 0.96466, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0613 - accuracy: 0.9795 - val_loss: 0.1246 - val_accuracy: 0.9647\n",
      "Epoch 15/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0551 - accuracy: 0.9816\n",
      "Epoch 00015: val_accuracy did not improve from 0.96466\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0551 - accuracy: 0.9816 - val_loss: 0.1684 - val_accuracy: 0.9520\n",
      "Epoch 16/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0490 - accuracy: 0.9830\n",
      "Epoch 00016: val_accuracy improved from 0.96466 to 0.97688, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0490 - accuracy: 0.9830 - val_loss: 0.0862 - val_accuracy: 0.9769\n",
      "Epoch 17/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9864\n",
      "Epoch 00017: val_accuracy did not improve from 0.97688\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0420 - accuracy: 0.9864 - val_loss: 0.1468 - val_accuracy: 0.9568\n",
      "Epoch 18/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9861\n",
      "Epoch 00018: val_accuracy did not improve from 0.97688\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0410 - accuracy: 0.9861 - val_loss: 0.1016 - val_accuracy: 0.9664\n",
      "Epoch 19/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9875\n",
      "Epoch 00019: val_accuracy did not improve from 0.97688\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0367 - accuracy: 0.9875 - val_loss: 0.1638 - val_accuracy: 0.9620\n",
      "Epoch 20/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9898\n",
      "Epoch 00020: val_accuracy improved from 0.97688 to 0.97993, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0302 - accuracy: 0.9898 - val_loss: 0.0794 - val_accuracy: 0.9799\n",
      "Epoch 21/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9903\n",
      "Epoch 00021: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.9667 - val_accuracy: 0.8298\n",
      "Epoch 22/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9896\n",
      "Epoch 00022: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.0935 - val_accuracy: 0.9777\n",
      "Epoch 23/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0309 - accuracy: 0.9896\n",
      "Epoch 00023: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.0936 - val_accuracy: 0.9782\n",
      "Epoch 24/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9924\n",
      "Epoch 00024: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.2351 - val_accuracy: 0.9468\n",
      "Epoch 25/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9917\n",
      "Epoch 00025: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.1547 - val_accuracy: 0.9651\n",
      "Epoch 26/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9919\n",
      "Epoch 00026: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 0.3995 - val_accuracy: 0.9293\n",
      "Epoch 27/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9926\n",
      "Epoch 00027: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.2758 - val_accuracy: 0.9346\n",
      "Epoch 28/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9930\n",
      "Epoch 00028: val_accuracy improved from 0.97993 to 0.98429, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.0598 - val_accuracy: 0.9843\n",
      "Epoch 29/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9956\n",
      "Epoch 00029: val_accuracy did not improve from 0.98429\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0965 - val_accuracy: 0.9751\n",
      "Epoch 30/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9940\n",
      "Epoch 00030: val_accuracy did not improve from 0.98429\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.1933 - val_accuracy: 0.9577\n",
      "Epoch 31/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9947\n",
      "Epoch 00031: val_accuracy did not improve from 0.98429\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0756 - val_accuracy: 0.9817\n",
      "Epoch 32/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9953\n",
      "Epoch 00032: val_accuracy did not improve from 0.98429\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0907 - val_accuracy: 0.9760\n",
      "Epoch 33/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9954\n",
      "Epoch 00033: val_accuracy did not improve from 0.98429\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0728 - val_accuracy: 0.9804\n",
      "Epoch 34/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9950\n",
      "Epoch 00034: val_accuracy did not improve from 0.98429\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.1162 - val_accuracy: 0.9777\n",
      "Epoch 35/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9959\n",
      "Epoch 00035: val_accuracy improved from 0.98429 to 0.98647, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0524 - val_accuracy: 0.9865\n",
      "Epoch 36/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9968\n",
      "Epoch 00036: val_accuracy improved from 0.98647 to 0.98735, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0563 - val_accuracy: 0.9873\n",
      "Epoch 37/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9963\n",
      "Epoch 00037: val_accuracy did not improve from 0.98735\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0958 - val_accuracy: 0.9795\n",
      "Epoch 38/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9956\n",
      "Epoch 00038: val_accuracy did not improve from 0.98735\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.0462 - val_accuracy: 0.9869\n",
      "Epoch 39/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9965\n",
      "Epoch 00039: val_accuracy improved from 0.98735 to 0.98997, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0435 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9978\n",
      "Epoch 00040: val_accuracy improved from 0.98997 to 0.99127, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0411 - val_accuracy: 0.9913\n",
      "Epoch 41/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 00041: val_accuracy improved from 0.99127 to 0.99171, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0346 - val_accuracy: 0.9917\n",
      "Epoch 42/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9981\n",
      "Epoch 00042: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0408 - val_accuracy: 0.9913\n",
      "Epoch 43/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9973\n",
      "Epoch 00043: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0431 - val_accuracy: 0.9882\n",
      "Epoch 44/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 00044: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0462 - val_accuracy: 0.9887\n",
      "Epoch 45/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9963\n",
      "Epoch 00045: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0569 - val_accuracy: 0.9878\n",
      "Epoch 46/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9982\n",
      "Epoch 00046: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0645 - val_accuracy: 0.9860\n",
      "Epoch 47/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9969\n",
      "Epoch 00047: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0464 - val_accuracy: 0.9873\n",
      "Epoch 48/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9965\n",
      "Epoch 00048: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0096 - accuracy: 0.9965 - val_loss: 0.0779 - val_accuracy: 0.9834\n",
      "Epoch 49/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9973\n",
      "Epoch 00049: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0619 - val_accuracy: 0.9856\n",
      "Epoch 50/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 00050: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0333 - val_accuracy: 0.9913\n",
      "Epoch 51/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9976\n",
      "Epoch 00051: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0799 - val_accuracy: 0.9830\n",
      "Epoch 52/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9981\n",
      "Epoch 00052: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.0507 - val_accuracy: 0.9913\n",
      "Epoch 53/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9975\n",
      "Epoch 00053: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.1567 - val_accuracy: 0.9747\n",
      "Epoch 54/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9973\n",
      "Epoch 00054: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.1344 - val_accuracy: 0.9703\n",
      "Epoch 55/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9970\n",
      "Epoch 00055: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.0906 - val_accuracy: 0.9830\n",
      "Epoch 56/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9972\n",
      "Epoch 00056: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0709 - val_accuracy: 0.9847\n",
      "Epoch 57/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 00057: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0494 - val_accuracy: 0.9882\n",
      "Epoch 58/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9989\n",
      "Epoch 00058: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0660 - val_accuracy: 0.9847\n",
      "Epoch 59/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 00059: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0512 - val_accuracy: 0.9882\n",
      "Epoch 60/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9975\n",
      "Epoch 00060: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.0479 - val_accuracy: 0.9891\n",
      "Epoch 61/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9980\n",
      "Epoch 00061: val_accuracy did not improve from 0.99171\n",
      "Restoring model weights from the end of the best epoch.\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 0.0442 - val_accuracy: 0.9900\n",
      "Epoch 00061: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:01:30<00:00, 1845.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.72      0.88      0.79       684\n",
      "        car_horn       0.97      0.65      0.78       354\n",
      "children_playing       0.81      0.79      0.80       600\n",
      "        dog_bark       0.87      0.89      0.88       600\n",
      "           siren       0.95      0.92      0.93       996\n",
      "\n",
      "        accuracy                           0.85      3234\n",
      "       macro avg       0.86      0.83      0.84      3234\n",
      "    weighted avg       0.86      0.85      0.85      3234\n",
      "\n",
      "\n",
      "Validation fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21006, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21006, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2334, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2334, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2808, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2808, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_11\n",
      "Epoch 1/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 1.1997 - accuracy: 0.6154\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73350, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 1.1993 - accuracy: 0.6154 - val_loss: 0.7456 - val_accuracy: 0.7335\n",
      "Epoch 2/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.7324 - accuracy: 0.7385\n",
      "Epoch 00002: val_accuracy improved from 0.73350 to 0.76435, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.7325 - accuracy: 0.7385 - val_loss: 0.6386 - val_accuracy: 0.7644\n",
      "Epoch 3/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.6152 - accuracy: 0.7781\n",
      "Epoch 00003: val_accuracy improved from 0.76435 to 0.80377, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.6148 - accuracy: 0.7783 - val_loss: 0.5902 - val_accuracy: 0.8038\n",
      "Epoch 4/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.5399 - accuracy: 0.8041\n",
      "Epoch 00004: val_accuracy improved from 0.80377 to 0.83805, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.5399 - accuracy: 0.8040 - val_loss: 0.5179 - val_accuracy: 0.8380\n",
      "Epoch 5/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.4744 - accuracy: 0.8275\n",
      "Epoch 00005: val_accuracy improved from 0.83805 to 0.88732, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.4742 - accuracy: 0.8275 - val_loss: 0.3088 - val_accuracy: 0.8873\n",
      "Epoch 6/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.4231 - accuracy: 0.8454\n",
      "Epoch 00006: val_accuracy did not improve from 0.88732\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.4231 - accuracy: 0.8452 - val_loss: 0.4493 - val_accuracy: 0.8410\n",
      "Epoch 7/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8625\n",
      "Epoch 00007: val_accuracy did not improve from 0.88732\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.3851 - accuracy: 0.8626 - val_loss: 0.3781 - val_accuracy: 0.8715\n",
      "Epoch 8/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.3620 - accuracy: 0.8683\n",
      "Epoch 00008: val_accuracy improved from 0.88732 to 0.90103, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.3620 - accuracy: 0.8684 - val_loss: 0.2947 - val_accuracy: 0.9010\n",
      "Epoch 9/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.3281 - accuracy: 0.8825\n",
      "Epoch 00009: val_accuracy improved from 0.90103 to 0.91345, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.3279 - accuracy: 0.8826 - val_loss: 0.2347 - val_accuracy: 0.9135\n",
      "Epoch 10/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.3043 - accuracy: 0.8895\n",
      "Epoch 00010: val_accuracy did not improve from 0.91345\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.3040 - accuracy: 0.8897 - val_loss: 0.3364 - val_accuracy: 0.8715\n",
      "Epoch 11/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.8953\n",
      "Epoch 00011: val_accuracy did not improve from 0.91345\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.2896 - accuracy: 0.8954 - val_loss: 0.2481 - val_accuracy: 0.9135\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.2649 - accuracy: 0.9036\n",
      "Epoch 00012: val_accuracy improved from 0.91345 to 0.91731, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.2649 - accuracy: 0.9036 - val_loss: 0.2292 - val_accuracy: 0.9173\n",
      "Epoch 13/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.2545 - accuracy: 0.9060\n",
      "Epoch 00013: val_accuracy did not improve from 0.91731\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.2551 - accuracy: 0.9057 - val_loss: 0.3112 - val_accuracy: 0.8985\n",
      "Epoch 14/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.9124\n",
      "Epoch 00014: val_accuracy improved from 0.91731 to 0.92931, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.2416 - accuracy: 0.9123 - val_loss: 0.1945 - val_accuracy: 0.9293\n",
      "Epoch 15/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.9224\n",
      "Epoch 00015: val_accuracy improved from 0.92931 to 0.93016, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.2143 - accuracy: 0.9225 - val_loss: 0.1877 - val_accuracy: 0.9302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.2092 - accuracy: 0.9231\n",
      "Epoch 00016: val_accuracy improved from 0.93016 to 0.93488, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.2094 - accuracy: 0.9229 - val_loss: 0.1776 - val_accuracy: 0.9349\n",
      "Epoch 17/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1982 - accuracy: 0.9265\n",
      "Epoch 00017: val_accuracy improved from 0.93488 to 0.94944, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.1987 - accuracy: 0.9264 - val_loss: 0.1575 - val_accuracy: 0.9494\n",
      "Epoch 18/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1859 - accuracy: 0.9303\n",
      "Epoch 00018: val_accuracy did not improve from 0.94944\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1859 - accuracy: 0.9304 - val_loss: 0.1637 - val_accuracy: 0.9456\n",
      "Epoch 19/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.9330\n",
      "Epoch 00019: val_accuracy did not improve from 0.94944\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1818 - accuracy: 0.9328 - val_loss: 0.1568 - val_accuracy: 0.9482\n",
      "Epoch 20/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1696 - accuracy: 0.9377\n",
      "Epoch 00020: val_accuracy improved from 0.94944 to 0.96230, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.1698 - accuracy: 0.9377 - val_loss: 0.1188 - val_accuracy: 0.9623\n",
      "Epoch 21/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1620 - accuracy: 0.9406\n",
      "Epoch 00021: val_accuracy improved from 0.96230 to 0.96872, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.1619 - accuracy: 0.9405 - val_loss: 0.0988 - val_accuracy: 0.9687\n",
      "Epoch 22/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1525 - accuracy: 0.9448\n",
      "Epoch 00022: val_accuracy did not improve from 0.96872\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1524 - accuracy: 0.9447 - val_loss: 0.1476 - val_accuracy: 0.9464\n",
      "Epoch 23/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1470 - accuracy: 0.9453\n",
      "Epoch 00023: val_accuracy did not improve from 0.96872\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1469 - accuracy: 0.9453 - val_loss: 0.0926 - val_accuracy: 0.9666\n",
      "Epoch 24/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1416 - accuracy: 0.9488\n",
      "Epoch 00024: val_accuracy did not improve from 0.96872\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1422 - accuracy: 0.9486 - val_loss: 0.1071 - val_accuracy: 0.9640\n",
      "Epoch 25/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1366 - accuracy: 0.9508\n",
      "Epoch 00025: val_accuracy improved from 0.96872 to 0.97087, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.1364 - accuracy: 0.9509 - val_loss: 0.0970 - val_accuracy: 0.9709\n",
      "Epoch 26/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9539\n",
      "Epoch 00026: val_accuracy improved from 0.97087 to 0.97686, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.1285 - accuracy: 0.9539 - val_loss: 0.0802 - val_accuracy: 0.9769\n",
      "Epoch 27/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1203 - accuracy: 0.9558\n",
      "Epoch 00027: val_accuracy did not improve from 0.97686\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1202 - accuracy: 0.9559 - val_loss: 0.0872 - val_accuracy: 0.9739\n",
      "Epoch 28/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1174 - accuracy: 0.9570\n",
      "Epoch 00028: val_accuracy did not improve from 0.97686\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1175 - accuracy: 0.9571 - val_loss: 0.0785 - val_accuracy: 0.9743\n",
      "Epoch 29/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1140 - accuracy: 0.9583\n",
      "Epoch 00029: val_accuracy did not improve from 0.97686\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1141 - accuracy: 0.9583 - val_loss: 0.0732 - val_accuracy: 0.9764\n",
      "Epoch 30/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9590\n",
      "Epoch 00030: val_accuracy did not improve from 0.97686\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1109 - accuracy: 0.9591 - val_loss: 0.0903 - val_accuracy: 0.9726\n",
      "Epoch 31/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1045 - accuracy: 0.9632\n",
      "Epoch 00031: val_accuracy did not improve from 0.97686\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1044 - accuracy: 0.9632 - val_loss: 0.1031 - val_accuracy: 0.9692\n",
      "Epoch 32/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 0.9660\n",
      "Epoch 00032: val_accuracy did not improve from 0.97686\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0960 - accuracy: 0.9660 - val_loss: 0.0760 - val_accuracy: 0.9751\n",
      "Epoch 33/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0974 - accuracy: 0.9656\n",
      "Epoch 00033: val_accuracy improved from 0.97686 to 0.97943, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0973 - accuracy: 0.9657 - val_loss: 0.0627 - val_accuracy: 0.9794\n",
      "Epoch 34/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0938 - accuracy: 0.9658\n",
      "Epoch 00034: val_accuracy did not improve from 0.97943\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0938 - accuracy: 0.9658 - val_loss: 0.0655 - val_accuracy: 0.9781\n",
      "Epoch 35/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0886 - accuracy: 0.9691\n",
      "Epoch 00035: val_accuracy did not improve from 0.97943\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0888 - accuracy: 0.9691 - val_loss: 0.0715 - val_accuracy: 0.9756\n",
      "Epoch 36/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9656\n",
      "Epoch 00036: val_accuracy did not improve from 0.97943\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0900 - accuracy: 0.9656 - val_loss: 0.1132 - val_accuracy: 0.9614\n",
      "Epoch 37/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9693\n",
      "Epoch 00037: val_accuracy did not improve from 0.97943\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0872 - accuracy: 0.9692 - val_loss: 0.0710 - val_accuracy: 0.9786\n",
      "Epoch 38/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0805 - accuracy: 0.9702\n",
      "Epoch 00038: val_accuracy improved from 0.97943 to 0.98372, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0805 - accuracy: 0.9702 - val_loss: 0.0533 - val_accuracy: 0.9837\n",
      "Epoch 39/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0776 - accuracy: 0.9724\n",
      "Epoch 00039: val_accuracy did not improve from 0.98372\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0776 - accuracy: 0.9724 - val_loss: 0.0567 - val_accuracy: 0.9811\n",
      "Epoch 40/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.9737\n",
      "Epoch 00040: val_accuracy improved from 0.98372 to 0.98415, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0728 - accuracy: 0.9737 - val_loss: 0.0520 - val_accuracy: 0.9841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9732\n",
      "Epoch 00041: val_accuracy did not improve from 0.98415\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0753 - accuracy: 0.9733 - val_loss: 0.0552 - val_accuracy: 0.9803\n",
      "Epoch 42/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9743\n",
      "Epoch 00042: val_accuracy did not improve from 0.98415\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0686 - accuracy: 0.9742 - val_loss: 0.0614 - val_accuracy: 0.9824\n",
      "Epoch 43/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0722 - accuracy: 0.9742\n",
      "Epoch 00043: val_accuracy did not improve from 0.98415\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0722 - accuracy: 0.9742 - val_loss: 0.0600 - val_accuracy: 0.9833\n",
      "Epoch 44/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 0.9768\n",
      "Epoch 00044: val_accuracy did not improve from 0.98415\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0649 - accuracy: 0.9768 - val_loss: 0.0547 - val_accuracy: 0.9833\n",
      "Epoch 45/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0684 - accuracy: 0.9745\n",
      "Epoch 00045: val_accuracy did not improve from 0.98415\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0684 - accuracy: 0.9744 - val_loss: 0.0516 - val_accuracy: 0.9833\n",
      "Epoch 46/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0660 - accuracy: 0.9757\n",
      "Epoch 00046: val_accuracy did not improve from 0.98415\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0659 - accuracy: 0.9758 - val_loss: 0.0605 - val_accuracy: 0.9816\n",
      "Epoch 47/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9790\n",
      "Epoch 00047: val_accuracy improved from 0.98415 to 0.98715, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0581 - accuracy: 0.9790 - val_loss: 0.0345 - val_accuracy: 0.9871\n",
      "Epoch 48/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0624 - accuracy: 0.9776\n",
      "Epoch 00048: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0625 - accuracy: 0.9776 - val_loss: 0.0483 - val_accuracy: 0.9820\n",
      "Epoch 49/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 0.9789\n",
      "Epoch 00049: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0595 - accuracy: 0.9789 - val_loss: 0.0506 - val_accuracy: 0.9854\n",
      "Epoch 50/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 0.9784\n",
      "Epoch 00050: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0594 - accuracy: 0.9784 - val_loss: 0.0497 - val_accuracy: 0.9807\n",
      "Epoch 51/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9792\n",
      "Epoch 00051: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0577 - accuracy: 0.9791 - val_loss: 0.0685 - val_accuracy: 0.9781\n",
      "Epoch 52/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9814\n",
      "Epoch 00052: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0524 - accuracy: 0.9813 - val_loss: 0.0557 - val_accuracy: 0.9820\n",
      "Epoch 53/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 0.9806\n",
      "Epoch 00053: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0551 - accuracy: 0.9806 - val_loss: 0.0440 - val_accuracy: 0.9833\n",
      "Epoch 54/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0510 - accuracy: 0.9824\n",
      "Epoch 00054: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0512 - accuracy: 0.9824 - val_loss: 0.0464 - val_accuracy: 0.9841\n",
      "Epoch 55/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0530 - accuracy: 0.9808\n",
      "Epoch 00055: val_accuracy improved from 0.98715 to 0.98800, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0529 - accuracy: 0.9809 - val_loss: 0.0420 - val_accuracy: 0.9880\n",
      "Epoch 56/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0481 - accuracy: 0.9823\n",
      "Epoch 00056: val_accuracy did not improve from 0.98800\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0481 - accuracy: 0.9823 - val_loss: 0.0439 - val_accuracy: 0.9863\n",
      "Epoch 57/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9821\n",
      "Epoch 00057: val_accuracy improved from 0.98800 to 0.98843, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0501 - accuracy: 0.9821 - val_loss: 0.0364 - val_accuracy: 0.9884\n",
      "Epoch 58/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0458 - accuracy: 0.9839\n",
      "Epoch 00058: val_accuracy improved from 0.98843 to 0.98972, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0458 - accuracy: 0.9839 - val_loss: 0.0326 - val_accuracy: 0.9897\n",
      "Epoch 59/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 0.9820\n",
      "Epoch 00059: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0513 - accuracy: 0.9820 - val_loss: 0.0366 - val_accuracy: 0.9889\n",
      "Epoch 60/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0454 - accuracy: 0.9839\n",
      "Epoch 00060: val_accuracy improved from 0.98972 to 0.99057, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0454 - accuracy: 0.9840 - val_loss: 0.0342 - val_accuracy: 0.9906\n",
      "Epoch 61/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0433 - accuracy: 0.9846\n",
      "Epoch 00061: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0432 - accuracy: 0.9846 - val_loss: 0.0331 - val_accuracy: 0.9906\n",
      "Epoch 62/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0415 - accuracy: 0.9863\n",
      "Epoch 00062: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0415 - accuracy: 0.9863 - val_loss: 0.0394 - val_accuracy: 0.9880\n",
      "Epoch 63/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9831\n",
      "Epoch 00063: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0448 - accuracy: 0.9831 - val_loss: 0.0369 - val_accuracy: 0.9859\n",
      "Epoch 64/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9851\n",
      "Epoch 00064: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0402 - accuracy: 0.9851 - val_loss: 0.0486 - val_accuracy: 0.9863\n",
      "Epoch 65/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9855\n",
      "Epoch 00065: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0408 - accuracy: 0.9855 - val_loss: 0.0333 - val_accuracy: 0.9906\n",
      "Epoch 66/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9849\n",
      "Epoch 00066: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0414 - accuracy: 0.9850 - val_loss: 0.0371 - val_accuracy: 0.9867\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655/657 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9876\n",
      "Epoch 00067: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0367 - accuracy: 0.9876 - val_loss: 0.0387 - val_accuracy: 0.9884\n",
      "Epoch 68/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.9868\n",
      "Epoch 00068: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0387 - accuracy: 0.9868 - val_loss: 0.0321 - val_accuracy: 0.9897\n",
      "Epoch 69/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9865\n",
      "Epoch 00069: val_accuracy improved from 0.99057 to 0.99229, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0366 - accuracy: 0.9865 - val_loss: 0.0274 - val_accuracy: 0.9923\n",
      "Epoch 70/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9875\n",
      "Epoch 00070: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0353 - accuracy: 0.9876 - val_loss: 0.0423 - val_accuracy: 0.9876\n",
      "Epoch 71/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9861\n",
      "Epoch 00071: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0380 - accuracy: 0.9861 - val_loss: 0.0355 - val_accuracy: 0.9884\n",
      "Epoch 72/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9879\n",
      "Epoch 00072: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0343 - accuracy: 0.9879 - val_loss: 0.0274 - val_accuracy: 0.9901\n",
      "Epoch 73/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9881\n",
      "Epoch 00073: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0357 - accuracy: 0.9881 - val_loss: 0.0299 - val_accuracy: 0.9897\n",
      "Epoch 74/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9879\n",
      "Epoch 00074: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 0.0310 - val_accuracy: 0.9914\n",
      "Epoch 75/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9883\n",
      "Epoch 00075: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0337 - accuracy: 0.9883 - val_loss: 0.0340 - val_accuracy: 0.9889\n",
      "Epoch 76/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9884\n",
      "Epoch 00076: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0319 - accuracy: 0.9883 - val_loss: 0.0454 - val_accuracy: 0.9880\n",
      "Epoch 77/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9884\n",
      "Epoch 00077: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0330 - accuracy: 0.9883 - val_loss: 0.0517 - val_accuracy: 0.9807\n",
      "Epoch 78/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0309 - accuracy: 0.9896\n",
      "Epoch 00078: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0310 - accuracy: 0.9894 - val_loss: 0.0344 - val_accuracy: 0.9901\n",
      "Epoch 79/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.9888\n",
      "Epoch 00079: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0316 - accuracy: 0.9889 - val_loss: 0.0333 - val_accuracy: 0.9893\n",
      "Epoch 80/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9871\n",
      "Epoch 00080: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0343 - accuracy: 0.9871 - val_loss: 0.0339 - val_accuracy: 0.9880\n",
      "Epoch 81/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9899\n",
      "Epoch 00081: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0292 - accuracy: 0.9899 - val_loss: 0.0295 - val_accuracy: 0.9914\n",
      "Epoch 82/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9900\n",
      "Epoch 00082: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.0279 - val_accuracy: 0.9914\n",
      "Epoch 83/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9897\n",
      "Epoch 00083: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0303 - accuracy: 0.9897 - val_loss: 0.0286 - val_accuracy: 0.9901\n",
      "Epoch 84/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9907\n",
      "Epoch 00084: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0295 - accuracy: 0.9907 - val_loss: 0.0532 - val_accuracy: 0.9867\n",
      "Epoch 85/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9910\n",
      "Epoch 00085: val_accuracy improved from 0.99229 to 0.99314, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0276 - accuracy: 0.9910 - val_loss: 0.0221 - val_accuracy: 0.9931\n",
      "Epoch 86/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9896\n",
      "Epoch 00086: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0299 - accuracy: 0.9895 - val_loss: 0.0338 - val_accuracy: 0.9901\n",
      "Epoch 87/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9900\n",
      "Epoch 00087: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0273 - accuracy: 0.9900 - val_loss: 0.0352 - val_accuracy: 0.9906\n",
      "Epoch 88/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9904\n",
      "Epoch 00088: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0291 - accuracy: 0.9904 - val_loss: 0.0251 - val_accuracy: 0.9910\n",
      "Epoch 89/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9904\n",
      "Epoch 00089: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0280 - accuracy: 0.9904 - val_loss: 0.0262 - val_accuracy: 0.9914\n",
      "Epoch 90/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9913\n",
      "Epoch 00090: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.0302 - val_accuracy: 0.9919\n",
      "Epoch 91/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9905\n",
      "Epoch 00091: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 0.0559 - val_accuracy: 0.9837\n",
      "Epoch 92/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 0.9909\n",
      "Epoch 00092: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0264 - accuracy: 0.9909 - val_loss: 0.0288 - val_accuracy: 0.9923\n",
      "Epoch 93/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9903\n",
      "Epoch 00093: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.0266 - val_accuracy: 0.9931\n",
      "Epoch 94/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9919\n",
      "Epoch 00094: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0371 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9895\n",
      "Epoch 00095: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.0345 - val_accuracy: 0.9910\n",
      "Epoch 96/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9913\n",
      "Epoch 00096: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0249 - accuracy: 0.9912 - val_loss: 0.0290 - val_accuracy: 0.9914\n",
      "Epoch 97/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9917\n",
      "Epoch 00097: val_accuracy improved from 0.99314 to 0.99357, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0249 - val_accuracy: 0.9936\n",
      "Epoch 98/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9915\n",
      "Epoch 00098: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.0246 - val_accuracy: 0.9927\n",
      "Epoch 99/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9919\n",
      "Epoch 00099: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0289 - val_accuracy: 0.9910\n",
      "Epoch 100/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9912\n",
      "Epoch 00100: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0271 - accuracy: 0.9912 - val_loss: 0.0341 - val_accuracy: 0.9914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [24:42<24:42, 1482.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.74      0.94      0.83       594\n",
      "        car_horn       0.97      0.88      0.92       588\n",
      "children_playing       0.84      0.83      0.84       600\n",
      "        dog_bark       0.89      0.81      0.85       600\n",
      "           siren       0.98      0.85      0.91       426\n",
      "\n",
      "        accuracy                           0.86      2808\n",
      "       macro avg       0.88      0.86      0.87      2808\n",
      "    weighted avg       0.88      0.86      0.87      2808\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_12\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 19s - loss: 2.3862 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0220s vs `on_train_batch_end` time: 0.0379s). Check your callbacks.\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.9370 - accuracy: 0.6512\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78706, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 63ms/step - loss: 0.9369 - accuracy: 0.6512 - val_loss: 0.5781 - val_accuracy: 0.7871\n",
      "Epoch 2/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.5702 - accuracy: 0.7954\n",
      "Epoch 00002: val_accuracy improved from 0.78706 to 0.83205, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.5702 - accuracy: 0.7954 - val_loss: 0.4484 - val_accuracy: 0.8320\n",
      "Epoch 3/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.4218 - accuracy: 0.8528\n",
      "Epoch 00003: val_accuracy did not improve from 0.83205\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.4220 - accuracy: 0.8529 - val_loss: 0.6764 - val_accuracy: 0.7288\n",
      "Epoch 4/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3312 - accuracy: 0.8851\n",
      "Epoch 00004: val_accuracy improved from 0.83205 to 0.91003, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.3312 - accuracy: 0.8851 - val_loss: 0.2753 - val_accuracy: 0.9100\n",
      "Epoch 5/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.9105\n",
      "Epoch 00005: val_accuracy did not improve from 0.91003\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.2670 - accuracy: 0.9105 - val_loss: 0.3063 - val_accuracy: 0.8942\n",
      "Epoch 6/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2106 - accuracy: 0.9269\n",
      "Epoch 00006: val_accuracy did not improve from 0.91003\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.2105 - accuracy: 0.9269 - val_loss: 0.4081 - val_accuracy: 0.8736\n",
      "Epoch 7/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1778 - accuracy: 0.9412\n",
      "Epoch 00007: val_accuracy improved from 0.91003 to 0.95673, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.1779 - accuracy: 0.9412 - val_loss: 0.1287 - val_accuracy: 0.9567\n",
      "Epoch 8/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1448 - accuracy: 0.9502\n",
      "Epoch 00008: val_accuracy did not improve from 0.95673\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.1447 - accuracy: 0.9502 - val_loss: 0.2124 - val_accuracy: 0.9327\n",
      "Epoch 9/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1296 - accuracy: 0.9562\n",
      "Epoch 00009: val_accuracy improved from 0.95673 to 0.96444, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.1296 - accuracy: 0.9562 - val_loss: 0.1016 - val_accuracy: 0.9644\n",
      "Epoch 10/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 0.9609\n",
      "Epoch 00010: val_accuracy did not improve from 0.96444\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.1161 - accuracy: 0.9609 - val_loss: 0.1109 - val_accuracy: 0.9550\n",
      "Epoch 11/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0994 - accuracy: 0.9670\n",
      "Epoch 00011: val_accuracy did not improve from 0.96444\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0995 - accuracy: 0.9670 - val_loss: 0.1314 - val_accuracy: 0.9563\n",
      "Epoch 12/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0843 - accuracy: 0.9713\n",
      "Epoch 00012: val_accuracy did not improve from 0.96444\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0844 - accuracy: 0.9712 - val_loss: 0.2747 - val_accuracy: 0.9126\n",
      "Epoch 13/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0750 - accuracy: 0.9753\n",
      "Epoch 00013: val_accuracy did not improve from 0.96444\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0749 - accuracy: 0.9753 - val_loss: 0.2901 - val_accuracy: 0.9165\n",
      "Epoch 14/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0713 - accuracy: 0.9762\n",
      "Epoch 00014: val_accuracy improved from 0.96444 to 0.96872, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0713 - accuracy: 0.9762 - val_loss: 0.0908 - val_accuracy: 0.9687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9789\n",
      "Epoch 00015: val_accuracy improved from 0.96872 to 0.97301, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0617 - accuracy: 0.9789 - val_loss: 0.0855 - val_accuracy: 0.9730\n",
      "Epoch 16/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9816\n",
      "Epoch 00016: val_accuracy improved from 0.97301 to 0.97515, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0533 - accuracy: 0.9816 - val_loss: 0.0671 - val_accuracy: 0.9751\n",
      "Epoch 17/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0459 - accuracy: 0.9838\n",
      "Epoch 00017: val_accuracy did not improve from 0.97515\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0460 - accuracy: 0.9837 - val_loss: 0.5212 - val_accuracy: 0.8650\n",
      "Epoch 18/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9857\n",
      "Epoch 00018: val_accuracy did not improve from 0.97515\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 0.1239 - val_accuracy: 0.9640\n",
      "Epoch 19/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9851\n",
      "Epoch 00019: val_accuracy improved from 0.97515 to 0.97901, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0449 - accuracy: 0.9851 - val_loss: 0.0717 - val_accuracy: 0.9790\n",
      "Epoch 20/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.9873\n",
      "Epoch 00020: val_accuracy improved from 0.97901 to 0.98372, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0388 - accuracy: 0.9873 - val_loss: 0.0697 - val_accuracy: 0.9837\n",
      "Epoch 21/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9883\n",
      "Epoch 00021: val_accuracy did not improve from 0.98372\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0344 - accuracy: 0.9883 - val_loss: 0.0636 - val_accuracy: 0.9829\n",
      "Epoch 22/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9902\n",
      "Epoch 00022: val_accuracy did not improve from 0.98372\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.0565 - val_accuracy: 0.9811\n",
      "Epoch 23/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9909\n",
      "Epoch 00023: val_accuracy did not improve from 0.98372\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 0.0715 - val_accuracy: 0.9833\n",
      "Epoch 24/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9922\n",
      "Epoch 00024: val_accuracy did not improve from 0.98372\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.2346 - val_accuracy: 0.9370\n",
      "Epoch 25/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9886\n",
      "Epoch 00025: val_accuracy did not improve from 0.98372\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0343 - accuracy: 0.9886 - val_loss: 0.0803 - val_accuracy: 0.9764\n",
      "Epoch 26/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9907\n",
      "Epoch 00026: val_accuracy improved from 0.98372 to 0.98886, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0272 - accuracy: 0.9907 - val_loss: 0.0398 - val_accuracy: 0.9889\n",
      "Epoch 27/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9932\n",
      "Epoch 00027: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0736 - val_accuracy: 0.9824\n",
      "Epoch 28/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9924\n",
      "Epoch 00028: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0216 - accuracy: 0.9924 - val_loss: 0.0609 - val_accuracy: 0.9841\n",
      "Epoch 29/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9945\n",
      "Epoch 00029: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0439 - val_accuracy: 0.9880\n",
      "Epoch 30/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9945\n",
      "Epoch 00030: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.1025 - val_accuracy: 0.9709\n",
      "Epoch 31/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9942\n",
      "Epoch 00031: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0497 - val_accuracy: 0.9889\n",
      "Epoch 32/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9942\n",
      "Epoch 00032: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.3929 - val_accuracy: 0.9083\n",
      "Epoch 33/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9936\n",
      "Epoch 00033: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.1297 - val_accuracy: 0.9657\n",
      "Epoch 34/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9941\n",
      "Epoch 00034: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0569 - val_accuracy: 0.9867\n",
      "Epoch 35/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9957\n",
      "Epoch 00035: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.0436 - val_accuracy: 0.9876\n",
      "Epoch 36/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9954\n",
      "Epoch 00036: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0524 - val_accuracy: 0.9876\n",
      "Epoch 37/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9946\n",
      "Epoch 00037: val_accuracy improved from 0.98886 to 0.98972, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.0401 - val_accuracy: 0.9897\n",
      "Epoch 38/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9946\n",
      "Epoch 00038: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.0563 - val_accuracy: 0.9820\n",
      "Epoch 39/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9943\n",
      "Epoch 00039: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.0461 - val_accuracy: 0.9880\n",
      "Epoch 40/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9972\n",
      "Epoch 00040: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0633 - val_accuracy: 0.9867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9951\n",
      "Epoch 00041: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0813 - val_accuracy: 0.9816\n",
      "Epoch 42/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9972\n",
      "Epoch 00042: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0506 - val_accuracy: 0.9884\n",
      "Epoch 43/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9974\n",
      "Epoch 00043: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0549 - val_accuracy: 0.9889\n",
      "Epoch 44/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9970\n",
      "Epoch 00044: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.1702 - val_accuracy: 0.9627\n",
      "Epoch 45/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9968\n",
      "Epoch 00045: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.0436 - val_accuracy: 0.9884\n",
      "Epoch 46/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 00046: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.8007 - val_accuracy: 0.8719\n",
      "Epoch 47/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9952\n",
      "Epoch 00047: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 2.8722 - val_accuracy: 0.6997\n",
      "Epoch 48/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9964\n",
      "Epoch 00048: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0491 - val_accuracy: 0.9884\n",
      "Epoch 49/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9964\n",
      "Epoch 00049: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.0624 - val_accuracy: 0.9846\n",
      "Epoch 50/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9975\n",
      "Epoch 00050: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0663 - val_accuracy: 0.9833\n",
      "Epoch 51/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 00051: val_accuracy improved from 0.98972 to 0.99143, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0367 - val_accuracy: 0.9914\n",
      "Epoch 52/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 00052: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1093 - val_accuracy: 0.9756\n",
      "Epoch 53/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9971\n",
      "Epoch 00053: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 4.3032 - val_accuracy: 0.6765\n",
      "Epoch 54/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.9971\n",
      "Epoch 00054: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0469 - val_accuracy: 0.9871\n",
      "Epoch 55/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9976\n",
      "Epoch 00055: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0356 - val_accuracy: 0.9914\n",
      "Epoch 56/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 00056: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0673 - val_accuracy: 0.9841\n",
      "Epoch 57/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984\n",
      "Epoch 00057: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0457 - val_accuracy: 0.9906\n",
      "Epoch 58/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982\n",
      "Epoch 00058: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0470 - val_accuracy: 0.9897\n",
      "Epoch 59/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9978\n",
      "Epoch 00059: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0591 - val_accuracy: 0.9897\n",
      "Epoch 60/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 00060: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0649 - val_accuracy: 0.9889\n",
      "Epoch 61/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9970\n",
      "Epoch 00061: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0617 - val_accuracy: 0.9859\n",
      "Epoch 62/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 00062: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0930 - val_accuracy: 0.9803\n",
      "Epoch 63/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9981\n",
      "Epoch 00063: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.0444 - val_accuracy: 0.9901\n",
      "Epoch 64/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 00064: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0475 - val_accuracy: 0.9893\n",
      "Epoch 65/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9980\n",
      "Epoch 00065: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0761 - val_accuracy: 0.9829\n",
      "Epoch 66/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 00066: val_accuracy improved from 0.99143 to 0.99186, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0417 - val_accuracy: 0.9919\n",
      "Epoch 67/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 00067: val_accuracy did not improve from 0.99186\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0453 - val_accuracy: 0.9880\n",
      "Epoch 68/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00068: val_accuracy did not improve from 0.99186\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1768 - val_accuracy: 0.9687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 00069: val_accuracy improved from 0.99186 to 0.99314, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0384 - val_accuracy: 0.9931\n",
      "Epoch 70/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n",
      "Epoch 00070: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0405 - val_accuracy: 0.9927\n",
      "Epoch 71/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 00071: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0451 - val_accuracy: 0.9927\n",
      "Epoch 72/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 00072: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0532 - val_accuracy: 0.9919\n",
      "Epoch 73/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 00073: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0515 - val_accuracy: 0.9897\n",
      "Epoch 74/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 00074: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0439 - val_accuracy: 0.9906\n",
      "Epoch 75/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 00075: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0431 - val_accuracy: 0.9910\n",
      "Epoch 76/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9985\n",
      "Epoch 00076: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0425 - val_accuracy: 0.9919\n",
      "Epoch 77/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00077: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0463 - val_accuracy: 0.9923\n",
      "Epoch 78/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 00078: val_accuracy improved from 0.99314 to 0.99357, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0362 - val_accuracy: 0.9936\n",
      "Epoch 79/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 00079: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0760 - val_accuracy: 0.9863\n",
      "Epoch 80/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9973\n",
      "Epoch 00080: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0492 - val_accuracy: 0.9901\n",
      "Epoch 81/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 00081: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0553 - val_accuracy: 0.9910\n",
      "Epoch 82/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 00082: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1491 - val_accuracy: 0.9739\n",
      "Epoch 83/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984\n",
      "Epoch 00083: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0576 - val_accuracy: 0.9910\n",
      "Epoch 84/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00084: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0432 - val_accuracy: 0.9919\n",
      "Epoch 85/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 00085: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0414 - val_accuracy: 0.9910\n",
      "Epoch 86/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 00086: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.1666 - val_accuracy: 0.9743\n",
      "Epoch 87/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9982\n",
      "Epoch 00087: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1232 - val_accuracy: 0.9751\n",
      "Epoch 88/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 00088: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0760 - val_accuracy: 0.9850\n",
      "Epoch 89/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 00089: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0448 - val_accuracy: 0.9919\n",
      "Epoch 90/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 00090: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0547 - val_accuracy: 0.9897\n",
      "Epoch 91/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 00091: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0523 - val_accuracy: 0.9919\n",
      "Epoch 92/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 00092: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0453 - val_accuracy: 0.9923\n",
      "Epoch 93/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 00093: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0855 - val_accuracy: 0.9837\n",
      "Epoch 94/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 00094: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0525 - val_accuracy: 0.9906\n",
      "Epoch 95/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 00095: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0612 - val_accuracy: 0.9914\n",
      "Epoch 96/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 00096: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0449 - val_accuracy: 0.9927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00097: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0572 - val_accuracy: 0.9876\n",
      "Epoch 98/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 00098: val_accuracy did not improve from 0.99357\n",
      "Restoring model weights from the end of the best epoch.\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0683 - val_accuracy: 0.9893\n",
      "Epoch 00098: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:31:50<00:00, 2755.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.72      0.92      0.81       594\n",
      "        car_horn       0.97      0.89      0.93       588\n",
      "children_playing       0.89      0.78      0.83       600\n",
      "        dog_bark       0.88      0.87      0.87       600\n",
      "           siren       0.97      0.90      0.93       426\n",
      "\n",
      "        accuracy                           0.87      2808\n",
      "       macro avg       0.89      0.87      0.87      2808\n",
      "    weighted avg       0.88      0.87      0.87      2808\n",
      "\n",
      "\n",
      "Validation fold: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21373, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21373, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2375, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2375, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2400, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2400, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_13\n",
      "Epoch 1/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 1.1537 - accuracy: 0.6149\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70905, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 1.1537 - accuracy: 0.6149 - val_loss: 0.8128 - val_accuracy: 0.7091\n",
      "Epoch 2/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.7519 - accuracy: 0.7284\n",
      "Epoch 00002: val_accuracy improved from 0.70905 to 0.76168, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.7519 - accuracy: 0.7284 - val_loss: 0.6863 - val_accuracy: 0.7617\n",
      "Epoch 3/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.6325 - accuracy: 0.7700\n",
      "Epoch 00003: val_accuracy improved from 0.76168 to 0.77053, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.6327 - accuracy: 0.7699 - val_loss: 0.6473 - val_accuracy: 0.7705\n",
      "Epoch 4/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.5476 - accuracy: 0.7995\n",
      "Epoch 00004: val_accuracy improved from 0.77053 to 0.85558, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.5474 - accuracy: 0.7995 - val_loss: 0.4215 - val_accuracy: 0.8556\n",
      "Epoch 5/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.4887 - accuracy: 0.8221\n",
      "Epoch 00005: val_accuracy did not improve from 0.85558\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.4885 - accuracy: 0.8222 - val_loss: 0.5592 - val_accuracy: 0.8131\n",
      "Epoch 6/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.4492 - accuracy: 0.8385\n",
      "Epoch 00006: val_accuracy did not improve from 0.85558\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.4492 - accuracy: 0.8386 - val_loss: 0.5462 - val_accuracy: 0.8362\n",
      "Epoch 7/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.4022 - accuracy: 0.8525\n",
      "Epoch 00007: val_accuracy did not improve from 0.85558\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.4023 - accuracy: 0.8524 - val_loss: 0.5808 - val_accuracy: 0.8122\n",
      "Epoch 8/100\n",
      "666/668 [============================>.] - ETA: 0s - loss: 0.3699 - accuracy: 0.8638\n",
      "Epoch 00008: val_accuracy did not improve from 0.85558\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.3697 - accuracy: 0.8639 - val_loss: 0.6532 - val_accuracy: 0.7857\n",
      "Epoch 9/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3307 - accuracy: 0.8780\n",
      "Epoch 00009: val_accuracy improved from 0.85558 to 0.89474, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.3310 - accuracy: 0.8781 - val_loss: 0.3011 - val_accuracy: 0.8947\n",
      "Epoch 10/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3102 - accuracy: 0.8892\n",
      "Epoch 00010: val_accuracy improved from 0.89474 to 0.89895, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.3100 - accuracy: 0.8893 - val_loss: 0.2721 - val_accuracy: 0.8989\n",
      "Epoch 11/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2857 - accuracy: 0.8961\n",
      "Epoch 00011: val_accuracy improved from 0.89895 to 0.91958, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.2857 - accuracy: 0.8961 - val_loss: 0.2357 - val_accuracy: 0.9196\n",
      "Epoch 12/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.9014\n",
      "Epoch 00012: val_accuracy did not improve from 0.91958\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2660 - accuracy: 0.9014 - val_loss: 0.2675 - val_accuracy: 0.9006\n",
      "Epoch 13/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2501 - accuracy: 0.9071\n",
      "Epoch 00013: val_accuracy did not improve from 0.91958\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2500 - accuracy: 0.9071 - val_loss: 0.3156 - val_accuracy: 0.8981\n",
      "Epoch 14/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2347 - accuracy: 0.9127\n",
      "Epoch 00014: val_accuracy improved from 0.91958 to 0.93095, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.2347 - accuracy: 0.9126 - val_loss: 0.2014 - val_accuracy: 0.9309\n",
      "Epoch 15/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2290 - accuracy: 0.9171\n",
      "Epoch 00015: val_accuracy did not improve from 0.93095\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2289 - accuracy: 0.9171 - val_loss: 0.3201 - val_accuracy: 0.8947\n",
      "Epoch 16/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2109 - accuracy: 0.9215\n",
      "Epoch 00016: val_accuracy improved from 0.93095 to 0.93895, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.2109 - accuracy: 0.9215 - val_loss: 0.1844 - val_accuracy: 0.9389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2052 - accuracy: 0.9261\n",
      "Epoch 00017: val_accuracy improved from 0.93895 to 0.94147, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.2055 - accuracy: 0.9261 - val_loss: 0.1930 - val_accuracy: 0.9415\n",
      "Epoch 18/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1911 - accuracy: 0.9307\n",
      "Epoch 00018: val_accuracy did not improve from 0.94147\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1911 - accuracy: 0.9306 - val_loss: 0.2066 - val_accuracy: 0.9284\n",
      "Epoch 19/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.9324\n",
      "Epoch 00019: val_accuracy improved from 0.94147 to 0.95284, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1764 - accuracy: 0.9325 - val_loss: 0.1468 - val_accuracy: 0.9528\n",
      "Epoch 20/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1700 - accuracy: 0.9391\n",
      "Epoch 00020: val_accuracy did not improve from 0.95284\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1703 - accuracy: 0.9389 - val_loss: 0.1577 - val_accuracy: 0.9444\n",
      "Epoch 21/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1582 - accuracy: 0.9425\n",
      "Epoch 00021: val_accuracy did not improve from 0.95284\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1583 - accuracy: 0.9424 - val_loss: 0.1676 - val_accuracy: 0.9411\n",
      "Epoch 22/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 0.9448\n",
      "Epoch 00022: val_accuracy improved from 0.95284 to 0.96000, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1535 - accuracy: 0.9448 - val_loss: 0.1288 - val_accuracy: 0.9600\n",
      "Epoch 23/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1463 - accuracy: 0.9482\n",
      "Epoch 00023: val_accuracy did not improve from 0.96000\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1465 - accuracy: 0.9482 - val_loss: 0.1594 - val_accuracy: 0.9495\n",
      "Epoch 24/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.9445\n",
      "Epoch 00024: val_accuracy did not improve from 0.96000\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1500 - accuracy: 0.9444 - val_loss: 0.1283 - val_accuracy: 0.9549\n",
      "Epoch 25/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1324 - accuracy: 0.9506\n",
      "Epoch 00025: val_accuracy did not improve from 0.96000\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1323 - accuracy: 0.9506 - val_loss: 0.1321 - val_accuracy: 0.9558\n",
      "Epoch 26/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1245 - accuracy: 0.9549\n",
      "Epoch 00026: val_accuracy did not improve from 0.96000\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1245 - accuracy: 0.9549 - val_loss: 0.1311 - val_accuracy: 0.9575\n",
      "Epoch 27/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1233 - accuracy: 0.9535\n",
      "Epoch 00027: val_accuracy improved from 0.96000 to 0.96632, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1232 - accuracy: 0.9536 - val_loss: 0.1086 - val_accuracy: 0.9663\n",
      "Epoch 28/100\n",
      "666/668 [============================>.] - ETA: 0s - loss: 0.1193 - accuracy: 0.9580\n",
      "Epoch 00028: val_accuracy improved from 0.96632 to 0.97137, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1192 - accuracy: 0.9580 - val_loss: 0.0910 - val_accuracy: 0.9714\n",
      "Epoch 29/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1177 - accuracy: 0.9580\n",
      "Epoch 00029: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1177 - accuracy: 0.9579 - val_loss: 0.1031 - val_accuracy: 0.9672\n",
      "Epoch 30/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1083 - accuracy: 0.9606\n",
      "Epoch 00030: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1084 - accuracy: 0.9605 - val_loss: 0.1354 - val_accuracy: 0.9604\n",
      "Epoch 31/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1031 - accuracy: 0.9628\n",
      "Epoch 00031: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1030 - accuracy: 0.9629 - val_loss: 0.1138 - val_accuracy: 0.9638\n",
      "Epoch 32/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 0.9626\n",
      "Epoch 00032: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1024 - accuracy: 0.9627 - val_loss: 0.1081 - val_accuracy: 0.9672\n",
      "Epoch 33/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1001 - accuracy: 0.9639\n",
      "Epoch 00033: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1001 - accuracy: 0.9639 - val_loss: 0.1034 - val_accuracy: 0.9642\n",
      "Epoch 34/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9674\n",
      "Epoch 00034: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0929 - accuracy: 0.9675 - val_loss: 0.1476 - val_accuracy: 0.9503\n",
      "Epoch 35/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0886 - accuracy: 0.9678\n",
      "Epoch 00035: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0886 - accuracy: 0.9679 - val_loss: 0.1049 - val_accuracy: 0.9642\n",
      "Epoch 36/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0863 - accuracy: 0.9698\n",
      "Epoch 00036: val_accuracy improved from 0.97137 to 0.97726, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0862 - accuracy: 0.9699 - val_loss: 0.0789 - val_accuracy: 0.9773\n",
      "Epoch 37/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9675\n",
      "Epoch 00037: val_accuracy did not improve from 0.97726\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0861 - accuracy: 0.9675 - val_loss: 0.1480 - val_accuracy: 0.9575\n",
      "Epoch 38/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0785 - accuracy: 0.9730\n",
      "Epoch 00038: val_accuracy improved from 0.97726 to 0.97979, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0785 - accuracy: 0.9730 - val_loss: 0.0674 - val_accuracy: 0.9798\n",
      "Epoch 39/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9703\n",
      "Epoch 00039: val_accuracy improved from 0.97979 to 0.98105, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0805 - accuracy: 0.9703 - val_loss: 0.0666 - val_accuracy: 0.9811\n",
      "Epoch 40/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0829 - accuracy: 0.9705\n",
      "Epoch 00040: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0828 - accuracy: 0.9705 - val_loss: 0.0904 - val_accuracy: 0.9739\n",
      "Epoch 41/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0779 - accuracy: 0.9725\n",
      "Epoch 00041: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0779 - accuracy: 0.9725 - val_loss: 0.0832 - val_accuracy: 0.9743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9746\n",
      "Epoch 00042: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0693 - accuracy: 0.9745 - val_loss: 0.0815 - val_accuracy: 0.9773\n",
      "Epoch 43/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9733\n",
      "Epoch 00043: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0711 - accuracy: 0.9733 - val_loss: 0.0882 - val_accuracy: 0.9739\n",
      "Epoch 44/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0704 - accuracy: 0.9745\n",
      "Epoch 00044: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0703 - accuracy: 0.9745 - val_loss: 0.0962 - val_accuracy: 0.9735\n",
      "Epoch 45/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9755\n",
      "Epoch 00045: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0693 - accuracy: 0.9755 - val_loss: 0.0570 - val_accuracy: 0.9806\n",
      "Epoch 46/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9774\n",
      "Epoch 00046: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0634 - accuracy: 0.9774 - val_loss: 0.0605 - val_accuracy: 0.9802\n",
      "Epoch 47/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 0.9786\n",
      "Epoch 00047: val_accuracy improved from 0.98105 to 0.98358, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0619 - accuracy: 0.9786 - val_loss: 0.0540 - val_accuracy: 0.9836\n",
      "Epoch 48/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0568 - accuracy: 0.9794\n",
      "Epoch 00048: val_accuracy did not improve from 0.98358\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0568 - accuracy: 0.9795 - val_loss: 0.0749 - val_accuracy: 0.9802\n",
      "Epoch 49/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0583 - accuracy: 0.9800\n",
      "Epoch 00049: val_accuracy improved from 0.98358 to 0.98653, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0583 - accuracy: 0.9800 - val_loss: 0.0522 - val_accuracy: 0.9865\n",
      "Epoch 50/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9798\n",
      "Epoch 00050: val_accuracy did not improve from 0.98653\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0579 - accuracy: 0.9798 - val_loss: 0.0547 - val_accuracy: 0.9857\n",
      "Epoch 51/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9781\n",
      "Epoch 00051: val_accuracy did not improve from 0.98653\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0587 - accuracy: 0.9781 - val_loss: 0.0702 - val_accuracy: 0.9798\n",
      "Epoch 52/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9803\n",
      "Epoch 00052: val_accuracy did not improve from 0.98653\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0565 - accuracy: 0.9803 - val_loss: 0.0619 - val_accuracy: 0.9827\n",
      "Epoch 53/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9792\n",
      "Epoch 00053: val_accuracy improved from 0.98653 to 0.98779, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0565 - accuracy: 0.9792 - val_loss: 0.0496 - val_accuracy: 0.9878\n",
      "Epoch 54/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0553 - accuracy: 0.9811\n",
      "Epoch 00054: val_accuracy did not improve from 0.98779\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0552 - accuracy: 0.9811 - val_loss: 0.0527 - val_accuracy: 0.9853\n",
      "Epoch 55/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 0.9800\n",
      "Epoch 00055: val_accuracy improved from 0.98779 to 0.98821, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0551 - accuracy: 0.9800 - val_loss: 0.0420 - val_accuracy: 0.9882\n",
      "Epoch 56/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9810\n",
      "Epoch 00056: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0514 - accuracy: 0.9811 - val_loss: 0.0510 - val_accuracy: 0.9861\n",
      "Epoch 57/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9822\n",
      "Epoch 00057: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0495 - accuracy: 0.9823 - val_loss: 0.0473 - val_accuracy: 0.9840\n",
      "Epoch 58/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0489 - accuracy: 0.9830\n",
      "Epoch 00058: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0489 - accuracy: 0.9831 - val_loss: 0.1001 - val_accuracy: 0.9714\n",
      "Epoch 59/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 0.9821\n",
      "Epoch 00059: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0496 - accuracy: 0.9821 - val_loss: 0.0394 - val_accuracy: 0.9878\n",
      "Epoch 60/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9837\n",
      "Epoch 00060: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0465 - accuracy: 0.9837 - val_loss: 0.0496 - val_accuracy: 0.9853\n",
      "Epoch 61/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0467 - accuracy: 0.9830\n",
      "Epoch 00061: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0467 - accuracy: 0.9831 - val_loss: 0.0604 - val_accuracy: 0.9840\n",
      "Epoch 62/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0446 - accuracy: 0.9846\n",
      "Epoch 00062: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0446 - accuracy: 0.9846 - val_loss: 0.0523 - val_accuracy: 0.9844\n",
      "Epoch 63/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9829\n",
      "Epoch 00063: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0476 - accuracy: 0.9830 - val_loss: 0.0575 - val_accuracy: 0.9832\n",
      "Epoch 64/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0411 - accuracy: 0.9855\n",
      "Epoch 00064: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0411 - accuracy: 0.9855 - val_loss: 0.0616 - val_accuracy: 0.9823\n",
      "Epoch 65/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9860\n",
      "Epoch 00065: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0393 - accuracy: 0.9861 - val_loss: 0.0726 - val_accuracy: 0.9827\n",
      "Epoch 66/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9861\n",
      "Epoch 00066: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0414 - accuracy: 0.9861 - val_loss: 0.0583 - val_accuracy: 0.9836\n",
      "Epoch 67/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9863\n",
      "Epoch 00067: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0399 - accuracy: 0.9863 - val_loss: 0.0397 - val_accuracy: 0.9882\n",
      "Epoch 68/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9863\n",
      "Epoch 00068: val_accuracy improved from 0.98821 to 0.98905, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0420 - accuracy: 0.9863 - val_loss: 0.0366 - val_accuracy: 0.9891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0427 - accuracy: 0.9855\n",
      "Epoch 00069: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0427 - accuracy: 0.9855 - val_loss: 0.0381 - val_accuracy: 0.9891\n",
      "Epoch 70/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0392 - accuracy: 0.9859\n",
      "Epoch 00070: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0391 - accuracy: 0.9860 - val_loss: 0.0859 - val_accuracy: 0.9722\n",
      "Epoch 71/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9874\n",
      "Epoch 00071: val_accuracy improved from 0.98905 to 0.98947, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0360 - accuracy: 0.9874 - val_loss: 0.0400 - val_accuracy: 0.9895\n",
      "Epoch 72/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9873\n",
      "Epoch 00072: val_accuracy did not improve from 0.98947\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 0.0428 - val_accuracy: 0.9886\n",
      "Epoch 73/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9880\n",
      "Epoch 00073: val_accuracy did not improve from 0.98947\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0347 - accuracy: 0.9880 - val_loss: 0.0429 - val_accuracy: 0.9869\n",
      "Epoch 74/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0357 - accuracy: 0.9869\n",
      "Epoch 00074: val_accuracy did not improve from 0.98947\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0357 - accuracy: 0.9869 - val_loss: 0.0510 - val_accuracy: 0.9840\n",
      "Epoch 75/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9878\n",
      "Epoch 00075: val_accuracy did not improve from 0.98947\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0371 - accuracy: 0.9877 - val_loss: 0.0449 - val_accuracy: 0.9865\n",
      "Epoch 76/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9892\n",
      "Epoch 00076: val_accuracy did not improve from 0.98947\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.0420 - val_accuracy: 0.9874\n",
      "Epoch 77/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9877\n",
      "Epoch 00077: val_accuracy did not improve from 0.98947\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0352 - accuracy: 0.9877 - val_loss: 0.0405 - val_accuracy: 0.9886\n",
      "Epoch 78/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9890\n",
      "Epoch 00078: val_accuracy improved from 0.98947 to 0.99032, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0318 - accuracy: 0.9891 - val_loss: 0.0421 - val_accuracy: 0.9903\n",
      "Epoch 79/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9876\n",
      "Epoch 00079: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0338 - accuracy: 0.9876 - val_loss: 0.0429 - val_accuracy: 0.9874\n",
      "Epoch 80/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9884\n",
      "Epoch 00080: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0326 - accuracy: 0.9884 - val_loss: 0.0409 - val_accuracy: 0.9878\n",
      "Epoch 81/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9880\n",
      "Epoch 00081: val_accuracy improved from 0.99032 to 0.99074, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0344 - accuracy: 0.9880 - val_loss: 0.0340 - val_accuracy: 0.9907\n",
      "Epoch 82/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0328 - accuracy: 0.9882\n",
      "Epoch 00082: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0328 - accuracy: 0.9883 - val_loss: 0.0374 - val_accuracy: 0.9899\n",
      "Epoch 83/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9900\n",
      "Epoch 00083: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 0.0409 - val_accuracy: 0.9869\n",
      "Epoch 84/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9891\n",
      "Epoch 00084: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0315 - accuracy: 0.9891 - val_loss: 0.0398 - val_accuracy: 0.9882\n",
      "Epoch 85/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9904\n",
      "Epoch 00085: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0279 - accuracy: 0.9904 - val_loss: 0.0507 - val_accuracy: 0.9865\n",
      "Epoch 86/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9897\n",
      "Epoch 00086: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0295 - accuracy: 0.9898 - val_loss: 0.0378 - val_accuracy: 0.9886\n",
      "Epoch 87/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9914\n",
      "Epoch 00087: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0251 - accuracy: 0.9914 - val_loss: 0.0568 - val_accuracy: 0.9836\n",
      "Epoch 88/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9904\n",
      "Epoch 00088: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0295 - accuracy: 0.9904 - val_loss: 0.0413 - val_accuracy: 0.9865\n",
      "Epoch 89/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9901\n",
      "Epoch 00089: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0281 - accuracy: 0.9901 - val_loss: 0.0509 - val_accuracy: 0.9844\n",
      "Epoch 90/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9906\n",
      "Epoch 00090: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.0340 - val_accuracy: 0.9907\n",
      "Epoch 91/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9909\n",
      "Epoch 00091: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0276 - accuracy: 0.9909 - val_loss: 0.0420 - val_accuracy: 0.9895\n",
      "Epoch 92/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9895\n",
      "Epoch 00092: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0294 - accuracy: 0.9895 - val_loss: 0.0420 - val_accuracy: 0.9903\n",
      "Epoch 93/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9912\n",
      "Epoch 00093: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.0378 - val_accuracy: 0.9891\n",
      "Epoch 94/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9918\n",
      "Epoch 00094: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.0292 - val_accuracy: 0.9903\n",
      "Epoch 95/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9903\n",
      "Epoch 00095: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0260 - accuracy: 0.9903 - val_loss: 0.0380 - val_accuracy: 0.9886\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/668 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9911\n",
      "Epoch 00096: val_accuracy improved from 0.99074 to 0.99116, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.0262 - val_accuracy: 0.9912\n",
      "Epoch 97/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9907\n",
      "Epoch 00097: val_accuracy did not improve from 0.99116\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0252 - accuracy: 0.9907 - val_loss: 0.0476 - val_accuracy: 0.9857\n",
      "Epoch 98/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9919\n",
      "Epoch 00098: val_accuracy did not improve from 0.99116\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0432 - val_accuracy: 0.9869\n",
      "Epoch 99/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9914\n",
      "Epoch 00099: val_accuracy improved from 0.99116 to 0.99284, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.0276 - val_accuracy: 0.9928\n",
      "Epoch 100/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9911\n",
      "Epoch 00100: val_accuracy did not improve from 0.99284\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.0443 - val_accuracy: 0.9827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [25:09<25:09, 1509.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.80      0.78      0.79       588\n",
      "        car_horn       0.76      0.88      0.81       168\n",
      "children_playing       0.87      0.94      0.91       600\n",
      "        dog_bark       0.92      0.92      0.92       600\n",
      "           siren       0.86      0.75      0.80       444\n",
      "\n",
      "        accuracy                           0.86      2400\n",
      "       macro avg       0.84      0.85      0.85      2400\n",
      "    weighted avg       0.86      0.86      0.86      2400\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_14\n",
      "Epoch 1/100\n",
      "  2/668 [..............................] - ETA: 20s - loss: 2.2205 - accuracy: 0.1406WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0220s vs `on_train_batch_end` time: 0.0382s). Check your callbacks.\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.9125 - accuracy: 0.6621\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76463, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 63ms/step - loss: 0.9125 - accuracy: 0.6621 - val_loss: 0.6816 - val_accuracy: 0.7646\n",
      "Epoch 2/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.8147\n",
      "Epoch 00002: val_accuracy improved from 0.76463 to 0.79747, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.5393 - accuracy: 0.8147 - val_loss: 0.5377 - val_accuracy: 0.7975\n",
      "Epoch 3/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.3991 - accuracy: 0.8633\n",
      "Epoch 00003: val_accuracy improved from 0.79747 to 0.82905, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.3991 - accuracy: 0.8633 - val_loss: 0.4842 - val_accuracy: 0.8291\n",
      "Epoch 4/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.8951\n",
      "Epoch 00004: val_accuracy improved from 0.82905 to 0.84168, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.3042 - accuracy: 0.8951 - val_loss: 0.4720 - val_accuracy: 0.8417\n",
      "Epoch 5/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.2486 - accuracy: 0.9145\n",
      "Epoch 00005: val_accuracy improved from 0.84168 to 0.91411, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.2486 - accuracy: 0.9145 - val_loss: 0.2490 - val_accuracy: 0.9141\n",
      "Epoch 6/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.9279\n",
      "Epoch 00006: val_accuracy improved from 0.91411 to 0.91621, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.2064 - accuracy: 0.9279 - val_loss: 0.2330 - val_accuracy: 0.9162\n",
      "Epoch 7/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.1622 - accuracy: 0.9450\n",
      "Epoch 00007: val_accuracy improved from 0.91621 to 0.95747, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1622 - accuracy: 0.9450 - val_loss: 0.1188 - val_accuracy: 0.9575\n",
      "Epoch 8/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.9513\n",
      "Epoch 00008: val_accuracy did not improve from 0.95747\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.1422 - accuracy: 0.9513 - val_loss: 0.2230 - val_accuracy: 0.9276\n",
      "Epoch 9/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9603\n",
      "Epoch 00009: val_accuracy did not improve from 0.95747\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1160 - accuracy: 0.9603 - val_loss: 0.1599 - val_accuracy: 0.9436\n",
      "Epoch 10/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9646\n",
      "Epoch 00010: val_accuracy improved from 0.95747 to 0.96000, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1008 - accuracy: 0.9646 - val_loss: 0.1115 - val_accuracy: 0.9600\n",
      "Epoch 11/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9707\n",
      "Epoch 00011: val_accuracy did not improve from 0.96000\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0848 - accuracy: 0.9707 - val_loss: 0.1267 - val_accuracy: 0.9583\n",
      "Epoch 12/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9752\n",
      "Epoch 00012: val_accuracy improved from 0.96000 to 0.96379, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0773 - accuracy: 0.9752 - val_loss: 0.1144 - val_accuracy: 0.9638\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/668 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9783\n",
      "Epoch 00013: val_accuracy did not improve from 0.96379\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0663 - accuracy: 0.9783 - val_loss: 0.4263 - val_accuracy: 0.8792\n",
      "Epoch 14/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9800\n",
      "Epoch 00014: val_accuracy improved from 0.96379 to 0.97095, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0590 - accuracy: 0.9800 - val_loss: 0.0932 - val_accuracy: 0.9709\n",
      "Epoch 15/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9798\n",
      "Epoch 00015: val_accuracy improved from 0.97095 to 0.97600, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0593 - accuracy: 0.9798 - val_loss: 0.0818 - val_accuracy: 0.9760\n",
      "Epoch 16/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9843\n",
      "Epoch 00016: val_accuracy did not improve from 0.97600\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0470 - accuracy: 0.9843 - val_loss: 0.1100 - val_accuracy: 0.9667\n",
      "Epoch 17/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9848\n",
      "Epoch 00017: val_accuracy did not improve from 0.97600\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0470 - accuracy: 0.9848 - val_loss: 0.0889 - val_accuracy: 0.9731\n",
      "Epoch 18/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9846\n",
      "Epoch 00018: val_accuracy did not improve from 0.97600\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0429 - accuracy: 0.9846 - val_loss: 0.0803 - val_accuracy: 0.9747\n",
      "Epoch 19/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9873\n",
      "Epoch 00019: val_accuracy did not improve from 0.97600\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0369 - accuracy: 0.9873 - val_loss: 0.1176 - val_accuracy: 0.9642\n",
      "Epoch 20/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9885\n",
      "Epoch 00020: val_accuracy improved from 0.97600 to 0.98442, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 0.0586 - val_accuracy: 0.9844\n",
      "Epoch 21/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9870\n",
      "Epoch 00021: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0386 - accuracy: 0.9870 - val_loss: 0.1284 - val_accuracy: 0.9621\n",
      "Epoch 22/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9884\n",
      "Epoch 00022: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.0903 - val_accuracy: 0.9752\n",
      "Epoch 23/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9896\n",
      "Epoch 00023: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0310 - accuracy: 0.9896 - val_loss: 0.0888 - val_accuracy: 0.9760\n",
      "Epoch 24/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9921\n",
      "Epoch 00024: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.1653 - val_accuracy: 0.9579\n",
      "Epoch 25/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9936\n",
      "Epoch 00025: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.0724 - val_accuracy: 0.9819\n",
      "Epoch 26/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9910\n",
      "Epoch 00026: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0254 - accuracy: 0.9910 - val_loss: 0.1132 - val_accuracy: 0.9718\n",
      "Epoch 27/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9933\n",
      "Epoch 00027: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.0781 - val_accuracy: 0.9823\n",
      "Epoch 28/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9935\n",
      "Epoch 00028: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.0640 - val_accuracy: 0.9827\n",
      "Epoch 29/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9952\n",
      "Epoch 00029: val_accuracy improved from 0.98442 to 0.98526, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0540 - val_accuracy: 0.9853\n",
      "Epoch 30/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9956\n",
      "Epoch 00030: val_accuracy improved from 0.98526 to 0.98568, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.0696 - val_accuracy: 0.9857\n",
      "Epoch 31/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9915\n",
      "Epoch 00031: val_accuracy did not improve from 0.98568\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.1011 - val_accuracy: 0.9697\n",
      "Epoch 32/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9942\n",
      "Epoch 00032: val_accuracy did not improve from 0.98568\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0582 - val_accuracy: 0.9802\n",
      "Epoch 33/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9951\n",
      "Epoch 00033: val_accuracy improved from 0.98568 to 0.98737, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.0505 - val_accuracy: 0.9874\n",
      "Epoch 34/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9950\n",
      "Epoch 00034: val_accuracy did not improve from 0.98737\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.0790 - val_accuracy: 0.9789\n",
      "Epoch 35/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9941\n",
      "Epoch 00035: val_accuracy did not improve from 0.98737\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.1075 - val_accuracy: 0.9794\n",
      "Epoch 36/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9958\n",
      "Epoch 00036: val_accuracy did not improve from 0.98737\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0502 - val_accuracy: 0.9861\n",
      "Epoch 37/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9961\n",
      "Epoch 00037: val_accuracy did not improve from 0.98737\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0852 - val_accuracy: 0.9815\n",
      "Epoch 38/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9965\n",
      "Epoch 00038: val_accuracy improved from 0.98737 to 0.98863, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0533 - val_accuracy: 0.9886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9962\n",
      "Epoch 00039: val_accuracy did not improve from 0.98863\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.0673 - val_accuracy: 0.9823\n",
      "Epoch 40/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9955\n",
      "Epoch 00040: val_accuracy did not improve from 0.98863\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.0546 - val_accuracy: 0.9865\n",
      "Epoch 41/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9966\n",
      "Epoch 00041: val_accuracy did not improve from 0.98863\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0666 - val_accuracy: 0.9819\n",
      "Epoch 42/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9969\n",
      "Epoch 00042: val_accuracy did not improve from 0.98863\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0844 - val_accuracy: 0.9836\n",
      "Epoch 43/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9958\n",
      "Epoch 00043: val_accuracy did not improve from 0.98863\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0781 - val_accuracy: 0.9840\n",
      "Epoch 44/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9959\n",
      "Epoch 00044: val_accuracy did not improve from 0.98863\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0570 - val_accuracy: 0.9853\n",
      "Epoch 45/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9966\n",
      "Epoch 00045: val_accuracy improved from 0.98863 to 0.98905, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0503 - val_accuracy: 0.9891\n",
      "Epoch 46/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 00046: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0513 - val_accuracy: 0.9891\n",
      "Epoch 47/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9971\n",
      "Epoch 00047: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0541 - val_accuracy: 0.9882\n",
      "Epoch 48/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9978\n",
      "Epoch 00048: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0517 - val_accuracy: 0.9865\n",
      "Epoch 49/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 00049: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0556 - val_accuracy: 0.9874\n",
      "Epoch 50/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9965\n",
      "Epoch 00050: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0765 - val_accuracy: 0.9811\n",
      "Epoch 51/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9971\n",
      "Epoch 00051: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0827 - val_accuracy: 0.9861\n",
      "Epoch 52/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9978\n",
      "Epoch 00052: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0929 - val_accuracy: 0.9815\n",
      "Epoch 53/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 00053: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0803 - val_accuracy: 0.9811\n",
      "Epoch 54/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9978\n",
      "Epoch 00054: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0664 - val_accuracy: 0.9891\n",
      "Epoch 55/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984\n",
      "Epoch 00055: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0653 - val_accuracy: 0.9857\n",
      "Epoch 56/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 00056: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0770 - val_accuracy: 0.9857\n",
      "Epoch 57/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 00057: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0967 - val_accuracy: 0.9794\n",
      "Epoch 58/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9967\n",
      "Epoch 00058: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0697 - val_accuracy: 0.9844\n",
      "Epoch 59/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 00059: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0584 - val_accuracy: 0.9891\n",
      "Epoch 60/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9976\n",
      "Epoch 00060: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0952 - val_accuracy: 0.9811\n",
      "Epoch 61/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9971\n",
      "Epoch 00061: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0656 - val_accuracy: 0.9882\n",
      "Epoch 62/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9980\n",
      "Epoch 00062: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0498 - val_accuracy: 0.9891\n",
      "Epoch 63/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 00063: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0583 - val_accuracy: 0.9886\n",
      "Epoch 64/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 00064: val_accuracy improved from 0.98905 to 0.99032, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0522 - val_accuracy: 0.9903\n",
      "Epoch 65/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 00065: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0682 - val_accuracy: 0.9869\n",
      "Epoch 66/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 00066: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0572 - val_accuracy: 0.9886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9979\n",
      "Epoch 00067: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0621 - val_accuracy: 0.9886\n",
      "Epoch 68/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 00068: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0618 - val_accuracy: 0.9895\n",
      "Epoch 69/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 00069: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0864 - val_accuracy: 0.9861\n",
      "Epoch 70/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 00070: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0722 - val_accuracy: 0.9836\n",
      "Epoch 71/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 00071: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0598 - val_accuracy: 0.9891\n",
      "Epoch 72/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 00072: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0615 - val_accuracy: 0.9891\n",
      "Epoch 73/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 00073: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0717 - val_accuracy: 0.9869\n",
      "Epoch 74/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9988\n",
      "Epoch 00074: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0638 - val_accuracy: 0.9874\n",
      "Epoch 75/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 00075: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0595 - val_accuracy: 0.9878\n",
      "Epoch 76/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00076: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0623 - val_accuracy: 0.9891\n",
      "Epoch 77/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n",
      "Epoch 00077: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0671 - val_accuracy: 0.9903\n",
      "Epoch 78/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n",
      "Epoch 00078: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0630 - val_accuracy: 0.9903\n",
      "Epoch 79/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 00079: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0675 - val_accuracy: 0.9903\n",
      "Epoch 80/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 00080: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0716 - val_accuracy: 0.9903\n",
      "Epoch 81/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 00081: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0757 - val_accuracy: 0.9903\n",
      "Epoch 82/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989\n",
      "Epoch 00082: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0665 - val_accuracy: 0.9895\n",
      "Epoch 83/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 00083: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0639 - val_accuracy: 0.9899\n",
      "Epoch 84/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 00084: val_accuracy did not improve from 0.99032\n",
      "Restoring model weights from the end of the best epoch.\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1005 - val_accuracy: 0.9827\n",
      "Epoch 00084: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:23:39<00:00, 2509.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.81      0.83      0.82       588\n",
      "        car_horn       0.87      0.86      0.87       168\n",
      "children_playing       0.92      0.92      0.92       600\n",
      "        dog_bark       0.91      0.96      0.93       600\n",
      "           siren       0.92      0.81      0.86       444\n",
      "\n",
      "        accuracy                           0.88      2400\n",
      "       macro avg       0.88      0.88      0.88      2400\n",
      "    weighted avg       0.89      0.88      0.88      2400\n",
      "\n",
      "\n",
      "Validation fold: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21346, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21346, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2372, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2372, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2430, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2430, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_15\n",
      "Epoch 1/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 1.1518 - accuracy: 0.6182\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75337, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 1.1517 - accuracy: 0.6182 - val_loss: 0.7068 - val_accuracy: 0.7534\n",
      "Epoch 2/100\n",
      "666/668 [============================>.] - ETA: 0s - loss: 0.7252 - accuracy: 0.7411\n",
      "Epoch 00002: val_accuracy improved from 0.75337 to 0.79806, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.7252 - accuracy: 0.7411 - val_loss: 0.5650 - val_accuracy: 0.7981\n",
      "Epoch 3/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.6018 - accuracy: 0.7855\n",
      "Epoch 00003: val_accuracy improved from 0.79806 to 0.81535, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.6017 - accuracy: 0.7855 - val_loss: 0.5350 - val_accuracy: 0.8153\n",
      "Epoch 4/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.5260 - accuracy: 0.8103\n",
      "Epoch 00004: val_accuracy improved from 0.81535 to 0.84148, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.5259 - accuracy: 0.8103 - val_loss: 0.4476 - val_accuracy: 0.8415\n",
      "Epoch 5/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.4653 - accuracy: 0.8333\n",
      "Epoch 00005: val_accuracy improved from 0.84148 to 0.88406, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.4653 - accuracy: 0.8332 - val_loss: 0.3147 - val_accuracy: 0.8841\n",
      "Epoch 6/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.4184 - accuracy: 0.8511\n",
      "Epoch 00006: val_accuracy did not improve from 0.88406\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.4183 - accuracy: 0.8511 - val_loss: 0.6683 - val_accuracy: 0.7462\n",
      "Epoch 7/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8625\n",
      "Epoch 00007: val_accuracy did not improve from 0.88406\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.3814 - accuracy: 0.8626 - val_loss: 0.3577 - val_accuracy: 0.8744\n",
      "Epoch 8/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3500 - accuracy: 0.8728\n",
      "Epoch 00008: val_accuracy did not improve from 0.88406\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.3501 - accuracy: 0.8727 - val_loss: 0.3606 - val_accuracy: 0.8664\n",
      "Epoch 9/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3282 - accuracy: 0.8808\n",
      "Epoch 00009: val_accuracy improved from 0.88406 to 0.91400, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.3283 - accuracy: 0.8808 - val_loss: 0.2486 - val_accuracy: 0.9140\n",
      "Epoch 10/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3003 - accuracy: 0.8903\n",
      "Epoch 00010: val_accuracy improved from 0.91400 to 0.92707, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.3003 - accuracy: 0.8903 - val_loss: 0.2066 - val_accuracy: 0.9271\n",
      "Epoch 11/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2789 - accuracy: 0.8970\n",
      "Epoch 00011: val_accuracy improved from 0.92707 to 0.94224, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.2789 - accuracy: 0.8970 - val_loss: 0.1748 - val_accuracy: 0.9422\n",
      "Epoch 12/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2594 - accuracy: 0.9043\n",
      "Epoch 00012: val_accuracy did not improve from 0.94224\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2595 - accuracy: 0.9043 - val_loss: 0.2035 - val_accuracy: 0.9351\n",
      "Epoch 13/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.9079\n",
      "Epoch 00013: val_accuracy improved from 0.94224 to 0.95236, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.2554 - accuracy: 0.9079 - val_loss: 0.1443 - val_accuracy: 0.9524\n",
      "Epoch 14/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2281 - accuracy: 0.9182\n",
      "Epoch 00014: val_accuracy did not improve from 0.95236\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2280 - accuracy: 0.9182 - val_loss: 0.1920 - val_accuracy: 0.9347\n",
      "Epoch 15/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2212 - accuracy: 0.9207\n",
      "Epoch 00015: val_accuracy did not improve from 0.95236\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2212 - accuracy: 0.9207 - val_loss: 0.1661 - val_accuracy: 0.9397\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/668 [============================>.] - ETA: 0s - loss: 0.2096 - accuracy: 0.9244\n",
      "Epoch 00016: val_accuracy did not improve from 0.95236\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2096 - accuracy: 0.9244 - val_loss: 0.1448 - val_accuracy: 0.9524\n",
      "Epoch 17/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1957 - accuracy: 0.9301\n",
      "Epoch 00017: val_accuracy did not improve from 0.95236\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1957 - accuracy: 0.9302 - val_loss: 0.1715 - val_accuracy: 0.9452\n",
      "Epoch 18/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1824 - accuracy: 0.9330\n",
      "Epoch 00018: val_accuracy improved from 0.95236 to 0.95911, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1824 - accuracy: 0.9330 - val_loss: 0.1296 - val_accuracy: 0.9591\n",
      "Epoch 19/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1737 - accuracy: 0.9365\n",
      "Epoch 00019: val_accuracy improved from 0.95911 to 0.95995, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1737 - accuracy: 0.9365 - val_loss: 0.1248 - val_accuracy: 0.9599\n",
      "Epoch 20/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9414\n",
      "Epoch 00020: val_accuracy improved from 0.95995 to 0.96585, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1617 - accuracy: 0.9414 - val_loss: 0.1100 - val_accuracy: 0.9659\n",
      "Epoch 21/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1621 - accuracy: 0.9406\n",
      "Epoch 00021: val_accuracy improved from 0.96585 to 0.97049, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1621 - accuracy: 0.9406 - val_loss: 0.0881 - val_accuracy: 0.9705\n",
      "Epoch 22/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1569 - accuracy: 0.9425\n",
      "Epoch 00022: val_accuracy did not improve from 0.97049\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1569 - accuracy: 0.9425 - val_loss: 0.0954 - val_accuracy: 0.9692\n",
      "Epoch 23/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1449 - accuracy: 0.9487\n",
      "Epoch 00023: val_accuracy improved from 0.97049 to 0.97175, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1449 - accuracy: 0.9487 - val_loss: 0.0873 - val_accuracy: 0.9718\n",
      "Epoch 24/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1407 - accuracy: 0.9496\n",
      "Epoch 00024: val_accuracy improved from 0.97175 to 0.97470, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1407 - accuracy: 0.9496 - val_loss: 0.0900 - val_accuracy: 0.9747\n",
      "Epoch 25/100\n",
      "666/668 [============================>.] - ETA: 0s - loss: 0.1320 - accuracy: 0.9515\n",
      "Epoch 00025: val_accuracy did not improve from 0.97470\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1324 - accuracy: 0.9515 - val_loss: 0.1150 - val_accuracy: 0.9604\n",
      "Epoch 26/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 0.9452\n",
      "Epoch 00026: val_accuracy did not improve from 0.97470\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1450 - accuracy: 0.9452 - val_loss: 0.0882 - val_accuracy: 0.9709\n",
      "Epoch 27/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1255 - accuracy: 0.9547\n",
      "Epoch 00027: val_accuracy did not improve from 0.97470\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1254 - accuracy: 0.9547 - val_loss: 0.0897 - val_accuracy: 0.9726\n",
      "Epoch 28/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9570\n",
      "Epoch 00028: val_accuracy did not improve from 0.97470\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1165 - accuracy: 0.9570 - val_loss: 0.0820 - val_accuracy: 0.9743\n",
      "Epoch 29/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9589\n",
      "Epoch 00029: val_accuracy did not improve from 0.97470\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1156 - accuracy: 0.9589 - val_loss: 0.0906 - val_accuracy: 0.9680\n",
      "Epoch 30/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1098 - accuracy: 0.9606\n",
      "Epoch 00030: val_accuracy did not improve from 0.97470\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1098 - accuracy: 0.9606 - val_loss: 0.0884 - val_accuracy: 0.9709\n",
      "Epoch 31/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9617\n",
      "Epoch 00031: val_accuracy improved from 0.97470 to 0.98229, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1063 - accuracy: 0.9617 - val_loss: 0.0668 - val_accuracy: 0.9823\n",
      "Epoch 32/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9630\n",
      "Epoch 00032: val_accuracy did not improve from 0.98229\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1060 - accuracy: 0.9630 - val_loss: 0.0854 - val_accuracy: 0.9739\n",
      "Epoch 33/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1049 - accuracy: 0.9626\n",
      "Epoch 00033: val_accuracy did not improve from 0.98229\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1049 - accuracy: 0.9626 - val_loss: 0.0730 - val_accuracy: 0.9777\n",
      "Epoch 34/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9672\n",
      "Epoch 00034: val_accuracy did not improve from 0.98229\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0937 - accuracy: 0.9671 - val_loss: 0.0915 - val_accuracy: 0.9705\n",
      "Epoch 35/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1098 - accuracy: 0.9610\n",
      "Epoch 00035: val_accuracy did not improve from 0.98229\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1098 - accuracy: 0.9610 - val_loss: 0.0685 - val_accuracy: 0.9789\n",
      "Epoch 36/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.9659\n",
      "Epoch 00036: val_accuracy did not improve from 0.98229\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0939 - accuracy: 0.9659 - val_loss: 0.0688 - val_accuracy: 0.9789\n",
      "Epoch 37/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 0.9710\n",
      "Epoch 00037: val_accuracy improved from 0.98229 to 0.98272, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0859 - accuracy: 0.9710 - val_loss: 0.0583 - val_accuracy: 0.9827\n",
      "Epoch 38/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0862 - accuracy: 0.9688\n",
      "Epoch 00038: val_accuracy improved from 0.98272 to 0.98609, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0862 - accuracy: 0.9688 - val_loss: 0.0507 - val_accuracy: 0.9861\n",
      "Epoch 39/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 0.9711\n",
      "Epoch 00039: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0823 - accuracy: 0.9711 - val_loss: 0.0734 - val_accuracy: 0.9798\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/668 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9738\n",
      "Epoch 00040: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0740 - accuracy: 0.9738 - val_loss: 0.0761 - val_accuracy: 0.9777\n",
      "Epoch 41/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0725 - accuracy: 0.9738\n",
      "Epoch 00041: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0727 - accuracy: 0.9737 - val_loss: 0.0501 - val_accuracy: 0.9831\n",
      "Epoch 42/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0797 - accuracy: 0.9717\n",
      "Epoch 00042: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0797 - accuracy: 0.9717 - val_loss: 0.0785 - val_accuracy: 0.9726\n",
      "Epoch 43/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 0.9732\n",
      "Epoch 00043: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0737 - accuracy: 0.9731 - val_loss: 0.0895 - val_accuracy: 0.9730\n",
      "Epoch 44/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9748\n",
      "Epoch 00044: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0723 - accuracy: 0.9748 - val_loss: 0.0656 - val_accuracy: 0.9810\n",
      "Epoch 45/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9762\n",
      "Epoch 00045: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0679 - accuracy: 0.9762 - val_loss: 0.0541 - val_accuracy: 0.9840\n",
      "Epoch 46/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 0.9765\n",
      "Epoch 00046: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0628 - accuracy: 0.9765 - val_loss: 0.0790 - val_accuracy: 0.9764\n",
      "Epoch 47/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0615 - accuracy: 0.9783\n",
      "Epoch 00047: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0615 - accuracy: 0.9783 - val_loss: 0.0480 - val_accuracy: 0.9861\n",
      "Epoch 48/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 0.9772\n",
      "Epoch 00048: val_accuracy improved from 0.98609 to 0.98946, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0637 - accuracy: 0.9771 - val_loss: 0.0369 - val_accuracy: 0.9895\n",
      "Epoch 49/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9777\n",
      "Epoch 00049: val_accuracy did not improve from 0.98946\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0629 - accuracy: 0.9777 - val_loss: 0.0510 - val_accuracy: 0.9861\n",
      "Epoch 50/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0606 - accuracy: 0.9790\n",
      "Epoch 00050: val_accuracy did not improve from 0.98946\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0606 - accuracy: 0.9790 - val_loss: 0.0504 - val_accuracy: 0.9848\n",
      "Epoch 51/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0583 - accuracy: 0.9799\n",
      "Epoch 00051: val_accuracy did not improve from 0.98946\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0583 - accuracy: 0.9799 - val_loss: 0.0423 - val_accuracy: 0.9895\n",
      "Epoch 52/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0509 - accuracy: 0.9814\n",
      "Epoch 00052: val_accuracy did not improve from 0.98946\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0509 - accuracy: 0.9814 - val_loss: 0.0529 - val_accuracy: 0.9857\n",
      "Epoch 53/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9799\n",
      "Epoch 00053: val_accuracy did not improve from 0.98946\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0556 - accuracy: 0.9799 - val_loss: 0.0704 - val_accuracy: 0.9789\n",
      "Epoch 54/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0528 - accuracy: 0.9808\n",
      "Epoch 00054: val_accuracy did not improve from 0.98946\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0528 - accuracy: 0.9808 - val_loss: 0.0514 - val_accuracy: 0.9844\n",
      "Epoch 55/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9821\n",
      "Epoch 00055: val_accuracy improved from 0.98946 to 0.99030, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0512 - accuracy: 0.9821 - val_loss: 0.0395 - val_accuracy: 0.9903\n",
      "Epoch 56/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9810\n",
      "Epoch 00056: val_accuracy did not improve from 0.99030\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0538 - accuracy: 0.9809 - val_loss: 0.0394 - val_accuracy: 0.9869\n",
      "Epoch 57/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9819\n",
      "Epoch 00057: val_accuracy did not improve from 0.99030\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 0.0446 - val_accuracy: 0.9865\n",
      "Epoch 58/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9828\n",
      "Epoch 00058: val_accuracy improved from 0.99030 to 0.99115, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0494 - accuracy: 0.9828 - val_loss: 0.0403 - val_accuracy: 0.9911\n",
      "Epoch 59/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.9837\n",
      "Epoch 00059: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0477 - accuracy: 0.9837 - val_loss: 0.0385 - val_accuracy: 0.9890\n",
      "Epoch 60/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9846\n",
      "Epoch 00060: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0449 - accuracy: 0.9846 - val_loss: 0.0448 - val_accuracy: 0.9869\n",
      "Epoch 61/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9834\n",
      "Epoch 00061: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0450 - accuracy: 0.9834 - val_loss: 0.0443 - val_accuracy: 0.9861\n",
      "Epoch 62/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9794\n",
      "Epoch 00062: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0596 - accuracy: 0.9793 - val_loss: 0.0352 - val_accuracy: 0.9903\n",
      "Epoch 63/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9836\n",
      "Epoch 00063: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0467 - accuracy: 0.9835 - val_loss: 0.0374 - val_accuracy: 0.9895\n",
      "Epoch 64/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9821\n",
      "Epoch 00064: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0501 - accuracy: 0.9821 - val_loss: 0.0381 - val_accuracy: 0.9874\n",
      "Epoch 65/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0451 - accuracy: 0.9834\n",
      "Epoch 00065: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0451 - accuracy: 0.9834 - val_loss: 0.0443 - val_accuracy: 0.9857\n",
      "Epoch 66/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.9861\n",
      "Epoch 00066: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0394 - accuracy: 0.9861 - val_loss: 0.0424 - val_accuracy: 0.9895\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/668 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9857\n",
      "Epoch 00067: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0404 - accuracy: 0.9857 - val_loss: 0.0339 - val_accuracy: 0.9907\n",
      "Epoch 68/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9852\n",
      "Epoch 00068: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0407 - accuracy: 0.9852 - val_loss: 0.0391 - val_accuracy: 0.9899\n",
      "Epoch 69/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9856\n",
      "Epoch 00069: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0373 - accuracy: 0.9856 - val_loss: 0.0400 - val_accuracy: 0.9890\n",
      "Epoch 70/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9877\n",
      "Epoch 00070: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 0.0608 - val_accuracy: 0.9857\n",
      "Epoch 71/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0416 - accuracy: 0.9855\n",
      "Epoch 00071: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 0.0476 - val_accuracy: 0.9869\n",
      "Epoch 72/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9868\n",
      "Epoch 00072: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0368 - accuracy: 0.9868 - val_loss: 0.0537 - val_accuracy: 0.9827\n",
      "Epoch 73/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9873\n",
      "Epoch 00073: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0365 - accuracy: 0.9873 - val_loss: 0.0316 - val_accuracy: 0.9903\n",
      "Epoch 74/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9873\n",
      "Epoch 00074: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0351 - accuracy: 0.9873 - val_loss: 0.0287 - val_accuracy: 0.9911\n",
      "Epoch 75/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9881\n",
      "Epoch 00075: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0362 - accuracy: 0.9881 - val_loss: 0.0319 - val_accuracy: 0.9907\n",
      "Epoch 76/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9886\n",
      "Epoch 00076: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 0.0444 - val_accuracy: 0.9874\n",
      "Epoch 77/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0345 - accuracy: 0.9876\n",
      "Epoch 00077: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0347 - accuracy: 0.9876 - val_loss: 0.0406 - val_accuracy: 0.9882\n",
      "Epoch 78/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.9828\n",
      "Epoch 00078: val_accuracy did not improve from 0.99115\n",
      "Restoring model weights from the end of the best epoch.\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0484 - accuracy: 0.9828 - val_loss: 0.0389 - val_accuracy: 0.9890\n",
      "Epoch 00078: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [19:38<19:38, 1178.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.77      0.79      0.78       600\n",
      "        car_horn       0.81      0.81      0.81       168\n",
      "children_playing       0.86      0.91      0.89       600\n",
      "        dog_bark       0.88      0.88      0.88       600\n",
      "           siren       0.85      0.77      0.81       462\n",
      "\n",
      "        accuracy                           0.84      2430\n",
      "       macro avg       0.83      0.83      0.83      2430\n",
      "    weighted avg       0.84      0.84      0.84      2430\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_16\n",
      "Epoch 1/100\n",
      "  2/668 [..............................] - ETA: 20s - loss: 2.1847 - accuracy: 0.2031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0219s vs `on_train_batch_end` time: 0.0389s). Check your callbacks.\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.9219 - accuracy: 0.6600\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76307, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 63ms/step - loss: 0.9218 - accuracy: 0.6601 - val_loss: 0.6462 - val_accuracy: 0.7631\n",
      "Epoch 2/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.5619 - accuracy: 0.8046\n",
      "Epoch 00002: val_accuracy improved from 0.76307 to 0.81661, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.5619 - accuracy: 0.8046 - val_loss: 0.5377 - val_accuracy: 0.8166\n",
      "Epoch 3/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.4612 - accuracy: 0.8374\n",
      "Epoch 00003: val_accuracy did not improve from 0.81661\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.4612 - accuracy: 0.8374 - val_loss: 1.1384 - val_accuracy: 0.6197\n",
      "Epoch 4/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3358 - accuracy: 0.8824\n",
      "Epoch 00004: val_accuracy improved from 0.81661 to 0.87985, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.3358 - accuracy: 0.8824 - val_loss: 0.3318 - val_accuracy: 0.8798\n",
      "Epoch 5/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2636 - accuracy: 0.9081\n",
      "Epoch 00005: val_accuracy improved from 0.87985 to 0.91821, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.2636 - accuracy: 0.9081 - val_loss: 0.2370 - val_accuracy: 0.9182\n",
      "Epoch 6/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2096 - accuracy: 0.9286\n",
      "Epoch 00006: val_accuracy did not improve from 0.91821\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.2096 - accuracy: 0.9286 - val_loss: 1.4145 - val_accuracy: 0.6627\n",
      "Epoch 7/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1803 - accuracy: 0.9397\n",
      "Epoch 00007: val_accuracy improved from 0.91821 to 0.96121, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1803 - accuracy: 0.9397 - val_loss: 0.1199 - val_accuracy: 0.9612\n",
      "Epoch 8/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1512 - accuracy: 0.9464\n",
      "Epoch 00008: val_accuracy did not improve from 0.96121\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1513 - accuracy: 0.9464 - val_loss: 0.3128 - val_accuracy: 0.8963\n",
      "Epoch 9/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2536 - accuracy: 0.9122\n",
      "Epoch 00009: val_accuracy did not improve from 0.96121\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.2537 - accuracy: 0.9122 - val_loss: 0.1696 - val_accuracy: 0.9422\n",
      "Epoch 10/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9542\n",
      "Epoch 00010: val_accuracy did not improve from 0.96121\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1339 - accuracy: 0.9542 - val_loss: 0.1589 - val_accuracy: 0.9477\n",
      "Epoch 11/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1117 - accuracy: 0.9603\n",
      "Epoch 00011: val_accuracy did not improve from 0.96121\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1117 - accuracy: 0.9602 - val_loss: 0.1898 - val_accuracy: 0.9427\n",
      "Epoch 12/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1299 - accuracy: 0.9553\n",
      "Epoch 00012: val_accuracy improved from 0.96121 to 0.97218, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1298 - accuracy: 0.9553 - val_loss: 0.0948 - val_accuracy: 0.9722\n",
      "Epoch 13/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 0.9690\n",
      "Epoch 00013: val_accuracy did not improve from 0.97218\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0905 - accuracy: 0.9690 - val_loss: 0.1021 - val_accuracy: 0.9692\n",
      "Epoch 14/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.9742\n",
      "Epoch 00014: val_accuracy improved from 0.97218 to 0.97428, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0729 - accuracy: 0.9742 - val_loss: 0.0777 - val_accuracy: 0.9743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9795\n",
      "Epoch 00015: val_accuracy improved from 0.97428 to 0.97808, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0621 - accuracy: 0.9795 - val_loss: 0.0632 - val_accuracy: 0.9781\n",
      "Epoch 16/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0599 - accuracy: 0.9792\n",
      "Epoch 00016: val_accuracy did not improve from 0.97808\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0601 - accuracy: 0.9791 - val_loss: 0.5160 - val_accuracy: 0.8697\n",
      "Epoch 17/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0703 - accuracy: 0.9749\n",
      "Epoch 00017: val_accuracy improved from 0.97808 to 0.98019, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0703 - accuracy: 0.9749 - val_loss: 0.0765 - val_accuracy: 0.9802\n",
      "Epoch 18/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.9837\n",
      "Epoch 00018: val_accuracy did not improve from 0.98019\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0488 - accuracy: 0.9837 - val_loss: 0.0709 - val_accuracy: 0.9768\n",
      "Epoch 19/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.9861\n",
      "Epoch 00019: val_accuracy did not improve from 0.98019\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0379 - accuracy: 0.9861 - val_loss: 0.0895 - val_accuracy: 0.9777\n",
      "Epoch 20/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0411 - accuracy: 0.9859\n",
      "Epoch 00020: val_accuracy did not improve from 0.98019\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0411 - accuracy: 0.9859 - val_loss: 0.2134 - val_accuracy: 0.9439\n",
      "Epoch 21/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 0.9868\n",
      "Epoch 00021: val_accuracy improved from 0.98019 to 0.98524, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0389 - accuracy: 0.9868 - val_loss: 0.0550 - val_accuracy: 0.9852\n",
      "Epoch 22/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0331 - accuracy: 0.9891\n",
      "Epoch 00022: val_accuracy did not improve from 0.98524\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.0661 - val_accuracy: 0.9810\n",
      "Epoch 23/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9871\n",
      "Epoch 00023: val_accuracy did not improve from 0.98524\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0365 - accuracy: 0.9871 - val_loss: 0.0729 - val_accuracy: 0.9785\n",
      "Epoch 24/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9923\n",
      "Epoch 00024: val_accuracy improved from 0.98524 to 0.98651, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0489 - val_accuracy: 0.9865\n",
      "Epoch 25/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9901\n",
      "Epoch 00025: val_accuracy did not improve from 0.98651\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0293 - accuracy: 0.9901 - val_loss: 0.0838 - val_accuracy: 0.9798\n",
      "Epoch 26/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9930\n",
      "Epoch 00026: val_accuracy improved from 0.98651 to 0.98735, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.0543 - val_accuracy: 0.9874\n",
      "Epoch 27/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9924\n",
      "Epoch 00027: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.0737 - val_accuracy: 0.9823\n",
      "Epoch 28/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9929\n",
      "Epoch 00028: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.0703 - val_accuracy: 0.9827\n",
      "Epoch 29/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9928\n",
      "Epoch 00029: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.0738 - val_accuracy: 0.9827\n",
      "Epoch 30/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9917\n",
      "Epoch 00030: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0608 - val_accuracy: 0.9861\n",
      "Epoch 31/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9947\n",
      "Epoch 00031: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0831 - val_accuracy: 0.9840\n",
      "Epoch 32/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 00032: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.1085 - val_accuracy: 0.9793\n",
      "Epoch 33/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9937\n",
      "Epoch 00033: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0660 - val_accuracy: 0.9827\n",
      "Epoch 34/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9937\n",
      "Epoch 00034: val_accuracy improved from 0.98735 to 0.98820, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.0500 - val_accuracy: 0.9882\n",
      "Epoch 35/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9948\n",
      "Epoch 00035: val_accuracy did not improve from 0.98820\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.0745 - val_accuracy: 0.9810\n",
      "Epoch 36/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9957\n",
      "Epoch 00036: val_accuracy did not improve from 0.98820\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0607 - val_accuracy: 0.9861\n",
      "Epoch 37/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9959\n",
      "Epoch 00037: val_accuracy did not improve from 0.98820\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0978 - val_accuracy: 0.9785\n",
      "Epoch 38/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9960\n",
      "Epoch 00038: val_accuracy did not improve from 0.98820\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0694 - val_accuracy: 0.9840\n",
      "Epoch 39/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9965\n",
      "Epoch 00039: val_accuracy improved from 0.98820 to 0.98988, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0488 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9958\n",
      "Epoch 00040: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0608 - val_accuracy: 0.9865\n",
      "Epoch 41/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9942\n",
      "Epoch 00041: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.0555 - val_accuracy: 0.9844\n",
      "Epoch 42/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9962\n",
      "Epoch 00042: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0542 - val_accuracy: 0.9874\n",
      "Epoch 43/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9971\n",
      "Epoch 00043: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.0534 - val_accuracy: 0.9874\n",
      "Epoch 44/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9963\n",
      "Epoch 00044: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.0924 - val_accuracy: 0.9798\n",
      "Epoch 45/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9970\n",
      "Epoch 00045: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.0735 - val_accuracy: 0.9852\n",
      "Epoch 46/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9958\n",
      "Epoch 00046: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0759 - val_accuracy: 0.9840\n",
      "Epoch 47/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 00047: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.1349 - val_accuracy: 0.9755\n",
      "Epoch 48/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9680\n",
      "Epoch 00048: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1064 - accuracy: 0.9680 - val_loss: 0.0711 - val_accuracy: 0.9768\n",
      "Epoch 49/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0427 - accuracy: 0.9860\n",
      "Epoch 00049: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0427 - accuracy: 0.9860 - val_loss: 0.0598 - val_accuracy: 0.9827\n",
      "Epoch 50/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9952\n",
      "Epoch 00050: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0585 - val_accuracy: 0.9844\n",
      "Epoch 51/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9955\n",
      "Epoch 00051: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.0801 - val_accuracy: 0.9806\n",
      "Epoch 52/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9952\n",
      "Epoch 00052: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0527 - val_accuracy: 0.9852\n",
      "Epoch 53/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9951\n",
      "Epoch 00053: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.0794 - val_accuracy: 0.9810\n",
      "Epoch 54/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9959\n",
      "Epoch 00054: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0555 - val_accuracy: 0.9869\n",
      "Epoch 55/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9964\n",
      "Epoch 00055: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 0.0574 - val_accuracy: 0.9865\n",
      "Epoch 56/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9959\n",
      "Epoch 00056: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0973 - val_accuracy: 0.9789\n",
      "Epoch 57/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9940\n",
      "Epoch 00057: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 0.0521 - val_accuracy: 0.9899\n",
      "Epoch 58/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch 00058: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0815 - val_accuracy: 0.9836\n",
      "Epoch 59/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 00059: val_accuracy did not improve from 0.98988\n",
      "Restoring model weights from the end of the best epoch.\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.0679 - val_accuracy: 0.9857\n",
      "Epoch 00059: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:00:46<00:00, 1823.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.78      0.83      0.80       600\n",
      "        car_horn       0.86      0.83      0.85       168\n",
      "children_playing       0.90      0.91      0.91       600\n",
      "        dog_bark       0.89      0.90      0.89       600\n",
      "           siren       0.87      0.77      0.82       462\n",
      "\n",
      "        accuracy                           0.86      2430\n",
      "       macro avg       0.86      0.85      0.85      2430\n",
      "    weighted avg       0.86      0.86      0.86      2430\n",
      "\n",
      "\n",
      "Validation fold: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21427, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21427, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2381, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2381, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2340, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2340, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_17\n",
      "Epoch 1/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 1.1884 - accuracy: 0.6029\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70097, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 16s 23ms/step - loss: 1.1884 - accuracy: 0.6029 - val_loss: 0.7925 - val_accuracy: 0.7010\n",
      "Epoch 2/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.7415 - accuracy: 0.7336\n",
      "Epoch 00002: val_accuracy improved from 0.70097 to 0.77110, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.7415 - accuracy: 0.7336 - val_loss: 0.6536 - val_accuracy: 0.7711\n",
      "Epoch 3/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.7718\n",
      "Epoch 00003: val_accuracy improved from 0.77110 to 0.79504, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.6275 - accuracy: 0.7718 - val_loss: 0.5613 - val_accuracy: 0.7950\n",
      "Epoch 4/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.8030\n",
      "Epoch 00004: val_accuracy improved from 0.79504 to 0.84124, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.5415 - accuracy: 0.8030 - val_loss: 0.4332 - val_accuracy: 0.8412\n",
      "Epoch 5/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.4857 - accuracy: 0.8272\n",
      "Epoch 00005: val_accuracy did not improve from 0.84124\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.4857 - accuracy: 0.8272 - val_loss: 0.4765 - val_accuracy: 0.8320\n",
      "Epoch 6/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.8453\n",
      "Epoch 00006: val_accuracy improved from 0.84124 to 0.87274, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.4315 - accuracy: 0.8453 - val_loss: 0.3863 - val_accuracy: 0.8727\n",
      "Epoch 7/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.8595\n",
      "Epoch 00007: val_accuracy improved from 0.87274 to 0.87778, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.3887 - accuracy: 0.8595 - val_loss: 0.3357 - val_accuracy: 0.8778\n",
      "Epoch 8/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8711\n",
      "Epoch 00008: val_accuracy improved from 0.87778 to 0.89752, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.3607 - accuracy: 0.8711 - val_loss: 0.2866 - val_accuracy: 0.8975\n",
      "Epoch 9/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.8785\n",
      "Epoch 00009: val_accuracy did not improve from 0.89752\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.3333 - accuracy: 0.8785 - val_loss: 0.3016 - val_accuracy: 0.8904\n",
      "Epoch 10/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.8886\n",
      "Epoch 00010: val_accuracy did not improve from 0.89752\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.3076 - accuracy: 0.8886 - val_loss: 0.5569 - val_accuracy: 0.8404\n",
      "Epoch 11/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.8971\n",
      "Epoch 00011: val_accuracy improved from 0.89752 to 0.92188, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.2849 - accuracy: 0.8971 - val_loss: 0.2164 - val_accuracy: 0.9219\n",
      "Epoch 12/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.2599 - accuracy: 0.9056\n",
      "Epoch 00012: val_accuracy did not improve from 0.92188\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.2599 - accuracy: 0.9056 - val_loss: 0.2532 - val_accuracy: 0.9147\n",
      "Epoch 13/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.2461 - accuracy: 0.9104\n",
      "Epoch 00013: val_accuracy did not improve from 0.92188\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.2461 - accuracy: 0.9104 - val_loss: 0.2133 - val_accuracy: 0.9177\n",
      "Epoch 14/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.9145\n",
      "Epoch 00014: val_accuracy improved from 0.92188 to 0.92650, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.2335 - accuracy: 0.9145 - val_loss: 0.2053 - val_accuracy: 0.9265\n",
      "Epoch 15/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.9201\n",
      "Epoch 00015: val_accuracy did not improve from 0.92650\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.2161 - accuracy: 0.9201 - val_loss: 0.1936 - val_accuracy: 0.9240\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670/670 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9256\n",
      "Epoch 00016: val_accuracy improved from 0.92650 to 0.93952, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.2014 - accuracy: 0.9256 - val_loss: 0.1818 - val_accuracy: 0.9395\n",
      "Epoch 17/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1963 - accuracy: 0.9304\n",
      "Epoch 00017: val_accuracy improved from 0.93952 to 0.94582, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.1963 - accuracy: 0.9304 - val_loss: 0.1487 - val_accuracy: 0.9458\n",
      "Epoch 18/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.1860 - accuracy: 0.9316\n",
      "Epoch 00018: val_accuracy did not improve from 0.94582\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1860 - accuracy: 0.9316 - val_loss: 0.1532 - val_accuracy: 0.9429\n",
      "Epoch 19/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9349\n",
      "Epoch 00019: val_accuracy did not improve from 0.94582\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1798 - accuracy: 0.9349 - val_loss: 0.2741 - val_accuracy: 0.9105\n",
      "Epoch 20/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9394\n",
      "Epoch 00020: val_accuracy improved from 0.94582 to 0.96136, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.1659 - accuracy: 0.9394 - val_loss: 0.1129 - val_accuracy: 0.9614\n",
      "Epoch 21/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.9419\n",
      "Epoch 00021: val_accuracy did not improve from 0.96136\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1601 - accuracy: 0.9419 - val_loss: 0.1630 - val_accuracy: 0.9475\n",
      "Epoch 22/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9446\n",
      "Epoch 00022: val_accuracy did not improve from 0.96136\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1540 - accuracy: 0.9446 - val_loss: 0.1224 - val_accuracy: 0.9580\n",
      "Epoch 23/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9471\n",
      "Epoch 00023: val_accuracy did not improve from 0.96136\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1456 - accuracy: 0.9471 - val_loss: 0.1700 - val_accuracy: 0.9429\n",
      "Epoch 24/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9490\n",
      "Epoch 00024: val_accuracy improved from 0.96136 to 0.96346, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.1403 - accuracy: 0.9490 - val_loss: 0.1088 - val_accuracy: 0.9635\n",
      "Epoch 25/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9485\n",
      "Epoch 00025: val_accuracy did not improve from 0.96346\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1396 - accuracy: 0.9485 - val_loss: 0.1934 - val_accuracy: 0.9324\n",
      "Epoch 26/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9523\n",
      "Epoch 00026: val_accuracy did not improve from 0.96346\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1346 - accuracy: 0.9523 - val_loss: 0.1396 - val_accuracy: 0.9513\n",
      "Epoch 27/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9540\n",
      "Epoch 00027: val_accuracy did not improve from 0.96346\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1280 - accuracy: 0.9540 - val_loss: 0.1339 - val_accuracy: 0.9563\n",
      "Epoch 28/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.9559\n",
      "Epoch 00028: val_accuracy improved from 0.96346 to 0.97438, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1199 - accuracy: 0.9559 - val_loss: 0.0872 - val_accuracy: 0.9744\n",
      "Epoch 29/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9595\n",
      "Epoch 00029: val_accuracy did not improve from 0.97438\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1139 - accuracy: 0.9595 - val_loss: 0.1021 - val_accuracy: 0.9647\n",
      "Epoch 30/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9612\n",
      "Epoch 00030: val_accuracy did not improve from 0.97438\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1090 - accuracy: 0.9612 - val_loss: 0.1396 - val_accuracy: 0.9563\n",
      "Epoch 31/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9631\n",
      "Epoch 00031: val_accuracy did not improve from 0.97438\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1028 - accuracy: 0.9631 - val_loss: 0.1079 - val_accuracy: 0.9639\n",
      "Epoch 32/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9632\n",
      "Epoch 00032: val_accuracy did not improve from 0.97438\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1012 - accuracy: 0.9632 - val_loss: 0.1327 - val_accuracy: 0.9605\n",
      "Epoch 33/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.1009 - accuracy: 0.9637\n",
      "Epoch 00033: val_accuracy did not improve from 0.97438\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1009 - accuracy: 0.9637 - val_loss: 0.0871 - val_accuracy: 0.9719\n",
      "Epoch 34/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9681\n",
      "Epoch 00034: val_accuracy improved from 0.97438 to 0.97480, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0909 - accuracy: 0.9681 - val_loss: 0.0799 - val_accuracy: 0.9748\n",
      "Epoch 35/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9676\n",
      "Epoch 00035: val_accuracy did not improve from 0.97480\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0915 - accuracy: 0.9676 - val_loss: 0.1012 - val_accuracy: 0.9660\n",
      "Epoch 36/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9675\n",
      "Epoch 00036: val_accuracy improved from 0.97480 to 0.97564, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0901 - accuracy: 0.9675 - val_loss: 0.0856 - val_accuracy: 0.9756\n",
      "Epoch 37/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9689\n",
      "Epoch 00037: val_accuracy did not improve from 0.97564\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0864 - accuracy: 0.9689 - val_loss: 0.0849 - val_accuracy: 0.9744\n",
      "Epoch 38/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9695\n",
      "Epoch 00038: val_accuracy did not improve from 0.97564\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0844 - accuracy: 0.9695 - val_loss: 0.0761 - val_accuracy: 0.9752\n",
      "Epoch 39/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9698\n",
      "Epoch 00039: val_accuracy improved from 0.97564 to 0.97942, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0807 - accuracy: 0.9698 - val_loss: 0.0704 - val_accuracy: 0.9794\n",
      "Epoch 40/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9697\n",
      "Epoch 00040: val_accuracy did not improve from 0.97942\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0852 - accuracy: 0.9697 - val_loss: 0.0740 - val_accuracy: 0.9782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9739\n",
      "Epoch 00041: val_accuracy did not improve from 0.97942\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0751 - accuracy: 0.9739 - val_loss: 0.0927 - val_accuracy: 0.9748\n",
      "Epoch 42/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9709\n",
      "Epoch 00042: val_accuracy did not improve from 0.97942\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0800 - accuracy: 0.9709 - val_loss: 0.0615 - val_accuracy: 0.9794\n",
      "Epoch 43/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9752\n",
      "Epoch 00043: val_accuracy improved from 0.97942 to 0.98026, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0703 - accuracy: 0.9752 - val_loss: 0.0602 - val_accuracy: 0.9803\n",
      "Epoch 44/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9745\n",
      "Epoch 00044: val_accuracy did not improve from 0.98026\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0709 - accuracy: 0.9745 - val_loss: 0.0762 - val_accuracy: 0.9731\n",
      "Epoch 45/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9758\n",
      "Epoch 00045: val_accuracy did not improve from 0.98026\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0680 - accuracy: 0.9758 - val_loss: 0.1029 - val_accuracy: 0.9719\n",
      "Epoch 46/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9755\n",
      "Epoch 00046: val_accuracy did not improve from 0.98026\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0637 - accuracy: 0.9755 - val_loss: 0.0694 - val_accuracy: 0.9782\n",
      "Epoch 47/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9782\n",
      "Epoch 00047: val_accuracy improved from 0.98026 to 0.98194, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0631 - accuracy: 0.9782 - val_loss: 0.0669 - val_accuracy: 0.9819\n",
      "Epoch 48/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9765\n",
      "Epoch 00048: val_accuracy improved from 0.98194 to 0.98362, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0651 - accuracy: 0.9765 - val_loss: 0.0559 - val_accuracy: 0.9836\n",
      "Epoch 49/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9794\n",
      "Epoch 00049: val_accuracy did not improve from 0.98362\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0572 - accuracy: 0.9794 - val_loss: 0.0570 - val_accuracy: 0.9832\n",
      "Epoch 50/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9800\n",
      "Epoch 00050: val_accuracy did not improve from 0.98362\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0599 - accuracy: 0.9800 - val_loss: 0.0700 - val_accuracy: 0.9824\n",
      "Epoch 51/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9804\n",
      "Epoch 00051: val_accuracy improved from 0.98362 to 0.98614, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0546 - accuracy: 0.9804 - val_loss: 0.0508 - val_accuracy: 0.9861\n",
      "Epoch 52/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9795\n",
      "Epoch 00052: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0566 - accuracy: 0.9795 - val_loss: 0.1082 - val_accuracy: 0.9706\n",
      "Epoch 53/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9796\n",
      "Epoch 00053: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0576 - accuracy: 0.9796 - val_loss: 0.0701 - val_accuracy: 0.9773\n",
      "Epoch 54/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9811\n",
      "Epoch 00054: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0526 - accuracy: 0.9811 - val_loss: 0.0560 - val_accuracy: 0.9824\n",
      "Epoch 55/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9799\n",
      "Epoch 00055: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0549 - accuracy: 0.9799 - val_loss: 0.0772 - val_accuracy: 0.9777\n",
      "Epoch 56/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9821\n",
      "Epoch 00056: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0515 - accuracy: 0.9821 - val_loss: 0.0787 - val_accuracy: 0.9765\n",
      "Epoch 57/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9831\n",
      "Epoch 00057: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0467 - accuracy: 0.9831 - val_loss: 0.0649 - val_accuracy: 0.9828\n",
      "Epoch 58/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.9830\n",
      "Epoch 00058: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0484 - accuracy: 0.9831 - val_loss: 0.0533 - val_accuracy: 0.9845\n",
      "Epoch 59/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9843\n",
      "Epoch 00059: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0456 - accuracy: 0.9843 - val_loss: 0.0567 - val_accuracy: 0.9849\n",
      "Epoch 60/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9842\n",
      "Epoch 00060: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0463 - accuracy: 0.9842 - val_loss: 0.0604 - val_accuracy: 0.9824\n",
      "Epoch 61/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9830\n",
      "Epoch 00061: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0487 - accuracy: 0.9830 - val_loss: 0.0711 - val_accuracy: 0.9811\n",
      "Epoch 62/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9834\n",
      "Epoch 00062: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0465 - accuracy: 0.9834 - val_loss: 0.0852 - val_accuracy: 0.9761\n",
      "Epoch 63/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9841\n",
      "Epoch 00063: val_accuracy improved from 0.98614 to 0.98908, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0429 - accuracy: 0.9841 - val_loss: 0.0384 - val_accuracy: 0.9891\n",
      "Epoch 64/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9835\n",
      "Epoch 00064: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0475 - accuracy: 0.9835 - val_loss: 0.0498 - val_accuracy: 0.9853\n",
      "Epoch 65/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9839\n",
      "Epoch 00065: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0424 - accuracy: 0.9839 - val_loss: 0.0455 - val_accuracy: 0.9874\n",
      "Epoch 66/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9860\n",
      "Epoch 00066: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0382 - accuracy: 0.9860 - val_loss: 0.0544 - val_accuracy: 0.9840\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670/670 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9852\n",
      "Epoch 00067: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0404 - accuracy: 0.9852 - val_loss: 0.0456 - val_accuracy: 0.9878\n",
      "Epoch 68/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9865\n",
      "Epoch 00068: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0410 - accuracy: 0.9865 - val_loss: 0.0496 - val_accuracy: 0.9857\n",
      "Epoch 69/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9851\n",
      "Epoch 00069: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0414 - accuracy: 0.9851 - val_loss: 0.0651 - val_accuracy: 0.9824\n",
      "Epoch 70/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9864\n",
      "Epoch 00070: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0397 - accuracy: 0.9864 - val_loss: 0.0559 - val_accuracy: 0.9832\n",
      "Epoch 71/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9857\n",
      "Epoch 00071: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0383 - accuracy: 0.9857 - val_loss: 0.0552 - val_accuracy: 0.9853\n",
      "Epoch 72/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9860\n",
      "Epoch 00072: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0392 - accuracy: 0.9860 - val_loss: 0.0449 - val_accuracy: 0.9882\n",
      "Epoch 73/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9870\n",
      "Epoch 00073: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0373 - accuracy: 0.9870 - val_loss: 0.0439 - val_accuracy: 0.9861\n",
      "Epoch 74/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9871\n",
      "Epoch 00074: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0358 - accuracy: 0.9871 - val_loss: 0.0470 - val_accuracy: 0.9887\n",
      "Epoch 75/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9847\n",
      "Epoch 00075: val_accuracy improved from 0.98908 to 0.98992, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0432 - accuracy: 0.9847 - val_loss: 0.0402 - val_accuracy: 0.9899\n",
      "Epoch 76/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9873\n",
      "Epoch 00076: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0353 - accuracy: 0.9873 - val_loss: 0.0421 - val_accuracy: 0.9882\n",
      "Epoch 77/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9884\n",
      "Epoch 00077: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 0.0372 - val_accuracy: 0.9895\n",
      "Epoch 78/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9880\n",
      "Epoch 00078: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.0466 - val_accuracy: 0.9887\n",
      "Epoch 79/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9879\n",
      "Epoch 00079: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0336 - accuracy: 0.9879 - val_loss: 0.0528 - val_accuracy: 0.9853\n",
      "Epoch 80/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9887\n",
      "Epoch 00080: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 0.0468 - val_accuracy: 0.9891\n",
      "Epoch 81/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9887\n",
      "Epoch 00081: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 0.0802 - val_accuracy: 0.9811\n",
      "Epoch 82/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9888\n",
      "Epoch 00082: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0334 - accuracy: 0.9888 - val_loss: 0.0488 - val_accuracy: 0.9882\n",
      "Epoch 83/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9882\n",
      "Epoch 00083: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0327 - accuracy: 0.9882 - val_loss: 0.0566 - val_accuracy: 0.9874\n",
      "Epoch 84/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9896\n",
      "Epoch 00084: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.0465 - val_accuracy: 0.9870\n",
      "Epoch 85/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9901\n",
      "Epoch 00085: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0285 - accuracy: 0.9901 - val_loss: 0.0493 - val_accuracy: 0.9874\n",
      "Epoch 86/100\n",
      "668/670 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9898\n",
      "Epoch 00086: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0289 - accuracy: 0.9897 - val_loss: 0.0492 - val_accuracy: 0.9895\n",
      "Epoch 87/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9901\n",
      "Epoch 00087: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0277 - accuracy: 0.9901 - val_loss: 0.0535 - val_accuracy: 0.9882\n",
      "Epoch 88/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9898\n",
      "Epoch 00088: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0301 - accuracy: 0.9898 - val_loss: 0.0450 - val_accuracy: 0.9887\n",
      "Epoch 89/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9902\n",
      "Epoch 00089: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0265 - accuracy: 0.9902 - val_loss: 0.0372 - val_accuracy: 0.9895\n",
      "Epoch 90/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9896\n",
      "Epoch 00090: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.0451 - val_accuracy: 0.9891\n",
      "Epoch 91/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9904\n",
      "Epoch 00091: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0287 - accuracy: 0.9904 - val_loss: 0.0443 - val_accuracy: 0.9891\n",
      "Epoch 92/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9916\n",
      "Epoch 00092: val_accuracy improved from 0.98992 to 0.99076, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.0374 - val_accuracy: 0.9908\n",
      "Epoch 93/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9913\n",
      "Epoch 00093: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.0429 - val_accuracy: 0.9866\n",
      "Epoch 94/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9916\n",
      "Epoch 00094: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.0347 - val_accuracy: 0.9891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9917\n",
      "Epoch 00095: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 0.0411 - val_accuracy: 0.9891\n",
      "Epoch 96/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9923\n",
      "Epoch 00096: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0396 - val_accuracy: 0.9887\n",
      "Epoch 97/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9906\n",
      "Epoch 00097: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0259 - accuracy: 0.9906 - val_loss: 0.0445 - val_accuracy: 0.9878\n",
      "Epoch 98/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9915\n",
      "Epoch 00098: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0266 - accuracy: 0.9916 - val_loss: 0.0427 - val_accuracy: 0.9857\n",
      "Epoch 99/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9912\n",
      "Epoch 00099: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.0400 - val_accuracy: 0.9882\n",
      "Epoch 100/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9924\n",
      "Epoch 00100: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0214 - accuracy: 0.9924 - val_loss: 0.0511 - val_accuracy: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [25:10<25:10, 1510.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.51      0.88      0.65       480\n",
      "        car_horn       0.86      0.87      0.86       180\n",
      "children_playing       0.83      0.67      0.74       600\n",
      "        dog_bark       0.98      0.81      0.88       600\n",
      "           siren       0.78      0.58      0.67       480\n",
      "\n",
      "        accuracy                           0.74      2340\n",
      "       macro avg       0.79      0.76      0.76      2340\n",
      "    weighted avg       0.80      0.74      0.75      2340\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_18\n",
      "Epoch 1/100\n",
      "  2/670 [..............................] - ETA: 20s - loss: 2.4784 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0219s vs `on_train_batch_end` time: 0.0381s). Check your callbacks.\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.9055 - accuracy: 0.6641\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78958, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.9055 - accuracy: 0.6641 - val_loss: 0.5994 - val_accuracy: 0.7896\n",
      "Epoch 2/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.5258 - accuracy: 0.8153\n",
      "Epoch 00002: val_accuracy improved from 0.78958 to 0.82948, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.5259 - accuracy: 0.8152 - val_loss: 0.4936 - val_accuracy: 0.8295\n",
      "Epoch 3/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8719\n",
      "Epoch 00003: val_accuracy did not improve from 0.82948\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.3787 - accuracy: 0.8720 - val_loss: 1.0330 - val_accuracy: 0.7098\n",
      "Epoch 4/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.8977\n",
      "Epoch 00004: val_accuracy improved from 0.82948 to 0.86266, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.3001 - accuracy: 0.8977 - val_loss: 0.3801 - val_accuracy: 0.8627\n",
      "Epoch 5/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.2350 - accuracy: 0.9205\n",
      "Epoch 00005: val_accuracy improved from 0.86266 to 0.92776, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.2350 - accuracy: 0.9206 - val_loss: 0.2213 - val_accuracy: 0.9278\n",
      "Epoch 6/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.1909 - accuracy: 0.9356\n",
      "Epoch 00006: val_accuracy improved from 0.92776 to 0.94582, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.1908 - accuracy: 0.9356 - val_loss: 0.1734 - val_accuracy: 0.9458\n",
      "Epoch 7/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.1553 - accuracy: 0.9467\n",
      "Epoch 00007: val_accuracy did not improve from 0.94582\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.1553 - accuracy: 0.9466 - val_loss: 0.1696 - val_accuracy: 0.9395\n",
      "Epoch 8/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.1319 - accuracy: 0.9566\n",
      "Epoch 00008: val_accuracy did not improve from 0.94582\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.1318 - accuracy: 0.9566 - val_loss: 0.1855 - val_accuracy: 0.9353\n",
      "Epoch 9/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 0.9631\n",
      "Epoch 00009: val_accuracy improved from 0.94582 to 0.96724, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.1095 - accuracy: 0.9630 - val_loss: 0.0920 - val_accuracy: 0.9672\n",
      "Epoch 10/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0906 - accuracy: 0.9686\n",
      "Epoch 00010: val_accuracy did not improve from 0.96724\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0905 - accuracy: 0.9686 - val_loss: 0.2362 - val_accuracy: 0.9257\n",
      "Epoch 11/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0851 - accuracy: 0.9726\n",
      "Epoch 00011: val_accuracy did not improve from 0.96724\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0853 - accuracy: 0.9726 - val_loss: 0.5279 - val_accuracy: 0.8555\n",
      "Epoch 12/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9753\n",
      "Epoch 00012: val_accuracy did not improve from 0.96724\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0705 - accuracy: 0.9753 - val_loss: 0.3900 - val_accuracy: 0.8929\n",
      "Epoch 13/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9783\n",
      "Epoch 00013: val_accuracy did not improve from 0.96724\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0604 - accuracy: 0.9783 - val_loss: 0.2665 - val_accuracy: 0.9223\n",
      "Epoch 14/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 0.9816\n",
      "Epoch 00014: val_accuracy improved from 0.96724 to 0.97396, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0558 - accuracy: 0.9816 - val_loss: 0.0842 - val_accuracy: 0.9740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0545 - accuracy: 0.9821\n",
      "Epoch 00015: val_accuracy improved from 0.97396 to 0.98152, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0546 - accuracy: 0.9821 - val_loss: 0.0633 - val_accuracy: 0.9815\n",
      "Epoch 16/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9841\n",
      "Epoch 00016: val_accuracy did not improve from 0.98152\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0479 - accuracy: 0.9841 - val_loss: 0.0952 - val_accuracy: 0.9693\n",
      "Epoch 17/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0433 - accuracy: 0.9858\n",
      "Epoch 00017: val_accuracy did not improve from 0.98152\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0433 - accuracy: 0.9858 - val_loss: 0.0953 - val_accuracy: 0.9727\n",
      "Epoch 18/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.9855\n",
      "Epoch 00018: val_accuracy did not improve from 0.98152\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0430 - accuracy: 0.9855 - val_loss: 0.0603 - val_accuracy: 0.9807\n",
      "Epoch 19/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9876\n",
      "Epoch 00019: val_accuracy improved from 0.98152 to 0.98320, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 0.0599 - val_accuracy: 0.9832\n",
      "Epoch 20/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9899\n",
      "Epoch 00020: val_accuracy did not improve from 0.98320\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0301 - accuracy: 0.9899 - val_loss: 0.0643 - val_accuracy: 0.9832\n",
      "Epoch 21/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9921\n",
      "Epoch 00021: val_accuracy improved from 0.98320 to 0.98614, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.0594 - val_accuracy: 0.9861\n",
      "Epoch 22/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9905\n",
      "Epoch 00022: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.0884 - val_accuracy: 0.9765\n",
      "Epoch 23/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9929\n",
      "Epoch 00023: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.1059 - val_accuracy: 0.9735\n",
      "Epoch 24/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9926\n",
      "Epoch 00024: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.0670 - val_accuracy: 0.9803\n",
      "Epoch 25/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9937\n",
      "Epoch 00025: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0645 - val_accuracy: 0.9849\n",
      "Epoch 26/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9932\n",
      "Epoch 00026: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.0714 - val_accuracy: 0.9782\n",
      "Epoch 27/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9934\n",
      "Epoch 00027: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0948 - val_accuracy: 0.9740\n",
      "Epoch 28/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9940\n",
      "Epoch 00028: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.0490 - val_accuracy: 0.9861\n",
      "Epoch 29/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9954\n",
      "Epoch 00029: val_accuracy improved from 0.98614 to 0.98740, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0604 - val_accuracy: 0.9874\n",
      "Epoch 30/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9937\n",
      "Epoch 00030: val_accuracy did not improve from 0.98740\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.0576 - val_accuracy: 0.9849\n",
      "Epoch 31/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9952\n",
      "Epoch 00031: val_accuracy did not improve from 0.98740\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.1327 - val_accuracy: 0.9677\n",
      "Epoch 32/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9932\n",
      "Epoch 00032: val_accuracy did not improve from 0.98740\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0525 - val_accuracy: 0.9866\n",
      "Epoch 33/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9959\n",
      "Epoch 00033: val_accuracy improved from 0.98740 to 0.98992, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0384 - val_accuracy: 0.9899\n",
      "Epoch 34/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9941\n",
      "Epoch 00034: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0609 - val_accuracy: 0.9811\n",
      "Epoch 35/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9948\n",
      "Epoch 00035: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0452 - val_accuracy: 0.9866\n",
      "Epoch 36/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9965\n",
      "Epoch 00036: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.0512 - val_accuracy: 0.9861\n",
      "Epoch 37/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9958\n",
      "Epoch 00037: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0611 - val_accuracy: 0.9857\n",
      "Epoch 38/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9977\n",
      "Epoch 00038: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0557 - val_accuracy: 0.9857\n",
      "Epoch 39/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9969\n",
      "Epoch 00039: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.1007 - val_accuracy: 0.9740\n",
      "Epoch 40/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 00040: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0532 - val_accuracy: 0.9866\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/670 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9952\n",
      "Epoch 00041: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.0721 - val_accuracy: 0.9798\n",
      "Epoch 42/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9963\n",
      "Epoch 00042: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0619 - val_accuracy: 0.9803\n",
      "Epoch 43/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 00043: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.0906 - val_accuracy: 0.9773\n",
      "Epoch 44/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9973\n",
      "Epoch 00044: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0429 - val_accuracy: 0.9882\n",
      "Epoch 45/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9973\n",
      "Epoch 00045: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0520 - val_accuracy: 0.9866\n",
      "Epoch 46/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 00046: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0606 - val_accuracy: 0.9857\n",
      "Epoch 47/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9976\n",
      "Epoch 00047: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0501 - val_accuracy: 0.9882\n",
      "Epoch 48/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00048: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0456 - val_accuracy: 0.9891\n",
      "Epoch 49/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9982\n",
      "Epoch 00049: val_accuracy improved from 0.98992 to 0.99118, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0442 - val_accuracy: 0.9912\n",
      "Epoch 50/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 00050: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0720 - val_accuracy: 0.9840\n",
      "Epoch 51/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9982\n",
      "Epoch 00051: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0451 - val_accuracy: 0.9891\n",
      "Epoch 52/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9981\n",
      "Epoch 00052: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0557 - val_accuracy: 0.9870\n",
      "Epoch 53/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
      "Epoch 00053: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0506 - val_accuracy: 0.9866\n",
      "Epoch 54/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 00054: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0780 - val_accuracy: 0.9836\n",
      "Epoch 55/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch 00055: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0513 - val_accuracy: 0.9895\n",
      "Epoch 56/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00056: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0442 - val_accuracy: 0.9908\n",
      "Epoch 57/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9973\n",
      "Epoch 00057: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.0604 - val_accuracy: 0.9853\n",
      "Epoch 58/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 00058: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0734 - val_accuracy: 0.9870\n",
      "Epoch 59/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 00059: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0534 - val_accuracy: 0.9857\n",
      "Epoch 60/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 00060: val_accuracy improved from 0.99118 to 0.99202, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0400 - val_accuracy: 0.9920\n",
      "Epoch 61/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9983\n",
      "Epoch 00061: val_accuracy did not improve from 0.99202\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0529 - val_accuracy: 0.9899\n",
      "Epoch 62/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9972\n",
      "Epoch 00062: val_accuracy did not improve from 0.99202\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.0427 - val_accuracy: 0.9903\n",
      "Epoch 63/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9967\n",
      "Epoch 00063: val_accuracy did not improve from 0.99202\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0507 - val_accuracy: 0.9861\n",
      "Epoch 64/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9984\n",
      "Epoch 00064: val_accuracy did not improve from 0.99202\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0427 - val_accuracy: 0.9895\n",
      "Epoch 65/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 00065: val_accuracy did not improve from 0.99202\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0459 - val_accuracy: 0.9895\n",
      "Epoch 66/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 00066: val_accuracy did not improve from 0.99202\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0594 - val_accuracy: 0.9870\n",
      "Epoch 67/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 00067: val_accuracy improved from 0.99202 to 0.99286, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0383 - val_accuracy: 0.9929\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/670 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9978\n",
      "Epoch 00068: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0611 - val_accuracy: 0.9887\n",
      "Epoch 69/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 00069: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0637 - val_accuracy: 0.9866\n",
      "Epoch 70/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9982\n",
      "Epoch 00070: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0482 - val_accuracy: 0.9891\n",
      "Epoch 71/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 00071: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0374 - val_accuracy: 0.9924\n",
      "Epoch 72/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00072: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0455 - val_accuracy: 0.9891\n",
      "Epoch 73/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 00073: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.1124 - val_accuracy: 0.9744\n",
      "Epoch 74/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 00074: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0347 - val_accuracy: 0.9916\n",
      "Epoch 75/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 00075: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0381 - val_accuracy: 0.9920\n",
      "Epoch 76/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 00076: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0549 - val_accuracy: 0.9891\n",
      "Epoch 77/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 00077: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0811 - val_accuracy: 0.9853\n",
      "Epoch 78/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 00078: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0508 - val_accuracy: 0.9895\n",
      "Epoch 79/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 00079: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0409 - val_accuracy: 0.9920\n",
      "Epoch 80/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 00080: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0461 - val_accuracy: 0.9912\n",
      "Epoch 81/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 00081: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0398 - val_accuracy: 0.9924\n",
      "Epoch 82/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 00082: val_accuracy improved from 0.99286 to 0.99412, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0315 - val_accuracy: 0.9941\n",
      "Epoch 83/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 00083: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0314 - val_accuracy: 0.9937\n",
      "Epoch 84/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00084: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0509 - val_accuracy: 0.9899\n",
      "Epoch 85/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00085: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0395 - val_accuracy: 0.9912\n",
      "Epoch 86/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9985\n",
      "Epoch 00086: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0549 - val_accuracy: 0.9899\n",
      "Epoch 87/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 00087: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0378 - val_accuracy: 0.9912\n",
      "Epoch 88/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 00088: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0441 - val_accuracy: 0.9874\n",
      "Epoch 89/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991\n",
      "Epoch 00089: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0363 - val_accuracy: 0.9912\n",
      "Epoch 90/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9990\n",
      "Epoch 00090: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.0366 - val_accuracy: 0.9929\n",
      "Epoch 91/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9984\n",
      "Epoch 00091: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.0622 - val_accuracy: 0.9870\n",
      "Epoch 92/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9980\n",
      "Epoch 00092: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0387 - val_accuracy: 0.9903\n",
      "Epoch 93/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 00093: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0399 - val_accuracy: 0.9916\n",
      "Epoch 94/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 00094: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0367 - val_accuracy: 0.9912\n",
      "Epoch 95/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 00095: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0400 - val_accuracy: 0.9916\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/670 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 00096: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0473 - val_accuracy: 0.9916\n",
      "Epoch 97/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 00097: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0594 - val_accuracy: 0.9929\n",
      "Epoch 98/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00098: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0545 - val_accuracy: 0.9908\n",
      "Epoch 99/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 00099: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0453 - val_accuracy: 0.9912\n",
      "Epoch 100/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00100: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0505 - val_accuracy: 0.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:36:11<00:00, 2885.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.56      0.85      0.68       480\n",
      "        car_horn       0.88      0.89      0.89       180\n",
      "children_playing       0.86      0.79      0.82       600\n",
      "        dog_bark       0.90      0.86      0.88       600\n",
      "           siren       0.78      0.51      0.61       480\n",
      "\n",
      "        accuracy                           0.77      2340\n",
      "       macro avg       0.80      0.78      0.78      2340\n",
      "    weighted avg       0.80      0.77      0.77      2340\n",
      "\n",
      "\n",
      "Validation fold: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21394, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21394, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2378, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2378, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2376, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2376, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_19\n",
      "Epoch 1/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 1.2094 - accuracy: 0.5976\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71026, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 16s 23ms/step - loss: 1.2094 - accuracy: 0.5976 - val_loss: 0.7778 - val_accuracy: 0.7103\n",
      "Epoch 2/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.7482 - accuracy: 0.7313\n",
      "Epoch 00002: val_accuracy improved from 0.71026 to 0.77292, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.7475 - accuracy: 0.7317 - val_loss: 0.6138 - val_accuracy: 0.7729\n",
      "Epoch 3/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.6326 - accuracy: 0.7737\n",
      "Epoch 00003: val_accuracy improved from 0.77292 to 0.78553, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.6325 - accuracy: 0.7739 - val_loss: 0.6278 - val_accuracy: 0.7855\n",
      "Epoch 4/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.5575 - accuracy: 0.7983\n",
      "Epoch 00004: val_accuracy improved from 0.78553 to 0.84777, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.5575 - accuracy: 0.7984 - val_loss: 0.4146 - val_accuracy: 0.8478\n",
      "Epoch 5/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.5039 - accuracy: 0.8172\n",
      "Epoch 00005: val_accuracy did not improve from 0.84777\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.5036 - accuracy: 0.8173 - val_loss: 0.5151 - val_accuracy: 0.8188\n",
      "Epoch 6/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.4475 - accuracy: 0.8383\n",
      "Epoch 00006: val_accuracy did not improve from 0.84777\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.4475 - accuracy: 0.8383 - val_loss: 0.5588 - val_accuracy: 0.7939\n",
      "Epoch 7/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.4106 - accuracy: 0.8513\n",
      "Epoch 00007: val_accuracy improved from 0.84777 to 0.87048, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.4106 - accuracy: 0.8514 - val_loss: 0.3609 - val_accuracy: 0.8705\n",
      "Epoch 8/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.3749 - accuracy: 0.8631\n",
      "Epoch 00008: val_accuracy improved from 0.87048 to 0.89487, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.3752 - accuracy: 0.8631 - val_loss: 0.2904 - val_accuracy: 0.8949\n",
      "Epoch 9/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.3549 - accuracy: 0.8715\n",
      "Epoch 00009: val_accuracy improved from 0.89487 to 0.90959, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.3549 - accuracy: 0.8715 - val_loss: 0.2684 - val_accuracy: 0.9096\n",
      "Epoch 10/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.3240 - accuracy: 0.8855\n",
      "Epoch 00010: val_accuracy did not improve from 0.90959\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.3239 - accuracy: 0.8855 - val_loss: 0.2624 - val_accuracy: 0.9058\n",
      "Epoch 11/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.3084 - accuracy: 0.8893\n",
      "Epoch 00011: val_accuracy improved from 0.90959 to 0.91758, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.3089 - accuracy: 0.8891 - val_loss: 0.2339 - val_accuracy: 0.9176\n",
      "Epoch 12/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.8991\n",
      "Epoch 00012: val_accuracy did not improve from 0.91758\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2784 - accuracy: 0.8989 - val_loss: 0.2493 - val_accuracy: 0.9113\n",
      "Epoch 13/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.2718 - accuracy: 0.9021\n",
      "Epoch 00013: val_accuracy did not improve from 0.91758\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2719 - accuracy: 0.9020 - val_loss: 0.2351 - val_accuracy: 0.9087\n",
      "Epoch 14/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.2595 - accuracy: 0.9049\n",
      "Epoch 00014: val_accuracy improved from 0.91758 to 0.92304, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2592 - accuracy: 0.9050 - val_loss: 0.2143 - val_accuracy: 0.9230\n",
      "Epoch 15/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.2422 - accuracy: 0.9152\n",
      "Epoch 00015: val_accuracy did not improve from 0.92304\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2419 - accuracy: 0.9153 - val_loss: 0.2314 - val_accuracy: 0.9201\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/669 [============================>.] - ETA: 0s - loss: 0.2247 - accuracy: 0.9200\n",
      "Epoch 00016: val_accuracy did not improve from 0.92304\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2245 - accuracy: 0.9201 - val_loss: 0.2338 - val_accuracy: 0.9159\n",
      "Epoch 17/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.9215\n",
      "Epoch 00017: val_accuracy improved from 0.92304 to 0.92725, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2133 - accuracy: 0.9215 - val_loss: 0.2078 - val_accuracy: 0.9272\n",
      "Epoch 18/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.2071 - accuracy: 0.9248\n",
      "Epoch 00018: val_accuracy improved from 0.92725 to 0.94954, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2074 - accuracy: 0.9247 - val_loss: 0.1360 - val_accuracy: 0.9495\n",
      "Epoch 19/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1948 - accuracy: 0.9298\n",
      "Epoch 00019: val_accuracy improved from 0.94954 to 0.95374, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1947 - accuracy: 0.9298 - val_loss: 0.1417 - val_accuracy: 0.9537\n",
      "Epoch 20/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1819 - accuracy: 0.9333\n",
      "Epoch 00020: val_accuracy did not improve from 0.95374\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1817 - accuracy: 0.9334 - val_loss: 0.1534 - val_accuracy: 0.9487\n",
      "Epoch 21/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9381\n",
      "Epoch 00021: val_accuracy improved from 0.95374 to 0.95669, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1721 - accuracy: 0.9381 - val_loss: 0.1307 - val_accuracy: 0.9567\n",
      "Epoch 22/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1737 - accuracy: 0.9388\n",
      "Epoch 00022: val_accuracy did not improve from 0.95669\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1738 - accuracy: 0.9388 - val_loss: 0.1611 - val_accuracy: 0.9424\n",
      "Epoch 23/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1588 - accuracy: 0.9415\n",
      "Epoch 00023: val_accuracy improved from 0.95669 to 0.96678, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1587 - accuracy: 0.9416 - val_loss: 0.1064 - val_accuracy: 0.9668\n",
      "Epoch 24/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1583 - accuracy: 0.9432\n",
      "Epoch 00024: val_accuracy did not improve from 0.96678\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1582 - accuracy: 0.9432 - val_loss: 0.1040 - val_accuracy: 0.9668\n",
      "Epoch 25/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9473\n",
      "Epoch 00025: val_accuracy did not improve from 0.96678\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1485 - accuracy: 0.9473 - val_loss: 0.1413 - val_accuracy: 0.9605\n",
      "Epoch 26/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.1457 - accuracy: 0.9475\n",
      "Epoch 00026: val_accuracy improved from 0.96678 to 0.97056, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1457 - accuracy: 0.9475 - val_loss: 0.0953 - val_accuracy: 0.9706\n",
      "Epoch 27/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1422 - accuracy: 0.9482\n",
      "Epoch 00027: val_accuracy did not improve from 0.97056\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1421 - accuracy: 0.9482 - val_loss: 0.1320 - val_accuracy: 0.9567\n",
      "Epoch 28/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 0.9528\n",
      "Epoch 00028: val_accuracy did not improve from 0.97056\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1340 - accuracy: 0.9526 - val_loss: 0.0915 - val_accuracy: 0.9685\n",
      "Epoch 29/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1273 - accuracy: 0.9540\n",
      "Epoch 00029: val_accuracy did not improve from 0.97056\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1275 - accuracy: 0.9540 - val_loss: 0.0962 - val_accuracy: 0.9680\n",
      "Epoch 30/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1195 - accuracy: 0.9568\n",
      "Epoch 00030: val_accuracy improved from 0.97056 to 0.97098, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1197 - accuracy: 0.9568 - val_loss: 0.0898 - val_accuracy: 0.9710\n",
      "Epoch 31/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1211 - accuracy: 0.9565\n",
      "Epoch 00031: val_accuracy did not improve from 0.97098\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1210 - accuracy: 0.9565 - val_loss: 0.1420 - val_accuracy: 0.9516\n",
      "Epoch 32/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9597\n",
      "Epoch 00032: val_accuracy improved from 0.97098 to 0.97477, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1116 - accuracy: 0.9596 - val_loss: 0.0798 - val_accuracy: 0.9748\n",
      "Epoch 33/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1064 - accuracy: 0.9616\n",
      "Epoch 00033: val_accuracy did not improve from 0.97477\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1067 - accuracy: 0.9615 - val_loss: 0.0879 - val_accuracy: 0.9735\n",
      "Epoch 34/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.9595\n",
      "Epoch 00034: val_accuracy did not improve from 0.97477\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1110 - accuracy: 0.9594 - val_loss: 0.0844 - val_accuracy: 0.9739\n",
      "Epoch 35/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1004 - accuracy: 0.9644\n",
      "Epoch 00035: val_accuracy improved from 0.97477 to 0.97687, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1005 - accuracy: 0.9645 - val_loss: 0.0786 - val_accuracy: 0.9769\n",
      "Epoch 36/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9642\n",
      "Epoch 00036: val_accuracy improved from 0.97687 to 0.98024, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0986 - accuracy: 0.9643 - val_loss: 0.0685 - val_accuracy: 0.9802\n",
      "Epoch 37/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0975 - accuracy: 0.9648\n",
      "Epoch 00037: val_accuracy improved from 0.98024 to 0.98402, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0974 - accuracy: 0.9648 - val_loss: 0.0628 - val_accuracy: 0.9840\n",
      "Epoch 38/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9666\n",
      "Epoch 00038: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0947 - accuracy: 0.9665 - val_loss: 0.0626 - val_accuracy: 0.9790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0891 - accuracy: 0.9682\n",
      "Epoch 00039: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0892 - accuracy: 0.9681 - val_loss: 0.0660 - val_accuracy: 0.9781\n",
      "Epoch 40/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9687\n",
      "Epoch 00040: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0874 - accuracy: 0.9686 - val_loss: 0.0637 - val_accuracy: 0.9798\n",
      "Epoch 41/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9701\n",
      "Epoch 00041: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0831 - accuracy: 0.9700 - val_loss: 0.0703 - val_accuracy: 0.9769\n",
      "Epoch 42/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9697\n",
      "Epoch 00042: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0841 - accuracy: 0.9698 - val_loss: 0.0745 - val_accuracy: 0.9743\n",
      "Epoch 43/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0783 - accuracy: 0.9708\n",
      "Epoch 00043: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0783 - accuracy: 0.9708 - val_loss: 0.0773 - val_accuracy: 0.9765\n",
      "Epoch 44/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9739\n",
      "Epoch 00044: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0735 - accuracy: 0.9739 - val_loss: 0.1009 - val_accuracy: 0.9689\n",
      "Epoch 45/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0764 - accuracy: 0.9733\n",
      "Epoch 00045: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0763 - accuracy: 0.9734 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 46/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9732\n",
      "Epoch 00046: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0725 - accuracy: 0.9732 - val_loss: 0.0613 - val_accuracy: 0.9823\n",
      "Epoch 47/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9757\n",
      "Epoch 00047: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0710 - accuracy: 0.9757 - val_loss: 0.0608 - val_accuracy: 0.9828\n",
      "Epoch 48/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9767\n",
      "Epoch 00048: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0683 - accuracy: 0.9766 - val_loss: 0.0626 - val_accuracy: 0.9807\n",
      "Epoch 49/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0676 - accuracy: 0.9754\n",
      "Epoch 00049: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0676 - accuracy: 0.9754 - val_loss: 0.0601 - val_accuracy: 0.9823\n",
      "Epoch 50/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9769\n",
      "Epoch 00050: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0667 - accuracy: 0.9769 - val_loss: 0.0503 - val_accuracy: 0.9828\n",
      "Epoch 51/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9764\n",
      "Epoch 00051: val_accuracy improved from 0.98402 to 0.98528, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0656 - accuracy: 0.9764 - val_loss: 0.0475 - val_accuracy: 0.9853\n",
      "Epoch 52/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9787\n",
      "Epoch 00052: val_accuracy did not improve from 0.98528\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0619 - accuracy: 0.9787 - val_loss: 0.0550 - val_accuracy: 0.9832\n",
      "Epoch 53/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0592 - accuracy: 0.9790\n",
      "Epoch 00053: val_accuracy did not improve from 0.98528\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0592 - accuracy: 0.9790 - val_loss: 0.0567 - val_accuracy: 0.9836\n",
      "Epoch 54/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9790\n",
      "Epoch 00054: val_accuracy improved from 0.98528 to 0.98612, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0604 - accuracy: 0.9790 - val_loss: 0.0486 - val_accuracy: 0.9861\n",
      "Epoch 55/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0542 - accuracy: 0.9808\n",
      "Epoch 00055: val_accuracy improved from 0.98612 to 0.98823, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0543 - accuracy: 0.9807 - val_loss: 0.0391 - val_accuracy: 0.9882\n",
      "Epoch 56/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 0.9774\n",
      "Epoch 00056: val_accuracy did not improve from 0.98823\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0638 - accuracy: 0.9774 - val_loss: 0.0427 - val_accuracy: 0.9874\n",
      "Epoch 57/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9809\n",
      "Epoch 00057: val_accuracy did not improve from 0.98823\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0540 - accuracy: 0.9809 - val_loss: 0.0449 - val_accuracy: 0.9882\n",
      "Epoch 58/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9812\n",
      "Epoch 00058: val_accuracy did not improve from 0.98823\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0521 - accuracy: 0.9812 - val_loss: 0.0484 - val_accuracy: 0.9857\n",
      "Epoch 59/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9812\n",
      "Epoch 00059: val_accuracy improved from 0.98823 to 0.99117, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0535 - accuracy: 0.9813 - val_loss: 0.0404 - val_accuracy: 0.9912\n",
      "Epoch 60/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9823\n",
      "Epoch 00060: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0471 - accuracy: 0.9823 - val_loss: 0.0382 - val_accuracy: 0.9891\n",
      "Epoch 61/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9816\n",
      "Epoch 00061: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0510 - accuracy: 0.9817 - val_loss: 0.0406 - val_accuracy: 0.9895\n",
      "Epoch 62/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9831\n",
      "Epoch 00062: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0479 - accuracy: 0.9830 - val_loss: 0.0565 - val_accuracy: 0.9828\n",
      "Epoch 63/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9838\n",
      "Epoch 00063: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0482 - accuracy: 0.9838 - val_loss: 0.0388 - val_accuracy: 0.9882\n",
      "Epoch 64/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0443 - accuracy: 0.9850\n",
      "Epoch 00064: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0443 - accuracy: 0.9850 - val_loss: 0.0682 - val_accuracy: 0.9861\n",
      "Epoch 65/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9837\n",
      "Epoch 00065: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0463 - accuracy: 0.9838 - val_loss: 0.0535 - val_accuracy: 0.9861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0441 - accuracy: 0.9845\n",
      "Epoch 00066: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0441 - accuracy: 0.9845 - val_loss: 0.0467 - val_accuracy: 0.9886\n",
      "Epoch 67/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.9859\n",
      "Epoch 00067: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0430 - accuracy: 0.9860 - val_loss: 0.0439 - val_accuracy: 0.9895\n",
      "Epoch 68/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0443 - accuracy: 0.9847\n",
      "Epoch 00068: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0443 - accuracy: 0.9847 - val_loss: 0.0416 - val_accuracy: 0.9882\n",
      "Epoch 69/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9849\n",
      "Epoch 00069: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0433 - accuracy: 0.9849 - val_loss: 0.0419 - val_accuracy: 0.9899\n",
      "Epoch 70/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9846\n",
      "Epoch 00070: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0442 - accuracy: 0.9846 - val_loss: 0.0434 - val_accuracy: 0.9870\n",
      "Epoch 71/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.9848\n",
      "Epoch 00071: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0423 - accuracy: 0.9848 - val_loss: 0.0441 - val_accuracy: 0.9878\n",
      "Epoch 72/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9867\n",
      "Epoch 00072: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0371 - accuracy: 0.9867 - val_loss: 0.0406 - val_accuracy: 0.9903\n",
      "Epoch 73/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9863\n",
      "Epoch 00073: val_accuracy improved from 0.99117 to 0.99201, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0379 - accuracy: 0.9863 - val_loss: 0.0393 - val_accuracy: 0.9920\n",
      "Epoch 74/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9871\n",
      "Epoch 00074: val_accuracy improved from 0.99201 to 0.99369, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0369 - accuracy: 0.9871 - val_loss: 0.0393 - val_accuracy: 0.9937\n",
      "Epoch 75/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9870\n",
      "Epoch 00075: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0375 - accuracy: 0.9870 - val_loss: 0.0412 - val_accuracy: 0.9886\n",
      "Epoch 76/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0421 - accuracy: 0.9853\n",
      "Epoch 00076: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0420 - accuracy: 0.9853 - val_loss: 0.0336 - val_accuracy: 0.9920\n",
      "Epoch 77/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0377 - accuracy: 0.9866\n",
      "Epoch 00077: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0377 - accuracy: 0.9865 - val_loss: 0.0396 - val_accuracy: 0.9916\n",
      "Epoch 78/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9872\n",
      "Epoch 00078: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0373 - accuracy: 0.9872 - val_loss: 0.0425 - val_accuracy: 0.9920\n",
      "Epoch 79/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9867\n",
      "Epoch 00079: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0374 - accuracy: 0.9867 - val_loss: 0.0450 - val_accuracy: 0.9899\n",
      "Epoch 80/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9882\n",
      "Epoch 00080: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0340 - accuracy: 0.9883 - val_loss: 0.0363 - val_accuracy: 0.9907\n",
      "Epoch 81/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9878\n",
      "Epoch 00081: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.0366 - val_accuracy: 0.9933\n",
      "Epoch 82/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0337 - accuracy: 0.9887\n",
      "Epoch 00082: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.0401 - val_accuracy: 0.9924\n",
      "Epoch 83/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0331 - accuracy: 0.9880\n",
      "Epoch 00083: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0332 - accuracy: 0.9880 - val_loss: 0.0448 - val_accuracy: 0.9895\n",
      "Epoch 84/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9881\n",
      "Epoch 00084: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.0418 - val_accuracy: 0.9903\n",
      "Epoch 85/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9889\n",
      "Epoch 00085: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0322 - accuracy: 0.9890 - val_loss: 0.0385 - val_accuracy: 0.9899\n",
      "Epoch 86/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9874\n",
      "Epoch 00086: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0368 - accuracy: 0.9874 - val_loss: 0.0423 - val_accuracy: 0.9899\n",
      "Epoch 87/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9882\n",
      "Epoch 00087: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0329 - accuracy: 0.9882 - val_loss: 0.0419 - val_accuracy: 0.9912\n",
      "Epoch 88/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9892\n",
      "Epoch 00088: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0314 - accuracy: 0.9892 - val_loss: 0.0308 - val_accuracy: 0.9916\n",
      "Epoch 89/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9895\n",
      "Epoch 00089: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0313 - accuracy: 0.9895 - val_loss: 0.0373 - val_accuracy: 0.9929\n",
      "Epoch 90/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9898\n",
      "Epoch 00090: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0304 - accuracy: 0.9898 - val_loss: 0.0320 - val_accuracy: 0.9924\n",
      "Epoch 91/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9906\n",
      "Epoch 00091: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0272 - accuracy: 0.9907 - val_loss: 0.0425 - val_accuracy: 0.9895\n",
      "Epoch 92/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9910\n",
      "Epoch 00092: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0276 - accuracy: 0.9910 - val_loss: 0.0363 - val_accuracy: 0.9907\n",
      "Epoch 93/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9897\n",
      "Epoch 00093: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0287 - accuracy: 0.9897 - val_loss: 0.0402 - val_accuracy: 0.9933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9910\n",
      "Epoch 00094: val_accuracy did not improve from 0.99369\n",
      "Restoring model weights from the end of the best epoch.\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.0274 - val_accuracy: 0.9933\n",
      "Epoch 00094: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [23:48<23:48, 1428.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.85      0.90      0.88       492\n",
      "        car_horn       0.90      0.99      0.94       192\n",
      "children_playing       0.90      0.89      0.89       600\n",
      "        dog_bark       0.90      0.79      0.85       600\n",
      "           siren       0.94      0.99      0.97       492\n",
      "\n",
      "        accuracy                           0.90      2376\n",
      "       macro avg       0.90      0.91      0.90      2376\n",
      "    weighted avg       0.90      0.90      0.90      2376\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_20\n",
      "Epoch 1/100\n",
      "  2/669 [..............................] - ETA: 20s - loss: 2.2094 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0211s vs `on_train_batch_end` time: 0.0404s). Check your callbacks.\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.9624 - accuracy: 0.6389\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67746, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 65ms/step - loss: 0.9624 - accuracy: 0.6389 - val_loss: 0.7859 - val_accuracy: 0.6775\n",
      "Epoch 2/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.5868 - accuracy: 0.7944\n",
      "Epoch 00002: val_accuracy did not improve from 0.67746\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.5866 - accuracy: 0.7946 - val_loss: 0.9879 - val_accuracy: 0.6514\n",
      "Epoch 3/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.4117 - accuracy: 0.8556\n",
      "Epoch 00003: val_accuracy improved from 0.67746 to 0.88015, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.4114 - accuracy: 0.8558 - val_loss: 0.3197 - val_accuracy: 0.8802\n",
      "Epoch 4/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.3180 - accuracy: 0.8921\n",
      "Epoch 00004: val_accuracy improved from 0.88015 to 0.91548, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.3183 - accuracy: 0.8921 - val_loss: 0.2445 - val_accuracy: 0.9155\n",
      "Epoch 5/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.2460 - accuracy: 0.9159\n",
      "Epoch 00005: val_accuracy did not improve from 0.91548\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.2460 - accuracy: 0.9160 - val_loss: 0.4059 - val_accuracy: 0.8629\n",
      "Epoch 6/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.2231 - accuracy: 0.9216\n",
      "Epoch 00006: val_accuracy improved from 0.91548 to 0.94029, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.2230 - accuracy: 0.9217 - val_loss: 0.1751 - val_accuracy: 0.9403\n",
      "Epoch 7/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.1738 - accuracy: 0.9414\n",
      "Epoch 00007: val_accuracy improved from 0.94029 to 0.94491, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.1739 - accuracy: 0.9413 - val_loss: 0.1510 - val_accuracy: 0.9449\n",
      "Epoch 8/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9499\n",
      "Epoch 00008: val_accuracy improved from 0.94491 to 0.96720, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 65ms/step - loss: 0.1467 - accuracy: 0.9499 - val_loss: 0.1035 - val_accuracy: 0.9672\n",
      "Epoch 9/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.9602\n",
      "Epoch 00009: val_accuracy did not improve from 0.96720\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.1150 - accuracy: 0.9603 - val_loss: 0.2588 - val_accuracy: 0.9066\n",
      "Epoch 10/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.1106 - accuracy: 0.9604\n",
      "Epoch 00010: val_accuracy did not improve from 0.96720\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.1106 - accuracy: 0.9605 - val_loss: 0.1616 - val_accuracy: 0.9437\n",
      "Epoch 11/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0853 - accuracy: 0.9707\n",
      "Epoch 00011: val_accuracy improved from 0.96720 to 0.97225, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0853 - accuracy: 0.9707 - val_loss: 0.0939 - val_accuracy: 0.9722\n",
      "Epoch 12/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9702\n",
      "Epoch 00012: val_accuracy did not improve from 0.97225\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0870 - accuracy: 0.9703 - val_loss: 0.0956 - val_accuracy: 0.9693\n",
      "Epoch 13/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.9745\n",
      "Epoch 00013: val_accuracy improved from 0.97225 to 0.97393, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0739 - accuracy: 0.9745 - val_loss: 0.0831 - val_accuracy: 0.9739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0658 - accuracy: 0.9772\n",
      "Epoch 00014: val_accuracy did not improve from 0.97393\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0657 - accuracy: 0.9772 - val_loss: 0.1284 - val_accuracy: 0.9546\n",
      "Epoch 15/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9834\n",
      "Epoch 00015: val_accuracy improved from 0.97393 to 0.98066, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0493 - accuracy: 0.9835 - val_loss: 0.0597 - val_accuracy: 0.9807\n",
      "Epoch 16/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.9859\n",
      "Epoch 00016: val_accuracy improved from 0.98066 to 0.98486, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0431 - accuracy: 0.9859 - val_loss: 0.0468 - val_accuracy: 0.9849\n",
      "Epoch 17/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.9835\n",
      "Epoch 00017: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0499 - accuracy: 0.9835 - val_loss: 0.0604 - val_accuracy: 0.9798\n",
      "Epoch 18/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9865\n",
      "Epoch 00018: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0398 - accuracy: 0.9865 - val_loss: 0.1045 - val_accuracy: 0.9689\n",
      "Epoch 19/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0446 - accuracy: 0.9864\n",
      "Epoch 00019: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0446 - accuracy: 0.9864 - val_loss: 0.1193 - val_accuracy: 0.9638\n",
      "Epoch 20/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9872\n",
      "Epoch 00020: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 49s 73ms/step - loss: 0.0375 - accuracy: 0.9872 - val_loss: 0.0770 - val_accuracy: 0.9790\n",
      "Epoch 21/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9878\n",
      "Epoch 00021: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.1340 - val_accuracy: 0.9630\n",
      "Epoch 22/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9931\n",
      "Epoch 00022: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.1028 - val_accuracy: 0.9718\n",
      "Epoch 23/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9898\n",
      "Epoch 00023: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 45s 67ms/step - loss: 0.0311 - accuracy: 0.9899 - val_loss: 0.0721 - val_accuracy: 0.9794\n",
      "Epoch 24/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9902\n",
      "Epoch 00024: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0276 - accuracy: 0.9902 - val_loss: 0.1003 - val_accuracy: 0.9756\n",
      "Epoch 25/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9930\n",
      "Epoch 00025: val_accuracy improved from 0.98486 to 0.98528, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.0627 - val_accuracy: 0.9853\n",
      "Epoch 26/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9935\n",
      "Epoch 00026: val_accuracy did not improve from 0.98528\n",
      "669/669 [==============================] - 42s 64ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.0676 - val_accuracy: 0.9815\n",
      "Epoch 27/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9943\n",
      "Epoch 00027: val_accuracy did not improve from 0.98528\n",
      "669/669 [==============================] - 46s 69ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.0987 - val_accuracy: 0.9731\n",
      "Epoch 28/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9956\n",
      "Epoch 00028: val_accuracy did not improve from 0.98528\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0915 - val_accuracy: 0.9773\n",
      "Epoch 29/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9933\n",
      "Epoch 00029: val_accuracy improved from 0.98528 to 0.98654, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.0566 - val_accuracy: 0.9865\n",
      "Epoch 30/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9929\n",
      "Epoch 00030: val_accuracy did not improve from 0.98654\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 0.0611 - val_accuracy: 0.9853\n",
      "Epoch 31/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9950\n",
      "Epoch 00031: val_accuracy improved from 0.98654 to 0.98780, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.0593 - val_accuracy: 0.9878\n",
      "Epoch 32/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9945\n",
      "Epoch 00032: val_accuracy improved from 0.98780 to 0.98865, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.0462 - val_accuracy: 0.9886\n",
      "Epoch 33/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9944\n",
      "Epoch 00033: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0572 - val_accuracy: 0.9828\n",
      "Epoch 34/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9948\n",
      "Epoch 00034: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.0629 - val_accuracy: 0.9853\n",
      "Epoch 35/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 00035: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0564 - val_accuracy: 0.9878\n",
      "Epoch 36/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9958\n",
      "Epoch 00036: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 52s 78ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.1218 - val_accuracy: 0.9710\n",
      "Epoch 37/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9959\n",
      "Epoch 00037: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 55s 83ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0686 - val_accuracy: 0.9849\n",
      "Epoch 38/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9966\n",
      "Epoch 00038: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 67s 99ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.0495 - val_accuracy: 0.9886\n",
      "Epoch 39/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9978\n",
      "Epoch 00039: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0609 - val_accuracy: 0.9853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9968\n",
      "Epoch 00040: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0613 - val_accuracy: 0.9853\n",
      "Epoch 41/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9977\n",
      "Epoch 00041: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 45s 67ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0554 - val_accuracy: 0.9870\n",
      "Epoch 42/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00042: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0785 - val_accuracy: 0.9840\n",
      "Epoch 43/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9978\n",
      "Epoch 00043: val_accuracy improved from 0.98865 to 0.98907, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0480 - val_accuracy: 0.9891\n",
      "Epoch 44/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9959\n",
      "Epoch 00044: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 47s 70ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.1452 - val_accuracy: 0.9676\n",
      "Epoch 45/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 00045: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0673 - val_accuracy: 0.9878\n",
      "Epoch 46/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9973\n",
      "Epoch 00046: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0601 - val_accuracy: 0.9857\n",
      "Epoch 47/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9983\n",
      "Epoch 00047: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.2932 - val_accuracy: 0.9487\n",
      "Epoch 48/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 00048: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0539 - val_accuracy: 0.9874\n",
      "Epoch 49/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 00049: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0643 - val_accuracy: 0.9865\n",
      "Epoch 50/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9978\n",
      "Epoch 00050: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 44s 65ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0788 - val_accuracy: 0.9857\n",
      "Epoch 51/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9979\n",
      "Epoch 00051: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.0677 - val_accuracy: 0.9861\n",
      "Epoch 52/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9969\n",
      "Epoch 00052: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0715 - val_accuracy: 0.9849\n",
      "Epoch 53/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9967\n",
      "Epoch 00053: val_accuracy improved from 0.98907 to 0.98949, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0632 - val_accuracy: 0.9895\n",
      "Epoch 54/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9984\n",
      "Epoch 00054: val_accuracy did not improve from 0.98949\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.0638 - val_accuracy: 0.9853\n",
      "Epoch 55/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9971\n",
      "Epoch 00055: val_accuracy did not improve from 0.98949\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0906 - val_accuracy: 0.9769\n",
      "Epoch 56/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 00056: val_accuracy did not improve from 0.98949\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0659 - val_accuracy: 0.9870\n",
      "Epoch 57/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9985\n",
      "Epoch 00057: val_accuracy improved from 0.98949 to 0.99117, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0435 - val_accuracy: 0.9912\n",
      "Epoch 58/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 00058: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0568 - val_accuracy: 0.9874\n",
      "Epoch 59/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9982\n",
      "Epoch 00059: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0737 - val_accuracy: 0.9870\n",
      "Epoch 60/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 00060: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0698 - val_accuracy: 0.9865\n",
      "Epoch 61/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9978\n",
      "Epoch 00061: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0646 - val_accuracy: 0.9878\n",
      "Epoch 62/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00062: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0679 - val_accuracy: 0.9886\n",
      "Epoch 63/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 00063: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0863 - val_accuracy: 0.9828\n",
      "Epoch 64/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984\n",
      "Epoch 00064: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0589 - val_accuracy: 0.9874\n",
      "Epoch 65/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9972\n",
      "Epoch 00065: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.0601 - val_accuracy: 0.9874\n",
      "Epoch 66/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9973\n",
      "Epoch 00066: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0701 - val_accuracy: 0.9836\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668/669 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 00067: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0672 - val_accuracy: 0.9865\n",
      "Epoch 68/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 00068: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0536 - val_accuracy: 0.9886\n",
      "Epoch 69/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 00069: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0552 - val_accuracy: 0.9886\n",
      "Epoch 70/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 00070: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0550 - val_accuracy: 0.9891\n",
      "Epoch 71/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 00071: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0463 - val_accuracy: 0.9912\n",
      "Epoch 72/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 00072: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0638 - val_accuracy: 0.9878\n",
      "Epoch 73/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 00073: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0799 - val_accuracy: 0.9874\n",
      "Epoch 74/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9988\n",
      "Epoch 00074: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0603 - val_accuracy: 0.9899\n",
      "Epoch 75/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 00075: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0730 - val_accuracy: 0.9874\n",
      "Epoch 76/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n",
      "Epoch 00076: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0637 - val_accuracy: 0.9874\n",
      "Epoch 77/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 00077: val_accuracy did not improve from 0.99117\n",
      "Restoring model weights from the end of the best epoch.\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0530 - val_accuracy: 0.9903\n",
      "Epoch 00077: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:19:46<00:00, 2393.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.86      0.92      0.89       492\n",
      "        car_horn       0.87      0.97      0.91       192\n",
      "children_playing       0.87      0.88      0.88       600\n",
      "        dog_bark       0.88      0.78      0.83       600\n",
      "           siren       0.98      0.98      0.98       492\n",
      "\n",
      "        accuracy                           0.89      2376\n",
      "       macro avg       0.89      0.91      0.90      2376\n",
      "    weighted avg       0.89      0.89      0.89      2376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_set, models_set  = model_classifiers(classifiers, DB_from_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy(Train)</th>\n",
       "      <th>Accuracy(Val)</th>\n",
       "      <th>F1(Train)</th>\n",
       "      <th>F1(Val)</th>\n",
       "      <th>...</th>\n",
       "      <th>Precision(Val)</th>\n",
       "      <th>Recall(Train)</th>\n",
       "      <th>Recall(Val)</th>\n",
       "      <th>Conf_M</th>\n",
       "      <th>Process_time</th>\n",
       "      <th>Class_report(Val)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.872025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877201</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>[[555, 17, 31, 19, 26], [18, 198, 0, 0, 0], [11, 0, 543, 46, 0], [0, 0, 74, 517, 9], [20, 0, 60, 2, 434]]</td>\n",
       "      <td>1140.625</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.92      0.86      0.89       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>[[560, 2, 24, 46, 16], [33, 183, 0, 0, 0], [15, 0, 558, 25, 2], [4, 0, 18, 570, 8], [20, 0, 51, 2, 443]]</td>\n",
       "      <td>2156.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.89      0.86      0.87       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.803807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>[[562, 23, 13, 3, 17], [13, 185, 0, 0, 0], [22, 0, 539, 34, 5], [43, 5, 73, 472, 7], [26, 1, 91, 103, 277]]</td>\n",
       "      <td>1171.875</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.84      0.91      0.88       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.842998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854174</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>[[543, 24, 25, 12, 14], [9, 189, 0, 0, 0], [17, 5, 543, 28, 7], [28, 3, 23, 534, 12], [13, 5, 15, 149, 316]]</td>\n",
       "      <td>2312.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.89      0.88      0.88       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>[[531, 3, 25, 10, 7], [41, 202, 2, 6, 1], [53, 0, 536, 5, 6], [28, 13, 9, 545, 5], [32, 0, 47, 35, 432]]</td>\n",
       "      <td>1187.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.78      0.92      0.84       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>[[504, 19, 41, 12, 0], [9, 196, 34, 13, 0], [17, 0, 571, 11, 1], [10, 7, 12, 570, 1], [12, 12, 28, 9, 485]]</td>\n",
       "      <td>1859.375</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.91      0.88      0.89       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.856747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864665</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>[[609, 51, 37, 7, 16], [0, 257, 0, 1, 0], [17, 3, 531, 47, 2], [53, 9, 24, 501, 13], [113, 18, 3, 3, 577]]</td>\n",
       "      <td>781.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.77      0.85      0.81       7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>[[656, 17, 29, 6, 12], [3, 253, 0, 2, 0], [39, 0, 504, 57, 0], [36, 0, 14, 550, 0], [84, 3, 7, 1, 619]]</td>\n",
       "      <td>1750.000</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.80      0.91      0.85       7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.832186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841149</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>[[587, 18, 41, 9, 29], [102, 246, 2, 0, 4], [75, 0, 456, 58, 11], [6, 0, 57, 530, 7], [42, 0, 72, 15, 867]]</td>\n",
       "      <td>1218.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.86      0.78       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861982</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>[[601, 8, 30, 13, 32], [110, 231, 5, 5, 3], [73, 0, 471, 49, 7], [22, 0, 34, 536, 8], [27, 0, 43, 12, 914]]</td>\n",
       "      <td>2562.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.88      0.79       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.865765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875693</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>[[560, 2, 9, 21, 2], [56, 520, 6, 0, 6], [78, 0, 500, 21, 1], [35, 0, 80, 485, 0], [28, 15, 2, 20, 361]]</td>\n",
       "      <td>953.125</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.74      0.94      0.83       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>[[548, 3, 5, 35, 3], [63, 523, 1, 0, 1], [112, 0, 466, 16, 6], [27, 0, 48, 522, 3], [6, 13, 4, 21, 382]]</td>\n",
       "      <td>2593.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.92      0.81       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.855425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857062</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>[[456, 32, 33, 22, 45], [11, 147, 4, 3, 3], [20, 1, 567, 11, 1], [7, 5, 29, 554, 5], [76, 8, 19, 9, 332]]</td>\n",
       "      <td>828.125</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.80      0.78      0.79       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>[[488, 20, 24, 28, 28], [21, 145, 1, 1, 0], [30, 1, 553, 16, 0], [3, 0, 18, 575, 4], [64, 1, 7, 11, 361]]</td>\n",
       "      <td>1687.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.81      0.83      0.82       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838288</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>[[472, 6, 47, 53, 22], [22, 136, 3, 3, 4], [27, 0, 546, 14, 13], [17, 8, 26, 527, 22], [77, 18, 11, 1, 355]]</td>\n",
       "      <td>984.375</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.77      0.79      0.78       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>0.999437</td>\n",
       "      <td>0.857198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858832</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>[[501, 6, 25, 54, 14], [17, 140, 4, 4, 3], [36, 0, 545, 7, 12], [8, 5, 24, 539, 24], [83, 12, 5, 4, 358]]</td>\n",
       "      <td>1718.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.78      0.83      0.80       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.753047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795096</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>[[420, 8, 22, 8, 22], [13, 156, 11, 0, 0], [165, 0, 404, 3, 28], [30, 17, 41, 484, 28], [192, 0, 9, 0, 279]]</td>\n",
       "      <td>875.000</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.51      0.88      0.65       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>[[408, 1, 26, 23, 22], [11, 161, 8, 0, 0], [70, 6, 471, 33, 20], [4, 15, 38, 517, 26], [232, 0, 3, 2, 243]]</td>\n",
       "      <td>1906.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.56      0.85      0.68       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.896910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898546</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>[[445, 7, 24, 5, 11], [0, 191, 0, 1, 0], [17, 0, 534, 43, 6], [62, 15, 35, 476, 12], [0, 0, 3, 1, 488]]</td>\n",
       "      <td>968.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.85      0.90      0.88       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>[[453, 11, 14, 8, 6], [2, 186, 0, 2, 2], [11, 1, 530, 55, 3], [52, 17, 62, 468, 1], [7, 0, 1, 0, 484]]</td>\n",
       "      <td>1781.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.86      0.92      0.89       4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Fold  Accuracy(Train)  Accuracy(Val)  F1(Train)   F1(Val)  ...  Precision(Val)  Recall(Train)  Recall(Val)                                                                                                        Conf_M Process_time  \\\n",
       "0    Model_CNN_2D_Su    1         0.998774       0.870930   0.998775  0.872025  ...        0.877201       0.998774     0.870930     [[555, 17, 31, 19, 26], [18, 198, 0, 0, 0], [11, 0, 543, 46, 0], [0, 0, 74, 517, 9], [20, 0, 60, 2, 434]]     1140.625   \n",
       "1   Model_CNN_2D_Luz    1         1.000000       0.896899   1.000000  0.896829  ...        0.899769       1.000000     0.896899      [[560, 2, 24, 46, 16], [33, 183, 0, 0, 0], [15, 0, 558, 25, 2], [4, 0, 18, 570, 8], [20, 0, 51, 2, 443]]     2156.250   \n",
       "2    Model_CNN_2D_Su   10         0.999953       0.809467   0.999953  0.803807  ...        0.818571       0.999953     0.809467   [[562, 23, 13, 3, 17], [13, 185, 0, 0, 0], [22, 0, 539, 34, 5], [43, 5, 73, 472, 7], [26, 1, 91, 103, 277]]     1171.875   \n",
       "3   Model_CNN_2D_Luz   10         0.999953       0.845267   0.999953  0.842998  ...        0.854174       0.999953     0.845267  [[543, 24, 25, 12, 14], [9, 189, 0, 0, 0], [17, 5, 543, 28, 7], [28, 3, 23, 534, 12], [13, 5, 15, 149, 316]]     2312.500   \n",
       "4    Model_CNN_2D_Su    2         1.000000       0.872572   1.000000  0.872987  ...        0.880594       1.000000     0.872572      [[531, 3, 25, 10, 7], [41, 202, 2, 6, 1], [53, 0, 536, 5, 6], [28, 13, 9, 545, 5], [32, 0, 47, 35, 432]]     1187.500   \n",
       "5   Model_CNN_2D_Luz    2         1.000000       0.903652   1.000000  0.903831  ...        0.907639       1.000000     0.903652   [[504, 19, 41, 12, 0], [9, 196, 34, 13, 0], [17, 0, 571, 11, 1], [10, 7, 12, 570, 1], [12, 12, 28, 9, 485]]     1859.375   \n",
       "6    Model_CNN_2D_Su    3         0.999952       0.855809   0.999952  0.856747  ...        0.864665       0.999952     0.855809    [[609, 51, 37, 7, 16], [0, 257, 0, 1, 0], [17, 3, 531, 47, 2], [53, 9, 24, 501, 13], [113, 18, 3, 3, 577]]      781.250   \n",
       "7   Model_CNN_2D_Luz    3         1.000000       0.892808   1.000000  0.893536  ...        0.898510       1.000000     0.892808       [[656, 17, 29, 6, 12], [3, 253, 0, 2, 0], [39, 0, 504, 57, 0], [36, 0, 14, 550, 0], [84, 3, 7, 1, 619]]     1750.000   \n",
       "8    Model_CNN_2D_Su    4         0.999612       0.830550   0.999612  0.832186  ...        0.841149       0.999612     0.830550   [[587, 18, 41, 9, 29], [102, 246, 2, 0, 4], [75, 0, 456, 58, 11], [6, 0, 57, 530, 7], [42, 0, 72, 15, 867]]     1218.750   \n",
       "9   Model_CNN_2D_Luz    4         0.999903       0.851268   0.999903  0.851528  ...        0.861982       0.999903     0.851268   [[601, 8, 30, 13, 32], [110, 231, 5, 5, 3], [73, 0, 471, 49, 7], [22, 0, 34, 536, 8], [27, 0, 43, 12, 914]]     2562.500   \n",
       "10   Model_CNN_2D_Su    5         0.999381       0.863960   0.999381  0.865765  ...        0.875693       0.999381     0.863960      [[560, 2, 9, 21, 2], [56, 520, 6, 0, 6], [78, 0, 500, 21, 1], [35, 0, 80, 485, 0], [28, 15, 2, 20, 361]]      953.125   \n",
       "11  Model_CNN_2D_Luz    5         1.000000       0.869302   1.000000  0.871273  ...        0.881039       1.000000     0.869302      [[548, 3, 5, 35, 3], [63, 523, 1, 0, 1], [112, 0, 466, 16, 6], [27, 0, 48, 522, 3], [6, 13, 4, 21, 382]]     2593.750   \n",
       "12   Model_CNN_2D_Su    6         0.999298       0.856667   0.999298  0.855425  ...        0.857062       0.999298     0.856667     [[456, 32, 33, 22, 45], [11, 147, 4, 3, 3], [20, 1, 567, 11, 1], [7, 5, 29, 554, 5], [76, 8, 19, 9, 332]]      828.125   \n",
       "13  Model_CNN_2D_Luz    6         1.000000       0.884167   1.000000  0.883839  ...        0.885092       1.000000     0.884167     [[488, 20, 24, 28, 28], [21, 145, 1, 1, 0], [30, 1, 553, 16, 0], [3, 0, 18, 575, 4], [64, 1, 7, 11, 361]]     1687.500   \n",
       "14   Model_CNN_2D_Su    7         0.999438       0.837860   0.999438  0.837464  ...        0.838288       0.999438     0.837860  [[472, 6, 47, 53, 22], [22, 136, 3, 3, 4], [27, 0, 546, 14, 13], [17, 8, 26, 527, 22], [77, 18, 11, 1, 355]]      984.375   \n",
       "15  Model_CNN_2D_Luz    7         0.999438       0.857202   0.999437  0.857198  ...        0.858832       0.999438     0.857202     [[501, 6, 25, 54, 14], [17, 140, 4, 4, 3], [36, 0, 545, 7, 12], [8, 5, 24, 539, 24], [83, 12, 5, 4, 358]]     1718.750   \n",
       "16   Model_CNN_2D_Su    8         0.999487       0.744872   0.999487  0.753047  ...        0.795096       0.999487     0.744872  [[420, 8, 22, 8, 22], [13, 156, 11, 0, 0], [165, 0, 404, 3, 28], [30, 17, 41, 484, 28], [192, 0, 9, 0, 279]]      875.000   \n",
       "17  Model_CNN_2D_Luz    8         1.000000       0.769231   1.000000  0.769584  ...        0.795126       1.000000     0.769231   [[408, 1, 26, 23, 22], [11, 161, 8, 0, 0], [70, 6, 471, 33, 20], [4, 15, 38, 517, 26], [232, 0, 3, 2, 243]]     1906.250   \n",
       "18   Model_CNN_2D_Su    9         0.999860       0.898148   0.999860  0.896910  ...        0.898546       0.999860     0.898148       [[445, 7, 24, 5, 11], [0, 191, 0, 1, 0], [17, 0, 534, 43, 6], [62, 15, 35, 476, 12], [0, 0, 3, 1, 488]]      968.750   \n",
       "19  Model_CNN_2D_Luz    9         1.000000       0.892677   1.000000  0.891596  ...        0.892863       1.000000     0.892677        [[453, 11, 14, 8, 6], [2, 186, 0, 2, 2], [11, 1, 530, 55, 3], [52, 17, 62, 468, 1], [7, 0, 1, 0, 484]]     1781.250   \n",
       "\n",
       "                                                                                                          Class_report(Val)  \n",
       "0                     precision    recall  f1-score   support\\n\\n      background       0.92      0.86      0.89       6...  \n",
       "1                     precision    recall  f1-score   support\\n\\n      background       0.89      0.86      0.87       6...  \n",
       "2                     precision    recall  f1-score   support\\n\\n      background       0.84      0.91      0.88       6...  \n",
       "3                     precision    recall  f1-score   support\\n\\n      background       0.89      0.88      0.88       6...  \n",
       "4                     precision    recall  f1-score   support\\n\\n      background       0.78      0.92      0.84       5...  \n",
       "5                     precision    recall  f1-score   support\\n\\n      background       0.91      0.88      0.89       5...  \n",
       "6                     precision    recall  f1-score   support\\n\\n      background       0.77      0.85      0.81       7...  \n",
       "7                     precision    recall  f1-score   support\\n\\n      background       0.80      0.91      0.85       7...  \n",
       "8                     precision    recall  f1-score   support\\n\\n      background       0.72      0.86      0.78       6...  \n",
       "9                     precision    recall  f1-score   support\\n\\n      background       0.72      0.88      0.79       6...  \n",
       "10                    precision    recall  f1-score   support\\n\\n      background       0.74      0.94      0.83       5...  \n",
       "11                    precision    recall  f1-score   support\\n\\n      background       0.72      0.92      0.81       5...  \n",
       "12                    precision    recall  f1-score   support\\n\\n      background       0.80      0.78      0.79       5...  \n",
       "13                    precision    recall  f1-score   support\\n\\n      background       0.81      0.83      0.82       5...  \n",
       "14                    precision    recall  f1-score   support\\n\\n      background       0.77      0.79      0.78       6...  \n",
       "15                    precision    recall  f1-score   support\\n\\n      background       0.78      0.83      0.80       6...  \n",
       "16                    precision    recall  f1-score   support\\n\\n      background       0.51      0.88      0.65       4...  \n",
       "17                    precision    recall  f1-score   support\\n\\n      background       0.56      0.85      0.68       4...  \n",
       "18                    precision    recall  f1-score   support\\n\\n      background       0.85      0.90      0.88       4...  \n",
       "19                    precision    recall  f1-score   support\\n\\n      background       0.86      0.92      0.89       4...  \n",
       "\n",
       "[20 rows x 13 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy(Train)</th>\n",
       "      <th>Accuracy(Val)</th>\n",
       "      <th>F1(Train)</th>\n",
       "      <th>...</th>\n",
       "      <th>Precision(Val)</th>\n",
       "      <th>Recall(Train)</th>\n",
       "      <th>Recall(Val)</th>\n",
       "      <th>Conf_M</th>\n",
       "      <th>Process_time</th>\n",
       "      <th>Class_report(Val)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>[[408, 1, 26, 23, 22], [11, 161, 8, 0, 0], [70, 6, 471, 33, 20], [4, 15, 38, 517, 26], [232, 0, 3, 2, 243]]</td>\n",
       "      <td>1906.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.56      0.85      0.68       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854174</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>[[543, 24, 25, 12, 14], [9, 189, 0, 0, 0], [17, 5, 543, 28, 7], [28, 3, 23, 534, 12], [13, 5, 15, 149, 316]]</td>\n",
       "      <td>2312.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.89      0.88      0.88       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861982</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>[[601, 8, 30, 13, 32], [110, 231, 5, 5, 3], [73, 0, 471, 49, 7], [22, 0, 34, 536, 8], [27, 0, 43, 12, 914]]</td>\n",
       "      <td>2562.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.88      0.79       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>0.999437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858832</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>[[501, 6, 25, 54, 14], [17, 140, 4, 4, 3], [36, 0, 545, 7, 12], [8, 5, 24, 539, 24], [83, 12, 5, 4, 358]]</td>\n",
       "      <td>1718.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.78      0.83      0.80       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>[[548, 3, 5, 35, 3], [63, 523, 1, 0, 1], [112, 0, 466, 16, 6], [27, 0, 48, 522, 3], [6, 13, 4, 21, 382]]</td>\n",
       "      <td>2593.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.92      0.81       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>[[488, 20, 24, 28, 28], [21, 145, 1, 1, 0], [30, 1, 553, 16, 0], [3, 0, 18, 575, 4], [64, 1, 7, 11, 361]]</td>\n",
       "      <td>1687.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.81      0.83      0.82       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>[[453, 11, 14, 8, 6], [2, 186, 0, 2, 2], [11, 1, 530, 55, 3], [52, 17, 62, 468, 1], [7, 0, 1, 0, 484]]</td>\n",
       "      <td>1781.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.86      0.92      0.89       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>[[656, 17, 29, 6, 12], [3, 253, 0, 2, 0], [39, 0, 504, 57, 0], [36, 0, 14, 550, 0], [84, 3, 7, 1, 619]]</td>\n",
       "      <td>1750.000</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.80      0.91      0.85       7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>[[560, 2, 24, 46, 16], [33, 183, 0, 0, 0], [15, 0, 558, 25, 2], [4, 0, 18, 570, 8], [20, 0, 51, 2, 443]]</td>\n",
       "      <td>2156.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.89      0.86      0.87       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>[[504, 19, 41, 12, 0], [9, 196, 34, 13, 0], [17, 0, 571, 11, 1], [10, 7, 12, 570, 1], [12, 12, 28, 9, 485]]</td>\n",
       "      <td>1859.375</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.91      0.88      0.89       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795096</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>[[420, 8, 22, 8, 22], [13, 156, 11, 0, 0], [165, 0, 404, 3, 28], [30, 17, 41, 484, 28], [192, 0, 9, 0, 279]]</td>\n",
       "      <td>875.000</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.51      0.88      0.65       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>[[562, 23, 13, 3, 17], [13, 185, 0, 0, 0], [22, 0, 539, 34, 5], [43, 5, 73, 472, 7], [26, 1, 91, 103, 277]]</td>\n",
       "      <td>1171.875</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.84      0.91      0.88       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841149</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>[[587, 18, 41, 9, 29], [102, 246, 2, 0, 4], [75, 0, 456, 58, 11], [6, 0, 57, 530, 7], [42, 0, 72, 15, 867]]</td>\n",
       "      <td>1218.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.86      0.78       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838288</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>[[472, 6, 47, 53, 22], [22, 136, 3, 3, 4], [27, 0, 546, 14, 13], [17, 8, 26, 527, 22], [77, 18, 11, 1, 355]]</td>\n",
       "      <td>984.375</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.77      0.79      0.78       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864665</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>[[609, 51, 37, 7, 16], [0, 257, 0, 1, 0], [17, 3, 531, 47, 2], [53, 9, 24, 501, 13], [113, 18, 3, 3, 577]]</td>\n",
       "      <td>781.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.77      0.85      0.81       7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857062</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>[[456, 32, 33, 22, 45], [11, 147, 4, 3, 3], [20, 1, 567, 11, 1], [7, 5, 29, 554, 5], [76, 8, 19, 9, 332]]</td>\n",
       "      <td>828.125</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.80      0.78      0.79       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875693</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>[[560, 2, 9, 21, 2], [56, 520, 6, 0, 6], [78, 0, 500, 21, 1], [35, 0, 80, 485, 0], [28, 15, 2, 20, 361]]</td>\n",
       "      <td>953.125</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.74      0.94      0.83       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877201</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>[[555, 17, 31, 19, 26], [18, 198, 0, 0, 0], [11, 0, 543, 46, 0], [0, 0, 74, 517, 9], [20, 0, 60, 2, 434]]</td>\n",
       "      <td>1140.625</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.92      0.86      0.89       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>[[531, 3, 25, 10, 7], [41, 202, 2, 6, 1], [53, 0, 536, 5, 6], [28, 13, 9, 545, 5], [32, 0, 47, 35, 432]]</td>\n",
       "      <td>1187.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.78      0.92      0.84       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898546</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>[[445, 7, 24, 5, 11], [0, 191, 0, 1, 0], [17, 0, 534, 43, 6], [62, 15, 35, 476, 12], [0, 0, 3, 1, 488]]</td>\n",
       "      <td>968.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.85      0.90      0.88       4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index             Model Fold  Accuracy(Train)  Accuracy(Val)  F1(Train)  ...  Precision(Val)  Recall(Train)  Recall(Val)                                                                                                        Conf_M  Process_time  \\\n",
       "0      17  Model_CNN_2D_Luz    8         1.000000       0.769231   1.000000  ...        0.795126       1.000000     0.769231   [[408, 1, 26, 23, 22], [11, 161, 8, 0, 0], [70, 6, 471, 33, 20], [4, 15, 38, 517, 26], [232, 0, 3, 2, 243]]      1906.250   \n",
       "1       3  Model_CNN_2D_Luz   10         0.999953       0.845267   0.999953  ...        0.854174       0.999953     0.845267  [[543, 24, 25, 12, 14], [9, 189, 0, 0, 0], [17, 5, 543, 28, 7], [28, 3, 23, 534, 12], [13, 5, 15, 149, 316]]      2312.500   \n",
       "2       9  Model_CNN_2D_Luz    4         0.999903       0.851268   0.999903  ...        0.861982       0.999903     0.851268   [[601, 8, 30, 13, 32], [110, 231, 5, 5, 3], [73, 0, 471, 49, 7], [22, 0, 34, 536, 8], [27, 0, 43, 12, 914]]      2562.500   \n",
       "3      15  Model_CNN_2D_Luz    7         0.999438       0.857202   0.999437  ...        0.858832       0.999438     0.857202     [[501, 6, 25, 54, 14], [17, 140, 4, 4, 3], [36, 0, 545, 7, 12], [8, 5, 24, 539, 24], [83, 12, 5, 4, 358]]      1718.750   \n",
       "4      11  Model_CNN_2D_Luz    5         1.000000       0.869302   1.000000  ...        0.881039       1.000000     0.869302      [[548, 3, 5, 35, 3], [63, 523, 1, 0, 1], [112, 0, 466, 16, 6], [27, 0, 48, 522, 3], [6, 13, 4, 21, 382]]      2593.750   \n",
       "5      13  Model_CNN_2D_Luz    6         1.000000       0.884167   1.000000  ...        0.885092       1.000000     0.884167     [[488, 20, 24, 28, 28], [21, 145, 1, 1, 0], [30, 1, 553, 16, 0], [3, 0, 18, 575, 4], [64, 1, 7, 11, 361]]      1687.500   \n",
       "6      19  Model_CNN_2D_Luz    9         1.000000       0.892677   1.000000  ...        0.892863       1.000000     0.892677        [[453, 11, 14, 8, 6], [2, 186, 0, 2, 2], [11, 1, 530, 55, 3], [52, 17, 62, 468, 1], [7, 0, 1, 0, 484]]      1781.250   \n",
       "7       7  Model_CNN_2D_Luz    3         1.000000       0.892808   1.000000  ...        0.898510       1.000000     0.892808       [[656, 17, 29, 6, 12], [3, 253, 0, 2, 0], [39, 0, 504, 57, 0], [36, 0, 14, 550, 0], [84, 3, 7, 1, 619]]      1750.000   \n",
       "8       1  Model_CNN_2D_Luz    1         1.000000       0.896899   1.000000  ...        0.899769       1.000000     0.896899      [[560, 2, 24, 46, 16], [33, 183, 0, 0, 0], [15, 0, 558, 25, 2], [4, 0, 18, 570, 8], [20, 0, 51, 2, 443]]      2156.250   \n",
       "9       5  Model_CNN_2D_Luz    2         1.000000       0.903652   1.000000  ...        0.907639       1.000000     0.903652   [[504, 19, 41, 12, 0], [9, 196, 34, 13, 0], [17, 0, 571, 11, 1], [10, 7, 12, 570, 1], [12, 12, 28, 9, 485]]      1859.375   \n",
       "10     16   Model_CNN_2D_Su    8         0.999487       0.744872   0.999487  ...        0.795096       0.999487     0.744872  [[420, 8, 22, 8, 22], [13, 156, 11, 0, 0], [165, 0, 404, 3, 28], [30, 17, 41, 484, 28], [192, 0, 9, 0, 279]]       875.000   \n",
       "11      2   Model_CNN_2D_Su   10         0.999953       0.809467   0.999953  ...        0.818571       0.999953     0.809467   [[562, 23, 13, 3, 17], [13, 185, 0, 0, 0], [22, 0, 539, 34, 5], [43, 5, 73, 472, 7], [26, 1, 91, 103, 277]]      1171.875   \n",
       "12      8   Model_CNN_2D_Su    4         0.999612       0.830550   0.999612  ...        0.841149       0.999612     0.830550   [[587, 18, 41, 9, 29], [102, 246, 2, 0, 4], [75, 0, 456, 58, 11], [6, 0, 57, 530, 7], [42, 0, 72, 15, 867]]      1218.750   \n",
       "13     14   Model_CNN_2D_Su    7         0.999438       0.837860   0.999438  ...        0.838288       0.999438     0.837860  [[472, 6, 47, 53, 22], [22, 136, 3, 3, 4], [27, 0, 546, 14, 13], [17, 8, 26, 527, 22], [77, 18, 11, 1, 355]]       984.375   \n",
       "14      6   Model_CNN_2D_Su    3         0.999952       0.855809   0.999952  ...        0.864665       0.999952     0.855809    [[609, 51, 37, 7, 16], [0, 257, 0, 1, 0], [17, 3, 531, 47, 2], [53, 9, 24, 501, 13], [113, 18, 3, 3, 577]]       781.250   \n",
       "15     12   Model_CNN_2D_Su    6         0.999298       0.856667   0.999298  ...        0.857062       0.999298     0.856667     [[456, 32, 33, 22, 45], [11, 147, 4, 3, 3], [20, 1, 567, 11, 1], [7, 5, 29, 554, 5], [76, 8, 19, 9, 332]]       828.125   \n",
       "16     10   Model_CNN_2D_Su    5         0.999381       0.863960   0.999381  ...        0.875693       0.999381     0.863960      [[560, 2, 9, 21, 2], [56, 520, 6, 0, 6], [78, 0, 500, 21, 1], [35, 0, 80, 485, 0], [28, 15, 2, 20, 361]]       953.125   \n",
       "17      0   Model_CNN_2D_Su    1         0.998774       0.870930   0.998775  ...        0.877201       0.998774     0.870930     [[555, 17, 31, 19, 26], [18, 198, 0, 0, 0], [11, 0, 543, 46, 0], [0, 0, 74, 517, 9], [20, 0, 60, 2, 434]]      1140.625   \n",
       "18      4   Model_CNN_2D_Su    2         1.000000       0.872572   1.000000  ...        0.880594       1.000000     0.872572      [[531, 3, 25, 10, 7], [41, 202, 2, 6, 1], [53, 0, 536, 5, 6], [28, 13, 9, 545, 5], [32, 0, 47, 35, 432]]      1187.500   \n",
       "19     18   Model_CNN_2D_Su    9         0.999860       0.898148   0.999860  ...        0.898546       0.999860     0.898148       [[445, 7, 24, 5, 11], [0, 191, 0, 1, 0], [17, 0, 534, 43, 6], [62, 15, 35, 476, 12], [0, 0, 3, 1, 488]]       968.750   \n",
       "\n",
       "                                                                                                          Class_report(Val)  \n",
       "0                     precision    recall  f1-score   support\\n\\n      background       0.56      0.85      0.68       4...  \n",
       "1                     precision    recall  f1-score   support\\n\\n      background       0.89      0.88      0.88       6...  \n",
       "2                     precision    recall  f1-score   support\\n\\n      background       0.72      0.88      0.79       6...  \n",
       "3                     precision    recall  f1-score   support\\n\\n      background       0.78      0.83      0.80       6...  \n",
       "4                     precision    recall  f1-score   support\\n\\n      background       0.72      0.92      0.81       5...  \n",
       "5                     precision    recall  f1-score   support\\n\\n      background       0.81      0.83      0.82       5...  \n",
       "6                     precision    recall  f1-score   support\\n\\n      background       0.86      0.92      0.89       4...  \n",
       "7                     precision    recall  f1-score   support\\n\\n      background       0.80      0.91      0.85       7...  \n",
       "8                     precision    recall  f1-score   support\\n\\n      background       0.89      0.86      0.87       6...  \n",
       "9                     precision    recall  f1-score   support\\n\\n      background       0.91      0.88      0.89       5...  \n",
       "10                    precision    recall  f1-score   support\\n\\n      background       0.51      0.88      0.65       4...  \n",
       "11                    precision    recall  f1-score   support\\n\\n      background       0.84      0.91      0.88       6...  \n",
       "12                    precision    recall  f1-score   support\\n\\n      background       0.72      0.86      0.78       6...  \n",
       "13                    precision    recall  f1-score   support\\n\\n      background       0.77      0.79      0.78       6...  \n",
       "14                    precision    recall  f1-score   support\\n\\n      background       0.77      0.85      0.81       7...  \n",
       "15                    precision    recall  f1-score   support\\n\\n      background       0.80      0.78      0.79       5...  \n",
       "16                    precision    recall  f1-score   support\\n\\n      background       0.74      0.94      0.83       5...  \n",
       "17                    precision    recall  f1-score   support\\n\\n      background       0.92      0.86      0.89       6...  \n",
       "18                    precision    recall  f1-score   support\\n\\n      background       0.78      0.92      0.84       5...  \n",
       "19                    precision    recall  f1-score   support\\n\\n      background       0.85      0.90      0.88       4...  \n",
       "\n",
       "[20 rows x 14 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by Model and Accuracy test. Reset the index.\n",
    "\n",
    "metrics_set = metrics_set.sort_values(['Model', 'Accuracy(Val)'], ascending = [True, True]).reset_index()\n",
    "metrics_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_db288_row0_col1 {\n",
       "  background-color: #d9e7f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_db288_row1_col1 {\n",
       "  background-color: #4090c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row2_col1 {\n",
       "  background-color: #3686c0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row3_col1 {\n",
       "  background-color: #2c7cba;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row4_col1 {\n",
       "  background-color: #1a68ae;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row5_col1 {\n",
       "  background-color: #08509b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row6_col1, #T_db288_row7_col1 {\n",
       "  background-color: #084285;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row8_col1 {\n",
       "  background-color: #083a7a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row9_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row10_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_db288_row11_col1 {\n",
       "  background-color: #91c3de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_db288_row12_col1 {\n",
       "  background-color: #5da5d1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row13_col1 {\n",
       "  background-color: #4f9bcb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row14_col1 {\n",
       "  background-color: #2f7fbc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row15_col1 {\n",
       "  background-color: #2d7dbb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row16_col1 {\n",
       "  background-color: #2070b4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row17_col1 {\n",
       "  background-color: #1865ac;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row18_col1 {\n",
       "  background-color: #1663aa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row19_col1 {\n",
       "  background-color: #083877;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_db288\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_db288_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_db288_level0_col1\" class=\"col_heading level0 col1\" >Accuracy(Val)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_db288_row0_col0\" class=\"data row0 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row0_col1\" class=\"data row0 col1\" >0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_db288_row1_col0\" class=\"data row1 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row1_col1\" class=\"data row1 col1\" >0.845267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_db288_row2_col0\" class=\"data row2 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row2_col1\" class=\"data row2 col1\" >0.851268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_db288_row3_col0\" class=\"data row3 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row3_col1\" class=\"data row3 col1\" >0.857202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_db288_row4_col0\" class=\"data row4 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row4_col1\" class=\"data row4 col1\" >0.869302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_db288_row5_col0\" class=\"data row5 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row5_col1\" class=\"data row5 col1\" >0.884167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_db288_row6_col0\" class=\"data row6 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row6_col1\" class=\"data row6 col1\" >0.892677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_db288_row7_col0\" class=\"data row7 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row7_col1\" class=\"data row7 col1\" >0.892808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_db288_row8_col0\" class=\"data row8 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row8_col1\" class=\"data row8 col1\" >0.896899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_db288_row9_col0\" class=\"data row9 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row9_col1\" class=\"data row9 col1\" >0.903652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_db288_row10_col0\" class=\"data row10 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row10_col1\" class=\"data row10 col1\" >0.744872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_db288_row11_col0\" class=\"data row11 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row11_col1\" class=\"data row11 col1\" >0.809467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_db288_row12_col0\" class=\"data row12 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row12_col1\" class=\"data row12 col1\" >0.830550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_db288_row13_col0\" class=\"data row13 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row13_col1\" class=\"data row13 col1\" >0.837860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_db288_row14_col0\" class=\"data row14 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row14_col1\" class=\"data row14 col1\" >0.855809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_db288_row15_col0\" class=\"data row15 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row15_col1\" class=\"data row15 col1\" >0.856667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_db288_row16_col0\" class=\"data row16 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row16_col1\" class=\"data row16 col1\" >0.863960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_db288_row17_col0\" class=\"data row17 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row17_col1\" class=\"data row17 col1\" >0.870930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_db288_row18_col0\" class=\"data row18 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row18_col1\" class=\"data row18 col1\" >0.872572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_db288_row19_col0\" class=\"data row19 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row19_col1\" class=\"data row19 col1\" >0.898148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1457f08ad00>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_set[['Model', 'Accuracy(Val)']].style.background_gradient(cmap = cmap_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "Model_CNN_2D_Luz    0.903652\n",
       "Model_CNN_2D_Su     0.898148\n",
       "Name: Accuracy(Val), dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_accuracy = metrics_set.groupby('Model')['Accuracy(Val)'].max()\n",
    "highest_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dictionary of each classifier and its data explanation\n",
    "\n",
    "unique_models = []\n",
    "results       = {}\n",
    "\n",
    "for c in classifiers:\n",
    "    unique_models.append(c)\n",
    "\n",
    "for model in unique_models:\n",
    "    result = metrics_set[metrics_set['Model'] == model].describe().round(4)\n",
    "    results[model] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model...: Model_CNN_2D_Su\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Accuracy(Train)</th>\n",
       "      <th>Accuracy(Val)</th>\n",
       "      <th>F1(Train)</th>\n",
       "      <th>F1(Val)</th>\n",
       "      <th>Precision(Train)</th>\n",
       "      <th>Precision(Val)</th>\n",
       "      <th>Recall(Train)</th>\n",
       "      <th>Recall(Val)</th>\n",
       "      <th>Process_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.0000</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.8441</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.8446</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.8547</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.8441</td>\n",
       "      <td>1010.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.0553</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>159.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.7449</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.7449</td>\n",
       "      <td>781.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.8335</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>894.5312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.0000</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8561</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8609</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>976.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.5000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>1164.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8969</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8985</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>1218.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  Accuracy(Train)  Accuracy(Val)  F1(Train)  F1(Val)  Precision(Train)  Precision(Val)  Recall(Train)  Recall(Val)  Process_time\n",
       "count  10.0000          10.0000        10.0000    10.0000  10.0000           10.0000         10.0000        10.0000      10.0000       10.0000\n",
       "mean    9.0000           0.9996         0.8441     0.9996   0.8446            0.9996          0.8547         0.9996       0.8441     1010.9375\n",
       "std     6.0553           0.0004         0.0427     0.0004   0.0412            0.0004          0.0315         0.0004       0.0427      159.0120\n",
       "min     0.0000           0.9988         0.7449     0.9988   0.7530            0.9988          0.7951         0.9988       0.7449      781.2500\n",
       "25%     4.5000           0.9994         0.8324     0.9994   0.8335            0.9994          0.8390         0.9994       0.8324      894.5312\n",
       "50%     9.0000           0.9995         0.8562     0.9995   0.8561            0.9995          0.8609         0.9995       0.8562      976.5625\n",
       "75%    13.5000           0.9999         0.8692     0.9999   0.8705            0.9999          0.8768         0.9999       0.8692     1164.0625\n",
       "max    18.0000           1.0000         0.8981     1.0000   0.8969            1.0000          0.8985         1.0000       0.8981     1218.7500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model...: Model_CNN_2D_Luz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Accuracy(Train)</th>\n",
       "      <th>Accuracy(Val)</th>\n",
       "      <th>F1(Train)</th>\n",
       "      <th>F1(Val)</th>\n",
       "      <th>Precision(Train)</th>\n",
       "      <th>Precision(Val)</th>\n",
       "      <th>Recall(Train)</th>\n",
       "      <th>Recall(Val)</th>\n",
       "      <th>Process_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>2032.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.0553</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>348.9544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.7696</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>1687.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.5000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8529</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>1757.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8767</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8776</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8767</td>\n",
       "      <td>1882.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.5000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8931</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8971</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>2273.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9076</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>2593.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  Accuracy(Train)  Accuracy(Val)  F1(Train)  F1(Val)  Precision(Train)  Precision(Val)  Recall(Train)  Recall(Val)  Process_time\n",
       "count  10.0000          10.0000        10.0000    10.0000  10.0000           10.0000         10.0000        10.0000      10.0000       10.0000\n",
       "mean   10.0000           0.9999         0.8662     0.9999   0.8662            0.9999          0.8735         0.9999       0.8662     2032.8125\n",
       "std     6.0553           0.0002         0.0398     0.0002   0.0398            0.0002          0.0332         0.0002       0.0398      348.9544\n",
       "min     1.0000           0.9994         0.7692     0.9994   0.7696            0.9994          0.7951         0.9994       0.7692     1687.5000\n",
       "25%     5.5000           1.0000         0.8528     1.0000   0.8529            1.0000          0.8596         1.0000       0.8528     1757.8125\n",
       "50%    10.0000           1.0000         0.8767     1.0000   0.8776            1.0000          0.8831         1.0000       0.8767     1882.8125\n",
       "75%    14.5000           1.0000         0.8928     1.0000   0.8931            1.0000          0.8971         1.0000       0.8928     2273.4375\n",
       "max    19.0000           1.0000         0.9037     1.0000   0.9038            1.0000          0.9076         1.0000       0.9037     2593.7500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in results.keys():\n",
    "    print(f'Model...: {model}')\n",
    "    display(results[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy(Train)</th>\n",
       "      <th>Accuracy(Val)</th>\n",
       "      <th>F1(Train)</th>\n",
       "      <th>F1(Val)</th>\n",
       "      <th>Precision(Train)</th>\n",
       "      <th>Precision(Val)</th>\n",
       "      <th>Recall(Train)</th>\n",
       "      <th>Recall(Val)</th>\n",
       "      <th>Process_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.795126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1906.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.842998</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.854174</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>2312.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851528</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.861982</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>2562.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>0.999437</td>\n",
       "      <td>0.857198</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.858832</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>1718.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>2593.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>1687.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>1781.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>1750.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>2156.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>1859.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.753047</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.795096</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>875.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.803807</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>1171.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.832186</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.841149</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>1218.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837464</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.838288</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>984.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.856747</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.864665</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>781.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.855425</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.857062</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>828.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.865765</td>\n",
       "      <td>0.999382</td>\n",
       "      <td>0.875693</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>953.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.872025</td>\n",
       "      <td>0.998776</td>\n",
       "      <td>0.877201</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>1140.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>1187.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.896910</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898546</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>968.750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index             Model Fold  Accuracy(Train)  Accuracy(Val)  F1(Train)   F1(Val)  Precision(Train)  Precision(Val)  Recall(Train)  Recall(Val)  Process_time\n",
       "0      17  Model_CNN_2D_Luz    8         1.000000       0.769231   1.000000  0.769584          1.000000        0.795126       1.000000     0.769231      1906.250\n",
       "1       3  Model_CNN_2D_Luz   10         0.999953       0.845267   0.999953  0.842998          0.999953        0.854174       0.999953     0.845267      2312.500\n",
       "2       9  Model_CNN_2D_Luz    4         0.999903       0.851268   0.999903  0.851528          0.999903        0.861982       0.999903     0.851268      2562.500\n",
       "3      15  Model_CNN_2D_Luz    7         0.999438       0.857202   0.999437  0.857198          0.999439        0.858832       0.999438     0.857202      1718.750\n",
       "4      11  Model_CNN_2D_Luz    5         1.000000       0.869302   1.000000  0.871273          1.000000        0.881039       1.000000     0.869302      2593.750\n",
       "5      13  Model_CNN_2D_Luz    6         1.000000       0.884167   1.000000  0.883839          1.000000        0.885092       1.000000     0.884167      1687.500\n",
       "6      19  Model_CNN_2D_Luz    9         1.000000       0.892677   1.000000  0.891596          1.000000        0.892863       1.000000     0.892677      1781.250\n",
       "7       7  Model_CNN_2D_Luz    3         1.000000       0.892808   1.000000  0.893536          1.000000        0.898510       1.000000     0.892808      1750.000\n",
       "8       1  Model_CNN_2D_Luz    1         1.000000       0.896899   1.000000  0.896829          1.000000        0.899769       1.000000     0.896899      2156.250\n",
       "9       5  Model_CNN_2D_Luz    2         1.000000       0.903652   1.000000  0.903831          1.000000        0.907639       1.000000     0.903652      1859.375\n",
       "10     16   Model_CNN_2D_Su    8         0.999487       0.744872   0.999487  0.753047          0.999487        0.795096       0.999487     0.744872       875.000\n",
       "11      2   Model_CNN_2D_Su   10         0.999953       0.809467   0.999953  0.803807          0.999953        0.818571       0.999953     0.809467      1171.875\n",
       "12      8   Model_CNN_2D_Su    4         0.999612       0.830550   0.999612  0.832186          0.999612        0.841149       0.999612     0.830550      1218.750\n",
       "13     14   Model_CNN_2D_Su    7         0.999438       0.837860   0.999438  0.837464          0.999438        0.838288       0.999438     0.837860       984.375\n",
       "14      6   Model_CNN_2D_Su    3         0.999952       0.855809   0.999952  0.856747          0.999952        0.864665       0.999952     0.855809       781.250\n",
       "15     12   Model_CNN_2D_Su    6         0.999298       0.856667   0.999298  0.855425          0.999300        0.857062       0.999298     0.856667       828.125\n",
       "16     10   Model_CNN_2D_Su    5         0.999381       0.863960   0.999381  0.865765          0.999382        0.875693       0.999381     0.863960       953.125\n",
       "17      0   Model_CNN_2D_Su    1         0.998774       0.870930   0.998775  0.872025          0.998776        0.877201       0.998774     0.870930      1140.625\n",
       "18      4   Model_CNN_2D_Su    2         1.000000       0.872572   1.000000  0.872987          1.000000        0.880594       1.000000     0.872572      1187.500\n",
       "19     18   Model_CNN_2D_Su    9         0.999860       0.898148   0.999860  0.896910          0.999860        0.898546       0.999860     0.898148       968.750"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_set_no_cm = metrics_set.drop(['Conf_M', 'Class_report(Val)'], axis=1)\n",
    "metrics_set_no_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US8K_AV_metrics_set_CNN_2D_augmented.pkl\n",
      "US8K_AV_metrics_set_CNN_2D_augmented_no_cm.csv\n"
     ]
    }
   ],
   "source": [
    "metrics_set_name       = nom_dataset + '_metrics_set_CNN_2D' +  model_surname + '.pkl'\n",
    "metrics_set_name_no_cm = nom_dataset + '_metrics_set_CNN_2D' +  model_surname + '_no_cm.csv'\n",
    "\n",
    "print(metrics_set_name)\n",
    "print(metrics_set_name_no_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes de results to a PKL and CSV file\n",
    "\n",
    "with open(os.path.join(path_models, metrics_set_name), 'wb') as file:\n",
    "    pickle.dump(metrics_set, file)\n",
    "    \n",
    "metrics_set_no_cm.to_csv(os.path.join(path_models, metrics_set_name_no_cm), sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy(Train)</th>\n",
       "      <th>Accuracy(Val)</th>\n",
       "      <th>F1(Train)</th>\n",
       "      <th>...</th>\n",
       "      <th>Precision(Val)</th>\n",
       "      <th>Recall(Train)</th>\n",
       "      <th>Recall(Val)</th>\n",
       "      <th>Conf_M</th>\n",
       "      <th>Process_time</th>\n",
       "      <th>Class_report(Val)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>[[408, 1, 26, 23, 22], [11, 161, 8, 0, 0], [70, 6, 471, 33, 20], [4, 15, 38, 517, 26], [232, 0, 3, 2, 243]]</td>\n",
       "      <td>1906.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.56      0.85      0.68       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854174</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>[[543, 24, 25, 12, 14], [9, 189, 0, 0, 0], [17, 5, 543, 28, 7], [28, 3, 23, 534, 12], [13, 5, 15, 149, 316]]</td>\n",
       "      <td>2312.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.89      0.88      0.88       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861982</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>[[601, 8, 30, 13, 32], [110, 231, 5, 5, 3], [73, 0, 471, 49, 7], [22, 0, 34, 536, 8], [27, 0, 43, 12, 914]]</td>\n",
       "      <td>2562.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.88      0.79       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>0.999437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858832</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>[[501, 6, 25, 54, 14], [17, 140, 4, 4, 3], [36, 0, 545, 7, 12], [8, 5, 24, 539, 24], [83, 12, 5, 4, 358]]</td>\n",
       "      <td>1718.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.78      0.83      0.80       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>[[548, 3, 5, 35, 3], [63, 523, 1, 0, 1], [112, 0, 466, 16, 6], [27, 0, 48, 522, 3], [6, 13, 4, 21, 382]]</td>\n",
       "      <td>2593.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.92      0.81       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>[[488, 20, 24, 28, 28], [21, 145, 1, 1, 0], [30, 1, 553, 16, 0], [3, 0, 18, 575, 4], [64, 1, 7, 11, 361]]</td>\n",
       "      <td>1687.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.81      0.83      0.82       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>[[453, 11, 14, 8, 6], [2, 186, 0, 2, 2], [11, 1, 530, 55, 3], [52, 17, 62, 468, 1], [7, 0, 1, 0, 484]]</td>\n",
       "      <td>1781.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.86      0.92      0.89       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>[[656, 17, 29, 6, 12], [3, 253, 0, 2, 0], [39, 0, 504, 57, 0], [36, 0, 14, 550, 0], [84, 3, 7, 1, 619]]</td>\n",
       "      <td>1750.000</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.80      0.91      0.85       7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>[[560, 2, 24, 46, 16], [33, 183, 0, 0, 0], [15, 0, 558, 25, 2], [4, 0, 18, 570, 8], [20, 0, 51, 2, 443]]</td>\n",
       "      <td>2156.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.89      0.86      0.87       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>[[504, 19, 41, 12, 0], [9, 196, 34, 13, 0], [17, 0, 571, 11, 1], [10, 7, 12, 570, 1], [12, 12, 28, 9, 485]]</td>\n",
       "      <td>1859.375</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.91      0.88      0.89       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795096</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>[[420, 8, 22, 8, 22], [13, 156, 11, 0, 0], [165, 0, 404, 3, 28], [30, 17, 41, 484, 28], [192, 0, 9, 0, 279]]</td>\n",
       "      <td>875.000</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.51      0.88      0.65       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>[[562, 23, 13, 3, 17], [13, 185, 0, 0, 0], [22, 0, 539, 34, 5], [43, 5, 73, 472, 7], [26, 1, 91, 103, 277]]</td>\n",
       "      <td>1171.875</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.84      0.91      0.88       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841149</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>[[587, 18, 41, 9, 29], [102, 246, 2, 0, 4], [75, 0, 456, 58, 11], [6, 0, 57, 530, 7], [42, 0, 72, 15, 867]]</td>\n",
       "      <td>1218.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.86      0.78       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838288</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>[[472, 6, 47, 53, 22], [22, 136, 3, 3, 4], [27, 0, 546, 14, 13], [17, 8, 26, 527, 22], [77, 18, 11, 1, 355]]</td>\n",
       "      <td>984.375</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.77      0.79      0.78       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864665</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>[[609, 51, 37, 7, 16], [0, 257, 0, 1, 0], [17, 3, 531, 47, 2], [53, 9, 24, 501, 13], [113, 18, 3, 3, 577]]</td>\n",
       "      <td>781.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.77      0.85      0.81       7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857062</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>[[456, 32, 33, 22, 45], [11, 147, 4, 3, 3], [20, 1, 567, 11, 1], [7, 5, 29, 554, 5], [76, 8, 19, 9, 332]]</td>\n",
       "      <td>828.125</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.80      0.78      0.79       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875693</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>[[560, 2, 9, 21, 2], [56, 520, 6, 0, 6], [78, 0, 500, 21, 1], [35, 0, 80, 485, 0], [28, 15, 2, 20, 361]]</td>\n",
       "      <td>953.125</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.74      0.94      0.83       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877201</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>[[555, 17, 31, 19, 26], [18, 198, 0, 0, 0], [11, 0, 543, 46, 0], [0, 0, 74, 517, 9], [20, 0, 60, 2, 434]]</td>\n",
       "      <td>1140.625</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.92      0.86      0.89       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>[[531, 3, 25, 10, 7], [41, 202, 2, 6, 1], [53, 0, 536, 5, 6], [28, 13, 9, 545, 5], [32, 0, 47, 35, 432]]</td>\n",
       "      <td>1187.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.78      0.92      0.84       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898546</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>[[445, 7, 24, 5, 11], [0, 191, 0, 1, 0], [17, 0, 534, 43, 6], [62, 15, 35, 476, 12], [0, 0, 3, 1, 488]]</td>\n",
       "      <td>968.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.85      0.90      0.88       4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index             Model Fold  Accuracy(Train)  Accuracy(Val)  F1(Train)  ...  Precision(Val)  Recall(Train)  Recall(Val)                                                                                                        Conf_M  Process_time  \\\n",
       "0      17  Model_CNN_2D_Luz    8         1.000000       0.769231   1.000000  ...        0.795126       1.000000     0.769231   [[408, 1, 26, 23, 22], [11, 161, 8, 0, 0], [70, 6, 471, 33, 20], [4, 15, 38, 517, 26], [232, 0, 3, 2, 243]]      1906.250   \n",
       "1       3  Model_CNN_2D_Luz   10         0.999953       0.845267   0.999953  ...        0.854174       0.999953     0.845267  [[543, 24, 25, 12, 14], [9, 189, 0, 0, 0], [17, 5, 543, 28, 7], [28, 3, 23, 534, 12], [13, 5, 15, 149, 316]]      2312.500   \n",
       "2       9  Model_CNN_2D_Luz    4         0.999903       0.851268   0.999903  ...        0.861982       0.999903     0.851268   [[601, 8, 30, 13, 32], [110, 231, 5, 5, 3], [73, 0, 471, 49, 7], [22, 0, 34, 536, 8], [27, 0, 43, 12, 914]]      2562.500   \n",
       "3      15  Model_CNN_2D_Luz    7         0.999438       0.857202   0.999437  ...        0.858832       0.999438     0.857202     [[501, 6, 25, 54, 14], [17, 140, 4, 4, 3], [36, 0, 545, 7, 12], [8, 5, 24, 539, 24], [83, 12, 5, 4, 358]]      1718.750   \n",
       "4      11  Model_CNN_2D_Luz    5         1.000000       0.869302   1.000000  ...        0.881039       1.000000     0.869302      [[548, 3, 5, 35, 3], [63, 523, 1, 0, 1], [112, 0, 466, 16, 6], [27, 0, 48, 522, 3], [6, 13, 4, 21, 382]]      2593.750   \n",
       "5      13  Model_CNN_2D_Luz    6         1.000000       0.884167   1.000000  ...        0.885092       1.000000     0.884167     [[488, 20, 24, 28, 28], [21, 145, 1, 1, 0], [30, 1, 553, 16, 0], [3, 0, 18, 575, 4], [64, 1, 7, 11, 361]]      1687.500   \n",
       "6      19  Model_CNN_2D_Luz    9         1.000000       0.892677   1.000000  ...        0.892863       1.000000     0.892677        [[453, 11, 14, 8, 6], [2, 186, 0, 2, 2], [11, 1, 530, 55, 3], [52, 17, 62, 468, 1], [7, 0, 1, 0, 484]]      1781.250   \n",
       "7       7  Model_CNN_2D_Luz    3         1.000000       0.892808   1.000000  ...        0.898510       1.000000     0.892808       [[656, 17, 29, 6, 12], [3, 253, 0, 2, 0], [39, 0, 504, 57, 0], [36, 0, 14, 550, 0], [84, 3, 7, 1, 619]]      1750.000   \n",
       "8       1  Model_CNN_2D_Luz    1         1.000000       0.896899   1.000000  ...        0.899769       1.000000     0.896899      [[560, 2, 24, 46, 16], [33, 183, 0, 0, 0], [15, 0, 558, 25, 2], [4, 0, 18, 570, 8], [20, 0, 51, 2, 443]]      2156.250   \n",
       "9       5  Model_CNN_2D_Luz    2         1.000000       0.903652   1.000000  ...        0.907639       1.000000     0.903652   [[504, 19, 41, 12, 0], [9, 196, 34, 13, 0], [17, 0, 571, 11, 1], [10, 7, 12, 570, 1], [12, 12, 28, 9, 485]]      1859.375   \n",
       "10     16   Model_CNN_2D_Su    8         0.999487       0.744872   0.999487  ...        0.795096       0.999487     0.744872  [[420, 8, 22, 8, 22], [13, 156, 11, 0, 0], [165, 0, 404, 3, 28], [30, 17, 41, 484, 28], [192, 0, 9, 0, 279]]       875.000   \n",
       "11      2   Model_CNN_2D_Su   10         0.999953       0.809467   0.999953  ...        0.818571       0.999953     0.809467   [[562, 23, 13, 3, 17], [13, 185, 0, 0, 0], [22, 0, 539, 34, 5], [43, 5, 73, 472, 7], [26, 1, 91, 103, 277]]      1171.875   \n",
       "12      8   Model_CNN_2D_Su    4         0.999612       0.830550   0.999612  ...        0.841149       0.999612     0.830550   [[587, 18, 41, 9, 29], [102, 246, 2, 0, 4], [75, 0, 456, 58, 11], [6, 0, 57, 530, 7], [42, 0, 72, 15, 867]]      1218.750   \n",
       "13     14   Model_CNN_2D_Su    7         0.999438       0.837860   0.999438  ...        0.838288       0.999438     0.837860  [[472, 6, 47, 53, 22], [22, 136, 3, 3, 4], [27, 0, 546, 14, 13], [17, 8, 26, 527, 22], [77, 18, 11, 1, 355]]       984.375   \n",
       "14      6   Model_CNN_2D_Su    3         0.999952       0.855809   0.999952  ...        0.864665       0.999952     0.855809    [[609, 51, 37, 7, 16], [0, 257, 0, 1, 0], [17, 3, 531, 47, 2], [53, 9, 24, 501, 13], [113, 18, 3, 3, 577]]       781.250   \n",
       "15     12   Model_CNN_2D_Su    6         0.999298       0.856667   0.999298  ...        0.857062       0.999298     0.856667     [[456, 32, 33, 22, 45], [11, 147, 4, 3, 3], [20, 1, 567, 11, 1], [7, 5, 29, 554, 5], [76, 8, 19, 9, 332]]       828.125   \n",
       "16     10   Model_CNN_2D_Su    5         0.999381       0.863960   0.999381  ...        0.875693       0.999381     0.863960      [[560, 2, 9, 21, 2], [56, 520, 6, 0, 6], [78, 0, 500, 21, 1], [35, 0, 80, 485, 0], [28, 15, 2, 20, 361]]       953.125   \n",
       "17      0   Model_CNN_2D_Su    1         0.998774       0.870930   0.998775  ...        0.877201       0.998774     0.870930     [[555, 17, 31, 19, 26], [18, 198, 0, 0, 0], [11, 0, 543, 46, 0], [0, 0, 74, 517, 9], [20, 0, 60, 2, 434]]      1140.625   \n",
       "18      4   Model_CNN_2D_Su    2         1.000000       0.872572   1.000000  ...        0.880594       1.000000     0.872572      [[531, 3, 25, 10, 7], [41, 202, 2, 6, 1], [53, 0, 536, 5, 6], [28, 13, 9, 545, 5], [32, 0, 47, 35, 432]]      1187.500   \n",
       "19     18   Model_CNN_2D_Su    9         0.999860       0.898148   0.999860  ...        0.898546       0.999860     0.898148       [[445, 7, 24, 5, 11], [0, 191, 0, 1, 0], [17, 0, 534, 43, 6], [62, 15, 35, 476, 12], [0, 0, 3, 1, 488]]       968.750   \n",
       "\n",
       "                                                                                                          Class_report(Val)  \n",
       "0                     precision    recall  f1-score   support\\n\\n      background       0.56      0.85      0.68       4...  \n",
       "1                     precision    recall  f1-score   support\\n\\n      background       0.89      0.88      0.88       6...  \n",
       "2                     precision    recall  f1-score   support\\n\\n      background       0.72      0.88      0.79       6...  \n",
       "3                     precision    recall  f1-score   support\\n\\n      background       0.78      0.83      0.80       6...  \n",
       "4                     precision    recall  f1-score   support\\n\\n      background       0.72      0.92      0.81       5...  \n",
       "5                     precision    recall  f1-score   support\\n\\n      background       0.81      0.83      0.82       5...  \n",
       "6                     precision    recall  f1-score   support\\n\\n      background       0.86      0.92      0.89       4...  \n",
       "7                     precision    recall  f1-score   support\\n\\n      background       0.80      0.91      0.85       7...  \n",
       "8                     precision    recall  f1-score   support\\n\\n      background       0.89      0.86      0.87       6...  \n",
       "9                     precision    recall  f1-score   support\\n\\n      background       0.91      0.88      0.89       5...  \n",
       "10                    precision    recall  f1-score   support\\n\\n      background       0.51      0.88      0.65       4...  \n",
       "11                    precision    recall  f1-score   support\\n\\n      background       0.84      0.91      0.88       6...  \n",
       "12                    precision    recall  f1-score   support\\n\\n      background       0.72      0.86      0.78       6...  \n",
       "13                    precision    recall  f1-score   support\\n\\n      background       0.77      0.79      0.78       6...  \n",
       "14                    precision    recall  f1-score   support\\n\\n      background       0.77      0.85      0.81       7...  \n",
       "15                    precision    recall  f1-score   support\\n\\n      background       0.80      0.78      0.79       5...  \n",
       "16                    precision    recall  f1-score   support\\n\\n      background       0.74      0.94      0.83       5...  \n",
       "17                    precision    recall  f1-score   support\\n\\n      background       0.92      0.86      0.89       6...  \n",
       "18                    precision    recall  f1-score   support\\n\\n      background       0.78      0.92      0.84       5...  \n",
       "19                    precision    recall  f1-score   support\\n\\n      background       0.85      0.90      0.88       4...  \n",
       "\n",
       "[20 rows x 14 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_set_from_pkl = pd.read_pickle(os.path.join(path_models, metrics_set_name))\n",
    "metrics_set_from_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model_CNN_2D_Luz': {'Accuracy(Val)': 0.9036519036519036,\n",
       "  'Conf_M': array([[504,  19,  41,  12,   0],\n",
       "         [  9, 196,  34,  13,   0],\n",
       "         [ 17,   0, 571,  11,   1],\n",
       "         [ 10,   7,  12, 570,   1],\n",
       "         [ 12,  12,  28,   9, 485]], dtype=int64)},\n",
       " 'Model_CNN_2D_Su': {'Accuracy(Val)': 0.8981481481481481,\n",
       "  'Conf_M': array([[445,   7,  24,   5,  11],\n",
       "         [  0, 191,   0,   1,   0],\n",
       "         [ 17,   0, 534,  43,   6],\n",
       "         [ 62,  15,  35, 476,  12],\n",
       "         [  0,   0,   3,   1, 488]], dtype=int64)}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = metrics_set.groupby('Model')['Accuracy(Val)'].idxmax()\n",
    "conf_matrices = metrics_set.loc[idx, ['Model','Accuracy(Val)','Conf_M']]\n",
    "conf_matrices.set_index('Model', inplace=True)\n",
    "conf_matrices_dict = conf_matrices.to_dict('index')\n",
    "conf_matrices_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[445,   7,  24,   5,  11],\n",
       "       [  0, 191,   0,   1,   0],\n",
       "       [ 17,   0, 534,  43,   6],\n",
       "       [ 62,  15,  35, 476,  12],\n",
       "       [  0,   0,   3,   1, 488]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrices_dict['Model_CNN_2D_Su']['Conf_M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Model_CNN_2D_Luz\n",
      "0.9036519036519036\n",
      "[[504  19  41  12   0]\n",
      " [  9 196  34  13   0]\n",
      " [ 17   0 571  11   1]\n",
      " [ 10   7  12 570   1]\n",
      " [ 12  12  28   9 485]]\n",
      "2\n",
      "Model_CNN_2D_Su\n",
      "0.8981481481481481\n",
      "[[445   7  24   5  11]\n",
      " [  0 191   0   1   0]\n",
      " [ 17   0 534  43   6]\n",
      " [ 62  15  35 476  12]\n",
      " [  0   0   3   1 488]]\n"
     ]
    }
   ],
   "source": [
    "for i, idx in zip(conf_matrices_dict.keys(), range(1, len(conf_matrices_dict) + 1)):\n",
    "    print(idx)\n",
    "    print(i)\n",
    "    print(conf_matrices_dict[i]['Accuracy(Val)'])\n",
    "    print(conf_matrices_dict[i]['Conf_M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the confusion matrix for the highest accuracy test classifiers\n",
    "\n",
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.suptitle(nom_dataset + model_surname + ' - Confusion matrices of the best results for each classifier', fontsize = 16,  y=0.99)\n",
    "for i, idx in zip(conf_matrices_dict.keys(), range(1, len(conf_matrices_dict) + 1)):\n",
    "    title = 'Classifier '+ i + ' (Highest accuracy validation of the best models: ' + str(\"{:0.4f}\".format(conf_matrices_dict[i]['Accuracy(Val)'])) +')'\n",
    "    plt.subplot(1,2,idx)\n",
    "    plot_confusion_matrix(conf_matrices_dict[i]['Conf_M'],  \n",
    "                          nom_classes, \n",
    "                          title,\n",
    "                          cmap = None,                          \n",
    "                          normalize = False)\n",
    "\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.suptitle(f'{nom_dataset} - Box plot each classifier (batch type: {model_surname})', fontsize = 16,  y=0.97)\n",
    "box_plot = sns.boxplot(data=metrics_set, x=\"Model\", y=\"Accuracy(Val)\", showfliers = True)\n",
    "\n",
    "medians = list(metrics_set.groupby(['Model'])['Accuracy(Val)'].median())\n",
    "medians = [round(element, 2) for element in medians]\n",
    "\n",
    "vertical_offset = metrics_set['Accuracy(Val)'].median()*0.0001  # offset from median for display\n",
    "\n",
    "for xtick in box_plot.get_xticks():\n",
    "    box_plot.text(xtick, medians[xtick] + vertical_offset, medians[xtick], \n",
    "            horizontalalignment='center',size='medium',color='w',weight='semibold')\n",
    "plt.savefig(os.path.join(path_pic, picture_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mark3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
