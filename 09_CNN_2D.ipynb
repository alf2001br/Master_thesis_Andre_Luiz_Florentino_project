{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-1PkcG8ARink"
   },
   "source": [
    "### Faculdade de Engenharia Industrial - FEI\n",
    "\n",
    "### Centro Universitário da Fundação Educacional Inaciana \"Padre Sabóia de Medeiros\" (FEI)\n",
    "\n",
    "\n",
    "*FEI's Stricto Sensu Graduate Program in Electrical Engineering*\n",
    "\n",
    "Concentration area: ARTIFICIAL INTELLIGENCE APPLIED TO AUTOMATION AND ROBOTICS\n",
    "\n",
    "Master's thesis student Andre Luiz Florentino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')\n",
      "------------------------------------------------------------------------------------------\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "<function is_built_with_cuda at 0x000001F779DB90D0>\n",
      "/device:GPU:0\n",
      "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "pd = tf.config.experimental.list_physical_devices()\n",
    "for i in pd:\n",
    "    print(i)\n",
    "print('------------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
    "\n",
    "print(tf.test.is_built_with_cuda)\n",
    "# <function is_built_with_cuda at 0x000001AA24AFEC10>\n",
    "\n",
    "print(tf.test.gpu_device_name())\n",
    "# /device:GPU:0\n",
    "\n",
    "#gvd = tf.config.get_visible_devices()\n",
    "for j in tf.config.get_visible_devices():\n",
    "    print(j)\n",
    "# PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
    "# PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
    "\n",
    "#physical_devices = tf.config.experimental.list_physical_devices()\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[2], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9: Convolutional Neural Network (2D)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The paper entitled \"ESC-ConvNet: Environmental Sound Classification with Convolutional Neural Networks\" (PICZAK, 2015) serves as the foundation for the following analysis. In this study, the author employs Convolutional Neural Networks (CNNs) for image classification, utilizing fixed dimension images that consist of multiple channels (such as RGB for color images). The network undergoes various stages of convolution, pooling, and fully connected layers, ultimately outputting class probabilities for the given image. With the aim to replicate this approach using sound clips, the utilization of log-scaled mel-spectrograms and their respective deltas from each sound clip is proposed instead of directly using the sound file as an amplitude vs. time signal. In order to address the requirement of fixed size input, the sound clips are segmented into 60x41 segments (60 bands and 44 frames - windowing techinique). The log-scaled mel-spectrograms are extracted from all the recordings, which were resampled to 22050 Hz and normalized with a window size of 1024, a hop length of 512, and 60 mel-bands.\n",
    "\n",
    "- The human auditory system perceives sound on a logarithmic scale, rendering it difficult to distinguish closely-scaled frequencies. This effect becomes more pronounced with increasing frequency. Therefore, only the power within different frequency bands is considered. As a result, the mel-spectrograms and their corresponding deltas are transformed into two channels that are subsequently inputted into the CNN for analysis.\n",
    "\n",
    "- During the iterative process of file exploration, it was noticed that each sound is 4, 5 or 10 seconds in duration and has in its duration (sometimes) silent periods. In order to achieve a more representative \"sound image\", for each sound, the \"extract_feature\" methods are utilized to trim the silent periods and duplicate the sound, effectively doubling its trimmed length (augmented audio). Subsequently, the aforementioned features, along with the class labels, are calculated and appended to arrays.\n",
    "\n",
    "- The final result transformed the audio file into a spectrogram image consisting of 60 bands, 44 frames, and 2 channels. After a few cross-validations, it was confirmed the accuracy has improved when the deltas are aggreated to the image instead of using them as channels, therefore, the final image dimension was 180 (60 mels, 60 delta 1 and 60 delta 2) x 44 frames. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "import itertools\n",
    "import mimetypes\n",
    "import time\n",
    "\n",
    "import pandas     as pd\n",
    "import seaborn    as sns\n",
    "import numpy      as np\n",
    "\n",
    "from matplotlib  import pyplot  as plt\n",
    "from keras       import backend as K\n",
    "\n",
    "from tqdm                        import tqdm\n",
    "\n",
    "from sklearn                     import metrics\n",
    "from sklearn.model_selection     import train_test_split\n",
    "from sklearn.metrics             import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow                  import keras\n",
    "from tensorflow.keras.models     import Sequential, load_model\n",
    "from tensorflow.keras.layers     import Dense, Dropout, Flatten, InputLayer, Conv2D\n",
    "from tensorflow.keras.layers     import MaxPooling2D, BatchNormalization, Activation\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks             import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers            import SGD\n",
    "from keras.constraints           import maxnorm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 12)\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "\n",
    "cmap_cm   = plt.cm.Blues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# For the picture names\n",
    "pic_first_name = '09_CNN_2D_'\n",
    "\n",
    "# For Librosa\n",
    "FRAME_SIZE  = 1024\n",
    "HOP_LENGTH  = 512\n",
    "SEED        = 1000\n",
    "SR          = 22050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1-) ESC-10\n",
      "2-) BDLib2\n",
      "3-) US8K\n",
      "4-) US8K_AV\n",
      "\n",
      "Select the dataset: \n",
      "\n",
      "1-) ESC-10\n",
      "2-) BDLib2\n",
      "3-) US8K\n",
      "4-) US8K_AV\n",
      "\n",
      "Select the dataset: \n",
      "\n",
      "1-) ESC-10\n",
      "2-) BDLib2\n",
      "3-) US8K\n",
      "4-) US8K_AV\n",
      "\n",
      "Select the dataset: 4\n"
     ]
    }
   ],
   "source": [
    "# Select the dataset\n",
    "\n",
    "opcD = 0\n",
    "while str(opcD) not in '1234':\n",
    "    print()\n",
    "    print(\"1-) ESC-10\")\n",
    "    print(\"2-) BDLib2\")\n",
    "    print(\"3-) US8K\")\n",
    "    print(\"4-) US8K_AV\")\n",
    "\n",
    "    opcD = input(\"\\nSelect the dataset: \")\n",
    "    if opcD.isdigit():\n",
    "        opcD = int(opcD)\n",
    "    else:\n",
    "        opcD = 0\n",
    "\n",
    "if opcD == 1:\n",
    "\n",
    "    path        = os.path.join(current_path, \"_dataset\", \"ESC-10\")\n",
    "    path_pic    = os.path.join(current_path, \"ESC-10_results\")\n",
    "    path_models = os.path.join(current_path, \"ESC-10_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "   \n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'ESC-10' \n",
    "    csv_file    = 'ESC-10.csv'\n",
    "    fold        = 1\n",
    "    dog_set     = 'Dog bark'\n",
    "    \n",
    "    pkl_features_CNN_2D          = 'ESC-10_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'ESC-10_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'ESC-10_features_CNN_2D_augmented.pkl'\n",
    "    \n",
    "\n",
    "    \n",
    "if opcD == 2:\n",
    "    \n",
    "    path        = os.path.join(current_path, \"_dataset\", \"BDLib2\")\n",
    "    path_pic    = os.path.join(current_path, \"BDLib2_results\")\n",
    "    path_models = os.path.join(current_path, \"BDLib2_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "\n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'BDLib2' \n",
    "    csv_file    = 'BDLib2.csv'\n",
    "    fold        = 'fold-1'\n",
    "    dog_set     = 'dogs'\n",
    "    \n",
    "    pkl_features_CNN_2D          = 'BDLib2_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'BDLib2_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'BDLib2_features_CNN_2D_augmented.pkl'\n",
    "    \n",
    "    \n",
    "if opcD == 3:\n",
    "    \n",
    "    path        = os.path.join(current_path, \"_dataset\", \"US8K\")\n",
    "    path_pic    = os.path.join(current_path, \"US8K_results\")\n",
    "    path_models = os.path.join(current_path, \"US8K_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "        \n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'US8K' \n",
    "    csv_file    = 'US8K.csv'\n",
    "    fold        = '1'\n",
    "    dog_set     = 'dog_bark'\n",
    "\n",
    "    pkl_features_CNN_2D          = 'US8K_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'US8K_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'US8K_features_CNN_2D_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large\n",
    "    \n",
    "    \n",
    "if opcD == 4:\n",
    "\n",
    "    path        = os.path.join(current_path, \"_dataset\", \"US8K_AV\")\n",
    "    path_pic    = os.path.join(current_path, \"US8K_AV_results\")\n",
    "    path_models = os.path.join(current_path, \"US8K_AV_saved_models\")\n",
    "    \n",
    "    # Check if the folder exists, if not, create it\n",
    "    if not os.path.exists(path_models):\n",
    "        os.makedirs(path_models)\n",
    "\n",
    "\n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'US8K_AV' \n",
    "    csv_file    = 'US8K_AV.csv'\n",
    "    fold        = '1'\n",
    "    dog_set     = 'dog_bark'\n",
    "    \n",
    "    pkl_features_CNN_2D          = 'US8K_AV_features_CNN_2D_original.pkl'\n",
    "    pkl_aug_features_CNN_2D      = 'US8K_AV_features_CNN_2D_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features_CNN_2D = 'US8K_AV_features_CNN_2D_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_file_number(folder: str):\n",
    "    files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) and f.startswith(pic_first_name)]\n",
    "    if not files:\n",
    "        return 1\n",
    "    else:\n",
    "        numbers = [int(f.split('.')[0].split('_')[-1]) for f in files]\n",
    "        return max(numbers) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MT_loadDataset import loadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classes:\n",
      "--------------------\n",
      "Class_categorical\n",
      "dog_bark            1000\n",
      "children_playing    1000\n",
      "background          1000\n",
      "siren                929\n",
      "car_horn             429\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total number of unique files..........:  4358\n",
      "Total number of AUDIO files...........:  4358\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Folder_name</th>\n",
       "      <th>Class_OHEV</th>\n",
       "      <th>Class_categorical</th>\n",
       "      <th>File_name</th>\n",
       "      <th>Path</th>\n",
       "      <th>classID</th>\n",
       "      <th>fsID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>salience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>fold5</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100032-3-0-0.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>100032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>fold5</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-117.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>100263</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>fold5</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-121.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>100263</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>fold5</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-126.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>100263</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>fold5</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-137.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>100263</td>\n",
       "      <td>68.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4353</th>\n",
       "      <td>7</td>\n",
       "      <td>fold7</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>car_horn</td>\n",
       "      <td>99812-1-2-0.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-2-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>99812</td>\n",
       "      <td>159.522205</td>\n",
       "      <td>163.522205</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354</th>\n",
       "      <td>7</td>\n",
       "      <td>fold7</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>car_horn</td>\n",
       "      <td>99812-1-3-0.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-3-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>99812</td>\n",
       "      <td>181.142431</td>\n",
       "      <td>183.284976</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355</th>\n",
       "      <td>7</td>\n",
       "      <td>fold7</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>car_horn</td>\n",
       "      <td>99812-1-4-0.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-4-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>99812</td>\n",
       "      <td>242.691902</td>\n",
       "      <td>246.197885</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>7</td>\n",
       "      <td>fold7</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>car_horn</td>\n",
       "      <td>99812-1-5-0.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-5-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>99812</td>\n",
       "      <td>253.209850</td>\n",
       "      <td>255.741948</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357</th>\n",
       "      <td>7</td>\n",
       "      <td>fold7</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>car_horn</td>\n",
       "      <td>99812-1-6-0.wav</td>\n",
       "      <td>C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-6-0.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>99812</td>\n",
       "      <td>332.289233</td>\n",
       "      <td>334.821332</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4358 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fold Folder_name       Class_OHEV Class_categorical           File_name                                                                                                Path  classID    fsID       start         end  salience\n",
       "0        5       fold5  [0, 0, 0, 1, 0]          dog_bark    100032-3-0-0.wav    C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100032-3-0-0.wav        3  100032    0.000000    0.317551         1\n",
       "1        5       fold5  [0, 0, 1, 0, 0]  children_playing  100263-2-0-117.wav  C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-117.wav        2  100263   58.500000   62.500000         1\n",
       "2        5       fold5  [0, 0, 1, 0, 0]  children_playing  100263-2-0-121.wav  C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-121.wav        2  100263   60.500000   64.500000         1\n",
       "3        5       fold5  [0, 0, 1, 0, 0]  children_playing  100263-2-0-126.wav  C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-126.wav        2  100263   63.000000   67.000000         1\n",
       "4        5       fold5  [0, 0, 1, 0, 0]  children_playing  100263-2-0-137.wav  C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold5\\100263-2-0-137.wav        2  100263   68.500000   72.500000         1\n",
       "...    ...         ...              ...               ...                 ...                                                                                                 ...      ...     ...         ...         ...       ...\n",
       "4353     7       fold7  [0, 1, 0, 0, 0]          car_horn     99812-1-2-0.wav     C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-2-0.wav        1   99812  159.522205  163.522205         2\n",
       "4354     7       fold7  [0, 1, 0, 0, 0]          car_horn     99812-1-3-0.wav     C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-3-0.wav        1   99812  181.142431  183.284976         2\n",
       "4355     7       fold7  [0, 1, 0, 0, 0]          car_horn     99812-1-4-0.wav     C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-4-0.wav        1   99812  242.691902  246.197885         2\n",
       "4356     7       fold7  [0, 1, 0, 0, 0]          car_horn     99812-1-5-0.wav     C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-5-0.wav        1   99812  253.209850  255.741948         2\n",
       "4357     7       fold7  [0, 1, 0, 0, 0]          car_horn     99812-1-6-0.wav     C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\_dataset\\US8K\\fold7\\99812-1-6-0.wav        1   99812  332.289233  334.821332         2\n",
       "\n",
       "[4358 rows x 11 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadDataset = loadDataset(path)\n",
    "DB          = loadDataset.db_B\n",
    "\n",
    "print(\"\\nClasses:\\n--------------------\")\n",
    "print(DB[\"Class_categorical\"].value_counts())\n",
    "print(\"\\nTotal number of unique files..........: \", len(np.unique(DB[\"File_name\"])))\n",
    "print(\"Total number of AUDIO files...........: \", len(DB))\n",
    "DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABHQAAAHqCAYAAABlWBkiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABno0lEQVR4nO3deVhUZePG8XvYQVHADSRey33JBRdwy4XSyj3ELJfUNPe9TE0rS03N0txxN1PLXAtzNyu1ME1fLcvUckdRAUnZl/n9wc95ndxFOAx8P9fFpZxzhrnPzBzPcPs8Z0xms9ksAAAAAAAA2Aw7owMAAAAAAADgwVDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAJBFOnfurM6dO99xfVBQkEaMGGG17NixYxoyZIjq1aunJ598UvXr19fgwYP1+++/33L77du3Kzg4WP7+/mrSpIlmzpyp5ORky/q1a9eqXLlyOnfu3C23XbJkicqVK6dBgwYpJSXlofavY8eOKleunDZu3GhZlpCQoBo1aqhnz553vF10dLSefPJJTZ48+aHu94Zz586pXLlyCg4OVmpq6i3r9+7dq3Llymnv3r2Zup/7dbvnMye4ePGiOnXqpMqVK6tOnTpKSEh44J9xt9dSXjNkyBCVK1fulq9vvvnG6GgAgDzGwegAAAAgw/Hjx9W+fXtVqVJFo0aNUuHChXXx4kUtW7ZM7du312effaZq1apJkvbs2aP+/furWbNmev3113Xs2DFNmTJF0dHReuedd+56P59++qkmTJigli1batKkSbK3t3/grKdPn9b+/ftVtmxZff7552rWrJkkydXVVc2bN9eaNWsUHR0tLy+vW267YcMGpaSkqG3btg98v7dz5MgRzZ8/X3369HkkPy+3+fTTT3Xw4EFNnjxZxYoVk6urq9GRbNoff/yhVq1aqWPHjlbLS5QoYVAiAEBexQgdAAByiMWLF8vDw0MLFixQs2bNFBAQoFatWmnJkiXy8vLS7NmzLduuXbtWxYsX1+TJk1WvXj1169ZNXbp00ZdffnnXETdLly7VBx98oLZt2+rDDz98qDJHktasWSNvb2/17dtXP//8s/766y/LupCQEKWmplqN3LnZ+vXrVbNmTZUsWfKh7vvfChQooFmzZun48eOP5OflNlevXlXRokXVrFkz1ahRw+g4Ni0hIUGnT59W3bp1Va1aNasvT09Po+MBAPIYCh0AAHKIK1euSJLMZrPVcjc3N40cOVLPP/+8ZVlycrJcXV2tChlPT0+lpKQoLi7utj9/6dKlGj9+vDp06KDx48fLzu7h3gakpaVp/fr1atSokYKCguTu7q6VK1da1lepUkVly5ZVWFjYLbc9fvy4jhw5onbt2j3Ufd9Or169lD9/fo0YMUJpaWl33O5OU7D+PTUuKChIM2fO1IQJExQYGCh/f3+9/vrriouL07x589SgQQPVqFFDAwYMUExMjNXPSklJ0bhx41SrVi3VqlVLw4cPV3R0tNU2+/fvV6dOnVS1alUFBATcss3atWtVsWJFrVq1SvXr11eDBg3uWFZdu3ZNEyZM0DPPPKPKlSurRYsWWr16tdW+rF27VhERESpXrpxmzJhxx8dnz5496tixo/z9/VW/fn298847io2NveP2q1atUnBwsKpVq6YqVaqodevWViVeenq6pk2bpqCgID355JMKCgrSlClTrArHjRs3qlWrVqpSpYpq166tN954Q5cuXbrlfpo3b64nn3xSjRo10owZM6ym2EVHR+uNN95QvXr1VLlyZbVu3Vrr16+/Y25Jt50ydeMrKCjojrf7888/lZ6ergoVKtz15wMAkB2YcgUAQA7RqFEjff/993rppZfUtm1b1a5dWyVLlpTJZNJzzz1ntW3Hjh3Vo0cPLViwQC+++KL+/vtvffrpp2rYsKE8PDxu+dmfffaZxo8fr86dO2v06NGZyrl7925FRkbqhRdekLOzs5o1a6b169dr6NChcnFxkSS1bdtWEyZM0JkzZ/Sf//zHctt169Ypf/78evbZZzOV4WZeXl565513NGTIEC1YsEC9evXK9M9cvHix6tatq6lTp+rXX3/VlClTdOTIERUrVkxjx47VyZMn9eGHH6pw4cJ69913LbfbtGmTqlSpookTJyo6OlofffSRTp8+rS+++EKStG/fPnXr1k21a9fWJ598otjYWE2bNk2vvPKKVq9ebXn80tLSFBoaqnHjxik6OlqlS5e+JWNiYqI6dOigK1euaMCAAfLz89P27ds1atQoXblyRb1799bMmTP1ySef6Pfff9fMmTPl7e192/39/vvv1bt3bwUFBWnq1KmKjY3V5MmTdfr0aX366ae3bL98+XKNGzdO/fv31/Dhw3X16lXNnz9fw4YNU7Vq1VS8eHHNnz9fy5cv1/Dhw+Xn56dDhw5p6tSpcnR01IABA/TLL7/ojTfeUN++fVWrVi1dvHhRkydP1uuvv67PPvtMkjR37lxNnTpVnTp10siRI/XHH39oxowZunDhgj744ANJ0rBhwxQVFaX33ntP+fLl09dff63hw4fLx8dHgYGBt93fmwvIf3Nycrrjuj/++EOS9Pnnn2v79u2KjY1VlSpVNHz4cFWtWvWOtwMAICtQ6AAAkEN06NBBly9f1sKFC/X+++9Lyhh1U79+fXXu3NnqF8bAwEB1795dkydPtlxcuGLFivr4449v+bnLly/XokWLZDKZbhkt8jDWrFmjkiVLWq7nExISopUrV2rTpk164YUXJEmtWrXSRx99pK+//lr9+/eXlFFShIWFqUWLFo/8Oi7NmjXT5s2bNXPmTAUFBalMmTKZ+nn58uXT1KlT5eDgoLp162rdunW6dOmSVq1aJXd3dzVs2FDh4eE6cOCA1e0KFCigBQsWKH/+/JIynr9+/fpp9+7dql+/vj7++GM98cQTmjt3rmV0VdWqVS3XHbr5uiy9e/dWo0aN7phx7dq1OnbsmFasWGGZSvXUU08pNTVVs2fP1ksvvaSKFSvKy8tLTk5OlufrdqZPn67y5ctr1qxZlmUuLi6aMmWKIiMjb9n+7NmzevXVV9WvXz/Lsscee0zBwcE6cOCAihcvrp9//lmVKlWyXCspICBArq6ulsfml19+kbOzs1577TU5OztLkjw8PPTrr7/KbDbr+vXrmjNnjtq3b28pIevXry8PDw+NHj1a3bp1U5kyZfTzzz+rb9++euaZZyRlHBseHh53nU54t8fibm4UOklJSZoyZYquXr2qefPm6ZVXXtHKlStVvnz5h/q5AAA8DKZcAQBgIJPJZPX9oEGDtGvXLn388ccKCQlR/vz5FRYWpvbt21uNlHj33Xe1cOFC9enTx3JdnJiYGPXo0eOWTzFatGiRBg4cqF69eumbb77RqlWrHjpvTEyMvv32Wz3//PP6559/9M8//+jxxx/XE088YRmFImWMmgkKCrKadrVnzx5dunTpntOtUlNTrb7S09PvK9u7775rmZ52t6lX96NKlSpycPjf/3sVKVJEJUuWlLu7u2WZh4eHrl27ZnW7hg0bWgoLKWPKk6Ojo3788UclJCTo0KFDatiwocxms2X//Pz8VKpUKe3Zs8fqZ5UtW/auGX/++Wf5+vrecl2cVq1aKSkpSYcOHbqvfU1MTNSRI0cshcgNzz77rLZs2aJixYrdcpsRI0Zo2LBhunbtmn799VeFhYVp+fLlkmSZUhUYGKgff/xRHTp00OLFi/XXX3+pU6dOatOmjSSpVq1aSkxMVMuWLTV16lT98ssvql+/vvr37y+TyaSDBw8qISFBQUFBVq+HG1OibjxegYGBmjFjhgYNGqS1a9cqOjpaw4cPV82aNe+4z/9+jd38dbfXTteuXbVkyRJNnDhRgYGBevbZZ7V48WK5uroqNDT0vh5vAAAeFUboAACQRdzc3HT16tU7rr9xHZx/K1iwoFq0aKEWLVpIkn7//Xe9+eab+uijj9SqVSslJyfryy+/VK9evTR48GBJGb/UVq5cWS1bttSaNWvUqVMny88bNGiQ+vbtq5SUFO3atUvjx49X9erVVapUqQfep6+++kopKSmaNWuW1WiOG44ePWoZpRASEqLXXntNhw8fVpUqVfTVV1+pfPnyevLJJ+96H5UqVbL6vn///howYMA9sxUqVEhvv/22Xn/9dS1cuDBTU2BuLmVuuJ9RRYULF7b63s7OTh4eHpbyKz09XfPnz9f8+fNvue2NUSo3FCpU6K73FRsbe8v93Zzhn3/+uWfeGz/HbDbf8/5udubMGb3zzjsKDw+Xg4ODSpYsqXLlykn63zWgevTooXz58mnNmjWaNGmSJk6cqLJly+qtt95SnTp15O/vr3nz5mnJkiVauHChQkNDVaRIEb322mvq0qWL5djp2bPnbTPcuNbO1KlTFRoaqk2bNmnz5s2ys7NT3bp1NWbMGPn5+d32tv9+jd3M19dX33777W3XlSxZ8paLeRcoUEDVq1fX0aNH7/yAAQCQBSh0AADIIoULF9axY8duuy45OVnR0dGWX74jIyPVtm1bDRo06JYRLBUrVtTgwYPVr18/nT17VmlpaTKbzapevbrVdmXLlpWHh8ctF9Bt1aqVJMnR0VGTJ09WcHCwBg8erNWrV99SItzL2rVrVbVqVb3++utWyxMTE9WnTx99/vnneu+99yRlTI/x9vZWWFiYSpYsqe3bt2vYsGH3vI+bL+orSUWLFr3vfC1atNDmzZs1Y8YMjRgxwmrdjdFQ/x7xExcXp3z58t33fdzNv0uUtLQ0xcTEqFChQsqXL59MJpO6du2q5s2b33LbB52GVrBgQZ0+ffqW5ZcvX5ak+/7Upfz58992Ol5ycrJ++uknValSxWp5enq6evbsKUdHR3355ZeqWLGiHBwcdOLECX399deW7ezs7NSxY0d17NhRUVFR+v777xUaGqoBAwboxx9/lJOTk5566ik99dRTSkhIUHh4uGW0WbVq1VSgQAFJ0kcffaTHH3/8ltw3jh13d3cNGzZMw4YN099//60dO3Zo9uzZeu+997RgwYLb7vO/X2M3u9s1dL755ht5eHioXr16VsuTkpL4lCsAQLZjyhUAAFkkICBAEREROnz48C3rtm/frrS0NNWuXVtSxi+nDg4OWrFihZKSkm7Z/u+//5azs7NKlCihEiVKyN7eXr/88sst21y9elWPPfbYHTOVKlVKw4YN07FjxzRhwoQH2p9ff/1Vf/75p4KDgxUYGGj11bBhQ9WvX19hYWGWT9mys7PTCy+8oG3btunbb7+V2WxWy5Yt73k/lStXtvq63ZSfuxkzZozc3Nw0depUq+U3Rt1cuHDBsiw2NtbqI9cz68cff7T6BKYtW7YoNTVVgYGByp8/vypWrKi///7bav/KlCmjmTNn3vLpW/dSq1YtnT9//pbXwddffy1HR8dbipg7yZcvnypUqKAdO3ZYLd+9e7d69uypixcvWi2PiYnRyZMnFRISYjU17YcffpD0v8LspZde0rhx4yRljDYKDg5Wx44dde3aNV2/fl2TJk1SSEiIzGazXF1d1bhxYw0fPlxSxnNUtWpVOTo6KjIy0urxcnR01Mcff6xz587p/PnzatiwoTZv3iwpYwTNa6+9prp1696S+2b/fo3d/HVjpNHtrFixQmPGjFFycrJlWWRkpA4cOKCAgID7erwBAHhUGKEDAEAWadasmT799FO99tpr6tWrlypVqqT09HQdOHBACxYsUPPmzS2jbOzt7TVmzBj169dPbdu2VceOHVWqVCklJCRoz549Wr58uQYNGqSCBQtKkrp06aKFCxdKkurWrauIiAjNnDlTxYsX14svvnjXXJ06ddLOnTv1+eefq27dumratOl97c+aNWvk6Oh4x0+oatOmjb7//nuFhYXppZdekpTxaVehoaGaNWuWmjRpYsmflQoXLqxRo0bdMhqoXLly8vHx0cyZM+Xu7i47OzvNmzfvkV6g+cYnTnXu3FmnTp3SlClTVK9ePdWpU0eSNHToUPXs2VOvv/66WrVqpbS0NC1atEiHDh1Snz59Hui+goODtWLFCvXv318DBw6Un5+fvv32W61Zs0b9+/e3jHC5HwMHDlSfPn00ePBgBQcHKzo6Wh9//LEaN26sChUqWC4GLGWUM76+vlq+fLm8vb1VoEAB7d6923KNpxvXcKpVq5YWLVqkwoULy9/fX5GRkVq8eLECAgLk5eWlOnXqaPHixRoxYoRatWqllJQULViwQB4eHqpdu7Y8PDzUo0cPTZs2TdevX1dgYKAiIyM1bdo0mUwmlS9fXu7u7vL29ta4ceN0/fp1/ec//9Fvv/2m77///pF82tm/9evXT927d9eAAQPUsWNHxcbGaubMmSpQoIC6d+/+yO8PAIC7odABACCLODo6atmyZQoNDdWqVas0ffp02dnZqUSJEhoyZIjVdW6kjI8t//LLLy3XE4mOjpaTk5MqVqyoqVOnWhUvb775pooVK6YvvvhCixYtUtGiRVWvXj0NGTLkvkqTCRMmqGXLlho9erQqVaokX1/fu26flJSkb775RvXq1bvj1JJnnnlGBQoU0BdffGEpdPz8/BQYGKjw8HDLVKzs0KpVK23evNlq1Im9vb2mT5+uDz74QEOHDlXhwoXVpUsX/f333zp58uQjud8XX3xRiYmJ6tevn5ycnNSyZUsNGzbMMt2rfv36WrhwoWbOnKmBAwfK0dFRlSpV0uLFix/4k5dcXV312Wef6eOPP9b06dN1/fp1lSxZUuPHj1dISMgD/azGjRtr7ty5mjFjhvr16ydPT089//zzGjRo0G23nz17tsaPH68RI0bIyclJpUuX1pw5c/TBBx9o//796ty5swYNGiQnJyetWbNGs2bNkru7u4KCgizT9Ro0aKCPPvpIixYtslwIuUaNGlq6dKk8PDwkSYMHD1aRIkW0YsUKLViwQAULFlSdOnU0dOhQywWqZ86cqSlTpmjatGmKiYmRj4+P+vfvf8dr72RG3bp1tWDBAs2aNUtDhgyRnZ2d6tevr2HDhj1QgQYAwKNgMt+4ch0AAAAAAABsAiN0AADI425cZPlebv4YbwAAABiLEToAAORxnTt31s8//3zP7f78889sSAMAAID7QaEDAEAe9/fff1s+mepuKleunA1pAAAAcD8odAAAAAAAAGyMndEBAAAAAAAA8GAodAAAAAAAAGwMhQ4AAAAAAICN4fNHb+PKlWviykJ4WF5e+RQdfe+LiwK5FccA8jqOAYDjAOAYQGYVKeJ+z20YoQM8QiaTZG9vJ5PJ6CSAMTgGkNdxDAAcBwDHALILhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh3gHmJiYtS+fRsdOLDfsuzIkd/02mtd1KTJU2rXrpU2bFhvdZuNGzeoffs2euaZ+urevbN+++2wZV1aWppmzZqmli2bqkmTBhoxYqiuXLmSXbsDPDCOAQAA5wIAyHkodIC7OHz4v+rdu5vOnz9nWfbPP/9o2LBBeu655tq0aadGjHhb06dP1e+//yZJ2rt3r6ZOnaxRo8Zo8+bv1LTpcxoxYqgSExMlSZ9+ulA//xyuBQuWav36jXJ2dtakSWMN2T/gXjgGAACcCwAgZ6LQAe5g06YNeu+90erZs6/V8u+//1YFChRU27YvysHBQTVq1FLTps9p7dpVkqRVq1bpmWeaqkqVanJwcFD79h1VsKCHduzYKknasOErdezYRcWKeStfvvwaNOgNhYf/aPUmCcgJOAYAAJwLACDnotAB7iAgoLZWrlyvp59uarX85Mm/VKpUKatljz/+hE6cOC5JOnHihEqWvP3669ev69KlSJUqVdqyzsurkNzdC+ivv05k0Z4AD4djAADAuQAAci5DC53o6Gg1adJEe/futSw7dOiQ2rVrJ39/fwUFBWnVqlVWt1m3bp2aNGmiatWqKTg4WAcPHrSsS0tL06RJk1S3bl35+/urT58+unTpUrbtD3KXQoUKy8HB4Zbl8fHxcnFxtVrm4uKihIR4SVJcXJxcXW+/Pj4+zvL9nW4P5BQcAwAAzgUAkHMZVuj88ssvat++vc6cOWNZFhsbq549e6pNmzbat2+fxo8frwkTJujw4YwLqO3du1djx47VxIkTtW/fPrVq1Up9+vRRQkKCJGnOnDnas2eP1qxZo127dsnFxUWjR482ZP+Qe7m4uCopKdFqWWJiotzc3CRJrq6ulvnh/15/443P3W4P5HQcAwAAzgUAYDxDCp1169bpjTfe0JAhQ6yWb926VR4eHurYsaMcHBxUp04dtWzZUsuXL5eUMRe3efPmqlGjhhwdHdW1a1d5enpq48aNlvWvvfaafHx8lD9/fo0aNUo//PCDzp49m+37iNyrZMlSOnnyb6tlp06dtAwrLlOmzB3XFyhQQEWKFLVaHxV1Rf/8E6uSJUsLsAUcAwAAzgUAYDxDCp369etr27ZtatasmdXy48ePq2zZslbLSpcuraNHj0rKmIt7p/XXrl3TxYsXrdYXLlxYBQsW1J9//plFe4K8qGHDxoqKitKXX65QamqqDhzYr61bN6t589aSpJCQEG3dulkHDuxXamqqvvxyhaKjo9WgQWNJUrNmLfXppwsVEXFe8fFxmj79Y1WrVl2+vo8ZuVvAfeMYAABwLgAA4906ITYbFClS5LbL7zTXNj7+7nNx4+PjFReXMRf338M0XVxcLOvul8n0QJvnOHZ2JplsfSdyIHt7Ozk42KlQIS/NmDFHU6ZM1oIFc+Xp6amhQ4cpICBAJpNUp04dvfnmCH388URduhSpJ54opalTZ8jLy1OS9NprPZWenqZ+/V5TfHy8atSoqQ8++FAODlyj/FExmSSz2egUuQ/HgO0wm81KT+cgMMKN0y+nYWPxXijrcC6wDZwHjMW5ANnFZDYb+2tPuXLltHTpUgUGBmrcuHG6dOmSpk+fbln/2Wefac2aNVq/fr1atWqlF198UZ06dbKsHzBggHx8fNSvXz8FBAQoLCzMapROYGCgxo8fr2eeeSZb98tI6Waz7PjXA3kYxwDyPHO6ZOKXIuRd5vR0mew4BpB3cQwAeYMhI3TupGzZstqzZ4/VshMnTqhMmTKSMubiHj9+/Jb1DRo0UMGCBVWsWDGraVmXL1/W1atXb5mmdS9RUdds9n/37e3t5OmZT+t/Oauoa4n3vgEeLZPk4uykxKRkyUZfQ7auSAEXtarup+SjO5R2mY8+zXYmydXZUQlJKRwDBrHLX1jO/m0VExOntLR0o+PkOSaTVKiQu02/l7B1N94LXQn7RilR0UbHyZt4P2Qox0JeKtyyOecBA3EuwKNQuLD7PbfJUYVOkyZNNHnyZC1ZskQdO3bUL7/8orCwMM2ePVtSxlzcfv366fnnn1eNGjW0fPlyRUVFqUmTJpKk4OBgzZkzR5UrV5anp6c++OADBQQE6D//+c8D5TCbbX+6RtS1RF2MpdAxgpubWfHxSUbHyLNMdhkjc9Ljryr9nwsGp8l7TJLk5ixzfBLv4XMAWz+X2bLc8F7C1iVHRSs58pLRMfIkkyQHN2clcy4wxM2POf8OGYtzAbJajip0PD09tWjRIo0fP17Tp0+Xl5eXRo8erdq1a0vKmIv77rvvasyYMYqMjFTp0qU1f/58eXh4SJL69eun1NRUdezYUXFxcQoMDNQnn3xi3A4BAAAAAABkAcMLnX9/AlXlypX1xRdf3HH71q1bq3Xr1rdd5+joqDfeeENvvPHGI80IAAAAAACQk3ClLAAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGOBgdAAAAAAAAW3D69ClNm/aRfv/9N7m55VPr1sHq3Lmb7Ozs9N13O7RkyUJFRJyXp6eHnnuuubp06SE7OzuZzWatWLFU69evUWxsrCpUqKRBg4aqZMnSRu8SbBiFDgAAAAAA9xAfH6+hQ/srIKC2xo+frNjYqxo+fIjS0tJUt+5TGjv2Hb3//kTVrVtP165dUffuPeTi4qaXX+6k1atXasWKpZo4cYoqVKik9etXa+DA3lq2bLU8PDyM3jXYKKZcAQAAAABwD4cP/1cxMTEaOnS4XF1d5e3to1deeVXr16/RxYsRatOmrerVe0p2dnYqVaqUGjRopEOHDkiStm3brJCQl1S5clU5ODgoJOQlFSzooZ07txu8V7BljNABAAAAAOAe0tPT5ejoIAeH//0abTLZKTo6StWr11KjRk9blicmJurHH3eradPnLbd1cXG1+nkmk51Onz6VLdmROzFCBwAAAACAe6hcuaqcnV0UGjpTiYmJunjxgj7/fKkkKTk5ybJdXFyc+vXrJ2dnF7Vv30GS1LBhkFav/kLHj/+p1NRUrV+/WmfPnlZSUtJt7wu4H4zQAQAAAADgHtzd3fXRR9M0Y8ZUBQc3l6/vY3ruueb644/flT+/uyTpzJlTGjXqTRUrVlQzZoTKzS2fJOnllzspKSlRI0e+oZSUZAUFNVVAQG25u7sbuUuwcRQ6AAAAAADcQ0pKitLS0jR9eqhMJpMkad261Xr88ZJycXHRTz/t1pgxo9Sq1QsaPXqkrl5NkNmccdsrVy6rRYvW6tGjtyQpNTVV7dq10vPPtzRqd5ALMOUKAAAAAIB7MJvNGjKkv7755iuZzWYdPfqHli5dpBdffFm//far3nprmAYMGKr+/QdbXWdHkrZv36IRI15XbOxVxcfHKzR0phwdHVWv3lMG7Q1yA0boAAAAAEAuY2/P/90/ag4OLpo8eYo++eRjTZ8+RZ6eXurcuauCg9vqjTcGKzU1VdOmfaRp0z6SyWSS2WxW1ar++uSTmerUqbMuX45Up07tlJKSoqpV/TVz5lzly+d67zvGA0tPNys93Wx0jCxHoQMAAAAAucSNqUAFClAUZIWgoAYKCmpwy/KFC+ff87YffDBO0rgsSIV/S083KyYmLteXOhQ6AAAAAJDL/H34sqIuXjc6Rp5kkuTi4qjExBTl7johZ8pXwFkVaxeXnZ2JQgcAAAAAYFsS4pJ1PYaPxDaCSVK6m1nx8ckUOshSTKwEAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI3JkYXOkSNH1LFjR9WsWVP169fXuHHjlJycLEk6dOiQ2rVrJ39/fwUFBWnVqlVWt123bp2aNGmiatWqKTg4WAcPHjRiFwAAAAAAALJMjit00tPT1atXLz377LP6+eeftXr1au3evVvz589XbGysevbsqTZt2mjfvn0aP368JkyYoMOHD0uS9u7dq7Fjx2rixInat2+fWrVqpT59+ighIcHgvQIAAAAAAHh0clyhExsbq8uXLys9PV1ms1mSZGdnJ1dXV23dulUeHh7q2LGjHBwcVKdOHbVs2VLLly+XJK1atUrNmzdXjRo15OjoqK5du8rT01MbN240cpcAAAAAAAAeqRxX6Hh6eqpr166aNGmSKleurIYNG+rxxx9X165ddfz4cZUtW9Zq+9KlS+vo0aOSpBMnTtx1PQAAAAAAQG7gYHSAf0tPT5eLi4vefvtthYSE6PTp0+rfv7+mT5+uuLg4ubq6Wm3v4uKi+Ph4Sbrn+vtlMmVuH5B33XjtmEzS/w8wg4E4lA1g+t+fJo4Bw3E+y343nwdgLJM4DxiGc0GOwDFgII4BQ938us/t5+McV+hs27ZNW7Zs0ebNmyVJZcqUUb9+/TR+/Hi1bNlS165ds9o+MTFR+fLlkyS5uroqMTHxlvWenp4PlKFQIfdM7EHO4OLiJLcU/vUwiqurs9ER8ixnJ0dJkouzg+TG82AUN44B47hkHAOenvkMDpK35Yb3ErbOxcVJDpwHDMW5wBgOzhnnASdnB7m5ORmcJm9zc+XxN4JLHnovlOMKnQsXLlg+0eoGBwcHOTo6qmzZstqzZ4/VuhMnTqhMmTKSMsqf48eP37K+QYMGD5QhKuqazY6usLe3k6dnPiUmJis+PsnoOHmOyZRR5iQkJNnsa8jWJTlnzCRNTEpVOsdA9jNlvIGPT0iSOAYMYXJIkaukmJg4paWlGx0nzzGZMsocW34vYetufi+UzHnAGJwLDOWUlCJJSk5KVXx88j22RpYwZZQ58QnJHAMGsHPOGJZj6++FChe+938O5bhr6NSvX1+XL19WaGio0tLSdPbsWc2ZM0ctW7ZUkyZNdOXKFS1ZskQpKSkKDw9XWFiY2rZtK0kKCQlRWFiYwsPDlZKSoiVLligqKkpNmjR5oAxms+1+wVg3ngOei5zBzFe2f1netJiNz5JXv25m9Dkpr37x2Bv/+Os+jhW+su7L8o+R2fgsefHrBqNz5OUvyxNhNj5LXv26wehz0qM4n91NjhuhU7p0ac2dO1effPKJFixYIHd3d7Vq1Ur9+vWTk5OTFi1apPHjx2v69Ony8vLS6NGjVbt2bUlSnTp19O6772rMmDGKjIxU6dKlNX/+fHl4eBi7UwAAAAAAAI9Qjit0JKlu3bqqW7fubddVrlxZX3zxxR1v27p1a7Vu3TqrogEAAAAAABgux025AgAAAAAAwN1R6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgY3JkoXP16lW9+eabCgwMVK1atdS3b19dunRJknTo0CG1a9dO/v7+CgoK0qpVq6xuu27dOjVp0kTVqlVTcHCwDh48aMQuAAAAAAAAZJkcWegMGDBA8fHx2rZtm3bu3Cl7e3u9/fbbio2NVc+ePdWmTRvt27dP48eP14QJE3T48GFJ0t69ezV27FhNnDhR+/btU6tWrdSnTx8lJCQYvEcAAAAAAACPTo4rdH777TcdOnRIEydOVIECBZQ/f36NHTtWb7zxhrZu3SoPDw917NhRDg4OqlOnjlq2bKnly5dLklatWqXmzZurRo0acnR0VNeuXeXp6amNGzcavFcAAAAAAACPjoPRAf7t8OHDKl26tL788kt9/vnnSkhI0FNPPaXhw4fr+PHjKlu2rNX2pUuX1urVqyVJJ06cUNu2bW9Zf/To0QfKYDJlbh+Qd9147ZhMktlsbBZIHMoGMP3vTxPHgOE4n2W/m88DMJZJnAcMw7kgR+AYMBDHgKFuft3n9vNxjit0YmNj9eeff+rJJ5/UunXrlJiYqDfffFPDhw9X4cKF5erqarW9i4uL4uPjJUlxcXF3XX+/ChVyz9xO5AAuLk5yS+FfD6O4ujobHSHPcnZylCS5ODtIbjwPRnHjGDCOS8Yx4OmZz+AgeVtueC9h61xcnOTAecBQnAuM4eCccR5wcnaQm5uTwWnyNjdXHn8juOSh90I5rtBxcsp40Y8aNUrOzs7Knz+/Bg8erBdffFHBwcFKTEy02j4xMVH58mU8Ua6urrdd7+np+UAZoqKu2ezoCnt7O3l65lNiYrLi45OMjpPnmEwZZU5CQpLNvoZsXZJzxkzSxKRUpXMMZD9Txhv4+IQkiWPAECaHFLlKiomJU1pautFx8hyTKaPMseX3Erbu5vdCyZwHjMG5wFBOSSmSpOSkVMXHJxucJo8yZZQ58QnJHAMGsHPOGJZj6++FChe+938O5bhCp3Tp0kpPT1dKSoqcnTNa/fT0jCehQoUKWrFihdX2J06cUJkyZSRJZcqU0fHjx29Z36BBgwfKYDYzXQYP58brhtdPzsDTkP0sw4rNPP5GuXlkMf8WGYf3EsYzi3+HjMK5IGfgGDAOx4Cxbn7Mc/u5OMddFLlu3bry8/PTW2+9pbi4OEVHR2vq1Kl65pln1KJFC125ckVLlixRSkqKwsPDFRYWZrluTkhIiMLCwhQeHq6UlBQtWbJEUVFRatKkicF7BQAAAAAA8OjkuELH0dFRn332mezt7fXss8/q2Weflbe3tz744AN5enpq0aJF2rx5swIDAzV69GiNHj1atWvXliTVqVNH7777rsaMGaOAgAB98803mj9/vjw8PIzdKQAAAAAAgEcox025kqRixYpp6tSpt11XuXJlffHFF3e8bevWrdW6deusigYAAAAAAGC4RzZC5/r164/qRwEAAAAAAOAuHrjQCQgIuO3yRo0aZTYLAAAAAAAA7sN9Tbk6ffq03nnnHZnNZl2/fl2vvPKK1frr16+rQIECWRIQAAAAAAAA1u6r0ClRooSaNm2qmJgYHThw4JZROk5OTgoKCsqSgAAAAAAAALB23xdF7tixoyTpscceU5s2bbIqDwAAAAAAAO7hgT/lqk2bNjp8+LBOnjwps9l8yzoAAAAAAABkrQcudKZMmaL58+erSJEicnD4381NJhOFDgAAAAAAQDZ44ELnq6++UmhoqBo2bJgVeQAAAAAAAHAPD/yx5fHx8WrQoEFWZAEAAAAAAMB9eOBCp1GjRgoLC8uKLAAAAAAAALgPDzzlKikpSSNGjFBoaKgKFy5stW7p0qWPLBgAAAAAAABu74ELnbJly6ps2bJZkQUAAAAAAAD34YELnf79+2dFDgAAAAAAANynBy50Ro4cecd1EyZMyFQYAAAAAAAA3NsDXxT532JiYrRp0ya5ubk9ijwAAAAAAAC4hwceoXO7UTg//vijVqxY8UgCAQAAAAAA4O4yPUJHkurWravw8PBH8aMAAAAAAABwDw88QuffUlNTtWHDBnl5eT2KPAAAAAAAALiHBy50ypcvL5PJZLXM3t5eo0aNemShAAAAAAAAcGcPXOgsXbrU6ns7OzuVKFFCRYoUeWShAAAAAAAAcGcPfA2dgIAA1axZUy4uLrpy5YokqVChQo88GAAAAAAAAG7vgUfoXL58Wb1799bRo0fl4eGhmJgYPf7441q0aJG8vb2zIiMAAAAAAABu8sAjdCZNmqTHH39cP//8s/bs2aO9e/eqQoUKt/04cwAAAAAAADx6DzxCJzw8XJs3b1a+fPkkSe7u7hozZoyefvrpRx4OAAAAAAAAt3rgETrp6em3fMqVyWSSo6PjIwsFAAAAAACAO3vgQicwMFBjxoxRfHy8JCkuLk5jxoxRQEDAIw8HAAAAAACAWz3wlKthw4apW7duCggIkIeHh65evapSpUpp3rx5WZEPAAAAAAAA//JAhY7ZbFZqaqq++eYb7d+/X1FRUTp//ry6d+8ue3v7rMoIAAAAAACAm9z3lKv4+Hi9/PLL+vDDD+Xg4KDatWurdu3amjlzpjp37myZggUAAAAAAICsdd+Fzpw5c+To6Kj33nvPsqxQoULauXOnUlNTNXfu3CwJCAAAAAAAAGv3Xehs2bJF48aNU6FChayWFypUSO+99542b978yMMBAAAAAADgVvdd6ERFRalEiRK3XVehQgVdvnz5kYUCAAAAAADAnd13oZM/f37FxMTcdt3Vq1fl6ur6yEIBAAAAAADgzu670KlTp46WL19+23UrVqxQtWrVHlUmAAAAAAAA3MV9f2x5r169FBwcrJiYGDVr1kxFihTRpUuXtGnTJq1Zs0bLli3LypwAAAAAAAD4f/dd6DzxxBNauHCh3n33XS1fvlwmk0lms1lly5bV/Pnz9eSTT2ZlTgAAAAAAAPy/+y50JKl69eoKCwvT2bNnFR0drSJFiqh48eJZlQ0AAAAAAAC38UCFzg1+fn7y8/N71FkAAAByvLS0NA0a1Ec+PsU1atQYSdJ33+3QkiULFRFxXp6eHnruuebq0qWH7OzsZDabtWLFUq1fv0axsbGqUKGSBg0aqpIlSxu7IwAAwKbd90WRAQAAIC1ePF+HD//X8v3Ro39o7Nh39NprfbRly07Nnz9fGzdu0MqVKyRJq1ev1IoVS/XOO2O1ceMOPfVUAw0c2FtXr141ZgcAAECuQKEDAABwn375ZZ++++5bNWwYZFl28WKE2rRpq3r1npKdnZ1KlSqlBg0a6dChA5Kkbds2KyTkJVWuXFUODg4KCXlJBQt6aOfO7UbtBgAAyAUodAAAAO5DTEy0Jk4cq3ffHScXFxfL8kaNntaAAUMt3ycmJurHH3erXLkKkqT09HS5uLha/SyTyU6nT5/KltwAACB3otABAAC4h/T0dL3//ttq376DypQpe8ft4uLi1K9fPzk7u6h9+w6SpIYNg7R69Rc6fvxPpaamav361Tp79rSSkpKyKz4AAMiFHuqiyAAAAHnJZ58tlpOTk0JCXrrjNmfOnNKoUW+qWLGimjEjVG5u+SRJL7/cSUlJiRo58g2lpCQrKKipAgJqy93dPbviAwCAXIhCBwAA4B62bNmoK1eu6LnnGknKmFYlSbt2fafNm7/TTz/t1pgxo9Sq1QsaPXqkrl5NkNmccdsrVy6rRYvW6tGjtyQpNTVV7dq10vPPt8z+HQEAALkGhQ4AAMA9rFixxur78ePHSJJGjRqj3377VW+9NUyvvz5CLVu2loOD9dur7du3aPv2rZo2bbYcHZ20aNE8OTo6ql69p7IrPgAAyIUodAAAyIXs7blMXlYymUySJAcHOy1btlipqamaNu0jTZv2kUwmk8xms6pW9dcnn8xUp06ddflypDp1aqeUlBRVreqvmTPnKl8+13vcCx4Gr30AQF5BoQMAQG6S0TOoQAHKgqw0depHlr8vXDj/ntt/8ME4SeOyMBFulm5Ol30+N6NjAACQpSh0AADIRf5/4Ih+OL1HJ2NOGZolLzKZJBcXRyUmpliuoYPsVTifl5qXeV52zi733hgAABtGoQMAQC4UmxirS3GXjI6R55hMkpvZWfHxSRQ6BrFjxhUAII/glAcAAAAAAGBjKHQAAAAAAABsTI4tdNLS0tS5c2eNGDHCsuzQoUNq166d/P39FRQUpFWrVlndZt26dWrSpImqVaum4OBgHTx4MLtjAwAAAAAAZLkcW+jMnDlT+/fvt3wfGxurnj17qk2bNtq3b5/Gjx+vCRMm6PDhw5KkvXv3auzYsZo4caL27dunVq1aqU+fPkpISDBqFwAAAAAAALJEjix0fvrpJ23dulVNmza1LNu6das8PDzUsWNHOTg4qE6dOmrZsqWWL18uSVq1apWaN2+uGjVqyNHRUV27dpWnp6c2btxo1G4AAAAAAABkiRz3KVdRUVEaNWqUZs+erSVLlliWHz9+XGXLlrXatnTp0lq9erUk6cSJE2rbtu0t648ePfrAGW585CvwoG68dkwm8ekmOQCHsgFM//vTxDFgKJOJ85nRePyNx1NgEM4FOYJJHAOG4Rgw1M2v+9x+Ls5RhU56erqGDRumbt26qXz58lbr4uLi5OrqarXMxcVF8fHx97X+QRQq5P7At8lpXFyc5JbCvx5GcXV1NjpCnuXs5ChJcnF2kNx4HozixjFgnP8/BpycHOTGMWAYHnvjODs7/u9PngdDcS4whsP/HwNOzg5yc3MyOE3e5ubK428EF5eMY8DTM5/BSbJejip05s6dKycnJ3Xu3PmWda6urrp27ZrVssTEROXLl8+yPjEx8Zb1np6eD5wjKuqazY6usLe3k6dnPiUmJis+PsnoOHmOyZRR5iQkJNnsa8jWJTlnzCRNTEpVOsdA9jNlvIGPT0iSOAYMYeeUIhdJycmpnAcM4ubmzGNvoCS7lIw/k1J4HozCucBQTkkZx0ByUqri45MNTpNHmTLKnPiEZI4BA9g5ZwzLiYmJU1pausFpHl7hwvceaJKjCp2vvvpKly5dUs2aNSXJUtBs375db775pvbs2WO1/YkTJ1SmTBlJUpkyZXT8+PFb1jdo0OCBc5jNTJfBw7nxuuH1kzPwNGQ/y7BiM4+/0TiXGePmod08/sbjKTAG54KcwSwef6NwDBjr5sc8t5+Lc9RFkTdv3qwDBw5o//792r9/v1q0aKEWLVpo//79atKkia5cuaIlS5YoJSVF4eHhCgsLs1w3JyQkRGFhYQoPD1dKSoqWLFmiqKgoNWnSxOC9AgAAAAAAeLRy1Aidu/H09NSiRYs0fvx4TZ8+XV5eXho9erRq164tSapTp47effddjRkzRpGRkSpdurTmz58vDw8PY4MDAAAAAAA8Yjm60Jk4caLV95UrV9YXX3xxx+1bt26t1q1bZ3UsAAAAAAAAQ+WoKVcAAAAAAAC4NwodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGNyZKFz9OhRdevWTQEBAapXr57efPNNRUdHS5IOHTqkdu3ayd/fX0FBQVq1apXVbdetW6cmTZqoWrVqCg4O1sGDB43YBQAAAAAAgCyT4wqdxMRE9ejRQ/7+/tq9e7c2bNigq1ev6q233lJsbKx69uypNm3aaN++fRo/frwmTJigw4cPS5L27t2rsWPHauLEidq3b59atWqlPn36KCEhweC9AgAAAAAAeHRyXKETERGh8uXLq1+/fnJycpKnp6fat2+vffv2aevWrfLw8FDHjh3l4OCgOnXqqGXLllq+fLkkadWqVWrevLlq1KghR0dHde3aVZ6entq4caPBewUAAAAAAPDoOBgd4N9KliypBQsWWC3bsmWLKlWqpOPHj6ts2bJW60qXLq3Vq1dLkk6cOKG2bdvesv7o0aMPlMFkeojggP732jGZJLPZ2CyQOJQNYPrfnyaOAUOZTJzPjMbjbzyeAoNwLsgRTOIYMAzHgKFuft3n9nNxjit0bmY2m/XJJ59o586dWrZsmZYuXSpXV1erbVxcXBQfHy9JiouLu+v6+1WokHvmgucALi5OckvhXw+juLo6Gx0hz3J2cpQkuTg7SG48D0Zx4xgwzv8fA05ODnLjGDAMj71xnJ0d//cnz4OhOBcYw+H/jwEnZwe5uTkZnCZvc3Pl8TeCi0vGMeDpmc/gJFkvxxY6169f18iRI3XkyBEtW7ZM5cqVk6urq65du2a1XWJiovLly3iiXF1dlZiYeMt6T0/PB7rvqKhrNju6wt7eTp6e+ZSYmKz4+CSj4+Q5JlNGmZOQkGSzryFbl+ScMZM0MSlV6RwD2c+U8QY+PiFJ4hgwhJ1TilwkJSench4wiJubM4+9gZLsUjL+TErheTAK5wJDOSVlHAPJSamKj082OE0eZcooc+ITkjkGDGDnnDEsJyYmTmlp6QaneXiFC997oEmOLHTOnDmj1157TcWLF9fq1avl5eUlSSpbtqz27Nljte2JEydUpkwZSVKZMmV0/PjxW9Y3aNDgge7fbGa6DB7OjdcNr5+cgach+1mGFZt5/I3GucwYNw/t5vE3Hk+BMTgX5Axm8fgbhWPAWDc/5rn9XJzjLoocGxurLl26qHr16lq4cKGlzJGkJk2a6MqVK1qyZIlSUlIUHh6usLAwy3VzQkJCFBYWpvDwcKWkpGjJkiWKiopSkyZNjNodAAAAAACARy7HjdBZu3atIiIitGnTJm3evNlq3cGDB7Vo0SKNHz9e06dPl5eXl0aPHq3atWtLkurUqaN3331XY8aMUWRkpEqXLq358+fLw8PDgD0BAAAAAADIGjmu0OnWrZu6det2x/WVK1fWF198ccf1rVu3VuvWrbMiGgAAAAAAQI6Q46ZcAQAAAAAA4O4odAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNodABAAAAAACwMRQ6AAAAAAAANoZCBwAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgcAAAAAAMDGUOgAAAAAAADYGAodAAAAAAAAG0OhAwAAAAAAYGModAAAAAAAAGwMhQ4AAAAAAICNyXWFTlRUlPr27auaNWsqMDBQ48ePV2pqqtGxAAAAAAAAHplcV+gMHjxYbm5u2rVrl1avXq2ffvpJS5YsMToWAAAAAADAI5OrCp3Tp0/r559/1rBhw+Tq6io/Pz/17dtXy5cvNzoaAAAAAADAI5OrCp3jx4/Lw8NDxYoVsywrVaqUIiIi9M8//xiYDAAAAAAA4NFxMDrAoxQXFydXV1erZTe+j4+PV4ECBe7r59jZSWbzI4+XrXy93OTqnKueXttgkuzt7ZXm7ijZ+GvIVnnld5YkORQpIXtHR4PT5EEmSfb2ckxL4xgwiMmtoCSpfOGyKuzmZXCavMnewU5pqelGx8iz8jnly/izSiU5/+cxg9PkXQ729nJOSzM6Rp5k7+omSfIt46kij+U3OE3eZW9vp7Q0zgVGcHC0t/zdLlcNYblVrvqN383NTQkJCVbLbnyfL1+++/45Xl7ujzSXEZ6r4mt0BMBQDn41JT+jU+RdVGnGK1OotMoUKm10DMAwbo8/bnQEwFAehd2MjgAYytPz/jsAW5Wr+qoyZcro6tWrunLlimXZX3/9JW9vb7m7235JAwAAAAAAIOWyQufxxx9XjRo19MEHH+j69es6e/asZs+erZCQEKOjAQAAAAAAPDIms9nWrxZj7cqVK3r//fe1d+9e2dnZqU2bNnrjjTdkb29/7xsDAAAAAADYgFxX6AAAAAAAAOR2uWrKFQAAAAAAQF5AoQMAAAAAAGBjKHQAAAAAAABsDIUOAAAAAACAjaHQAQAAAAAAsDEUOgAAAAAAADaGQgfIpP3799+y7Nq1a3r99dcNSAMAAAAAyAscjA4A2Lq+fftqyZIlqlixoiRp9+7deuutt1SoUCGDkwHZo3PnzjKZTLcsd3R0lJeXlxo3bqxmzZoZkAzIPsePH9eHH36oU6dOKT093Wrdjh07DEoFZK2RI0fec5sJEyZkQxLAeMnJyYqOjr7lHFC8eHGDEiEvoNABMmnEiBF67bXXFBoaqjVr1mj16tXq1auX+vTpY3Q0IFtUrVpVK1eu1Isvvig/Pz9FRERo5cqVatCggQoXLqzx48crKipKnTt3NjoqkGXeeecdubq6qmfPnnJw4O0V8paYmBjt2rVLjRs3lp+fnyIjI7Vt2zY1bdrU6GhAtti0aZPeffddXbt2zbLMbDbLZDLpjz/+MDAZcjuT2Ww2Gx0CsHWrVq3SO++8o9KlS+vDDz9UhQoVjI4EZJsOHTpo6NChqlmzpmXZoUOHNHnyZC1btkxHjx7VoEGDtGXLFgNTAlmrevXq+uGHH5Q/f36jowDZrnfv3mrXrp2efvppy7Ldu3crNDRUy5YtMzAZkD2aNWumpk2b6oUXXril1Pf19TUoFfIC/gsJeEj79u2z/P3xxx9XixYtdODAAV29etWyrlatWkbFA7LNsWPHVL16datllStX1u+//y5JKl++vC5fvmxENCDbFC1aVMnJyUbHAAyxd+9ezZ4922pZnTp1NGDAAIMSAdnrwoUL6t+/PyM0ke14xQEP6U7TR7p16yZJDLFEnuHn56c1a9aoXbt2lmVhYWGWOeNHjhxRkSJFjIoHZItOnTqpX79+euWVV1S4cGGrdZT7yO18fX21adMmNW/e3LJs7dq1KlGihIGpgOxTqVIlnThxQuXLlzc6CvIYplwBmXT27Fn5+fkZHQMwzI8//qg+ffqoQoUK8vX1VUREhI4eParp06ercOHC6tChg0aNGqWQkBCjowJZ5k5v4in3kRfs2LFDgwYNUpUqVeTj46Nz587p2LFjCg0NVWBgoNHxgCw3ZcoUffnll3ruueduKfX79+9vUCrkBRQ6QCbVrVtXW7du5boJyNPOnTunsLAwXbx4Ub6+vmrdurWKFSumixcvKiYmhutKIdej3Ede9/fff2vjxo26dOmSvL291bJlS44J5Bl3GrlvMpm0dOnSbE6DvIRCB8ikZs2aacaMGSpVqpTRUQAABqHcBwAA2Y1r6ACZVKZMGb344ouqVq2aihYtarVuwoQJBqUCss/x48f14Ycf6tSpU0pPT7dat2PHDoNSAdnLw8NDkZGRFDrIkzgPANJff/2lzz//XBcvXtTYsWP1zTffqFOnTkbHQi5HoQNkkpubm5o2bWp0DMAw77zzjlxdXdWzZ08+3QF5FuU+8jLOA8jr9uzZowEDBqhx48b68ccflZiYqFmzZik+Pl49e/Y0Oh5yMaZcAQAypXr16vrhhx8YmYA8beTIkXdcR6GD3I7zAPK6tm3bauDAgWrYsKFq1aqlffv26ddff9XgwYMZpYYsRYUOZFJycrLCwsIUGRlpGWackpKiY8eOac6cOQanA7Je0aJFlZycbHQMwFCUNsjLOA8grzt9+rQaNGggKeNCyJJUuXJlxcbGGhkLeQCFDpBJb731lnbt2iVPT0+lpKTIzc1Nx48fV5s2bYyOBmSLTp06qV+/fnrllVdu+ajOWrVqGZQKyH6ffvqpVq5cqfPnz6tIkSIKCQlRr169LG/ugdyK8wDyuuLFi+vAgQOqUaOGZdmvv/4qHx8fA1MhL6DQATJp165d+vzzzxUdHa3PP/9cH3/8sRYtWqTDhw8bHQ3IFuPGjZMkHTx40Gq5yWTSH3/8YUQkINt9+umnWrx4sXr27KnHHntMZ86c0YIFC2RnZ8f1E5DrcR5AXterVy/16dNHL7/8slJSUjR//nx99tlnGjp0qNHRkMtxDR0gk27Mk42OjlanTp20ceNGJSUl6emnn9bu3buNjgcAyAbPP/+8Pv74Y1WsWNGy7Pfff9eAAQO4fgIA5AHff/+9li9frvPnz8vb21svvviinn32WaNjIZdjhA6QSd7e3jp79qz8/PwUFRWl+Ph42dnZKS4uzuhoQJa6ePGivL29FRERccdtihcvno2JAONcunRJ5cuXt1pWvnx5Xb161ZhAQDbiPIC8buzYsRoyZIgaNmxodBTkMRQ6QCa1bNlSHTp00OrVq9WoUSP16dNHzs7OevLJJ42OBmSpZs2a6cCBAwoKCpLJZNKNAZ83/s5Qe+QlJUqU0LZt26z+N3bbtm0qUaKEgamA7HG788ANnAeQF4SFhd310w6BrMKUK+AR2LRpkxo2bKj09HRNnjxZ169f1+DBg+Xn52d0NCDLXLhwQT4+Pjp//vwdt/H19c3GRIBxtm/frsGDB6tJkyby8/PTmTNntGPHDk2fPl2NGzc2Oh6Qpf59HoiOjtaCBQv09NNPq1WrVgalArLPpEmTFBcXpxdeeEFFixa1KjUZpYasRKEDPEIxMTHy9PQ0OgaQrUaMGKG2bdvySSbI88LDw7Vu3TpduXJFvr6+CgkJUZUqVYyOBRji2rVreuGFF7R9+3ajowBZ7uYptzfKHEYrIzsw5QrIpOvXr2vixIkKCwtTcnKyXF1d9dJLL2nw4MFycnIyOh6Q5dzc3DRgwAC5u7vrhRdeUHBwsLy9vY2OBWS72rVrq3bt2kbHAHKMf/75x+gIQLbg4vcwCiN0gEx6++23dezYMQ0cOFA+Pj46e/aspk2bpsDAQA0fPtzoeEC2SElJ0c6dO7Vu3Trt2bNHtWrVUtu2bfXMM89QbCJPuHTpkmbNmqWzZ88qNTXVat3SpUsNSgVkj5kzZ1p9n5KSol27dqlw4cKaN2+eQakAIPej0AEyqX79+vr666/l5eVlWXbx4kWFhITwseXIk/773//q/fff1++//66CBQsqODhYffv2lbu7u9HRgCzTrVs3xcbG6qmnnpKjo6PVuv79+xuUCsgenTt3tvre3t5epUqVUq9evVS0aFGDUgFZr3r16jpw4IDKly9vdd2cmzHlClmJKVdAJrm6usre3t5qmZubm9LT0w1KBGS/y5cva8OGDfrqq6/0119/qWHDhurfv7+KFy+uTz75RH369NGyZcuMjglkmf/+97/64YcfKC6RJ3322WdGRwAMcWME2tKlS5WamioHBwelp6crKSlJx44dU9WqVQ1OiNyOQgd4SBEREZKkNm3aaMiQIRoxYoR8fX116dIlTZ48WV27djU2IJBNunfvrvDwcJUsWVLBwcFq3bq11Yi1oUOHqn379gYmBLKej4+P7OzsjI4BGGb79u1auXKlzp8/ryJFiigkJEQtW7Y0OhaQpWrWrCkp45qao0eP1o8//qjZs2crNDRUJpNJo0aNUkBAgMEpkZsx5Qp4SDeGVt58CHFVe+RF7777rtq2bXvHT/OJi4vTxYsXVapUqWxOBmS9G+X+119/rd9//119+vRRwYIFrbbhI2uR24WFhem9995T+/bt9dhjj+nMmTP68ssvNWLECLVr187oeECWa9eundq1a6eQkBDVr19fEyZMUKFChTRkyBBt27bN6HjIxSh0gId0/vz5e27j6+srKeOaOnzqD/KS1NRUHTt2TBUrVjQ6CpClKPcBqVWrVnrrrbesPuUtPDxc77//vjZu3GhgMiB7BAYGau/evfr999/VsWNH7du3Tw4ODvL399fBgweNjodcjClXwEO6Udbcj2bNmunAgQNZmAYwzvfff68xY8YoMjLS6pdaBwcH/frrrwYmA7Leg3xULeU+cquIiAgFBgZaLQsICNDFixcNSgRkL1dXV0VFRenbb79VjRo15ODgoKNHj8rT09PoaMjlKHSAbMBAOORmkydPVtOmTVWgQAH9+eefatGihWbNmqWQkBCjowFZjnIfkLy9vbVv3z6ra4Xs27eP6YbIM9q2bas2bdron3/+0fTp0/Xbb7+pR48eevXVV42OhlyOQgfIBnf6GEMgNzh79qyGDRumc+fOKTw8XE2bNlXJkiU1ZMiQWz7KFsjLKPeRW3Xp0kX9+vVT+/bt5efnpzNnzmjlypUaOXKk0dGAbDFgwAAFBATI2dlZ1apV04ULF/T++++radOmRkdDLkehAwDIFC8vL9nZ2al48eL666+/JEmlS5dmqD3wL5T7yK3atWsne3t7rV27Vtu3b5evr6/GjRun5557zuhoQLa5edqhj4+PfHx8DEyDvIJCBwCQKeXKldO0adPUr18/FSpUSN9//71cXFzk7OxsdDQAQDYYO3ashgwZouDgYKOjAECeYmd0AACAbRs2bJi2b9+uy5cva+DAgerbt6+6du2q7t27Gx0NAJANwsLC5OrqanQMAMhz+NhyIBtUr16dC2Eiz7h06ZLi4uL0xBNPGB0FyFE4FyC3mjRpkuLi4vTCCy+oaNGiVtMLuTAyAGQdplwB2cDJycnoCMAjt2/fvruuv3LlimrVqpVNaQAARlm8eLEk6csvv7SUOWazWSaTSX/88YeR0QAgV2OEDpBJ69evv+1yR0dHeXl5qVq1agxDRq5Uvnz5u67njTzykv3796t69eqys7vzbPbatWsrPDw8G1MB2eP8+fN3XOfr65uNSQAgb6HQATLp5Zdf1n//+18VKlRIvr6+unDhgi5fvixvb28lJCTIZDJp0aJFqlChgtFRAQBZJDAwUN999x0FPvKkiIiI2y53dHRUwYIFGakMAFmEKVdAJpUrV061atXS4MGDLf8zO3PmTMXGxmrUqFFatGiRJkyYoKVLlxqcFMg6J0+e1DfffKPLly/L19dXLVq04LoJyFP8/Pz066+/KiAgwOgoQLZr0qSJ0tPTJf1vqtUNdnZ2qlu3riZNmiQvLy+jIgJArsQIHSCT6tevr507d8rR0dGyLCUlRY0bN9bu3buVmpqq2rVra//+/QamBLLO9u3bNXjwYD355JMqXry4zp07p+PHj2v+/PmqWbOm0fGAbNG9e3eFh4frscceu+WisBT6yO2WLVumnTt36q233pKfn5/OnTunDz/8UE8++aSaNm2qOXPmyMHBQZMnTzY6KgDkKozQAR6Bs2fPqmTJkpbvz58/r9TUVElSYmKiVdkD5DZTp07VuHHj1KZNG8uy1atXa8KECVqzZo1xwYBs5O/vL39/f6NjAIb49NNPtWrVKnl4eEiSSpYsqUmTJqlt27bq37+/xo4dq6efftrYkACQC1HoAJkUEhKinj17qlevXipevLgiIiK0cOFCBQcHKyoqSm+++aYaNmxodEwgy0RERKhVq1ZWy1544QVNmDDBoERA9uvfv7/REQDDxMTEyN7e3mqZyWRSVFSUJMnV1dUyJQsA8OhQ6ACZNHDgQLm5uWnBggW6cOGCihcvrvbt26tLly767bffVLJkSQ0ePNjomECWqVKlirZu3arnnnvOsuznn39WtWrVjAsFZLOYmBh99tlnioyMtPzimpKSomPHjunrr782OB2QtZ566im9/vrrGjVqlOU/tyZPnqz69esrOTlZs2bNUqVKlYyOCQC5DtfQAQBkyqhRo7R+/Xo1atRIJUqUUGRkpLZv366aNWuqaNGilu0YsYPcrHfv3jp16pS8vLx0/fp1FS9eXLt371bHjh01cuRIo+MBWerq1at6/fXXtWfPHsv1oxo1aqTx48fr6NGjmjRpkqZMmaJSpUoZnBQAchcKHSCTzGazli5dqpUrV+r8+fMqUqSIQkJC1KtXL6uLYgK51f3+skqhg9ysRo0a2rhxoyIjIzVv3jzNnDlTX331lTZs2KD58+cbHQ/IFpGRkbp48aKKFy+uIkWKKDExUS4uLkbHAoBciylXQCYtXbpUixcvVs+ePfXYY4/pzJkzWrBggezs7NSzZ0+j4wFZ7n6KmjFjxmR9EMBADg4OKlasmFxdXfXnn39Kkpo3b64PP/zQ4GRA1lu6dKleeeUVFStWTMWKFZMk/fe//9Xw4cO1ZcsWg9MBQO5lZ3QAwNZ98cUXmj17tjp06KAGDRqoU6dOmj17tlauXGl0NCDH4BoiyO18fX3122+/qUCBAoqLi1N0dLTi4+OVmJhodDQgy82ZM0dr166VJKWmpmrKlCnq1KmT6tata3AyAMjdGKEDZNKlS5dUvnx5q2Xly5fX1atXjQkE5EDM7kVu16FDB3Xu3FnffPONWrRooS5dusjBwUG1atUyOhqQ5RYuXKju3bsrJiZGGzZs0D///KMFCxaodu3aRkcDgFyNETpAJpUoUULbtm2zWrZt2zaVKFHCoERAzsP1pJDbhYSEqG/fvrK3t9ewYcP07LPPKioqiilXyBMqVqyoBQsWaO7cufLw8NCGDRsocwAgGzBCB8ikvn37avDgwdq8ebP8/Px0+vRpffvtt5o+fbrR0QAA2WT69Olat26dmjRpIkdHR1WoUEGOjo768ssv1aNHD6PjAVli5syZVt9Xr15d4eHhmjt3rhwcMn7N6N+/vxHRACBP4FOugEdg7969Wrt2raKiouTr66u2bduqSpUqRscCcozq1avrwIEDRscAskyDBg20fPly+fn5WZadOXNGXbp00c6dOw1MBmSdzp0733W9yWTS0qVLsykNAOQ9jNABHlLnzp1vmUZiNpt18uRJffTRR5LEmxgAyCOuX78uHx8fq2U+Pj6Kj483KBGQ9T777DPL381ms9LT02Vvb6/Lly/Ly8tL9vb2BqYDgNyPa+gADykwMFABAQEqXry4fv/9d1WoUEHPPfecqlatqj///FNPPPGE0RGBHIPBoMjtKlWqpHnz5lktW7Ro0S0XzQdyo6NHjyooKEhHjhyRJC1YsEBNmzbVyZMnDU4GALkbU66ATOrQoYPeeOMNVa9e3bLst99+09tvv61169YZmAzIOZYsWaKuXbsaHQPIMkeOHNGrr74qV1dXeXt76+LFi0pNTdWCBQsodZDrde7cWbVq1VLfvn3l4OCg1NRUhYaG6sCBA1q0aJHR8QAg16LQATLJ399f+/fvtxpWnJKSooCAAB08eNDAZED2iIyM1Jw5c3Tq1Cmlp6dbrWPaIfKS2NhY7dy5U5cuXZKPj48aNWokd3d3o2MBWa5mzZrat2+f1VT0tLQ01a5dW/v27TMwGQDkblxDB8ikUqVKacmSJerevbtlWWhoKP8jizxj5MiRunLliho3bixHR0ej4wCGKViwoNq0aWN0DCDb5c+fXydPnlTJkiUty86ePasCBQoYmAoAcj9G6ACZdODAAfXu3Vtubm7y9vZWRESE0tPTtXDhQpUrV87oeECWq1WrlrZs2SIvLy+jowAADDBt2jRt3LhRPXr0UPHixRUREaGFCxeqZcuW6tevn9HxACDXYoQOkEnVq1fX1q1b9d133ykyMlLe3t4KCgpimD3yDHd3dzk5ORkdAwBgkP79+8vOzk6hoaG6fPmyfHx8FBwcrB49ehgdDQByNUboAAAyZfXq1fr+++/12muvqXDhwlbrihcvblAqAAAAIHej0AEAZMq/rxdlMplkNptlMpn0xx9/GJQKAJBdkpOTFRYWpsjISMvF8VNSUnTs2DHNmTPH4HQAkHsx5QoAkCk7duwwOgIAwEBvvfWWdu3aJU9PT6WkpMjNzU3Hjx/nIuEAkMXsjA4AALBtvr6+8vX1VWxsrI4cOaIiRYrIxcVFvr6+RkcDAGSDXbt26fPPP9e4ceNUrVo1hYWF6c0331RiYqLR0QAgV6PQAQBkSlRUlF566SW9+OKLGj58uM6ePatnnnlGBw8eNDoaACAbpKenq2TJkipZsqRlqm3Hjh21f/9+g5MBQO5GoQMAyJQPPvhAZcuW1b59++Tg4KBSpUqpZ8+e+vDDD42OBgDIBt7e3jp79qy8vLwUFRWl+Ph4mc1mxcXFGR0NAHI1rqEDAMiU8PBwbd++Xa6urjKZTJKkHj16aNGiRQYnAwBkh5YtW6pDhw5avXq1GjVqpD59+sjZ2VlPPvmk0dEAIFej0AEAZIqjo6MSExPl6uqqGx+cGBcXp3z58hmcDACQHXr27Ck/Pz/ly5dPgwcP1ty5c3X9+nW9/fbbRkcDgFyNKVcAgEwJCgrSsGHDdOrUKZlMJkVFRem9995Tw4YNjY4GAMgGcXFx2r17t+rVq6egoCB9/fXXKlKkiIoVK2Z0NADI1UzmG/+dCgDAQ4iLi9PIkSO1detWSZLJZFLDhg01efJkubu7G5wOAJDV3n77bR07dkwDBw6Uj4+Pzp49q2nTpikwMFDDhw83Oh4A5FoUOgCATNm/f7/8/f0VGxurc+fOydvbW0WLFjU6FgAgm9SvX19ff/21vLy8LMsuXryokJAQ7d6928BkAJC7MeUKAJAp/fr1U3Jysry8vFSlShXKHADIY1xdXWVvb2+1zM3NTenp6QYlAoC8gUIHAJApfn5++vXXX42OAQDIZhEREYqIiFCbNm00ZMgQHTt2THFxcTp58qRGjBihrl27Gh0RAHI1plwBADKle/fuCg8P12OPPaaiRYtaPrpckpYuXWpgMgBAVipfvrxMJpNu/nXixjnAbDbLZDLpjz/+MCoeAOR6fGw5ACBT/P395e/vb3QMAEA227Fjh9ERACBPY4QOAAAAAACAjWGEDgDgoYwcOfKe20yYMCEbkgAAAAB5DxdFBgBkSkxMjL7++mtdu3ZNHh4eSkpK0oYNG5ScnGx0NAAAACDXYsoVACBTevfurXbt2unpp5+2LNu9e7dCQ0O1bNkyA5MBAAAAuReFDgAgU/z9/fXLL7/Izu5/gz7T0tJUs2ZNHTx40MBkAAAAQO7FlCsAQKb4+vpq06ZNVsvWrl2rEiVKGJQIAAAAyP0YoQMAyJQdO3Zo0KBBqlKlinx8fHTu3DkdO3ZMoaGhCgwMNDoeAAAAkCtR6AAAMu3vv//Wxo0bdenSJXl7e6tly5by8/MzOhYAAACQa1HoAAAAAAAA2BgHowMAAGxTUFCQTCbTXbfZsWNHNqUBAAAA8hYKHQDAQ+nfv/89Cx0AAAAAWYMpVwAAAAAAADaGEToAgIfSs2dPzZs3T507d77jSJ2lS5dmcyoAAAAgb6DQAQA8lBo1akgSH00OAAAAGIApVwAAAAAAADaGEToAgEyJi4vT8uXLdfbsWaWmplqtmzBhgkGpAAAAgNzNzugAAADbNnLkSC1fvlzx8fFGRwEAAADyDKZcAQAyxd/fX1u2bFHRokWNjgIAAADkGYzQAQBkSpEiReTp6Wl0DAAAACBPodABAGTKSy+9pEmTJumff/4xOgoAAACQZzDlCgDwUMqXLy+TyaQbpxGTyXTLNn/88Ud2xwIAAADyBD7lCgDwUJYuXSpJMpvNOnXqlFxdXeXt7a0LFy4oKSlJjz/+uLEBAQAAgFyMKVcAgIcSEBCggIAA7d27V6GhoapSpYoCAgKUP39+zZ07V4cPHzY6IgAAAJBrMeUKAJApDRo00PLly+Xn52dZdubMGXXp0kU7d+40MBkAAACQezFCBwCQKdevX5ePj4/VMh8fH8XHxxuUCAAAAMj9KHQAAJlSqVIlzZs3z2rZokWLVL58eYMSAQAAALkfU64AAJly5MgRvfrqq5aLIl+8eFGpqalasGABpQ4AAACQRSh0AACZFhsbq507d+rSpUvy8fFRo0aN5O7ubnQsAAAAINei0AEAAAAAALAxXEMHAAAAAADAxlDoAAAAAAAA2BgKHQAAAAAAABtDoQMAAJBF0tLSdPbsWaNjAACAXIhCBwAAGOrkyZMaPny4GjRoIH9/fz3zzDP66KOPFBcXJ0kqV66c9u7da3DKhzNkyBCtX7/ekPvev3+//P39M/1zZsyYoc6dOz+CRAAA4FGi0AEAAIY5cOCAXnjhBfn6+mr9+vU6ePCg5s+fr0OHDunVV19VWlqa0REzJSYmxrD7rlmzpg4ePGjY/QMAgKxFoQMAAAzzzjvvqE2bNho4cKC8vLwkSU888YSmTp2qQoUK3TJd6a+//lKvXr3UqFEjValSRc2aNdPOnTst62fMmKGGDRsqICBAbdu21Y4dOyRJqampGjNmjOrVq6fAwEB16NBBv/zyy31lTE1N1bRp09SwYUNVr15dHTt21NGjRyVJkZGRGjx4sIKCglS1alU9/fTTWr16tSRp1KhR2r9/v+bOnavevXtLks6cOaPevXsrMDBQjRs31tSpU5WcnGy5r2+++UbPPvusatasqe7du+vtt9/WiBEjJEnp6emaN2+ennnmGdWoUUMhISHatWuX5bZBQUF65513VK9ePbVp00Y//fSTypUrZ1l/5MgRde7cWf7+/qpfv76mTZsms9ksSVq9erWCg4MVGBgof39/9erVS9HR0ff1+AAAAGNQ6AAAAEOcOXNGx48fV4sWLW5ZV7hwYc2ePVuPP/641fIBAwaobNmy2rZtm/bv36/69etrzJgxkqTw8HCtXLlSq1at0t69e9WuXTuNGjVKKSkp+uqrr3Tw4EFt2rRJP/74o2rVqqX33nvvvnLOmTNHGzZs0MKFC7Vv3z4FBASoV69eSktL0+jRo+Xo6KhvvvlGBw4cUKdOnTR27FjFxcVp/Pjxqlmzpnr16qXQ0FDFx8era9euKlOmjH744QetWLFCP/74o2bMmCFJOnjwoIYPH67hw4crPDxcL730ktauXWvJMWvWLC1fvlzTpk3T3r179eqrr6pv3746fPiwZZvDhw9r06ZNWrp0qezs/vc27+rVq3r11VcVGBiovXv3asWKFVq7dq1Wrlypw4cPa9y4cRozZoz27t2rTZs26dSpU1q6dOn9PpUAAMAADkYHAAAAedONESCFCxe+79vMnTtXxYoVk9ls1vnz51WgQAFFRkZKkpydnRUbG6svv/xSjRs3Vrt27dS+fXuZTCa5uLjo3LlzWr16tRo0aKBBgwZpyJAh93Wf69atU69evVS6dGlJUp8+fdSwYUOZzWaNGzdO+fLlk6OjoyIiIpQvXz4lJiYqNjZW+fLls/o53333nZKTkzV06FCZTCb5+Pho0KBBGjhwoF5//XWtWbNGTZs2VVBQkCSpSZMmeuaZZyy3X7NmjXr27KlKlSpJkpo1a6YtW7Zo9erVqlKliiTp2WefVYECBW7Zh507d8rZ2Vn9+vWTyWTSf/7zHy1evFhubm7y8PDQhg0b9Nhjjyk2NlaXLl2Sl5eX5XEFAAA5E4UOAAAwRJEiRSRJly9fvmUkjiRduXLllrLn6NGj6tu3ry5fvqxSpUrJy8vLMm3I399fM2bM0GeffaYFCxbIxcVFnTt3Vp8+fdS8eXOlpKRo1apVmjJligoVKqTevXvr5ZdfvmfOy5cvq3jx4pbvnZycVK1aNUnS2bNn9eGHH+rUqVN6/PHHVaJECUkZ06P+7fz584qOjlatWrUsy8xms1JSUhQVFaULFy6oYsWKVrfx8/PTlStXLI+Hn5+f1frHHnvMMv1LkooWLXrHffDx8ZHJZLIsK1mypCQpOTlZS5cuVVhYmNzc3FSuXDldv37d8rgCAICciUIHAAAYwtfXV2XLltXGjRutSg5JioqKUuPGjTVhwgTLssjISA0aNEgzZ860jGLZsmWLtm7dKkmKiIhQoUKFtHDhQiUnJ+unn35S//79ValSJZUoUUKVKlVSmzZtlJiYqM2bN2v48OGqWbOmypQpc9ecPj4+unDhguX7lJQUTZ48Wd26dVOvXr00dOhQdejQQSaTSb/99pu+/vrr2/4cb29v/ec//9HmzZsty65fv66oqCh5eXnJ19dXERERVreJiIiQk5OT5fH69zWFzp49a1Xi3FzY/Pu+L1y4ILPZbNlm+/btun79ui5duqQ9e/YoLCzMUqDduOYPAADIubiGDgAAMMzbb7+tNWvWaObMmYqJiZHZbNYff/yh3r17q1KlSnr22Wct28bFxSktLU2urq6SpBMnTmjWrFmSMkaZ/Prrr+rRo4eOHj0qJycnFSpUSJLk6empnTt3qn///jp37pxcXFzk4eEhBwcHubu73zNjcHCwFi5cqJMnTyo1NVVz587V9u3blT9/fiUmJsrFxUUmk0kRERGaPHmypIzSR8oYzXPt2jVJUuPGjRUXF6cFCxYoOTlZ//zzj4YPH64hQ4bIZDKpXbt22rZtm3bt2qW0tDR9//33lrJKktq1a6d58+bpyJEjSktL06ZNm/Ttt9/qhRdeuOc+NGrUSKmpqQoNDVVycrLOnDmjDz74QElJSbp+/bocHBzk6Oio1NRUffXVV9q1a5dlHwAAQM7ECB0AAGCYgIAALVu2TKGhoWrevLkSEhJUuHBhPffcc+rVq5ccHR0t25YsWVJvvvmmhg0bpoSEBHl7e+vFF1/U5MmTdezYMT377LM6deqU+vTpo5iYGBUqVEhvvfWWqlatqkqVKikyMlIvvfSSrl+/Ll9fX02dOlXe3t73zNijRw+lpqaqe/fuio2NVeXKlTV//ny5u7vrgw8+0LRp0zRu3DgVKlRIL774ok6cOKFjx47piSeeUJs2bTRmzBj99ttvWrFihZYsWaKJEydqwYIFSk9PV2BgoObMmSNJqly5st577z2NGTNGMTExqlmzpurUqWN5DLp166b09HQNGTJEly9fVokSJTRlyhQFBATccx8KFCighQsXasKECVq8eLFcXV3VsWNHtW/fXlevXtWxY8fUuHFjOTs7q2LFiurQoYPCw8Mf8lkFAADZwWRmgjQAAIDhTp48qfT0dJUqVcqybMCAASpZsuR9X8AZAADkHUy5AgAAyAFOnDihLl266MyZM5KkvXv3ateuXWrYsKHByQAAQE7ECB0AAJBnLV68WNOnT7/j+pYtW+r999/Ptjxz5szRypUrFRsbK19fX/Xq1UstW7bMtvsHAAC2g0IHAAAAAADAxjDlCgAAAAAAwMZQ6AAAAAAAANgYCh0AAAAAAAAbQ6EDAAAAAABgYyh0AAAAAAAAbAyFDgAAAAAAgI2h0AEAAAAAALAxFDoAAAAAAAA2hkIHAAAAAADAxvwfQiGAdt1L2QAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1150.62x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analysis of the class balancing\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "gTitle = f'{nom_dataset} - Number of classes = ' + str(len(pd.Series(DB['Class_categorical']).unique()))\n",
    "g = sns.displot(DB,x='Class_categorical', hue='Class_categorical',height = 5, aspect = 2).set(title=gTitle)\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set_titles('Number of classes')\n",
    "\n",
    "# Retrieve the axes object from the plot\n",
    "axes = g.ax\n",
    "\n",
    "# Iterate over each bar in the plot\n",
    "for p in axes.patches:\n",
    "    # Get the coordinates of the bar\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    cord_x, cord_y = p.get_xy()\n",
    "    if height > 0:\n",
    "        axes.annotate(f'{height}', (cord_x + width/2, cord_y + height), ha='center')\n",
    "        \n",
    "g._legend.remove()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1-) Features original\n",
      "2-) Features augmented\n",
      "3-) Features augmented and windowed (US8K is only windowed)\n",
      "\n",
      "Select the dataset: \n",
      "\n",
      "1-) Features original\n",
      "2-) Features augmented\n",
      "3-) Features augmented and windowed (US8K is only windowed)\n",
      "\n",
      "Select the dataset: 3\n"
     ]
    }
   ],
   "source": [
    "# Read the pkl file with the augmented features extracted\n",
    "\n",
    "opc = 0\n",
    "while str(opc) not in '123':\n",
    "    print()\n",
    "    print(\"1-) Features original\")\n",
    "    print(\"2-) Features augmented\")\n",
    "    print(\"3-) Features augmented and windowed (US8K is only windowed)\")\n",
    "\n",
    "    opc = input(\"\\nSelect the dataset: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "\n",
    "if opc == 1:\n",
    "    DB_from_pkl      = pd.read_pickle(os.path.join(path_models, pkl_features_CNN_2D))\n",
    "    model_surname    = '_original'\n",
    "\n",
    "elif opc == 2:\n",
    "    DB_from_pkl      = pd.read_pickle(os.path.join(path_models, pkl_aug_features_CNN_2D))\n",
    "    model_surname    = '_augmented'\n",
    "\n",
    "elif opc == 3:\n",
    "    DB_from_pkl      = pd.read_pickle(os.path.join(path_models, pkl_aug_wind_features_CNN_2D))\n",
    "    model_surname    = '_windowed'\n",
    "    \n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_categorical</th>\n",
       "      <th>Class_OHEV</th>\n",
       "      <th>Fold</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog_bark</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[-44.0467643737793], [-39.25644302368164], [-38.62413787841797], [-36.58848571777344], [-32.5598030090332], [-31.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dog_bark</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[-29.934663772583008], [-34.787696838378906], [-40.06871795654297], [-41.22150802612305], [-41.03109359741211], [-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog_bark</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[-23.2158260345459], [-28.396337509155273], [-32.66521072387695], [-31.442462921142578], [-35.61741256713867], [-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dog_bark</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[-37.06025695800781], [-39.86629104614258], [-41.0966682434082], [-38.97296142578125], [-41.87018966674805], [-39....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dog_bark</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>[[[-28.527423858642578], [-29.930322647094727], [-35.48342514038086], [-38.032806396484375], [-38.82895278930664], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30501</th>\n",
       "      <td>car_horn</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[-16.7570743560791], [-12.688139915466309], [-16.03248405456543], [-15.612970352172852], [-12.660606384277344], [-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30502</th>\n",
       "      <td>car_horn</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[-14.313464164733887], [-12.228155136108398], [-15.787863731384277], [-16.082149505615234], [-12.465015411376953],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30503</th>\n",
       "      <td>car_horn</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[-24.34674835205078], [-17.664506912231445], [-11.443778038024902], [-11.371871948242188], [-12.617921829223633], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30504</th>\n",
       "      <td>car_horn</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[-20.291765213012695], [-13.778326034545898], [-9.759299278259277], [-8.09199333190918], [-8.728732109069824], [-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30505</th>\n",
       "      <td>car_horn</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "      <td>7</td>\n",
       "      <td>[[[-16.410991668701172], [-11.63617992401123], [-9.72879409790039], [-13.295160293579102], [-12.994491577148438], [-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30506 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class_categorical       Class_OHEV Fold                                                                                                                 features\n",
       "0              dog_bark  [0, 0, 0, 1, 0]    5  [[[-44.0467643737793], [-39.25644302368164], [-38.62413787841797], [-36.58848571777344], [-32.5598030090332], [-31.4...\n",
       "1              dog_bark  [0, 0, 0, 1, 0]    5  [[[-29.934663772583008], [-34.787696838378906], [-40.06871795654297], [-41.22150802612305], [-41.03109359741211], [-...\n",
       "2              dog_bark  [0, 0, 0, 1, 0]    5  [[[-23.2158260345459], [-28.396337509155273], [-32.66521072387695], [-31.442462921142578], [-35.61741256713867], [-3...\n",
       "3              dog_bark  [0, 0, 0, 1, 0]    5  [[[-37.06025695800781], [-39.86629104614258], [-41.0966682434082], [-38.97296142578125], [-41.87018966674805], [-39....\n",
       "4              dog_bark  [0, 0, 0, 1, 0]    5  [[[-28.527423858642578], [-29.930322647094727], [-35.48342514038086], [-38.032806396484375], [-38.82895278930664], [...\n",
       "...                 ...              ...  ...                                                                                                                      ...\n",
       "30501          car_horn  [0, 1, 0, 0, 0]    7  [[[-16.7570743560791], [-12.688139915466309], [-16.03248405456543], [-15.612970352172852], [-12.660606384277344], [-...\n",
       "30502          car_horn  [0, 1, 0, 0, 0]    7  [[[-14.313464164733887], [-12.228155136108398], [-15.787863731384277], [-16.082149505615234], [-12.465015411376953],...\n",
       "30503          car_horn  [0, 1, 0, 0, 0]    7  [[[-24.34674835205078], [-17.664506912231445], [-11.443778038024902], [-11.371871948242188], [-12.617921829223633], ...\n",
       "30504          car_horn  [0, 1, 0, 0, 0]    7  [[[-20.291765213012695], [-13.778326034545898], [-9.759299278259277], [-8.09199333190918], [-8.728732109069824], [-1...\n",
       "30505          car_horn  [0, 1, 0, 0, 0]    7  [[[-16.410991668701172], [-11.63617992401123], [-9.72879409790039], [-13.295160293579102], [-12.994491577148438], [-...\n",
       "\n",
       "[30506 rows x 4 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_from_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1150.62x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Analysis of the class balancing\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "gTitle = f'{nom_dataset} - Number of classes = ' + str(len(pd.Series(DB_from_pkl['Class_categorical']).unique()))\n",
    "g = sns.displot(DB_from_pkl,x='Class_categorical', hue='Class_categorical',height = 5, aspect = 2).set(title=gTitle)\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set_titles('Number of classes')\n",
    "\n",
    "# Retrieve the axes object from the plot\n",
    "axes = g.ax\n",
    "\n",
    "# Iterate over each bar in the plot\n",
    "for p in axes.patches:\n",
    "    # Get the coordinates of the bar\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    cord_x, cord_y = p.get_xy()\n",
    "    if height > 0:\n",
    "        axes.annotate(f'{height}', (cord_x + width/2, cord_y + height), ha='center')\n",
    "        \n",
    "g._legend.remove()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation fold: 1\n",
      "dbComplete_VAL size: 3010\n",
      "dbComplete_TRN size: 27496\n",
      "\n",
      "Validation fold: 10\n",
      "dbComplete_VAL size: 2933\n",
      "dbComplete_TRN size: 27573\n",
      "\n",
      "Validation fold: 2\n",
      "dbComplete_VAL size: 3003\n",
      "dbComplete_TRN size: 27503\n",
      "\n",
      "Validation fold: 3\n",
      "dbComplete_VAL size: 3374\n",
      "dbComplete_TRN size: 27132\n",
      "\n",
      "Validation fold: 4\n",
      "dbComplete_VAL size: 3773\n",
      "dbComplete_TRN size: 26733\n",
      "\n",
      "Validation fold: 5\n",
      "dbComplete_VAL size: 3276\n",
      "dbComplete_TRN size: 27230\n",
      "\n",
      "Validation fold: 6\n",
      "dbComplete_VAL size: 2800\n",
      "dbComplete_TRN size: 27706\n",
      "\n",
      "Validation fold: 7\n",
      "dbComplete_VAL size: 2835\n",
      "dbComplete_TRN size: 27671\n",
      "\n",
      "Validation fold: 8\n",
      "dbComplete_VAL size: 2730\n",
      "dbComplete_TRN size: 27776\n",
      "\n",
      "Validation fold: 9\n",
      "dbComplete_VAL size: 2772\n",
      "dbComplete_TRN size: 27734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold in np.unique(DB_from_pkl['Fold']):\n",
    "    print(f\"Validation fold: {fold}\")\n",
    "    \n",
    "    valsize = len(DB_from_pkl[DB_from_pkl['Fold'] == fold])\n",
    "    trnsize = len(DB_from_pkl[DB_from_pkl['Fold'] != fold])\n",
    "    print(f'dbComplete_VAL size: {valsize}')\n",
    "    print(f'dbComplete_TRN size: {trnsize}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set fold = '1' to train the model to be used in the ESR data preparation\n",
    "\n",
    "fold = '1'\n",
    "fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class_categorical    object\n",
       "Class_OHEV           object\n",
       "Fold                 object\n",
       "features             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_from_pkl.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB_from_pkl['Class_OHEV'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30506,)\n",
      "(5,)\n",
      "(180, 44, 1)\n"
     ]
    }
   ],
   "source": [
    "print(DB_from_pkl['Fold'].shape)\n",
    "print(DB_from_pkl['Class_OHEV'][0].shape)\n",
    "print(DB_from_pkl['features'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'numpy.int32'>\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(DB_from_pkl['Fold'][0][0]))\n",
    "print(type(DB_from_pkl['Class_OHEV'][0][0]))\n",
    "print(type(DB_from_pkl['features'][0][0][0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class_categorical       \n",
      "background         10508    [1, 0, 0, 0, 0]\n",
      "car_horn           26470    [0, 1, 0, 0, 0]\n",
      "children_playing   6670     [0, 0, 1, 0, 0]\n",
      "dog_bark           24002    [0, 0, 0, 1, 0]\n",
      "siren              18540    [0, 0, 0, 0, 1]\n",
      "Name: Class_OHEV, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'background': array([1, 0, 0, 0, 0]),\n",
       " 'car_horn': array([0, 1, 0, 0, 0]),\n",
       " 'children_playing': array([0, 0, 1, 0, 0]),\n",
       " 'dog_bark': array([0, 0, 0, 1, 0]),\n",
       " 'siren': array([0, 0, 0, 0, 1])}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by the class and get one random sample of each class\n",
    "k = DB_from_pkl.groupby('Class_categorical')['Class_OHEV'].apply(lambda s: s.sample(1))\n",
    "print(k)\n",
    "\n",
    "# Convert the pandas series into a dataframe\n",
    "temp_k_df = k.reset_index()\n",
    "\n",
    "# Delete the index from the grouppby result\n",
    "del temp_k_df['level_1']\n",
    "\n",
    "# Set the \"Class\" as the dataframe index\n",
    "temp_k_df.set_index(\"Class_categorical\", inplace=True)\n",
    "\n",
    "# Convert the dataframe to a dictionary (Class: Class_encoder)\n",
    "encoder_dict = temp_k_df[\"Class_OHEV\"].to_dict()\n",
    "encoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of classes in the dataset\n",
    "\n",
    "num_classes = len(encoder_dict.keys())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['background', 'car_horn', 'children_playing', 'dog_bark', 'siren']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name of the classes\n",
    "\n",
    "nom_classes = list(encoder_dict.keys())\n",
    "nom_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate 1 fold for validation and create a DB for the training / testing\n",
    "\n",
    "DB_from_pkl_VAL = DB_from_pkl[DB_from_pkl['Fold'] == fold].copy()\n",
    "DB_from_pkl_TRN = DB_from_pkl[DB_from_pkl['Fold'] != fold].copy()\n",
    "\n",
    "X      = DB_from_pkl_TRN['features'].to_numpy()\n",
    "y      = np.array(DB_from_pkl_TRN.Class_categorical.to_list())\n",
    "y_OHEV = np.array(DB_from_pkl_TRN.Class_OHEV.to_list())\n",
    "\n",
    "X_val      = DB_from_pkl_VAL['features'].to_numpy()\n",
    "y_val      = np.array(DB_from_pkl_VAL.Class_categorical.to_list())\n",
    "y_OHEV_val = np.array(DB_from_pkl_VAL.Class_OHEV.to_list())\n",
    "\n",
    "\n",
    "# Stackup and pass all values to float32\n",
    "X = np.stack(X)\n",
    "X = np.asarray(X).astype(np.float32)\n",
    "\n",
    "X_val = np.stack(X_val)\n",
    "X_val = np.asarray(X_val).astype(np.float32)\n",
    "\n",
    "y_OHEV     = np.asarray(y_OHEV).astype(np.float32)\n",
    "y_OHEV_val = np.asarray(y_OHEV_val).astype(np.float32)\n",
    "\n",
    "\n",
    "# Retrieve the indexes used for training the classifiers\n",
    "idx_trn = np.genfromtxt(os.path.join(path_models, '_idx_trn_' + nom_dataset + model_surname + '.csv'), delimiter=',', dtype = int)\n",
    "idx_tst = np.genfromtxt(os.path.join(path_models, '_idx_tst_' + nom_dataset + model_surname + '.csv'), delimiter=',', dtype = int)\n",
    "\n",
    "X_train      = X[idx_trn]\n",
    "X_test       = X[idx_tst]\n",
    "y_train      = y[idx_trn]\n",
    "y_test       = y[idx_tst]\n",
    "y_train_OHEV = y_OHEV[idx_trn]\n",
    "y_test_OHEV  = y_OHEV[idx_tst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5221, 26886, 26007, ...,  1207, 16801, 16613])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12980,  2697, 15451, ...,  5356, 21051, 12598])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (24746, 180, 44, 1)\n",
      "y_train.........: (24746,)\n",
      "y_train_OHEV....: (24746, 5)\n",
      "\n",
      "==================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2750, 180, 44, 1)\n",
      "y_test..........: (2750,)\n",
      "y_test_OHEV.....: (2750, 5)\n",
      "\n",
      "==================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (3010, 180, 44, 1)\n",
      "y_val...........: (3010,)\n",
      "y_OHEV_val......: (3010, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n==================================\")\n",
    "print(\"Training set\\n\")\n",
    "\n",
    "print(f'X_train.........: {np.shape(X_train)}')\n",
    "print(f'y_train.........: {np.shape(y_train)}')\n",
    "print(f'y_train_OHEV....: {np.shape(y_train_OHEV)}')\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Testing set\\n\")\n",
    "\n",
    "print(f'X_test..........: {np.shape(X_test)}')\n",
    "print(f'y_test..........: {np.shape(y_test)}')\n",
    "print(f'y_test_OHEV.....: {np.shape(y_test_OHEV)}')\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Validation set\\n\")\n",
    "\n",
    "print(f'X_val...........: {np.shape(X_val)}')\n",
    "print(f'y_val...........: {np.shape(y_val)}')\n",
    "print(f'y_OHEV_val......: {np.shape(y_OHEV_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple confusion matrix\n",
    "\n",
    "def simple_conf_matrix(y_true, y_pred, nom_classes, clf, acc):\n",
    "    \n",
    "    picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "    conf_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "    title = nom_dataset + model_surname + norm_type + ' - Classifier ' + clf + ' - Validation accuracy: '+ str(\"{:0.2f} %\".format(acc*100))\n",
    "\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sns.heatmap(conf_matrix, \n",
    "                annot=True, \n",
    "                fmt='g', \n",
    "                cmap=cmap_cm, \n",
    "                annot_kws={\"size\": 8}, \n",
    "                xticklabels=nom_classes, \n",
    "                yticklabels=nom_classes)\n",
    "    plt.title(title, fontsize = 12)\n",
    "    plt.savefig(os.path.join(path_pic, picture_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title, cmap, normalize):\n",
    "\n",
    "    if labels is not None:\n",
    "        tick_marks = np.arange(len(labels))\n",
    "        plt.xticks(tick_marks, labels, fontsize=10, rotation=45)\n",
    "        plt.yticks(tick_marks, labels, fontsize=10)\n",
    "   \n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 8)\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 8)\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title, fontsize=13)\n",
    "    plt.colorbar(shrink=1)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(None)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G41d4lWCSIXW"
   },
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Convolutional Neural Networks** (CNNs) are a class of deep learning algorithms specifically designed for processing grid-like data, such as images and videos. CNNs are highly effective in tasks related to computer vision, including image recognition, object detection, and image segmentation. They are characterized by their ability to automatically and adaptively learn spatial hierarchies of features from input data. CNNs consist of multiple layers, including convolutional layers, pooling layers, and fully connected layers. The convolutional layers apply convolution operations to the input data, enabling the network to automatically learn patterns and features from images, such as edges, textures, and more complex structures. The pooling layers downsample the spatial dimensions of the data, reducing computational complexity while retaining important features. Fully connected layers at the end of the network process the learned features and make predictions based on them. One of the significant advantages of CNNs is their ability to capture local patterns and spatial hierarchies of features. By using shared weights and biases in the convolutional layers, CNNs are capable of learning translation-invariant features, making them well-suited for tasks where the spatial arrangement of features in the input data is essential. Additionally, CNNs can automatically learn relevant features from raw pixel values, eliminating the need for manual feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 44, 1)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputShape = X_train[0].shape\n",
    "inputShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjU1o2LPQ8Qi"
   },
   "outputs": [],
   "source": [
    "# Architecture based on Su et al. (2019)\n",
    "\n",
    "def basemodel_Su(model_name):\n",
    "       \n",
    "    model = Sequential(name = model_name)\n",
    "    \n",
    "    # Input is 44 x 180\n",
    "    # If we have N x N image size and F x F filter size, afer the convolution the result will be\n",
    "    # (N x N) * (F x F) = (N - F + 1) x (N - F + 1)\n",
    "    # (44 - 7 + 1) x (180 - 7 + 1) = (38 x 174)\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(inputShape), padding='same', strides=(2,2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), strides=(2,2), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten(name='Flatten'))\n",
    "\n",
    "    model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    epochs  = 100\n",
    "    lrate   = 0.001\n",
    "    decay   = lrate/epochs\n",
    "    sgd     = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architecture based on Luz et al. (2021)\n",
    "\n",
    "def basemodel_Luz(model_name):\n",
    "       \n",
    "    model = Sequential(name = model_name)\n",
    "    \n",
    "    model.add(Conv2D(24, (5, 5), input_shape=(inputShape), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(48, (5, 5), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(48, (5, 5), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(48, (5, 5), padding='same', strides=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten(name='Flatten'))\n",
    "\n",
    "    model.add(Dense(64, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    epochs  = 100\n",
    "    lrate   = 0.001\n",
    "    decay   = lrate/epochs\n",
    "    sgd     = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-kw6vXfvbsx"
   },
   "outputs": [],
   "source": [
    "monitor = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=20, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "if not os.path.exists(path_models):\n",
    "    os.makedirs(path_models)\n",
    "\n",
    "filepath       = os.path.join(path_models, 'Model_CNN_2D_weights_0_best' + model_surname + '.hdf5')\n",
    "checkpoint     = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint, monitor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "lw99-PBBaMkh",
    "outputId": "ff226441-ccbe-4ee2-8392-728db38108c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1-) Architecture based on Su et al. (2019)\n",
      "2-) Architecture based on Luz et al. (2021)\n",
      "\n",
      "Select the model: 2\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 180, 44, 24)       624       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 180, 44, 24)       96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 90, 22, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 90, 22, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 90, 22, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 45, 11, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 45, 11, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 45, 11, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 22, 5, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 22, 5, 48)         57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 22, 5, 48)         192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 11, 2, 48)         0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 1056)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                67648     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 222,053\n",
      "Trainable params: 221,717\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Select the model\n",
    "\n",
    "opc = 0\n",
    "while str(opc) not in '12':\n",
    "    print()\n",
    "    print(\"1-) Architecture based on Su et al. (2019)\")\n",
    "    print(\"2-) Architecture based on Luz et al. (2021)\")\n",
    "\n",
    "    opc = input(\"\\nSelect the model: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "\n",
    "if opc == 1:\n",
    "    basemodel = basemodel_Su\n",
    "    surName = '_Su'\n",
    "\n",
    "elif opc == 2:\n",
    "    basemodel = basemodel_Luz\n",
    "    surName = '_Luz'\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n",
    "Model_CNN_2D = basemodel('Model_CNN_2D' + surName)\n",
    "print(Model_CNN_2D.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(Model_CNN_2D, to_file= os.path.join(path_models, 'Model_CNN_2D' + model_surname + '.png'), show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the column \"Param\":\n",
    "\n",
    "1. For `Conv1D` layer:\n",
    "   - The number of parameters for a `Conv1D` layer is calculated as `(kernel_size * input_channels + 1) * output_channels`, where `kernel_size` is the size of the convolutional kernel, `input_channels` is the number of input channels (1 in this case), and `output_channels` is the number of output channels.\n",
    "\n",
    "2. For `Dense` layer:\n",
    "   - The number of parameters for a `Dense` layer is calculated as `(input_units + 1) * output_units`, where `input_units` is the number of input units and `output_units` is the number of output units.\n",
    "   \n",
    "3. In the calculation of parameters for a convolutional layer, the term \"channels\" refers to the number of filters used in that layer.\n",
    "4. Params = (filter_height * filter_width * input_channels + 1) * number_of_filters\n",
    "\n",
    "\n",
    "- 624   parameters is the result of 24 filters * (5 kernels * 5 kernels * 1 channel + 1)\n",
    "- 28,848 parameters is the result of 48 filter * (5 kernels * 5 kernels * 24 channels + 1)\n",
    "- 57,648 parameters is the result of 48 filter * (5 kernels * 5 kernels * 48 channels + 1)\n",
    "- 57,648 parameters is the result of 48 filter * (5 kernels * 5 kernels * 48 channels + 1)\n",
    "- 67,648  parameters is the result of 64 neurons with 1,056 features + 64 bias values\n",
    "- 8,320  parameters is the result of 128 neurons with 64 features + 128 bias values\n",
    "- 645  parameters is the result of 5 neurons with 128 features + 5 bias values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cx0OsC7UNwui"
   },
   "source": [
    "### CNN 2D adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (24746, 180, 44, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (24746, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2750, 180, 44, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2750, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (3010, 180, 44, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (3010, 5) .............type: <class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n========================================================================\")\n",
    "print(\"Training set\\n\")\n",
    "\n",
    "print(f'X_train.........: {np.shape(X_train)} ...type: {type(X_train[0][0][0][0])}')\n",
    "print(f'y_train_OHEV....: {np.shape(y_train_OHEV)} ............type: {type(y_train_OHEV[0][0])}')\n",
    "\n",
    "print(\"\\n========================================================================\")\n",
    "print(\"Testing set\\n\")\n",
    "\n",
    "print(f'X_test..........: {np.shape(X_test)} ....type: {type(X_test[0][0][0][0])}')\n",
    "print(f'y_test_OHEV.....: {np.shape(y_test_OHEV)} .............type: {type(y_test_OHEV[0][0])}')\n",
    "\n",
    "print(\"\\n========================================================================\")\n",
    "print(\"Validation set\\n\")\n",
    "\n",
    "print(f'X_val...........: {np.shape(X_val)} ....type: {type(X_val[0][0][0][0])}')\n",
    "print(f'y_OHEV_val......: {np.shape(y_OHEV_val)} .............type: {type(y_OHEV_val[0][0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  2/774 [..............................] - ETA: 1:02 - loss: 2.5214 - accuracy: 0.2031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0519s vs `on_train_batch_end` time: 0.1098s). Check your callbacks.\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.9272 - accuracy: 0.6429\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79745, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 139s 179ms/step - loss: 0.9272 - accuracy: 0.6429 - val_loss: 0.5483 - val_accuracy: 0.7975\n",
      "Epoch 2/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.5667 - accuracy: 0.7952\n",
      "Epoch 00002: val_accuracy improved from 0.79745 to 0.86509, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 133s 171ms/step - loss: 0.5667 - accuracy: 0.7952 - val_loss: 0.3834 - val_accuracy: 0.8651\n",
      "Epoch 3/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.8448\n",
      "Epoch 00003: val_accuracy did not improve from 0.86509\n",
      "774/774 [==============================] - 132s 170ms/step - loss: 0.4319 - accuracy: 0.8448 - val_loss: 0.4159 - val_accuracy: 0.8484\n",
      "Epoch 4/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.3542 - accuracy: 0.8736\n",
      "Epoch 00004: val_accuracy improved from 0.86509 to 0.88400, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 133s 172ms/step - loss: 0.3542 - accuracy: 0.8736 - val_loss: 0.3152 - val_accuracy: 0.8840\n",
      "Epoch 5/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.2956 - accuracy: 0.8953\n",
      "Epoch 00005: val_accuracy did not improve from 0.88400\n",
      "774/774 [==============================] - 132s 170ms/step - loss: 0.2956 - accuracy: 0.8953 - val_loss: 0.4926 - val_accuracy: 0.8229\n",
      "Epoch 6/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.2617 - accuracy: 0.9100\n",
      "Epoch 00006: val_accuracy improved from 0.88400 to 0.91564, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 131s 170ms/step - loss: 0.2617 - accuracy: 0.9100 - val_loss: 0.2288 - val_accuracy: 0.9156\n",
      "Epoch 7/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.9211\n",
      "Epoch 00007: val_accuracy improved from 0.91564 to 0.93018, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 131s 170ms/step - loss: 0.2248 - accuracy: 0.9211 - val_loss: 0.1955 - val_accuracy: 0.9302\n",
      "Epoch 8/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.9353\n",
      "Epoch 00008: val_accuracy improved from 0.93018 to 0.93818, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 138s 178ms/step - loss: 0.1872 - accuracy: 0.9353 - val_loss: 0.1802 - val_accuracy: 0.9382\n",
      "Epoch 9/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.1625 - accuracy: 0.9430\n",
      "Epoch 00009: val_accuracy did not improve from 0.93818\n",
      "774/774 [==============================] - 136s 176ms/step - loss: 0.1625 - accuracy: 0.9430 - val_loss: 0.2139 - val_accuracy: 0.9313\n",
      "Epoch 10/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.9476\n",
      "Epoch 00010: val_accuracy improved from 0.93818 to 0.95236, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 132s 170ms/step - loss: 0.1482 - accuracy: 0.9476 - val_loss: 0.1364 - val_accuracy: 0.9524\n",
      "Epoch 11/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9527\n",
      "Epoch 00011: val_accuracy did not improve from 0.95236\n",
      "774/774 [==============================] - 132s 170ms/step - loss: 0.1342 - accuracy: 0.9527 - val_loss: 0.1636 - val_accuracy: 0.9422\n",
      "Epoch 12/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.9584\n",
      "Epoch 00012: val_accuracy did not improve from 0.95236\n",
      "774/774 [==============================] - 131s 170ms/step - loss: 0.1161 - accuracy: 0.9584 - val_loss: 0.1410 - val_accuracy: 0.9516\n",
      "Epoch 13/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9632\n",
      "Epoch 00013: val_accuracy did not improve from 0.95236\n",
      "774/774 [==============================] - 131s 169ms/step - loss: 0.1028 - accuracy: 0.9632 - val_loss: 0.2691 - val_accuracy: 0.9262\n",
      "Epoch 14/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.9654\n",
      "Epoch 00014: val_accuracy did not improve from 0.95236\n",
      "774/774 [==============================] - 129s 167ms/step - loss: 0.0976 - accuracy: 0.9654 - val_loss: 0.2160 - val_accuracy: 0.9316\n",
      "Epoch 15/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9736\n",
      "Epoch 00015: val_accuracy did not improve from 0.95236\n",
      "774/774 [==============================] - 129s 167ms/step - loss: 0.0767 - accuracy: 0.9736 - val_loss: 0.1623 - val_accuracy: 0.9487\n",
      "Epoch 16/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9735\n",
      "Epoch 00016: val_accuracy did not improve from 0.95236\n",
      "774/774 [==============================] - 129s 167ms/step - loss: 0.0745 - accuracy: 0.9735 - val_loss: 0.1578 - val_accuracy: 0.9498\n",
      "Epoch 17/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.9746\n",
      "Epoch 00017: val_accuracy improved from 0.95236 to 0.96073, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 129s 167ms/step - loss: 0.0727 - accuracy: 0.9746 - val_loss: 0.1354 - val_accuracy: 0.9607\n",
      "Epoch 18/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9796\n",
      "Epoch 00018: val_accuracy improved from 0.96073 to 0.96545, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 130s 168ms/step - loss: 0.0595 - accuracy: 0.9796 - val_loss: 0.1174 - val_accuracy: 0.9655\n",
      "Epoch 19/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9832\n",
      "Epoch 00019: val_accuracy did not improve from 0.96545\n",
      "774/774 [==============================] - 130s 168ms/step - loss: 0.0504 - accuracy: 0.9832 - val_loss: 0.1881 - val_accuracy: 0.9487\n",
      "Epoch 20/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.9827\n",
      "Epoch 00020: val_accuracy improved from 0.96545 to 0.97055, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 129s 167ms/step - loss: 0.0504 - accuracy: 0.9827 - val_loss: 0.1045 - val_accuracy: 0.9705\n",
      "Epoch 21/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9871\n",
      "Epoch 00021: val_accuracy did not improve from 0.97055\n",
      "774/774 [==============================] - 129s 167ms/step - loss: 0.0365 - accuracy: 0.9871 - val_loss: 0.1374 - val_accuracy: 0.9669\n",
      "Epoch 22/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.9874\n",
      "Epoch 00022: val_accuracy did not improve from 0.97055\n",
      "774/774 [==============================] - 129s 167ms/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 0.1135 - val_accuracy: 0.9705\n",
      "Epoch 23/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 0.9865\n",
      "Epoch 00023: val_accuracy did not improve from 0.97055\n",
      "774/774 [==============================] - 129s 167ms/step - loss: 0.0387 - accuracy: 0.9865 - val_loss: 0.1405 - val_accuracy: 0.9698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9871\n",
      "Epoch 00024: val_accuracy did not improve from 0.97055\n",
      "774/774 [==============================] - 128s 166ms/step - loss: 0.0404 - accuracy: 0.9871 - val_loss: 0.1063 - val_accuracy: 0.9698\n",
      "Epoch 25/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9903\n",
      "Epoch 00025: val_accuracy did not improve from 0.97055\n",
      "774/774 [==============================] - 129s 167ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 0.1501 - val_accuracy: 0.9644\n",
      "Epoch 26/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9897\n",
      "Epoch 00026: val_accuracy did not improve from 0.97055\n",
      "774/774 [==============================] - 129s 167ms/step - loss: 0.0312 - accuracy: 0.9897 - val_loss: 0.1409 - val_accuracy: 0.9665\n",
      "Epoch 27/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0260 - accuracy: 0.9919\n",
      "Epoch 00027: val_accuracy did not improve from 0.97055\n",
      "774/774 [==============================] - 128s 166ms/step - loss: 0.0260 - accuracy: 0.9919 - val_loss: 0.1121 - val_accuracy: 0.9702\n",
      "Epoch 28/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9885\n",
      "Epoch 00028: val_accuracy did not improve from 0.97055\n",
      "774/774 [==============================] - 128s 166ms/step - loss: 0.0342 - accuracy: 0.9885 - val_loss: 0.1730 - val_accuracy: 0.9589\n",
      "Epoch 29/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9908\n",
      "Epoch 00029: val_accuracy did not improve from 0.97055\n",
      "774/774 [==============================] - 129s 166ms/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.1584 - val_accuracy: 0.9633\n",
      "Epoch 30/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9924\n",
      "Epoch 00030: val_accuracy did not improve from 0.97055\n",
      "774/774 [==============================] - 129s 166ms/step - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.1311 - val_accuracy: 0.9687\n",
      "Epoch 31/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9928\n",
      "Epoch 00031: val_accuracy improved from 0.97055 to 0.97564, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 127s 164ms/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 0.1110 - val_accuracy: 0.9756\n",
      "Epoch 32/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9927\n",
      "Epoch 00032: val_accuracy did not improve from 0.97564\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.1353 - val_accuracy: 0.9698\n",
      "Epoch 33/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9939\n",
      "Epoch 00033: val_accuracy did not improve from 0.97564\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.1862 - val_accuracy: 0.9611\n",
      "Epoch 34/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9939\n",
      "Epoch 00034: val_accuracy did not improve from 0.97564\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.1327 - val_accuracy: 0.9705\n",
      "Epoch 35/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9946\n",
      "Epoch 00035: val_accuracy improved from 0.97564 to 0.97673, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.1241 - val_accuracy: 0.9767\n",
      "Epoch 36/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9928\n",
      "Epoch 00036: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.1397 - val_accuracy: 0.9709\n",
      "Epoch 37/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 0.9930\n",
      "Epoch 00037: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 0.1116 - val_accuracy: 0.9767\n",
      "Epoch 38/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9953\n",
      "Epoch 00038: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.1142 - val_accuracy: 0.9764\n",
      "Epoch 39/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9940\n",
      "Epoch 00039: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0165 - accuracy: 0.9940 - val_loss: 0.1344 - val_accuracy: 0.9731\n",
      "Epoch 40/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9956\n",
      "Epoch 00040: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.1369 - val_accuracy: 0.9727\n",
      "Epoch 41/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 00041: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.1272 - val_accuracy: 0.9735\n",
      "Epoch 42/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9955\n",
      "Epoch 00042: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.1231 - val_accuracy: 0.9745\n",
      "Epoch 43/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9961\n",
      "Epoch 00043: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.1289 - val_accuracy: 0.9753\n",
      "Epoch 44/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 0.9967\n",
      "Epoch 00044: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 127s 164ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.1482 - val_accuracy: 0.9745\n",
      "Epoch 45/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9966\n",
      "Epoch 00045: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 127s 164ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.1112 - val_accuracy: 0.9767\n",
      "Epoch 46/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9964\n",
      "Epoch 00046: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.1355 - val_accuracy: 0.9749\n",
      "Epoch 47/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9973\n",
      "Epoch 00047: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0081 - accuracy: 0.9973 - val_loss: 0.1367 - val_accuracy: 0.9753\n",
      "Epoch 48/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9973\n",
      "Epoch 00048: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.1698 - val_accuracy: 0.9698\n",
      "Epoch 49/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9969\n",
      "Epoch 00049: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.1691 - val_accuracy: 0.9731\n",
      "Epoch 50/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9962\n",
      "Epoch 00050: val_accuracy did not improve from 0.97673\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.1327 - val_accuracy: 0.9753\n",
      "Epoch 51/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9978\n",
      "Epoch 00051: val_accuracy improved from 0.97673 to 0.97891, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.1186 - val_accuracy: 0.9789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 00052: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.1361 - val_accuracy: 0.9767\n",
      "Epoch 53/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9979\n",
      "Epoch 00053: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 0.1513 - val_accuracy: 0.9749\n",
      "Epoch 54/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 00054: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.1367 - val_accuracy: 0.9782\n",
      "Epoch 55/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9991\n",
      "Epoch 00055: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0041 - accuracy: 0.9991 - val_loss: 0.1437 - val_accuracy: 0.9764\n",
      "Epoch 56/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9980\n",
      "Epoch 00056: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0056 - accuracy: 0.9980 - val_loss: 0.1501 - val_accuracy: 0.9767\n",
      "Epoch 57/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9973\n",
      "Epoch 00057: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.1622 - val_accuracy: 0.9731\n",
      "Epoch 58/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9977\n",
      "Epoch 00058: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0082 - accuracy: 0.9977 - val_loss: 0.1323 - val_accuracy: 0.9767\n",
      "Epoch 59/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9977\n",
      "Epoch 00059: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.1667 - val_accuracy: 0.9738\n",
      "Epoch 60/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 00060: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.1408 - val_accuracy: 0.9738\n",
      "Epoch 61/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9983\n",
      "Epoch 00061: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.1339 - val_accuracy: 0.9738\n",
      "Epoch 62/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9988\n",
      "Epoch 00062: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 162ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.1434 - val_accuracy: 0.9767\n",
      "Epoch 63/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9980\n",
      "Epoch 00063: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1345 - val_accuracy: 0.9775\n",
      "Epoch 64/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 00064: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1355 - val_accuracy: 0.9782\n",
      "Epoch 65/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9981\n",
      "Epoch 00065: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.1340 - val_accuracy: 0.9767\n",
      "Epoch 66/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9977\n",
      "Epoch 00066: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0064 - accuracy: 0.9977 - val_loss: 0.1424 - val_accuracy: 0.9771\n",
      "Epoch 67/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 00067: val_accuracy did not improve from 0.97891\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.1435 - val_accuracy: 0.9778\n",
      "Epoch 68/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 00068: val_accuracy improved from 0.97891 to 0.98109, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.1261 - val_accuracy: 0.9811\n",
      "Epoch 69/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 00069: val_accuracy did not improve from 0.98109\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.1116 - val_accuracy: 0.9793\n",
      "Epoch 70/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 00070: val_accuracy did not improve from 0.98109\n",
      "774/774 [==============================] - 127s 164ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.1362 - val_accuracy: 0.9775\n",
      "Epoch 71/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n",
      "Epoch 00071: val_accuracy did not improve from 0.98109\n",
      "774/774 [==============================] - 127s 165ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.1300 - val_accuracy: 0.9782\n",
      "Epoch 72/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 00072: val_accuracy did not improve from 0.98109\n",
      "774/774 [==============================] - 127s 164ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1164 - val_accuracy: 0.9796\n",
      "Epoch 73/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n",
      "Epoch 00073: val_accuracy did not improve from 0.98109\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.1199 - val_accuracy: 0.9775\n",
      "Epoch 74/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 00074: val_accuracy did not improve from 0.98109\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1398 - val_accuracy: 0.9735\n",
      "Epoch 75/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 00075: val_accuracy did not improve from 0.98109\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1760 - val_accuracy: 0.9738\n",
      "Epoch 76/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 00076: val_accuracy did not improve from 0.98109\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1440 - val_accuracy: 0.9775\n",
      "Epoch 77/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00077: val_accuracy improved from 0.98109 to 0.98145, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_weights_0_best_windowed.hdf5\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.1285 - val_accuracy: 0.9815\n",
      "Epoch 78/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 00078: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1350 - val_accuracy: 0.9815\n",
      "Epoch 79/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9989\n",
      "Epoch 00079: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.1386 - val_accuracy: 0.9807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 00080: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1419 - val_accuracy: 0.9796\n",
      "Epoch 81/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 00081: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.1659 - val_accuracy: 0.9745\n",
      "Epoch 82/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 00082: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 127s 164ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1341 - val_accuracy: 0.9775\n",
      "Epoch 83/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 00083: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.1325 - val_accuracy: 0.9785\n",
      "Epoch 84/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 00084: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1356 - val_accuracy: 0.9800\n",
      "Epoch 85/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 00085: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 127s 164ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.2216 - val_accuracy: 0.9680\n",
      "Epoch 86/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 00086: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1605 - val_accuracy: 0.9749\n",
      "Epoch 87/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991\n",
      "Epoch 00087: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.1847 - val_accuracy: 0.9753\n",
      "Epoch 88/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9983\n",
      "Epoch 00088: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.1753 - val_accuracy: 0.9745\n",
      "Epoch 89/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 00089: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.1317 - val_accuracy: 0.9793\n",
      "Epoch 90/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 00090: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.1489 - val_accuracy: 0.9778\n",
      "Epoch 91/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00091: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.1753 - val_accuracy: 0.9764\n",
      "Epoch 92/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 00092: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.1551 - val_accuracy: 0.9782\n",
      "Epoch 93/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 00093: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.1655 - val_accuracy: 0.9771\n",
      "Epoch 94/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 00094: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1498 - val_accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 00095: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 126s 163ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.1432 - val_accuracy: 0.9785\n",
      "Epoch 96/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 00096: val_accuracy did not improve from 0.98145\n",
      "774/774 [==============================] - 127s 164ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.1582 - val_accuracy: 0.9793\n",
      "Epoch 97/100\n",
      "774/774 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 00097: val_accuracy did not improve from 0.98145\n",
      "Restoring model weights from the end of the best epoch.\n",
      "774/774 [==============================] - 127s 164ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.1502 - val_accuracy: 0.9785\n",
      "Epoch 00097: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs     = 100\n",
    "history    = Model_CNN_2D.fit(X_train, y_train_OHEV,\n",
    "                              batch_size      = batch_size,\n",
    "                              epochs          = epochs,\n",
    "                              verbose         = 1,\n",
    "                              validation_data = (X_test, y_test_OHEV),\n",
    "                              steps_per_epoch=int(np.ceil(X_train.shape[0] / float(batch_size))),\n",
    "                              callbacks       = callbacks_list,\n",
    "                              use_multiprocessing = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 4s 44ms/step - loss: 1.6384 - accuracy: 0.8299\n",
      "Test loss: 1.6384164094924927\n",
      "Test accuracy: 0.829900324344635\n"
     ]
    }
   ],
   "source": [
    "score_CNN_2D = Model_CNN_2D.evaluate(X_val, y_OHEV_val, verbose=1, batch_size = batch_size)\n",
    "print('Test loss:', score_CNN_2D[0])\n",
    "print('Test accuracy:', score_CNN_2D[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "fig.suptitle('CNN 2D - Training / Validation loss and accuracy')\n",
    "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)\n",
    "fig.tight_layout()\n",
    "plt.savefig(os.path.join(path_pic, picture_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and architecture to single file (not the best model though)\n",
    "\n",
    "# Model_CNN_2D.save(path_models + \"Model_CNN_2D.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_CNN_2d = np.argmax(Model_CNN_2D.predict(X_val),axis=1)\n",
    "y_pred_CNN_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_enc = np.argmax(y_OHEV_val, axis=1)\n",
    "y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.829900324344635"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_CNN_2D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.79      0.80      0.79       756\n",
      "        car_horn       0.95      0.82      0.88       252\n",
      "children_playing       0.75      0.87      0.81       700\n",
      "        dog_bark       0.85      0.85      0.85       700\n",
      "           siren       0.93      0.81      0.87       602\n",
      "\n",
      "        accuracy                           0.83      3010\n",
      "       macro avg       0.86      0.83      0.84      3010\n",
      "    weighted avg       0.84      0.83      0.83      3010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_set_CNN_2D = classification_report(y_test_enc, y_pred_CNN_2d, target_names=nom_classes)\n",
    "print(metrics_set_CNN_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 180, 44, 24)       624       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 180, 44, 24)       96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 90, 22, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 90, 22, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 90, 22, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 45, 11, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 45, 11, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 45, 11, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 22, 5, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 22, 5, 48)         57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 22, 5, 48)         192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 11, 2, 48)         0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 1056)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                67648     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 222,053\n",
      "Trainable params: 221,717\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the model with the highest accuracy\n",
    "# This model will be used in the notebook 10_ESR_data_preparation.ipynb\n",
    "\n",
    "# Architecture based on Luz et al. (2021)\n",
    "\n",
    "Model_CNN_2D_saved = load_model(os.path.join(path_models, 'Model_CNN_2D_weights_0_best' + model_surname + '.hdf5'))\n",
    "Model_CNN_2D_saved.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 4s 41ms/step - loss: 1.6384 - accuracy: 0.8299\n",
      "Test loss: 1.6384164094924927\n",
      "Test accuracy: 0.829900324344635\n"
     ]
    }
   ],
   "source": [
    "score_CNN_2D_saved = Model_CNN_2D_saved.evaluate(X_val, y_OHEV_val, verbose=1, batch_size = batch_size)\n",
    "print('Test loss:', score_CNN_2D_saved[0])\n",
    "print('Test accuracy:', score_CNN_2D_saved[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_CNN_2D_saved = np.argmax(Model_CNN_2D_saved.predict(X_val),axis=1)\n",
    "y_pred_CNN_2D_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "prob = np.round(Model_CNN_2D_saved.predict(X_val)[7],6)\n",
    "for i in prob:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.79      0.80      0.79       756\n",
      "        car_horn       0.95      0.82      0.88       252\n",
      "children_playing       0.75      0.87      0.81       700\n",
      "        dog_bark       0.85      0.85      0.85       700\n",
      "           siren       0.93      0.81      0.87       602\n",
      "\n",
      "        accuracy                           0.83      3010\n",
      "       macro avg       0.86      0.83      0.84      3010\n",
      "    weighted avg       0.84      0.83      0.83      3010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_set_CNN_2D_saved = classification_report(y_test_enc, y_pred_CNN_2D_saved, target_names=nom_classes)\n",
    "print(metrics_set_CNN_2D_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simple confusion matrix\n",
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "conf_matrix = metrics.confusion_matrix(y_test_enc, y_pred_CNN_2D_saved)\n",
    "title = nom_dataset + model_surname + ' - Classifier CNN 2D (best model) - Highest accuracy test: '+ str(\"{:0.2f}%\".format(score_CNN_2D_saved[1]*100))\n",
    "\n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(conf_matrix, \n",
    "            annot=True, \n",
    "            fmt='g', \n",
    "            cmap=cmap_cm, \n",
    "            annot_kws={\"size\": 8}, \n",
    "            xticklabels=nom_classes, \n",
    "            yticklabels=nom_classes)\n",
    "plt.title(title, fontsize = 12)\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x1f7c94d2dc0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1f7c94d2e20>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1f7c94da190>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1f7c94d2bb0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1f7d64e7340>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1f7c94d2a60>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1f7c715eee0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1f7c99a7be0>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1f7c9999d30>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x1f7c71e9fa0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x1f7c9999430>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x1f7c950eb20>,\n",
       " <tensorflow.python.keras.layers.core.Flatten at 0x1f7c951b910>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1f7c94efa30>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x1f7c95221c0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1f7c95325b0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1f7c9532790>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_CNN_2D_saved.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[[-8.94407928e-02,  4.85165864e-02,  9.37449653e-03,\n",
      "           2.59830821e-02, -1.69833362e-01, -7.90265724e-02,\n",
      "           3.54951073e-04,  1.68912753e-01, -1.58002786e-02,\n",
      "          -5.21692149e-02,  1.79596767e-01,  3.96305732e-02,\n",
      "           7.06855506e-02, -1.02945920e-02, -5.58533110e-02,\n",
      "          -3.11651945e-01,  2.74355430e-02,  7.35694766e-02,\n",
      "           8.32746923e-02, -1.65471900e-02,  9.78809670e-02,\n",
      "          -8.47885665e-03, -1.34837300e-01, -7.05119744e-02]],\n",
      "\n",
      "        [[ 3.23499814e-02, -1.14941155e-03,  8.22606534e-02,\n",
      "          -3.38686854e-02, -8.02912489e-02, -5.45309186e-02,\n",
      "           1.94970854e-02,  2.62895375e-01,  1.34725884e-01,\n",
      "           1.08515315e-01,  2.22600251e-01,  3.86003666e-02,\n",
      "           1.09981477e-01,  8.98171961e-02, -5.66624887e-02,\n",
      "           2.27877516e-02,  3.28382626e-02, -9.43799620e-04,\n",
      "          -4.84756660e-03,  1.03688136e-01,  1.76393673e-01,\n",
      "           1.21165484e-01, -1.27021432e-01, -4.78365384e-02]],\n",
      "\n",
      "        [[-1.12325428e-02,  9.17281359e-02,  1.15120403e-01,\n",
      "          -2.87743565e-02, -1.09933140e-02,  9.79536399e-03,\n",
      "          -4.68021967e-02,  2.51267672e-01, -1.29678240e-02,\n",
      "           1.28286585e-01,  2.85007387e-01,  2.92751521e-01,\n",
      "           3.67018022e-02,  7.94881582e-02, -1.45739332e-01,\n",
      "           3.13628018e-01,  3.82885411e-02, -1.38630979e-02,\n",
      "           1.24288043e-02,  4.77315560e-02,  3.64308357e-01,\n",
      "           1.10726006e-01, -6.02193289e-02, -2.21101698e-02]],\n",
      "\n",
      "        [[ 3.94163169e-02, -5.44248074e-02,  9.30299088e-02,\n",
      "          -3.18795554e-02, -2.51746532e-02, -4.77273650e-02,\n",
      "          -3.22611518e-02,  2.60206074e-01, -9.23813730e-02,\n",
      "           4.36272882e-02,  3.02895516e-01,  2.25524202e-01,\n",
      "          -1.66126434e-02,  1.75455045e-02, -1.77005321e-01,\n",
      "           2.33858138e-01,  2.36798655e-02,  4.19998690e-02,\n",
      "          -9.69195273e-03,  1.24114044e-01,  3.05726975e-01,\n",
      "          -3.60629074e-02, -1.54908076e-01, -6.15773350e-02]],\n",
      "\n",
      "        [[ 6.72696903e-02, -6.72188029e-03,  1.11448124e-01,\n",
      "           2.11827364e-02,  2.09303260e-01,  4.05919291e-02,\n",
      "          -4.90412861e-02,  2.49930680e-01, -7.17660785e-02,\n",
      "           8.98343921e-02,  2.00829521e-01,  9.27689895e-02,\n",
      "           1.22982182e-01,  6.26693070e-02, -2.60667533e-01,\n",
      "          -2.42164340e-02,  4.47097830e-02,  1.16856538e-01,\n",
      "          -5.70080942e-04,  4.54166941e-02,  8.50905403e-02,\n",
      "           1.96101665e-02, -8.21595713e-02,  1.34148508e-01]]],\n",
      "\n",
      "\n",
      "       [[[-5.33040278e-02,  1.65952910e-02, -4.54544015e-02,\n",
      "          -4.62592654e-02, -1.43408850e-01,  6.08151145e-02,\n",
      "           2.85945321e-03, -3.90036374e-01,  1.01926059e-01,\n",
      "          -6.68825805e-02,  1.49350792e-01, -1.83029547e-01,\n",
      "           1.17752858e-01,  9.86504182e-02,  1.39180422e-01,\n",
      "          -1.73893914e-01, -5.36380857e-02,  7.36927167e-02,\n",
      "           2.84404755e-02,  3.92423011e-03, -2.97035612e-02,\n",
      "          -5.11702932e-02,  2.33681370e-02, -4.65071760e-02]],\n",
      "\n",
      "        [[-1.17376357e-01,  8.94702673e-02,  1.41454443e-01,\n",
      "          -8.58379230e-02, -5.22253616e-03, -1.32531106e-01,\n",
      "          -1.03289708e-01, -3.26229721e-01, -4.05120477e-02,\n",
      "           6.85517564e-02,  1.27901658e-01, -1.21862389e-01,\n",
      "           5.94430789e-03,  1.17506728e-01,  6.03558980e-02,\n",
      "          -1.32476211e-01, -1.35733085e-02,  3.93209681e-02,\n",
      "           6.14932887e-02, -9.53500569e-02,  1.73477486e-01,\n",
      "           1.14781121e-02, -4.28068489e-02, -6.74213320e-02]],\n",
      "\n",
      "        [[-3.53857167e-02,  6.31282479e-02,  9.47302505e-02,\n",
      "          -9.81878862e-02, -1.63041968e-02, -1.46018967e-01,\n",
      "          -8.63435715e-02, -2.43517607e-01, -1.34268701e-01,\n",
      "          -2.79147681e-02,  1.51792198e-01, -2.47988738e-02,\n",
      "           1.06656954e-01,  2.00569883e-01,  4.70646694e-02,\n",
      "           2.84154534e-01,  8.13224819e-03,  1.07866175e-01,\n",
      "           4.28903177e-02, -6.71124980e-02,  2.15763047e-01,\n",
      "          -1.52599573e-01, -2.11119987e-02, -4.68801148e-02]],\n",
      "\n",
      "        [[-4.32451814e-02,  7.92649239e-02,  9.89490002e-02,\n",
      "          -8.88994038e-02,  1.32674634e-01, -5.73199205e-02,\n",
      "          -1.00499606e-02, -2.76899040e-01,  5.61534353e-02,\n",
      "           6.71244860e-02,  3.70793119e-02,  1.27467692e-01,\n",
      "          -9.76903588e-02,  1.98677048e-01, -1.36326671e-01,\n",
      "           2.43662804e-01,  2.94731674e-03,  9.69376639e-02,\n",
      "          -2.88990829e-02,  4.04480435e-02,  1.48890004e-01,\n",
      "           9.48324893e-03, -3.70911807e-02,  7.57358074e-02]],\n",
      "\n",
      "        [[ 6.47079665e-03, -4.78980364e-03,  7.96221048e-02,\n",
      "          -1.06850654e-01,  2.28586510e-01, -1.91349629e-02,\n",
      "          -6.31579161e-02, -3.90610069e-01,  6.61054552e-02,\n",
      "          -1.36607707e-01,  1.08969979e-01,  1.61976084e-01,\n",
      "          -1.85179431e-02,  1.88782737e-01, -1.49648085e-01,\n",
      "           8.92674029e-02,  3.01798265e-02,  3.66043411e-02,\n",
      "           1.08999453e-01, -7.20735565e-02, -4.51723747e-02,\n",
      "          -1.34965368e-02, -6.81130867e-03,  8.53001103e-02]]],\n",
      "\n",
      "\n",
      "       [[[-9.47589129e-02,  4.30644304e-02, -2.95059502e-01,\n",
      "          -1.08637027e-01, -1.44979954e-01, -5.92984678e-03,\n",
      "           4.64502200e-02, -3.86659615e-02, -1.25901446e-01,\n",
      "          -3.00970394e-02,  2.40637381e-02, -6.56219423e-02,\n",
      "          -1.06428459e-01, -5.66998795e-02,  6.71485886e-02,\n",
      "          -2.15043977e-01, -1.09342590e-01,  1.33831665e-01,\n",
      "           2.42184885e-02, -6.35474222e-03,  2.28751332e-01,\n",
      "          -2.11311758e-01,  1.53906405e-01,  1.20595068e-01]],\n",
      "\n",
      "        [[ 1.20644923e-03,  3.30629200e-02, -1.92138046e-01,\n",
      "          -1.85896918e-01,  3.87269482e-02, -6.20412175e-04,\n",
      "          -4.07602973e-02, -8.47996548e-02, -1.12423770e-01,\n",
      "           1.13707051e-01, -2.51087248e-02, -2.23854661e-01,\n",
      "           6.63053468e-02,  1.05788447e-01,  1.47409201e-01,\n",
      "          -1.28919333e-01, -3.58271822e-02, -1.44440085e-02,\n",
      "          -1.46868927e-02,  7.89596606e-03,  1.37787789e-01,\n",
      "          -1.88770637e-01, -3.05015929e-02,  1.82900220e-01]],\n",
      "\n",
      "        [[-8.46567079e-02,  9.08700749e-02, -2.31280401e-01,\n",
      "          -1.19662412e-01,  1.28418431e-01,  3.02003119e-02,\n",
      "          -1.09940633e-01, -8.26876536e-02,  1.35725945e-01,\n",
      "           1.78201050e-01, -4.17986102e-02, -2.06871539e-01,\n",
      "           3.37914154e-02,  1.09805912e-01,  7.89193809e-02,\n",
      "          -1.64329186e-02, -5.18841259e-02, -3.95197421e-03,\n",
      "           1.29323661e-01, -6.51761889e-02,  2.96471924e-01,\n",
      "          -1.87419608e-01,  1.60734765e-02,  1.69685051e-01]],\n",
      "\n",
      "        [[-1.08260497e-01,  9.18007046e-02, -1.42222762e-01,\n",
      "          -1.11595774e-03,  1.71490848e-01, -1.14476353e-01,\n",
      "          -1.19588286e-01, -6.42020628e-02,  2.02857152e-01,\n",
      "           2.03590542e-02,  9.31070186e-03, -1.14825025e-01,\n",
      "          -9.97302979e-02,  4.67283791e-03, -4.02117632e-02,\n",
      "           1.10471107e-01, -7.29556009e-02,  6.85883388e-02,\n",
      "           9.26521048e-02, -4.14252877e-02,  1.90669343e-01,\n",
      "          -2.17432633e-01,  8.26150253e-02,  4.28501479e-02]],\n",
      "\n",
      "        [[-7.37576932e-02,  3.75570282e-02, -2.95238435e-01,\n",
      "          -3.14027667e-02,  1.85175478e-01,  8.74123909e-03,\n",
      "          -7.59161683e-03, -6.83539584e-02,  4.01935689e-02,\n",
      "           4.26999442e-02,  1.96017902e-02,  2.03644961e-01,\n",
      "           2.83623077e-02,  2.81578619e-02, -9.36172009e-02,\n",
      "          -1.15955062e-01, -8.27257931e-02,  9.41415429e-02,\n",
      "          -8.45463574e-03,  4.31124456e-02,  1.97012663e-01,\n",
      "          -6.01266399e-02, -1.65004060e-02,  1.98393129e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 3.53784487e-03,  4.03259024e-02,  3.13225806e-01,\n",
      "          -4.09922935e-02, -1.27352178e-01,  1.26263797e-01,\n",
      "          -8.21431726e-02,  3.56310636e-01, -5.90736158e-02,\n",
      "          -1.44616589e-01, -9.77044925e-02,  4.76685874e-02,\n",
      "           9.48311910e-02, -1.59100682e-01,  4.89091314e-02,\n",
      "          -1.32493362e-01,  6.62574545e-02,  5.10287508e-02,\n",
      "          -1.49956737e-02,  1.08725101e-01, -1.14988446e-01,\n",
      "          -3.18193026e-02,  1.19896315e-01,  1.38245881e-01]],\n",
      "\n",
      "        [[-6.48966879e-02,  7.10156336e-02,  3.86716515e-01,\n",
      "          -7.78548270e-02, -9.88178775e-02,  1.26237914e-01,\n",
      "          -8.59606117e-02,  3.28156501e-01,  8.97992030e-02,\n",
      "          -9.13014263e-03, -1.55815527e-01,  9.14510265e-02,\n",
      "           8.51951465e-02, -1.52369663e-01,  8.37526023e-02,\n",
      "          -2.20922362e-02, -8.25606212e-02,  2.52456684e-02,\n",
      "           9.92401615e-02,  1.94413245e-01, -7.32090026e-02,\n",
      "           2.09931694e-02,  1.44479290e-01,  7.89986253e-02]],\n",
      "\n",
      "        [[-2.07892600e-02,  1.49566326e-02,  4.00847137e-01,\n",
      "           5.28124832e-02,  4.96915393e-02,  1.19241975e-01,\n",
      "          -2.17237771e-02,  4.09293979e-01,  1.65117502e-01,\n",
      "          -7.15450896e-03, -2.16848776e-01,  1.08723007e-02,\n",
      "           9.31497067e-02,  2.77019758e-03,  6.74652234e-02,\n",
      "          -1.12339929e-01, -1.01893865e-01,  4.41242196e-02,\n",
      "           1.09809756e-01,  1.16733119e-01, -2.43504390e-01,\n",
      "           1.81886647e-02,  1.76997349e-01,  1.82747811e-01]],\n",
      "\n",
      "        [[ 2.89092101e-02,  5.46197817e-02,  2.97793299e-01,\n",
      "          -3.47787663e-02,  1.55785352e-01,  8.81647468e-02,\n",
      "          -3.83832902e-02,  3.80985141e-01,  1.46686986e-01,\n",
      "          -7.03868046e-02, -2.92796016e-01, -1.79041058e-01,\n",
      "          -7.76248276e-02,  6.80735195e-03, -1.02933764e-01,\n",
      "           3.19626625e-03, -7.00835362e-02, -5.62116094e-02,\n",
      "           1.15410961e-01,  1.16226874e-01, -2.65468210e-01,\n",
      "          -2.95899697e-02,  1.36746183e-01,  3.00079677e-02]],\n",
      "\n",
      "        [[-4.47773188e-02,  5.65224141e-02,  3.06401759e-01,\n",
      "           6.24033101e-02,  7.06206784e-02, -1.05610406e-02,\n",
      "          -1.60783157e-02,  4.02190179e-01,  1.11855291e-01,\n",
      "          -6.77475333e-02, -2.37760663e-01,  3.46521363e-02,\n",
      "          -6.07471131e-02, -1.43638834e-01, -2.28820904e-03,\n",
      "          -1.92044917e-02, -5.29973954e-02,  8.50646049e-02,\n",
      "           8.28075260e-02,  1.41645104e-01, -9.54425931e-02,\n",
      "          -4.08185124e-02, -3.29407454e-02, -1.57758668e-01]]],\n",
      "\n",
      "\n",
      "       [[[ 3.14094834e-02,  3.36900763e-02, -3.58121514e-01,\n",
      "           1.20044366e-01,  5.86398728e-02,  1.13186277e-02,\n",
      "           1.02244029e-02, -2.74459898e-01,  6.51798099e-02,\n",
      "           3.15793566e-02, -5.58393300e-02,  1.44815907e-01,\n",
      "           3.28285657e-02, -1.21534765e-01,  1.53571397e-01,\n",
      "           1.32569596e-01, -2.16542520e-02,  5.71732409e-02,\n",
      "          -1.69037040e-02, -9.17502642e-02, -3.46094906e-01,\n",
      "           8.68164822e-02,  2.76642200e-02,  7.75010660e-02]],\n",
      "\n",
      "        [[ 5.20499758e-02,  3.59164574e-03, -1.55249909e-01,\n",
      "           8.20145905e-02, -8.29126388e-02,  4.93781641e-02,\n",
      "           1.09388651e-02, -1.94151402e-01,  3.38278823e-02,\n",
      "           1.34046823e-01, -1.71542704e-01,  1.54095098e-01,\n",
      "          -1.27404220e-02, -1.27938777e-01,  7.60142952e-02,\n",
      "           6.23688288e-02, -2.15160679e-02, -6.05924539e-02,\n",
      "          -4.53235917e-02,  6.41355738e-02, -4.13647503e-01,\n",
      "           1.96549118e-01,  1.24251790e-01, -4.80538718e-02]],\n",
      "\n",
      "        [[ 9.47488844e-02,  6.18864894e-02, -1.56961694e-01,\n",
      "           1.22288547e-01, -3.90052199e-02,  1.78464681e-01,\n",
      "          -5.98581433e-02, -2.32446745e-01,  8.02682787e-02,\n",
      "           1.30030423e-01, -1.95909470e-01,  8.93027335e-02,\n",
      "           1.27649203e-01, -3.13003082e-03,  6.11507595e-02,\n",
      "           1.18145086e-01,  3.45014967e-03, -2.08636909e-03,\n",
      "          -2.74210256e-02, -2.76658591e-03, -3.73282045e-01,\n",
      "           1.68683037e-01,  1.32964790e-01, -1.30671039e-01]],\n",
      "\n",
      "        [[ 7.17420429e-02,  3.48852761e-02, -1.62645251e-01,\n",
      "           1.39265969e-01, -7.31771514e-02,  1.82021648e-01,\n",
      "          -6.96341470e-02, -2.32825518e-01, -5.35082519e-02,\n",
      "           1.03946678e-01, -2.49123290e-01, -6.04015365e-02,\n",
      "           9.53581650e-03, -5.05603403e-02,  1.53761934e-02,\n",
      "          -5.68110831e-02,  1.97844002e-02, -2.76058111e-02,\n",
      "           1.12978101e-01,  7.53498152e-02, -3.74510914e-01,\n",
      "           1.36386618e-01, -7.14115128e-02,  1.94561519e-02]],\n",
      "\n",
      "        [[ 2.72230916e-02,  6.56954497e-02, -1.55842483e-01,\n",
      "           1.90751359e-01, -1.54738396e-01,  1.11701205e-01,\n",
      "           7.65693262e-02, -2.23427430e-01, -6.75039589e-02,\n",
      "           5.24811866e-03, -1.83855549e-01, -1.19856454e-01,\n",
      "           6.70517087e-02,  3.80725414e-02,  9.27421078e-02,\n",
      "          -6.15039840e-03,  4.12837975e-02,  5.12855593e-03,\n",
      "           8.28149840e-02,  1.47192059e-02, -3.27847809e-01,\n",
      "           2.62452006e-01, -5.66316359e-02, -1.26718774e-01]]]],\n",
      "      dtype=float32), array([-0.00677756, -0.02611751,  0.05706298,  0.00111842,  0.01139077,\n",
      "       -0.01112836, -0.01241499, -0.00318269, -0.1182639 ,  0.02018045,\n",
      "        0.01349617, -0.15722121,  0.24813458,  0.05071792,  0.0328858 ,\n",
      "       -0.00300123, -0.00559439, -0.03134774, -0.01654912,  0.14974983,\n",
      "        0.08447889,  0.01050356,  0.02486676, -0.00227589], dtype=float32)]\n",
      "[array([0.7875837 , 0.9550443 , 1.0596073 , 0.88528085, 1.0416274 ,\n",
      "       0.99019974, 0.76898843, 1.214312  , 0.9783833 , 0.96961707,\n",
      "       1.0836525 , 1.0219669 , 0.9771755 , 0.94848657, 0.97315836,\n",
      "       1.1214706 , 0.7629121 , 0.95528346, 0.95019686, 0.9712638 ,\n",
      "       1.3597817 , 0.983907  , 1.0352235 , 0.9788607 ], dtype=float32), array([-0.01831563, -0.03338549, -0.02046181,  0.0612915 ,  0.02177497,\n",
      "        0.07229616, -0.07214963,  0.10259314,  0.08193108,  0.04016002,\n",
      "        0.01494503,  0.07610366, -0.04764641,  0.10882876,  0.09703355,\n",
      "        0.12825647,  0.04534897,  0.06464835,  0.05631293,  0.01913227,\n",
      "        0.06331653,  0.06057374,  0.16311729,  0.1255264 ], dtype=float32), array([2.9640133 , 0.30600193, 0.6184881 , 2.6746418 , 0.62034357,\n",
      "       0.5345988 , 6.495853  , 1.7458668 , 0.23532477, 0.2442561 ,\n",
      "       2.8472524 , 0.30327678, 0.3440296 , 0.48660964, 1.6219286 ,\n",
      "       0.5892188 , 3.3027675 , 0.27686447, 0.30634743, 0.33142632,\n",
      "       3.1145556 , 1.2864639 , 0.7172349 , 0.3015347 ], dtype=float32), array([ 33.993977  ,   1.779651  ,   5.356039  ,  38.484306  ,\n",
      "         5.7843175 ,   6.46612   , 146.65767   ,  24.524342  ,\n",
      "         1.03972   ,   0.8700413 ,  41.52089   ,   1.6629171 ,\n",
      "         0.91971546,   3.3704734 ,  24.912758  ,   4.35429   ,\n",
      "        38.587936  ,   1.5425684 ,   1.7229873 ,   1.2499964 ,\n",
      "        50.330074  ,  22.464369  ,  11.519427  ,   1.299366  ],\n",
      "      dtype=float32)]\n",
      "[]\n",
      "[array([[[[-2.21710112e-02,  4.31211572e-03, -4.36864281e-03, ...,\n",
      "          -5.51155359e-02,  5.04860543e-02,  1.65556986e-02],\n",
      "         [ 5.17642871e-02, -3.04115918e-02, -4.52224091e-02, ...,\n",
      "           2.34702062e-02,  1.90327037e-02,  1.30856615e-02],\n",
      "         [ 7.32395798e-03, -6.17610142e-02, -1.53842038e-02, ...,\n",
      "           1.99145395e-02,  5.00830375e-02,  2.12139618e-02],\n",
      "         ...,\n",
      "         [ 2.69177239e-02,  5.24114482e-02,  3.45922150e-02, ...,\n",
      "          -1.89271029e-02,  2.98631936e-02, -4.10762616e-02],\n",
      "         [-1.85167622e-02, -4.28723693e-02, -6.05006628e-02, ...,\n",
      "          -7.12554008e-02,  2.19074935e-02, -9.18855369e-02],\n",
      "         [-1.83492918e-02, -1.73761544e-03,  2.21214890e-02, ...,\n",
      "          -6.51817173e-02, -4.85021733e-02,  2.64420696e-02]],\n",
      "\n",
      "        [[ 3.62798907e-02,  1.31249810e-02,  3.66554670e-02, ...,\n",
      "          -1.01979058e-02,  2.44610403e-02, -1.24236504e-02],\n",
      "         [ 1.99578200e-02, -1.82851423e-02,  3.09948996e-03, ...,\n",
      "          -5.41048422e-02, -2.74027288e-02,  2.37162337e-02],\n",
      "         [ 2.09041946e-02,  3.23177017e-02, -1.11492770e-02, ...,\n",
      "           7.98174553e-03, -5.14788143e-02, -6.26217749e-04],\n",
      "         ...,\n",
      "         [-2.79722009e-02,  4.38702479e-02, -1.59875993e-02, ...,\n",
      "           2.89735105e-02, -1.07369549e-03,  1.30139349e-03],\n",
      "         [ 2.00638585e-02, -5.04439399e-02, -1.37023116e-03, ...,\n",
      "          -5.03854230e-02, -1.47628412e-02, -6.27704710e-02],\n",
      "         [ 2.50700489e-02,  4.92632166e-02, -1.57824866e-02, ...,\n",
      "          -6.70810789e-02, -1.90284960e-02, -3.49907647e-03]],\n",
      "\n",
      "        [[ 4.14190032e-02,  3.42940609e-03,  1.59976981e-03, ...,\n",
      "          -5.57818189e-02, -3.29453661e-03, -1.69041865e-02],\n",
      "         [ 5.11963442e-02,  1.63274575e-02, -5.13658375e-02, ...,\n",
      "          -1.57657079e-02, -2.83547193e-02, -1.61489435e-02],\n",
      "         [ 2.51629427e-02,  4.01352979e-02,  6.00432083e-02, ...,\n",
      "          -2.08582431e-02,  2.52305586e-02, -5.99485114e-02],\n",
      "         ...,\n",
      "         [-6.52797744e-02, -5.60667948e-04, -4.61820103e-02, ...,\n",
      "          -5.64087415e-03,  7.71720931e-02,  5.29523240e-03],\n",
      "         [-1.27126742e-02, -3.30752283e-02, -1.60140321e-02, ...,\n",
      "           3.96016128e-02,  2.99348161e-02, -3.38321254e-02],\n",
      "         [ 4.84177731e-02,  2.97994483e-02,  3.46636958e-02, ...,\n",
      "           8.18529073e-03, -2.00692751e-02, -7.84863159e-02]],\n",
      "\n",
      "        [[ 2.38638185e-02, -2.31326334e-02, -1.46661419e-02, ...,\n",
      "          -3.67477462e-02,  4.75274138e-02, -1.89707577e-02],\n",
      "         [ 5.94348684e-02,  8.87771323e-03,  4.61172499e-02, ...,\n",
      "          -5.16282022e-02, -2.98852734e-02, -6.54330552e-02],\n",
      "         [ 4.37922180e-02,  8.02111998e-02,  7.00063705e-02, ...,\n",
      "          -8.02583322e-02, -5.10068052e-02, -8.07767957e-02],\n",
      "         ...,\n",
      "         [-2.53848862e-02,  2.09266543e-02,  1.32319937e-02, ...,\n",
      "           2.99762562e-02,  5.58854975e-02,  3.20626833e-02],\n",
      "         [-2.51002819e-03, -3.73873860e-02, -5.15424386e-02, ...,\n",
      "          -7.68462569e-02, -5.84943295e-02,  7.37803280e-02],\n",
      "         [ 1.44357551e-02, -3.60539928e-02,  2.81042494e-02, ...,\n",
      "           3.49456221e-02,  1.23590119e-02,  1.65383909e-02]],\n",
      "\n",
      "        [[ 4.21672724e-02, -3.76609415e-02, -4.89440300e-02, ...,\n",
      "          -6.31574914e-02, -2.29607616e-02,  1.36601459e-02],\n",
      "         [ 3.06738447e-02, -2.74211820e-02, -8.36283900e-03, ...,\n",
      "          -6.51236437e-03,  2.02534366e-02,  3.92229743e-02],\n",
      "         [-3.38434465e-02, -2.21933108e-02,  5.73618012e-03, ...,\n",
      "          -4.84385267e-02,  5.26581833e-04, -7.01112971e-02],\n",
      "         ...,\n",
      "         [-1.41877104e-02,  2.18294449e-02,  1.96494907e-02, ...,\n",
      "           3.52326147e-02,  6.12749942e-02,  2.39847805e-02],\n",
      "         [-5.08560091e-02, -2.13192757e-02,  5.07095009e-02, ...,\n",
      "           7.01074442e-03, -1.97962523e-02, -2.04554535e-02],\n",
      "         [ 1.58795305e-02, -6.84912875e-02,  4.08188365e-02, ...,\n",
      "          -3.33301015e-02, -4.82602045e-03, -2.37111654e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 3.06231920e-02,  2.48730611e-02, -3.70191671e-02, ...,\n",
      "          -8.90724361e-02, -2.47145258e-02,  2.03479454e-02],\n",
      "         [ 1.96944270e-02,  2.33343858e-02,  1.49306525e-02, ...,\n",
      "           3.64304967e-02, -1.77164041e-02, -7.35424738e-03],\n",
      "         [-3.81071679e-02,  6.38574585e-02,  7.27620022e-03, ...,\n",
      "          -8.76892433e-02, -1.82651170e-02,  3.47939320e-02],\n",
      "         ...,\n",
      "         [ 4.35518771e-02,  4.11760807e-02, -1.40753426e-02, ...,\n",
      "           2.65516955e-02, -2.76150648e-02, -1.16806710e-03],\n",
      "         [ 2.48012822e-02, -3.28800380e-02, -2.69531589e-02, ...,\n",
      "          -9.23651829e-03,  2.36097146e-02,  2.70449519e-02],\n",
      "         [-5.13748974e-02, -2.14614905e-02,  2.83799302e-02, ...,\n",
      "          -1.86810456e-02, -5.13251536e-02, -1.32385977e-02]],\n",
      "\n",
      "        [[ 2.45685112e-02, -4.18291129e-02, -2.88237650e-02, ...,\n",
      "           1.05081489e-02, -6.90199807e-03, -1.93366148e-02],\n",
      "         [-1.82264093e-02, -8.32761824e-02,  3.87517810e-02, ...,\n",
      "           3.00302496e-03,  3.32193635e-02,  5.75917773e-03],\n",
      "         [ 6.93128482e-02,  2.26020385e-02,  2.14975537e-03, ...,\n",
      "          -2.02909466e-02, -1.45937810e-02, -2.79795844e-02],\n",
      "         ...,\n",
      "         [-3.18447761e-02,  6.66156858e-02, -3.30981165e-02, ...,\n",
      "           1.48346499e-02,  7.54745305e-03, -5.26045710e-02],\n",
      "         [-1.15833152e-02,  3.31039317e-02,  4.16638777e-02, ...,\n",
      "          -1.66336223e-02,  4.83705029e-02, -3.63276042e-02],\n",
      "         [-2.48919446e-02,  1.03223906e-03,  5.26725091e-02, ...,\n",
      "           2.96910349e-02, -2.29851734e-02,  3.06017399e-02]],\n",
      "\n",
      "        [[-2.23664679e-02, -4.84467186e-02, -4.38415110e-02, ...,\n",
      "          -5.64566068e-02,  4.10437100e-02, -4.06198315e-02],\n",
      "         [-1.08104972e-02, -4.52267081e-02, -1.87287107e-02, ...,\n",
      "           1.53362360e-02, -1.62927294e-03, -2.32828874e-02],\n",
      "         [ 7.70522431e-02, -7.90034458e-02,  4.58794534e-02, ...,\n",
      "           7.19872415e-02, -3.12240645e-02, -1.46453106e-03],\n",
      "         ...,\n",
      "         [ 1.03870332e-02,  5.11464775e-02, -1.90427471e-02, ...,\n",
      "           1.82029326e-02,  2.79438011e-02,  2.30652653e-02],\n",
      "         [-9.24233440e-03, -4.05155122e-02, -9.68048628e-03, ...,\n",
      "           6.89021051e-02,  5.24454191e-02,  3.68632898e-02],\n",
      "         [ 3.11187170e-02, -1.49826854e-02,  4.77071404e-02, ...,\n",
      "           9.89756137e-02, -5.77411205e-02, -1.83548555e-02]],\n",
      "\n",
      "        [[-1.09075140e-02, -4.67878245e-02,  1.03845471e-03, ...,\n",
      "          -8.77252147e-02, -2.66496576e-02,  1.02042099e-02],\n",
      "         [ 5.89292571e-02,  1.33994557e-02,  4.01148153e-03, ...,\n",
      "          -2.98198145e-02, -2.63809822e-02,  4.38166894e-02],\n",
      "         [ 3.28272097e-02, -1.57320555e-02, -8.14249646e-03, ...,\n",
      "          -1.46955457e-02, -1.57241728e-02,  2.15229485e-03],\n",
      "         ...,\n",
      "         [-4.28949893e-02,  1.99502613e-02,  3.37057114e-02, ...,\n",
      "           4.65855300e-02,  6.18901923e-02, -6.07085787e-02],\n",
      "         [-1.46833304e-02,  2.38638977e-03, -1.44846579e-02, ...,\n",
      "           4.91423644e-02,  4.08893712e-02,  7.43972659e-02],\n",
      "         [ 2.72969548e-02,  3.19151953e-03, -7.49888420e-02, ...,\n",
      "          -6.88154846e-02,  3.01896455e-03, -5.29053807e-02]],\n",
      "\n",
      "        [[ 2.95654181e-02,  9.65229236e-03, -1.02272239e-02, ...,\n",
      "           2.74961405e-02,  3.33138965e-02,  4.38803919e-02],\n",
      "         [ 5.90794198e-02, -7.30321333e-02,  1.37203373e-02, ...,\n",
      "          -6.55651540e-02,  6.22808188e-02,  4.97482941e-02],\n",
      "         [-3.11965439e-02, -7.79337585e-02,  2.31245309e-02, ...,\n",
      "          -8.63202102e-03,  5.83035424e-02,  4.44102623e-02],\n",
      "         ...,\n",
      "         [-2.82398202e-02,  1.41216088e-02,  1.90532226e-02, ...,\n",
      "          -2.71486007e-02,  4.07558605e-02,  3.28494571e-02],\n",
      "         [-6.00235872e-02,  6.78190915e-03, -2.03942452e-02, ...,\n",
      "          -4.50804345e-02,  1.73154660e-02,  2.84785181e-02],\n",
      "         [-8.24639648e-02, -4.47305143e-02,  1.55544579e-02, ...,\n",
      "          -7.65332431e-02,  8.21085572e-02, -6.95512891e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 2.00053286e-02, -3.54937091e-02, -6.32677451e-02, ...,\n",
      "          -4.97943796e-02,  3.55203114e-02, -2.09296271e-02],\n",
      "         [-2.61616670e-02, -5.23314886e-02,  1.96820591e-02, ...,\n",
      "           2.35519093e-02,  3.07797957e-02, -2.01502722e-02],\n",
      "         [-4.40064073e-02, -1.37867508e-02,  6.81673735e-03, ...,\n",
      "          -3.71107981e-02,  1.78160537e-02, -4.31550527e-03],\n",
      "         ...,\n",
      "         [ 6.41221926e-02, -1.65325161e-02, -1.61208138e-02, ...,\n",
      "          -2.59361672e-03, -1.89338885e-02,  3.45475450e-02],\n",
      "         [ 2.51675174e-02,  6.75620884e-02,  2.41516568e-02, ...,\n",
      "          -2.11769547e-02,  2.22044103e-02, -4.73752171e-02],\n",
      "         [ 2.77285650e-02, -4.48365435e-02, -7.70097896e-02, ...,\n",
      "          -7.06281811e-02,  2.72547361e-02, -1.25749856e-02]],\n",
      "\n",
      "        [[-5.03235031e-03,  1.59415193e-02,  3.41481306e-02, ...,\n",
      "           2.18685344e-02,  3.00239436e-02,  1.17801744e-02],\n",
      "         [-1.77732174e-04, -2.83206056e-04,  2.17641573e-02, ...,\n",
      "           5.86701790e-03,  6.44438565e-02,  2.73502315e-03],\n",
      "         [-5.18006645e-02, -1.88765153e-02, -1.50919128e-02, ...,\n",
      "           3.10225561e-02, -3.06033790e-02,  6.01571053e-02],\n",
      "         ...,\n",
      "         [-1.77846029e-02, -8.52440484e-03,  1.11100338e-02, ...,\n",
      "          -6.51155263e-02, -4.64441329e-02, -3.35676372e-02],\n",
      "         [ 4.32454385e-02,  1.75513942e-02, -1.79289635e-02, ...,\n",
      "           1.76051222e-02,  4.95768748e-02, -6.20901957e-03],\n",
      "         [-4.15520296e-02,  5.06324247e-02, -4.85304818e-02, ...,\n",
      "           4.07574847e-02,  6.11312455e-03,  6.43738732e-02]],\n",
      "\n",
      "        [[ 3.33331525e-02,  2.31396258e-02,  2.15373579e-02, ...,\n",
      "          -1.96855739e-02,  4.14144956e-02,  4.37494330e-02],\n",
      "         [ 6.70836940e-02,  9.77654383e-03,  3.62979039e-03, ...,\n",
      "           2.12155338e-02, -2.15123054e-02,  4.93544936e-02],\n",
      "         [ 2.89815813e-02, -1.05098926e-01, -2.95646545e-02, ...,\n",
      "          -4.06676084e-02,  7.40521848e-02,  1.48054631e-03],\n",
      "         ...,\n",
      "         [-3.71167995e-02,  2.51596365e-02,  9.77149047e-03, ...,\n",
      "          -1.84071660e-02, -3.20546478e-02,  2.03623101e-02],\n",
      "         [ 4.28316109e-02, -1.37050198e-02, -2.30552908e-03, ...,\n",
      "          -3.63063253e-02, -2.09447760e-02, -3.42810564e-02],\n",
      "         [ 1.21789575e-02,  3.63045260e-02,  2.96249893e-02, ...,\n",
      "          -2.15325020e-02,  4.80844006e-02,  1.95221901e-02]],\n",
      "\n",
      "        [[-4.24486771e-02,  4.06586714e-02, -2.15104595e-02, ...,\n",
      "          -3.32407728e-02, -2.15989035e-02, -5.98603021e-03],\n",
      "         [ 6.50331154e-02, -4.35149968e-02,  6.36381879e-02, ...,\n",
      "           2.93966625e-02,  1.07006058e-02,  1.55567881e-02],\n",
      "         [ 6.86195940e-02, -8.04625750e-02,  5.00969775e-02, ...,\n",
      "          -4.83233435e-03,  4.30710763e-02, -2.00467017e-02],\n",
      "         ...,\n",
      "         [-5.20745367e-02, -1.94440167e-02, -9.40236787e-04, ...,\n",
      "           3.85681801e-02, -2.07135640e-02, -1.90159082e-02],\n",
      "         [ 1.84887256e-02,  5.33769764e-02, -4.13216576e-02, ...,\n",
      "           5.11571132e-02, -3.64265740e-02, -7.00181443e-03],\n",
      "         [-2.00493280e-02, -4.51882817e-02,  4.69323248e-04, ...,\n",
      "           1.28466161e-02,  3.07606012e-02, -4.40337770e-02]],\n",
      "\n",
      "        [[ 4.57352176e-02, -4.47893217e-02, -5.94095625e-02, ...,\n",
      "          -1.98173467e-02, -1.64683443e-03, -7.01644570e-02],\n",
      "         [-2.74017416e-02,  3.20121795e-02,  3.64884250e-02, ...,\n",
      "          -5.61331213e-02,  8.56743827e-02, -1.73404664e-02],\n",
      "         [ 5.57576977e-02, -9.42349732e-02,  8.63939858e-05, ...,\n",
      "          -8.92934389e-03,  8.52554739e-02,  2.39715632e-02],\n",
      "         ...,\n",
      "         [-6.40929267e-02, -1.33400625e-02, -5.90143874e-02, ...,\n",
      "          -3.16018946e-02, -3.70293185e-02, -1.13364691e-02],\n",
      "         [ 5.14812768e-02,  6.71345666e-02, -4.29237038e-02, ...,\n",
      "          -5.04745543e-02, -5.21744117e-02, -5.15658632e-02],\n",
      "         [ 2.02127881e-02,  4.45622429e-02,  2.43202201e-03, ...,\n",
      "          -2.74586231e-02,  3.26773971e-02, -2.39099264e-02]]],\n",
      "\n",
      "\n",
      "       [[[-5.03779240e-02, -1.25474222e-02,  1.17375795e-02, ...,\n",
      "          -1.19776912e-02, -4.40265462e-02,  3.40556465e-02],\n",
      "         [-3.37341055e-02,  2.50486191e-02, -1.22740520e-02, ...,\n",
      "          -2.55759750e-02,  4.65620719e-02, -7.73903877e-02],\n",
      "         [ 8.60170871e-02,  1.66209247e-02,  4.44545075e-02, ...,\n",
      "          -1.26863196e-02, -1.64110251e-02,  1.28386347e-02],\n",
      "         ...,\n",
      "         [ 1.51932659e-02, -3.41854095e-02, -3.68795842e-02, ...,\n",
      "           2.13359967e-02, -1.99015159e-03,  4.18280177e-02],\n",
      "         [-3.08584943e-02,  7.76004717e-02,  6.80401847e-02, ...,\n",
      "           1.00075407e-02,  3.71695496e-02, -6.70978203e-02],\n",
      "         [-3.62372845e-02,  2.32458767e-02, -1.92722380e-02, ...,\n",
      "          -2.75697280e-03, -6.26399834e-03,  4.75102589e-02]],\n",
      "\n",
      "        [[-4.67636734e-02,  2.77650282e-02, -1.12277027e-02, ...,\n",
      "           2.43266392e-03, -4.66552228e-02,  4.76584285e-02],\n",
      "         [-3.87812965e-02,  1.97752956e-02, -1.47276940e-02, ...,\n",
      "           5.93431070e-02, -3.60330380e-02, -8.18705484e-02],\n",
      "         [ 3.98555771e-02, -9.98037960e-03,  6.80472478e-02, ...,\n",
      "          -6.96619973e-03,  6.39248490e-02, -1.48945656e-02],\n",
      "         ...,\n",
      "         [ 2.32293345e-02, -5.98467514e-03, -1.39652826e-02, ...,\n",
      "          -1.83668900e-02, -2.53306678e-03,  4.51959185e-02],\n",
      "         [-3.42586567e-03,  5.31123616e-02,  1.90437809e-02, ...,\n",
      "          -5.99551126e-02,  4.02407683e-02, -6.77989647e-02],\n",
      "         [ 3.35768312e-02,  5.34825586e-02,  1.57230999e-02, ...,\n",
      "          -6.54212898e-04,  2.78764982e-02, -4.29487899e-02]],\n",
      "\n",
      "        [[-1.58179738e-03, -3.61958593e-02, -3.26963104e-02, ...,\n",
      "          -8.23016018e-02,  5.77398902e-03,  1.37031544e-02],\n",
      "         [-6.33538216e-02, -1.84320118e-02, -4.61367518e-02, ...,\n",
      "          -3.41246501e-02, -1.76324286e-02, -8.49322006e-02],\n",
      "         [ 1.09067090e-01, -4.54491787e-02, -9.75183968e-04, ...,\n",
      "          -1.54100899e-02,  7.41271153e-02,  7.54890405e-03],\n",
      "         ...,\n",
      "         [-2.06591208e-02, -7.12794736e-02,  3.17374319e-02, ...,\n",
      "          -1.52950839e-03,  3.91502231e-02, -2.25907564e-02],\n",
      "         [ 4.76097725e-02,  4.29504178e-03, -9.04781409e-05, ...,\n",
      "           3.85743789e-02, -1.91961434e-02, -5.52351288e-02],\n",
      "         [ 2.15006284e-02,  2.20958348e-02,  3.53226513e-02, ...,\n",
      "          -4.69075982e-03, -1.90998632e-02, -7.45310113e-02]],\n",
      "\n",
      "        [[ 2.66748518e-02, -6.19932711e-02, -6.10058941e-02, ...,\n",
      "          -1.26620696e-03, -2.05585212e-02, -5.97361512e-02],\n",
      "         [-4.82596159e-02,  2.67850645e-02, -3.76043245e-02, ...,\n",
      "          -2.56050099e-02,  1.47413108e-02, -5.75869754e-02],\n",
      "         [ 6.40710630e-03, -4.88464162e-02, -5.53230643e-02, ...,\n",
      "          -3.01311637e-04, -1.15573348e-03,  1.90941319e-02],\n",
      "         ...,\n",
      "         [-3.22979316e-02, -2.91493684e-02,  4.04290259e-02, ...,\n",
      "          -4.81197797e-02,  2.71198768e-02,  6.55774120e-03],\n",
      "         [ 1.31165674e-02,  8.44981745e-02,  7.24989548e-02, ...,\n",
      "          -4.43635099e-02, -1.52879069e-02, -3.99171785e-02],\n",
      "         [ 3.44732590e-02,  2.89378725e-02, -3.20543797e-04, ...,\n",
      "          -8.68018437e-03, -3.17035988e-02,  1.80330854e-02]],\n",
      "\n",
      "        [[-5.63373044e-02, -2.77548190e-02, -3.22427228e-02, ...,\n",
      "          -2.63085682e-02, -4.54878137e-02, -7.08567873e-02],\n",
      "         [-3.26662022e-03,  5.81645519e-02,  5.25698513e-02, ...,\n",
      "           6.04032390e-02,  4.39666696e-02, -1.41863162e-02],\n",
      "         [-3.02624106e-02, -4.98559959e-02, -5.17975092e-02, ...,\n",
      "          -2.40778527e-03,  3.49914655e-02,  2.69286595e-02],\n",
      "         ...,\n",
      "         [ 4.72092964e-02,  1.11320596e-02,  9.88889299e-03, ...,\n",
      "          -1.51812155e-02, -2.34464947e-02, -7.04385787e-02],\n",
      "         [-2.80587422e-03, -1.98840667e-02, -2.22292282e-02, ...,\n",
      "          -2.67769373e-03, -7.87337720e-02, -2.83718929e-02],\n",
      "         [ 2.29400806e-02,  4.39143479e-02,  6.53662300e-03, ...,\n",
      "           5.00819571e-02,  5.38195111e-03, -1.76999941e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 4.72768256e-03, -9.91828274e-03, -3.71195935e-02, ...,\n",
      "          -7.66817853e-02, -3.51334456e-03,  4.41473648e-02],\n",
      "         [-2.03618575e-02,  5.30010946e-02, -5.96522391e-02, ...,\n",
      "           2.94984765e-02,  1.21692428e-02,  2.83080228e-02],\n",
      "         [ 4.81663346e-02, -3.77812348e-02,  2.93386225e-02, ...,\n",
      "           2.84915436e-02,  4.87078773e-03, -5.01762331e-02],\n",
      "         ...,\n",
      "         [-5.17381467e-02,  3.40888910e-02, -8.25098604e-02, ...,\n",
      "          -2.29992974e-03,  3.66796590e-02,  1.59844551e-02],\n",
      "         [ 2.07409151e-02, -4.06652875e-02,  2.08886489e-02, ...,\n",
      "           1.13582909e-02,  2.04485171e-02, -4.66834456e-02],\n",
      "         [ 3.39569487e-02,  5.37503958e-02,  1.51837897e-02, ...,\n",
      "           3.65324467e-02,  4.01419923e-02, -3.57041024e-02]],\n",
      "\n",
      "        [[ 4.59819958e-02,  5.59690893e-02, -2.76090410e-02, ...,\n",
      "          -1.12751350e-02,  6.00201376e-02, -4.62714434e-02],\n",
      "         [-7.12285861e-02,  5.91229554e-03, -6.66362280e-03, ...,\n",
      "          -6.55834153e-02,  4.18528765e-02, -6.94210231e-02],\n",
      "         [ 7.08400756e-02,  3.25538628e-02, -1.94265172e-02, ...,\n",
      "          -8.91953334e-02, -1.71852345e-03, -6.14981949e-02],\n",
      "         ...,\n",
      "         [-6.53260872e-02, -3.30427429e-03, -1.55894114e-02, ...,\n",
      "          -2.85586435e-02, -1.62763223e-02,  4.48504202e-02],\n",
      "         [-9.82683559e-05, -1.59909427e-02,  1.92261655e-02, ...,\n",
      "           3.59701216e-02, -3.35472673e-02,  1.79254059e-02],\n",
      "         [ 1.17083210e-02, -5.30253490e-03,  1.19004697e-02, ...,\n",
      "          -2.56400257e-02, -2.40364391e-02,  4.06736322e-03]],\n",
      "\n",
      "        [[ 4.50416878e-02, -4.81018387e-02, -2.19853371e-02, ...,\n",
      "          -4.86681275e-02,  4.33362909e-02, -4.52271886e-02],\n",
      "         [-5.99102117e-03, -4.74864580e-02, -3.50568406e-02, ...,\n",
      "           3.76771577e-02, -3.67711037e-02, -6.57746941e-02],\n",
      "         [ 1.42727355e-02,  5.56569882e-02,  7.86123276e-02, ...,\n",
      "          -6.59666955e-02,  5.76703250e-02,  2.17763744e-02],\n",
      "         ...,\n",
      "         [ 2.04067770e-02,  3.74169238e-02, -7.35321119e-02, ...,\n",
      "           4.37928364e-02,  1.52328648e-02, -4.51309793e-02],\n",
      "         [-3.11209448e-02, -3.76416929e-02, -1.98107548e-02, ...,\n",
      "           5.87042235e-03, -3.76009233e-02,  2.70643551e-02],\n",
      "         [ 2.73992456e-02,  3.17520499e-02,  1.70018175e-03, ...,\n",
      "          -5.00128977e-02, -4.73508425e-02,  2.50522401e-02]],\n",
      "\n",
      "        [[-5.33091240e-02, -2.39356514e-02,  6.69020973e-03, ...,\n",
      "          -3.95394228e-02, -3.06900721e-02,  2.17318106e-02],\n",
      "         [-4.78237495e-02, -1.55130448e-03, -1.31462030e-02, ...,\n",
      "           5.69609134e-03,  3.64080556e-02, -5.66442348e-02],\n",
      "         [ 4.60298620e-02,  5.59368916e-02, -4.27780673e-02, ...,\n",
      "           8.47954862e-03, -1.41834188e-02,  1.29741728e-02],\n",
      "         ...,\n",
      "         [-2.95496196e-04,  6.55888095e-02, -8.65533948e-02, ...,\n",
      "           4.53188969e-03, -3.46271992e-02, -2.00424865e-02],\n",
      "         [ 5.48498295e-02,  4.85216407e-03, -7.87372068e-02, ...,\n",
      "           4.98600900e-02, -9.46922041e-03, -3.65663432e-02],\n",
      "         [ 4.15041782e-02,  6.00709617e-02, -5.80757074e-02, ...,\n",
      "          -4.15945500e-02,  3.59393135e-02, -3.75691652e-02]],\n",
      "\n",
      "        [[-2.39035413e-02,  8.56117904e-03, -3.83811370e-02, ...,\n",
      "          -3.00279371e-02, -8.95285141e-03, -4.36559357e-02],\n",
      "         [-1.79124274e-03, -8.57373513e-03, -7.29310736e-02, ...,\n",
      "           2.42307112e-02, -4.61663231e-02,  3.22755352e-02],\n",
      "         [ 2.84841005e-02, -1.67649668e-02, -1.52810412e-02, ...,\n",
      "           4.90075313e-02,  6.13384182e-03, -5.55695407e-02],\n",
      "         ...,\n",
      "         [-6.13500513e-02, -4.88729738e-02, -7.06852973e-02, ...,\n",
      "           3.68042453e-03, -5.14124483e-02, -8.81341379e-03],\n",
      "         [ 4.11958480e-03, -2.92787403e-02, -5.71910813e-02, ...,\n",
      "           6.80832043e-02, -5.54275289e-02,  5.24287187e-02],\n",
      "         [ 5.79448827e-02, -3.49631868e-02, -7.46775717e-02, ...,\n",
      "           6.96778577e-03, -1.23432663e-03,  3.68136279e-02]]]],\n",
      "      dtype=float32), array([-0.03618605,  0.01245631, -0.02117127, -0.00783405,  0.04977428,\n",
      "       -0.01464584, -0.02823471, -0.09730174, -0.03997353, -0.04986182,\n",
      "       -0.03526276, -0.08212931, -0.04488285, -0.08052466, -0.02354294,\n",
      "        0.00201753, -0.00087322, -0.0185351 , -0.02711125,  0.03041525,\n",
      "        0.02277551, -0.01339591,  0.0251053 ,  0.00234805,  0.0237572 ,\n",
      "       -0.00402611,  0.04046295,  0.01231212, -0.01639668, -0.04425318,\n",
      "       -0.0082607 , -0.01962575, -0.02507154, -0.00304748, -0.09218676,\n",
      "       -0.02063483, -0.0719754 , -0.00715814, -0.00731619,  0.02873566,\n",
      "       -0.00409837, -0.08154073, -0.02129448, -0.01017015, -0.03317972,\n",
      "       -0.01872825, -0.01791386,  0.01411503], dtype=float32)]\n",
      "[array([0.90999717, 1.0170072 , 0.95699775, 0.9642055 , 1.0243841 ,\n",
      "       0.94954115, 0.9363078 , 1.0905198 , 1.0090187 , 0.98935854,\n",
      "       1.0377786 , 0.9420812 , 0.9355167 , 0.9992326 , 0.9904997 ,\n",
      "       0.9994028 , 1.0822448 , 0.90946203, 1.0293696 , 1.0160217 ,\n",
      "       1.0590312 , 1.0957156 , 1.0963821 , 0.95566607, 0.96615356,\n",
      "       1.0766777 , 1.1172885 , 0.9125719 , 0.92571473, 0.9616193 ,\n",
      "       0.9257996 , 0.9759126 , 0.94686216, 1.0925272 , 1.0524004 ,\n",
      "       1.0194974 , 0.98791283, 0.9717733 , 0.9873687 , 1.0148842 ,\n",
      "       1.0245215 , 0.9734535 , 0.90742546, 1.0781139 , 0.921595  ,\n",
      "       1.049753  , 1.0163529 , 1.0229231 ], dtype=float32), array([ 0.06681795,  0.01273251, -0.00254625,  0.01796927,  0.02000602,\n",
      "        0.04328059,  0.0361208 ,  0.0319161 ,  0.02837559,  0.06208574,\n",
      "        0.00959573,  0.02859869,  0.03040328,  0.07331124, -0.03331976,\n",
      "        0.00241641,  0.0165753 ,  0.02115794, -0.04566059,  0.03666966,\n",
      "        0.01594885, -0.03577574,  0.01774995,  0.02905453,  0.0398165 ,\n",
      "        0.07759456,  0.02258568,  0.04255014,  0.03044159,  0.07272284,\n",
      "       -0.02018374,  0.04742275,  0.05013172, -0.04527489,  0.06969352,\n",
      "        0.00783462,  0.05534518, -0.00665756,  0.01052823,  0.01211989,\n",
      "        0.00386166,  0.04346059,  0.06616421,  0.03135335,  0.04615419,\n",
      "       -0.07353543, -0.00642389,  0.00619256], dtype=float32), array([0.5148587 , 0.4163074 , 0.51085395, 0.5141337 , 0.47532678,\n",
      "       0.31724557, 0.33565983, 0.39041144, 0.4467737 , 0.4764993 ,\n",
      "       0.5368523 , 0.70921034, 0.2603444 , 1.051058  , 0.41117725,\n",
      "       0.42292732, 0.40239805, 0.2236017 , 0.34532306, 0.49194998,\n",
      "       0.39059874, 0.43751836, 0.36903405, 0.435482  , 0.46008515,\n",
      "       0.39644393, 0.40106943, 0.5149432 , 0.5731888 , 0.7077763 ,\n",
      "       0.42439798, 0.44050026, 0.50259525, 0.35056534, 0.28694677,\n",
      "       0.55598027, 0.80597985, 0.71114105, 0.39268497, 0.50976104,\n",
      "       0.37165734, 0.23409978, 0.49997154, 0.33437243, 0.32347727,\n",
      "       0.5636705 , 0.5083803 , 0.38488495], dtype=float32), array([1.3321445 , 1.1335208 , 0.7071108 , 0.8825848 , 0.42912742,\n",
      "       0.5751466 , 0.38132825, 0.20634747, 0.37119332, 1.6132706 ,\n",
      "       0.3900334 , 2.158797  , 0.56633246, 4.25444   , 0.2381796 ,\n",
      "       0.4791338 , 0.60647637, 0.22532625, 0.25763696, 0.66957366,\n",
      "       0.51810473, 0.63063335, 0.5456366 , 0.6649346 , 1.045113  ,\n",
      "       0.5797258 , 0.4549572 , 1.0297552 , 0.5358364 , 2.5207512 ,\n",
      "       0.85765195, 1.3044785 , 1.6969717 , 0.47438988, 0.8691701 ,\n",
      "       0.6336278 , 2.9486203 , 0.80066717, 0.4364041 , 1.307791  ,\n",
      "       0.48197055, 0.6641945 , 1.0284485 , 0.34625617, 0.5428901 ,\n",
      "       0.4548488 , 1.4345708 , 0.59900177], dtype=float32)]\n",
      "[]\n",
      "[array([[[[ 4.82072011e-02, -4.79503833e-02,  4.22868840e-02, ...,\n",
      "          -3.17481812e-03,  1.76606365e-02,  6.24451898e-02],\n",
      "         [ 1.86391901e-02, -2.38246117e-02, -1.72404777e-02, ...,\n",
      "          -1.69551782e-02, -3.77077051e-02,  1.23768570e-02],\n",
      "         [ 8.01433530e-03,  4.35100794e-02,  5.52406244e-04, ...,\n",
      "           4.40984741e-02, -2.52236445e-02,  3.36057805e-02],\n",
      "         ...,\n",
      "         [-7.22844480e-03,  4.46674041e-02,  2.76078396e-02, ...,\n",
      "           2.17245147e-02,  2.85690054e-02, -2.11648252e-02],\n",
      "         [ 7.24930316e-02, -1.32207368e-02, -1.71787366e-02, ...,\n",
      "           1.63146295e-02, -2.35749828e-03,  1.43221617e-02],\n",
      "         [-4.08251733e-02, -4.04287167e-02, -3.35053205e-02, ...,\n",
      "          -3.66603583e-02,  8.89112055e-03, -1.44984191e-02]],\n",
      "\n",
      "        [[ 4.73507270e-02,  2.61704102e-02,  4.49893549e-02, ...,\n",
      "          -6.44867569e-02, -3.12448777e-02,  1.51618349e-03],\n",
      "         [ 2.92427763e-02,  3.46789882e-02,  2.40845184e-04, ...,\n",
      "           5.03477119e-02,  9.33269784e-03, -3.01543139e-02],\n",
      "         [-3.42323631e-02,  1.78859918e-03, -5.97025268e-03, ...,\n",
      "          -2.96223927e-02, -3.16710211e-02,  5.21287881e-02],\n",
      "         ...,\n",
      "         [ 2.53630485e-02,  1.77098811e-02,  3.85439992e-02, ...,\n",
      "          -3.25891748e-02,  7.82671850e-03,  1.01633917e-03],\n",
      "         [ 8.11428204e-03, -3.59976501e-03, -5.42286038e-02, ...,\n",
      "          -3.95150930e-02, -6.31493628e-02, -5.66747785e-02],\n",
      "         [ 2.26256102e-02, -3.83766666e-02, -4.85934056e-02, ...,\n",
      "          -6.16869964e-02, -3.08682173e-02, -2.10638158e-02]],\n",
      "\n",
      "        [[ 2.17906721e-02, -6.36614785e-02,  1.74515396e-02, ...,\n",
      "          -2.81695407e-02,  1.44599043e-02, -6.47443812e-03],\n",
      "         [-6.05988055e-02,  5.19007854e-02, -5.39900810e-02, ...,\n",
      "           2.73538362e-02,  2.27831304e-03,  4.70272452e-03],\n",
      "         [-4.76195738e-02,  1.24867521e-02,  3.31253335e-02, ...,\n",
      "           1.56865530e-02,  3.82483378e-02, -8.28958210e-03],\n",
      "         ...,\n",
      "         [ 5.51638193e-02,  6.68048859e-04, -2.75827833e-02, ...,\n",
      "          -3.73758413e-02, -2.11779978e-02,  9.59588587e-03],\n",
      "         [-5.16838096e-02,  8.83941054e-02, -4.50938493e-02, ...,\n",
      "          -2.82823499e-02, -4.90775220e-02, -8.83986875e-02],\n",
      "         [ 2.68518627e-02,  3.69155942e-03, -3.00280713e-02, ...,\n",
      "          -5.68669010e-03,  3.22326981e-02,  5.21158986e-03]],\n",
      "\n",
      "        [[-1.18921278e-02, -6.03912100e-02, -9.54934955e-03, ...,\n",
      "          -6.85777217e-02,  6.04415312e-02,  4.67596110e-03],\n",
      "         [-4.58258465e-02,  4.13219072e-02, -5.14387526e-02, ...,\n",
      "          -1.00246752e-02, -2.18115300e-02, -2.35859975e-02],\n",
      "         [-3.55284326e-02, -2.49825250e-02, -8.36760178e-03, ...,\n",
      "           1.29184444e-02,  4.97889780e-02,  6.60591479e-03],\n",
      "         ...,\n",
      "         [-8.76875129e-03,  7.80505836e-02, -5.85925439e-03, ...,\n",
      "          -2.93694269e-02,  4.87993024e-02,  6.05902402e-03],\n",
      "         [-1.17682954e-02,  3.83832902e-02, -2.29383577e-02, ...,\n",
      "           4.47238088e-02,  2.62968019e-02, -8.89858697e-03],\n",
      "         [-3.52256075e-02, -3.73487771e-02, -5.39279543e-02, ...,\n",
      "          -8.17221627e-02,  1.47390487e-02, -1.00509934e-02]],\n",
      "\n",
      "        [[-5.57095818e-02, -5.94910160e-02,  2.99989954e-02, ...,\n",
      "           1.67860426e-02, -2.32703108e-02,  3.51806334e-03],\n",
      "         [-2.33024135e-02,  4.26621623e-02, -6.52743503e-04, ...,\n",
      "           1.73119828e-02, -3.11559290e-02, -2.74628028e-02],\n",
      "         [-7.26376707e-03, -5.41283749e-02,  5.36412336e-02, ...,\n",
      "           2.80044712e-02,  7.90529698e-02,  1.49243400e-02],\n",
      "         ...,\n",
      "         [ 1.99785400e-02,  3.21036647e-03, -2.20447797e-02, ...,\n",
      "           4.84133186e-03, -1.44904377e-02,  4.96576764e-02],\n",
      "         [-1.23803783e-02, -2.57965252e-02, -4.05289307e-02, ...,\n",
      "          -2.65714694e-02,  4.94089676e-03, -1.20479548e-02],\n",
      "         [ 1.12533094e-02,  7.10007362e-03,  3.68640572e-02, ...,\n",
      "          -3.78702246e-02, -9.06688068e-03,  5.15590012e-02]]],\n",
      "\n",
      "\n",
      "       [[[-4.15691137e-02, -1.42719038e-02, -3.75136733e-02, ...,\n",
      "          -1.86616520e-03,  4.90234159e-02,  1.96914356e-02],\n",
      "         [-3.57780345e-02, -4.17894907e-02,  3.70313637e-02, ...,\n",
      "           3.68671608e-03,  2.99803596e-02,  2.50333436e-02],\n",
      "         [ 2.94440556e-02, -1.13782017e-02, -5.10800956e-03, ...,\n",
      "           1.21489409e-02, -2.43546534e-02, -4.12958898e-02],\n",
      "         ...,\n",
      "         [ 7.23708654e-03,  5.99330030e-02, -1.66497678e-02, ...,\n",
      "           5.39493375e-02,  1.80414505e-02, -9.77189932e-03],\n",
      "         [-1.67188719e-02, -1.67219434e-03,  6.37754984e-03, ...,\n",
      "           2.97739245e-02,  9.08525009e-03, -1.72272995e-02],\n",
      "         [-3.81013677e-02,  4.17777747e-02,  1.60593372e-02, ...,\n",
      "           5.59404306e-03,  1.26243057e-02, -2.52261218e-02]],\n",
      "\n",
      "        [[ 2.01380090e-03, -4.34331149e-02, -5.14532104e-02, ...,\n",
      "          -4.15365025e-02,  4.55073602e-02,  2.67646387e-02],\n",
      "         [ 1.68318376e-02, -1.72806624e-02,  3.25794192e-03, ...,\n",
      "          -2.19457764e-02,  2.07096268e-03, -3.92335318e-02],\n",
      "         [ 2.35868953e-04,  2.28897184e-02, -6.85346052e-02, ...,\n",
      "          -5.74703701e-02,  4.64331061e-02,  2.96920706e-02],\n",
      "         ...,\n",
      "         [ 2.75441352e-02,  2.08433475e-02,  1.48685630e-02, ...,\n",
      "           2.18313653e-02, -2.53911293e-03, -3.95592228e-02],\n",
      "         [ 2.58413684e-02,  6.30125627e-02,  1.54243754e-02, ...,\n",
      "          -2.22375570e-03,  2.74387393e-02,  1.75387356e-02],\n",
      "         [-3.36325280e-02, -6.19756291e-03, -4.23967540e-02, ...,\n",
      "          -3.28661427e-02,  4.87916283e-02, -1.43578434e-02]],\n",
      "\n",
      "        [[-3.68702714e-03,  2.75153853e-02, -1.86755359e-02, ...,\n",
      "          -4.32315879e-02, -3.03441565e-02,  3.09736431e-02],\n",
      "         [-2.33960785e-02, -5.10138609e-02,  5.12165539e-02, ...,\n",
      "           5.53316101e-02, -2.43983399e-02, -7.26122316e-03],\n",
      "         [ 8.48975684e-03,  1.48643861e-02,  1.18093295e-02, ...,\n",
      "           6.09409111e-03,  3.66707705e-03, -4.31496240e-02],\n",
      "         ...,\n",
      "         [-4.87006567e-02, -8.13099928e-03, -1.15818288e-02, ...,\n",
      "           3.36535200e-02, -9.13942792e-03,  4.60369466e-03],\n",
      "         [-1.35149583e-02,  1.38231432e-02, -7.93819502e-03, ...,\n",
      "           1.89117920e-02, -5.91636598e-02, -7.11247837e-03],\n",
      "         [ 1.46183511e-02,  3.22109535e-02, -1.67675167e-02, ...,\n",
      "          -4.68812771e-02,  3.70799862e-02,  4.53652032e-02]],\n",
      "\n",
      "        [[-3.42141129e-02,  2.69135777e-02,  1.86268426e-02, ...,\n",
      "           5.77830803e-03,  1.39698237e-02, -8.52736086e-03],\n",
      "         [-5.50549179e-02,  1.96477920e-02,  5.43312244e-02, ...,\n",
      "          -6.80060172e-03, -4.08397801e-02, -5.62001467e-02],\n",
      "         [-5.05657401e-03,  1.97983230e-03,  1.27391834e-02, ...,\n",
      "           1.02160312e-02,  7.11833015e-02, -4.91505153e-02],\n",
      "         ...,\n",
      "         [ 3.20017035e-03,  3.45849767e-02,  4.06552479e-02, ...,\n",
      "          -1.79120935e-02,  5.26997559e-02, -4.62950580e-03],\n",
      "         [ 8.27690121e-03,  5.25741093e-02, -2.82177459e-02, ...,\n",
      "           1.66202504e-02, -2.15229914e-02, -5.40036820e-02],\n",
      "         [-4.53003719e-02,  1.13365380e-02, -2.70154364e-02, ...,\n",
      "          -4.09944206e-02, -5.25975674e-02,  1.86021402e-02]],\n",
      "\n",
      "        [[ 1.02267051e-02,  1.92669835e-02,  3.29291001e-02, ...,\n",
      "           2.56372225e-02,  1.12712663e-02, -1.96589436e-02],\n",
      "         [-1.00012114e-02, -6.65974766e-02,  4.93830107e-02, ...,\n",
      "           5.76474657e-03,  1.31554594e-02, -3.11240591e-02],\n",
      "         [-4.53120517e-03, -1.51880346e-02, -2.02725157e-02, ...,\n",
      "          -4.55857962e-02,  9.13581531e-03, -1.54566551e-02],\n",
      "         ...,\n",
      "         [-2.21993607e-02, -1.85516048e-02,  5.11619486e-02, ...,\n",
      "           3.58053832e-04,  4.60311323e-02, -1.16033582e-02],\n",
      "         [ 5.46431392e-02, -3.11977975e-02,  3.99842970e-02, ...,\n",
      "           2.80510425e-03, -7.16982484e-02, -2.42145583e-02],\n",
      "         [-3.05929650e-02, -1.02333678e-02,  2.95833386e-02, ...,\n",
      "           1.00275641e-02,  7.27107516e-03, -3.64771336e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 4.71875779e-02, -5.20099625e-02,  2.62313206e-02, ...,\n",
      "           2.80604530e-02,  4.48021069e-02,  2.89639439e-02],\n",
      "         [-3.69204618e-02,  3.26214582e-02, -2.87918597e-02, ...,\n",
      "          -1.76764708e-02,  1.04411971e-03, -7.43703172e-02],\n",
      "         [ 2.15183981e-02, -9.35372338e-03, -1.87816825e-02, ...,\n",
      "          -1.49955181e-02,  4.40806672e-02,  4.18745652e-02],\n",
      "         ...,\n",
      "         [ 3.01773064e-02, -1.27109727e-02,  3.71681266e-02, ...,\n",
      "          -7.99010321e-03,  2.83700749e-02, -3.15891653e-02],\n",
      "         [ 3.58360261e-02, -1.54691339e-02, -6.84392080e-02, ...,\n",
      "          -6.99099991e-03,  8.70240573e-03,  1.94970798e-02],\n",
      "         [-4.12498116e-02, -2.36661080e-02,  2.53721587e-02, ...,\n",
      "          -2.83213686e-02,  5.02166562e-02,  3.92836630e-02]],\n",
      "\n",
      "        [[ 6.40741829e-03,  8.47153272e-03, -4.32811528e-02, ...,\n",
      "          -6.66239951e-03,  2.81940363e-02, -3.67915742e-02],\n",
      "         [-2.91770231e-02,  2.78622750e-02, -8.77230708e-03, ...,\n",
      "           1.80406198e-02, -3.65217887e-02, -9.20600593e-02],\n",
      "         [ 3.19528319e-02,  6.45781755e-02,  4.71502244e-02, ...,\n",
      "          -1.03053143e-02,  1.26776239e-02,  3.53471078e-02],\n",
      "         ...,\n",
      "         [-3.43043618e-02, -6.15090271e-03, -1.72602106e-02, ...,\n",
      "          -5.26941121e-02, -1.10612139e-02,  4.90037948e-02],\n",
      "         [ 2.96744914e-03,  6.77550735e-04,  2.06348468e-02, ...,\n",
      "          -3.05565689e-02, -4.49807607e-02,  1.81730725e-02],\n",
      "         [-3.56540494e-02,  2.46182010e-02,  4.81773494e-03, ...,\n",
      "           7.74455369e-02,  5.35228066e-02, -3.35268117e-02]],\n",
      "\n",
      "        [[-2.68566776e-02, -9.24201030e-03,  3.52456942e-02, ...,\n",
      "          -2.79179867e-02, -4.83866222e-02, -4.00314592e-02],\n",
      "         [-6.07202910e-02, -8.66786670e-03,  7.02161938e-02, ...,\n",
      "           2.57490948e-02, -7.72837503e-03, -1.85416341e-02],\n",
      "         [-1.03266146e-02,  6.23280071e-02, -4.30052541e-03, ...,\n",
      "           4.63359244e-02,  6.88879192e-03, -2.53764745e-02],\n",
      "         ...,\n",
      "         [-3.08290292e-02, -1.73732359e-02,  2.17633359e-02, ...,\n",
      "          -1.80422590e-04, -3.26959006e-02,  3.54138273e-03],\n",
      "         [ 1.88206676e-02, -7.12569396e-04,  3.54077667e-02, ...,\n",
      "          -6.06503598e-02,  1.37799429e-02,  3.50774862e-02],\n",
      "         [ 1.94135017e-03, -2.70693768e-02,  1.07241282e-02, ...,\n",
      "          -1.63564850e-02, -2.62450464e-02,  7.47336075e-04]],\n",
      "\n",
      "        [[-4.54492792e-02, -8.06710683e-03, -1.11632524e-02, ...,\n",
      "           3.53668034e-02,  1.50156557e-03, -3.11964341e-02],\n",
      "         [ 2.71366742e-02,  1.55433302e-03,  9.11497744e-04, ...,\n",
      "           3.51546309e-03,  3.08406353e-02, -3.22542824e-02],\n",
      "         [-6.66319132e-02,  1.36527661e-02, -9.64743271e-03, ...,\n",
      "          -2.21097302e-02, -5.67777976e-02,  4.64522205e-02],\n",
      "         ...,\n",
      "         [ 1.46979056e-02,  6.92550018e-02,  1.82050280e-02, ...,\n",
      "          -2.70905741e-03, -4.01223898e-02, -5.01447655e-02],\n",
      "         [ 2.43630297e-02, -2.03452948e-02, -5.08682281e-02, ...,\n",
      "           2.04380248e-02,  2.94869319e-02, -2.32392247e-03],\n",
      "         [ 7.78730353e-03,  6.57646060e-02,  2.53472421e-02, ...,\n",
      "          -1.37783140e-02,  6.13955185e-02,  4.84367926e-03]],\n",
      "\n",
      "        [[ 1.81100816e-02, -5.19899055e-02,  1.04767692e-04, ...,\n",
      "          -5.22508025e-02, -3.45919691e-02,  6.15539290e-02],\n",
      "         [-5.26401326e-02, -4.14555855e-02,  1.24417217e-02, ...,\n",
      "           2.66952105e-02, -2.08000615e-02, -1.29406585e-03],\n",
      "         [-2.66558994e-02,  2.06032488e-02, -1.89412199e-02, ...,\n",
      "          -3.59434187e-02, -4.73438427e-02,  1.26846489e-02],\n",
      "         ...,\n",
      "         [-5.07181045e-03, -8.07860587e-03, -1.50061892e-02, ...,\n",
      "           9.01874620e-03,  1.53129045e-02,  3.97171564e-02],\n",
      "         [ 3.07274908e-02, -5.53176180e-03, -1.49618313e-02, ...,\n",
      "          -1.43730743e-02,  6.44535795e-02,  1.92438010e-02],\n",
      "         [-2.37408839e-03,  2.25250386e-02,  5.64384088e-02, ...,\n",
      "          -1.38643710e-02,  1.16871931e-02,  2.45010275e-02]]],\n",
      "\n",
      "\n",
      "       [[[-4.37340066e-02,  9.30836610e-03,  4.87760128e-03, ...,\n",
      "           2.48239003e-02, -2.88979150e-02,  3.82039770e-02],\n",
      "         [ 1.02260814e-03, -2.52418518e-02,  2.63283867e-02, ...,\n",
      "          -2.28612702e-02, -1.26060378e-02, -2.18577608e-02],\n",
      "         [ 6.73677772e-02, -3.55131477e-02, -2.35103760e-02, ...,\n",
      "           5.51360734e-02,  2.35955268e-02,  6.02187440e-02],\n",
      "         ...,\n",
      "         [-2.27548857e-03,  9.61217098e-03, -2.40499415e-02, ...,\n",
      "           3.86673375e-04,  4.22066897e-02, -2.10592840e-02],\n",
      "         [-5.82592152e-02,  4.74492535e-02,  1.90006830e-02, ...,\n",
      "          -2.62274686e-02, -1.33390483e-02,  3.90256532e-02],\n",
      "         [-3.19731119e-03,  3.39069782e-04,  4.66785654e-02, ...,\n",
      "          -2.79463362e-03, -2.87496019e-02,  2.92486362e-02]],\n",
      "\n",
      "        [[-5.79886921e-02, -3.24182957e-02,  3.88961174e-02, ...,\n",
      "           5.41271418e-02,  1.68879107e-02,  2.66156644e-02],\n",
      "         [ 2.10116506e-02, -1.43588539e-02,  4.02660966e-02, ...,\n",
      "           1.02931932e-02, -2.60735918e-02, -6.10723579e-03],\n",
      "         [ 2.31692474e-02,  3.05560622e-02,  1.50904702e-02, ...,\n",
      "           1.31634378e-03, -7.13647995e-03, -2.12327923e-05],\n",
      "         ...,\n",
      "         [-1.79143883e-02, -5.45613952e-02,  1.16450330e-02, ...,\n",
      "           8.85766521e-02, -2.78704911e-02,  8.35488066e-02],\n",
      "         [ 2.61574574e-02,  2.27577519e-03,  2.10216120e-02, ...,\n",
      "           4.07269336e-02, -4.38383706e-02,  4.46990319e-02],\n",
      "         [ 5.35436766e-03,  7.00722728e-03,  1.22634135e-02, ...,\n",
      "           3.31537463e-02,  1.87471472e-02, -7.38304527e-03]],\n",
      "\n",
      "        [[ 1.40785817e-02,  1.25092510e-02, -3.20949666e-02, ...,\n",
      "           2.78126467e-02, -3.98714580e-02, -1.56629793e-02],\n",
      "         [-4.73875068e-02, -5.25778309e-02, -1.74171180e-02, ...,\n",
      "           9.90729127e-03, -4.83767390e-02, -4.57438193e-02],\n",
      "         [-4.45349663e-02, -1.13076847e-02, -3.60623524e-02, ...,\n",
      "           4.23766710e-02, -2.47048810e-02,  5.33966608e-02],\n",
      "         ...,\n",
      "         [ 1.96841657e-02, -3.21730413e-02,  1.78759526e-02, ...,\n",
      "           8.84809438e-03,  4.24843170e-02, -3.99302207e-02],\n",
      "         [-2.62608360e-02,  1.65274888e-02,  4.76192571e-02, ...,\n",
      "           2.90963631e-02, -2.32518744e-02,  5.17578945e-02],\n",
      "         [ 4.34958115e-02, -9.19063911e-02,  3.41423862e-02, ...,\n",
      "          -7.72973225e-02,  3.04647684e-02,  2.58236118e-02]],\n",
      "\n",
      "        [[-1.78875718e-02,  2.09496096e-02,  2.16960739e-02, ...,\n",
      "          -1.64531618e-02,  2.80753095e-02,  5.95499314e-02],\n",
      "         [ 2.77945008e-02, -1.75631363e-02,  4.81406152e-02, ...,\n",
      "          -3.33459377e-02,  1.53229795e-02, -7.10983202e-03],\n",
      "         [-4.79781106e-02, -1.80842355e-02, -3.79312746e-02, ...,\n",
      "           1.08084353e-02,  3.59390825e-02,  7.66913146e-02],\n",
      "         ...,\n",
      "         [ 1.13274893e-02, -2.96975896e-02,  5.46309948e-02, ...,\n",
      "          -3.79868387e-03, -3.77649330e-02, -1.94221584e-03],\n",
      "         [-5.90186156e-02,  2.57412996e-02,  4.34952006e-02, ...,\n",
      "          -4.44529541e-02, -4.35169786e-02, -2.41756812e-02],\n",
      "         [-4.03365269e-02, -7.15652574e-03,  4.90748920e-02, ...,\n",
      "           1.48713198e-02,  4.79686307e-03,  5.37349842e-02]],\n",
      "\n",
      "        [[ 2.41881646e-02, -1.33603858e-02,  2.19347607e-02, ...,\n",
      "          -3.11626662e-02,  2.74263471e-02, -1.27262780e-02],\n",
      "         [ 6.94923336e-03,  5.50893359e-02, -2.87053026e-02, ...,\n",
      "          -2.91700894e-03, -7.76670724e-02,  2.11420748e-02],\n",
      "         [ 3.14431917e-03, -1.91407483e-02, -5.83284423e-02, ...,\n",
      "           9.42125265e-03, -4.22299206e-02,  6.74584284e-02],\n",
      "         ...,\n",
      "         [-6.82842880e-02,  4.10831906e-02, -3.91767025e-02, ...,\n",
      "          -3.62650119e-02, -1.35477204e-02,  3.57483141e-02],\n",
      "         [ 3.37249860e-02,  1.18329013e-02,  3.98052623e-04, ...,\n",
      "          -5.01431059e-03,  5.35880364e-02,  4.16422151e-02],\n",
      "         [ 3.18553038e-02,  7.87420794e-02, -1.75066683e-02, ...,\n",
      "          -3.29085346e-03, -5.76043278e-02, -3.78164798e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 3.29928584e-02,  2.28663012e-02, -3.80443744e-02, ...,\n",
      "          -3.31970006e-02,  3.41726728e-02, -1.59234814e-02],\n",
      "         [-4.59197629e-03, -8.80416017e-03, -2.83931866e-02, ...,\n",
      "           5.32827601e-02, -1.30008189e-02,  8.03474113e-02],\n",
      "         [ 1.57372821e-02, -1.99706573e-02, -1.51707996e-02, ...,\n",
      "           6.22573541e-03, -2.32585706e-02, -2.09268592e-02],\n",
      "         ...,\n",
      "         [-1.68139208e-02, -1.42566757e-02,  3.75082307e-02, ...,\n",
      "          -3.27793434e-02,  6.36989949e-03,  9.59100854e-03],\n",
      "         [ 2.39535104e-02,  3.69569659e-02,  3.24527547e-02, ...,\n",
      "           6.56423643e-02,  5.37999049e-02,  2.46772785e-02],\n",
      "         [ 5.96057475e-02, -2.89788190e-02, -4.59173396e-02, ...,\n",
      "           2.43864078e-02, -1.24779651e-02, -1.01027638e-02]],\n",
      "\n",
      "        [[ 5.30333212e-03,  8.46944153e-02,  3.94118354e-02, ...,\n",
      "          -4.68187267e-04, -9.15042311e-03, -8.40670057e-03],\n",
      "         [-5.98704293e-02, -8.11624900e-03, -1.22235005e-03, ...,\n",
      "           4.75231037e-02,  3.55740339e-02,  1.80400219e-02],\n",
      "         [ 5.96118160e-02, -6.80543110e-02,  2.68020406e-02, ...,\n",
      "          -3.16398888e-04, -3.43464827e-03, -7.63149187e-02],\n",
      "         ...,\n",
      "         [ 5.55962436e-02, -5.46951480e-02,  3.94867323e-02, ...,\n",
      "          -7.98227265e-05,  2.03773156e-02, -2.41857693e-02],\n",
      "         [ 4.03826311e-03,  2.91879829e-02,  1.35483369e-02, ...,\n",
      "          -2.60357615e-02, -2.27611866e-02,  4.35327068e-02],\n",
      "         [ 1.23368204e-02,  4.24114279e-02, -2.58425158e-02, ...,\n",
      "           4.25362103e-02,  5.15186898e-02,  2.79226881e-02]],\n",
      "\n",
      "        [[ 1.52732118e-03,  1.95829011e-03, -3.32168117e-02, ...,\n",
      "           1.37510831e-02, -6.22515148e-03,  1.79661647e-03],\n",
      "         [ 1.57412235e-02, -1.47198280e-02,  3.55450734e-02, ...,\n",
      "           6.36880249e-02,  1.03771808e-02, -3.18492018e-03],\n",
      "         [-7.72882774e-02, -9.46244672e-02,  2.79063024e-02, ...,\n",
      "           4.41121571e-02, -3.97404954e-02, -9.40619260e-02],\n",
      "         ...,\n",
      "         [-7.00730458e-02,  3.47475260e-02, -4.43428159e-02, ...,\n",
      "           1.08949337e-02,  2.12227721e-02, -2.33366899e-02],\n",
      "         [-4.18162905e-02, -1.86401848e-02, -5.07664084e-02, ...,\n",
      "           1.07910298e-02, -2.30731741e-02,  3.25151496e-02],\n",
      "         [-1.27509248e-03, -7.84386247e-02, -6.29545674e-02, ...,\n",
      "           5.27043156e-02, -5.06011024e-02, -1.64284743e-02]],\n",
      "\n",
      "        [[-4.97669505e-04,  1.35175204e-02,  5.26232235e-02, ...,\n",
      "           3.73317413e-02, -1.02366079e-02,  4.18532714e-02],\n",
      "         [ 8.47684816e-02, -8.16416517e-02, -6.52457699e-02, ...,\n",
      "           7.10380450e-02,  3.23865935e-02, -2.08644173e-03],\n",
      "         [ 2.75486172e-03, -2.28285901e-02, -2.93769967e-02, ...,\n",
      "          -3.30960378e-02, -1.29505498e-02, -6.12429120e-02],\n",
      "         ...,\n",
      "         [ 1.44135635e-02, -4.12557721e-02,  3.99544500e-02, ...,\n",
      "           5.76000065e-02,  3.79819050e-02, -2.49533309e-03],\n",
      "         [ 1.66381523e-02,  1.99014135e-02, -3.94644700e-02, ...,\n",
      "           3.10615078e-02, -4.08862391e-03,  5.63136265e-02],\n",
      "         [ 1.12016043e-02,  4.94281761e-03,  6.85606524e-02, ...,\n",
      "           5.52387238e-02,  3.96206640e-02,  1.96931940e-02]],\n",
      "\n",
      "        [[-4.04639617e-02,  8.75218585e-02, -5.02413660e-02, ...,\n",
      "           1.00147277e-04,  2.53302883e-02, -2.51448248e-02],\n",
      "         [ 7.97802657e-02,  2.57235356e-02,  1.39769912e-03, ...,\n",
      "           4.36166860e-02,  1.54562024e-02,  3.73999216e-02],\n",
      "         [ 4.48197648e-02, -4.11357684e-03,  5.97398393e-02, ...,\n",
      "          -5.01372665e-02,  3.55852060e-02, -4.89547476e-02],\n",
      "         ...,\n",
      "         [ 6.78172428e-03,  2.65323054e-02,  2.92290021e-02, ...,\n",
      "           1.47451060e-02,  1.48690650e-02,  1.27545986e-02],\n",
      "         [ 7.03478977e-02,  2.11544819e-02, -1.27567584e-02, ...,\n",
      "           4.63326601e-03, -1.97178815e-02,  2.95281224e-03],\n",
      "         [ 1.35803111e-02, -3.24958153e-02,  3.61376181e-02, ...,\n",
      "           3.02693876e-03,  2.54088663e-03, -1.41674757e-03]]]],\n",
      "      dtype=float32), array([-1.84378587e-02, -2.56198533e-02,  2.44254526e-03, -1.49867292e-02,\n",
      "       -2.76608467e-02, -3.29968263e-03, -7.06339628e-03,  1.28162149e-02,\n",
      "       -1.90351624e-02, -1.18045481e-02,  3.58109792e-05,  9.98847187e-03,\n",
      "       -6.75915694e-03, -1.81453787e-02,  7.19445874e-04, -1.14616621e-02,\n",
      "       -8.43865052e-03,  1.76918140e-04, -3.50336097e-02, -3.67838927e-02,\n",
      "       -1.08325658e-02, -1.75117776e-02, -1.68335531e-02, -1.61604350e-03,\n",
      "       -3.14809047e-02,  1.10071385e-02,  1.61639380e-03, -1.55825894e-02,\n",
      "       -2.18790565e-02,  4.04031901e-03, -2.59953234e-02, -9.05711297e-03,\n",
      "       -1.33932987e-03,  2.14614775e-02, -1.42005486e-02, -3.12604047e-02,\n",
      "       -9.23152827e-03, -1.47867911e-02, -1.72445143e-03, -1.07600484e-02,\n",
      "        9.86382365e-03, -1.99069385e-03, -1.10997655e-03,  1.24360705e-02,\n",
      "       -2.21971162e-02, -1.31640388e-02,  5.48842887e-04, -6.55725645e-03],\n",
      "      dtype=float32)]\n",
      "[array([1.0077908 , 0.9956464 , 0.99164337, 1.0138867 , 1.0263128 ,\n",
      "       0.9904284 , 1.0082966 , 0.9773222 , 0.9785563 , 0.99261105,\n",
      "       0.97850716, 0.9052218 , 1.0090013 , 0.99055076, 0.9115562 ,\n",
      "       1.0046382 , 1.0658648 , 0.9915311 , 1.0674868 , 1.0326953 ,\n",
      "       0.9891711 , 1.0283539 , 1.0095133 , 0.9806152 , 0.9808248 ,\n",
      "       1.044803  , 0.9881268 , 1.0642153 , 0.98135185, 0.9967515 ,\n",
      "       1.0149119 , 1.0153885 , 0.9483359 , 0.99181306, 1.0318522 ,\n",
      "       1.0291559 , 0.9534514 , 0.97386575, 1.0154431 , 0.99001   ,\n",
      "       0.98534   , 1.0125476 , 1.0316243 , 0.9700282 , 1.064613  ,\n",
      "       0.96419114, 1.0094867 , 0.9820189 ], dtype=float32), array([ 0.01805429, -0.00254661,  0.02994197, -0.02077198, -0.00011048,\n",
      "        0.02178862,  0.0207116 ,  0.00288967,  0.00618164,  0.01596793,\n",
      "        0.02209488,  0.04495865, -0.01650043,  0.01157781, -0.01339408,\n",
      "        0.0389719 ,  0.03422091,  0.02157081, -0.03653555,  0.05427717,\n",
      "        0.02084522, -0.04871897,  0.03629858, -0.02410506,  0.00602716,\n",
      "        0.00911799,  0.01845975, -0.03446562, -0.01239695,  0.00216665,\n",
      "       -0.02410401, -0.01483689, -0.01368045,  0.00347428,  0.00858786,\n",
      "       -0.03903095,  0.02535888,  0.01144606, -0.0161249 , -0.00214266,\n",
      "       -0.01208845,  0.0304495 ,  0.01252086, -0.00991662,  0.01061968,\n",
      "        0.02042844,  0.00918133,  0.00376856], dtype=float32), array([0.20599648, 0.26252472, 1.0489768 , 0.312655  , 0.47586706,\n",
      "       0.38252014, 0.29388058, 0.80733126, 0.47987923, 0.24750093,\n",
      "       0.7746725 , 0.07355542, 0.29321715, 0.18890125, 0.30778924,\n",
      "       0.23273125, 0.55178976, 0.23999955, 0.4679796 , 0.2558148 ,\n",
      "       0.33013275, 0.2672543 , 0.19166538, 0.6612123 , 0.33185193,\n",
      "       0.6294909 , 0.39586338, 0.26820827, 0.9371655 , 0.7709148 ,\n",
      "       0.43002287, 0.16412628, 0.7624854 , 0.41101307, 0.38058275,\n",
      "       0.1949558 , 0.38951394, 0.19344932, 0.80249625, 0.21146996,\n",
      "       0.4383133 , 0.2658948 , 0.55357695, 0.29138467, 0.3702922 ,\n",
      "       0.36984622, 0.47711322, 0.9558575 ], dtype=float32), array([0.30440253, 0.64350486, 1.8649701 , 0.5047432 , 1.955731  ,\n",
      "       0.91813153, 0.80936664, 1.4123144 , 1.5984709 , 0.26381743,\n",
      "       0.8887145 , 0.18625203, 0.7338627 , 0.5344795 , 0.36787826,\n",
      "       0.31134844, 0.84617716, 0.7261019 , 1.3164209 , 0.76758546,\n",
      "       0.36079288, 0.8027086 , 0.35686246, 1.0655941 , 0.7866668 ,\n",
      "       1.3491056 , 0.9502434 , 1.0011836 , 1.900671  , 1.6709762 ,\n",
      "       0.9931275 , 0.32560003, 1.1056689 , 0.64777577, 0.87382287,\n",
      "       0.36227393, 0.51121354, 0.35721365, 2.049762  , 0.2880077 ,\n",
      "       0.6878883 , 0.7714797 , 0.9430873 , 0.33026686, 1.1988703 ,\n",
      "       0.85508686, 1.4566342 , 1.7200899 ], dtype=float32)]\n",
      "[]\n",
      "[array([[[[ 1.47396866e-02, -2.80399695e-02, -1.05360132e-02, ...,\n",
      "          -1.85442884e-02,  2.97650471e-02,  2.13892087e-02],\n",
      "         [-1.18721565e-02,  1.05243679e-02,  4.74640653e-02, ...,\n",
      "          -2.02098731e-02,  3.22266878e-03, -3.86175103e-02],\n",
      "         [ 4.78483774e-02,  6.05884520e-03,  2.65002362e-02, ...,\n",
      "          -3.41933519e-02, -1.21611198e-02,  4.05861484e-03],\n",
      "         ...,\n",
      "         [-5.90613708e-02,  5.91549370e-03,  8.21830425e-03, ...,\n",
      "          -2.97144316e-02,  3.62787023e-02, -7.23206997e-02],\n",
      "         [-5.64305075e-02, -1.68707296e-02,  1.66686028e-02, ...,\n",
      "           3.01209651e-02,  3.93189490e-02, -3.81493196e-02],\n",
      "         [ 3.72387730e-02, -9.72394773e-04, -2.76781786e-02, ...,\n",
      "           2.54250113e-02, -5.25275059e-02,  3.99675593e-02]],\n",
      "\n",
      "        [[-5.88435233e-02,  7.41142109e-02,  2.04465576e-02, ...,\n",
      "          -7.23164231e-02,  3.89123475e-03, -5.52080609e-02],\n",
      "         [-4.84918989e-02,  2.91540027e-02,  3.55155468e-02, ...,\n",
      "          -9.51321702e-03, -9.33438074e-03, -3.45019693e-03],\n",
      "         [ 5.22108264e-02,  3.04201897e-02, -2.49618590e-02, ...,\n",
      "          -2.78399605e-02,  6.10465556e-02,  2.87802014e-02],\n",
      "         ...,\n",
      "         [-2.35965382e-02,  8.16510711e-03, -1.50647433e-02, ...,\n",
      "          -1.55244833e-02,  3.37587297e-02, -3.66654918e-02],\n",
      "         [-1.56127028e-02,  5.00402376e-02,  1.18120564e-02, ...,\n",
      "           4.49898504e-02, -1.23187229e-02,  5.54356389e-02],\n",
      "         [ 4.50613685e-02, -6.27452359e-02,  8.61686002e-03, ...,\n",
      "          -3.04528158e-02,  3.81109444e-03,  1.63003858e-02]],\n",
      "\n",
      "        [[-3.95303480e-02,  4.58695786e-03, -4.22454961e-02, ...,\n",
      "          -7.43903965e-02,  3.70137170e-02,  4.30215672e-02],\n",
      "         [ 7.60460086e-03, -4.88667609e-03,  4.08443203e-03, ...,\n",
      "          -5.31852953e-02,  1.06403651e-02,  3.17144282e-02],\n",
      "         [ 4.42085639e-02, -2.14408636e-02,  1.74372178e-02, ...,\n",
      "          -8.27448349e-03,  4.17167228e-03, -8.27821437e-03],\n",
      "         ...,\n",
      "         [-1.12875270e-04,  2.83296667e-02, -8.93738493e-03, ...,\n",
      "          -2.08033826e-02,  4.75128219e-02,  4.27493863e-02],\n",
      "         [ 7.96943344e-03,  6.88451976e-02,  2.82228533e-02, ...,\n",
      "          -4.01251912e-02, -2.96495929e-02, -7.73004768e-03],\n",
      "         [ 3.70559953e-02, -2.90854201e-02, -5.86278690e-03, ...,\n",
      "           2.96049472e-03, -4.20994163e-02,  1.49782223e-03]],\n",
      "\n",
      "        [[-5.30537125e-03,  6.87187687e-02,  7.67397042e-03, ...,\n",
      "          -1.02369793e-01, -2.91079357e-02,  1.67102937e-03],\n",
      "         [ 2.07436215e-02, -1.01805525e-02, -7.37456009e-02, ...,\n",
      "           4.08701636e-02, -1.20432526e-02, -2.36586831e-03],\n",
      "         [ 1.86961181e-02, -6.30859332e-03,  1.48207238e-02, ...,\n",
      "          -2.11070944e-02, -3.29668373e-02, -2.27492973e-02],\n",
      "         ...,\n",
      "         [-1.02762701e-02,  1.38457846e-02, -5.02636880e-02, ...,\n",
      "          -5.48307411e-03,  3.22179422e-02, -5.24445586e-02],\n",
      "         [-7.72502497e-02,  4.56711091e-03, -5.48397005e-02, ...,\n",
      "           1.21446410e-02, -8.86142603e-04,  2.93866359e-03],\n",
      "         [ 1.04064681e-02, -2.39299517e-02, -1.99218895e-02, ...,\n",
      "          -1.35189481e-02, -1.30902110e-02,  4.49283980e-02]],\n",
      "\n",
      "        [[ 1.87464543e-02,  1.51780006e-02,  1.93114835e-03, ...,\n",
      "          -1.00987814e-02,  5.97592071e-02,  8.92271660e-03],\n",
      "         [ 3.47998436e-03,  5.25101349e-02, -2.82875337e-02, ...,\n",
      "           8.53980612e-03,  6.14770427e-02, -3.81140597e-02],\n",
      "         [-3.76291461e-02,  2.22814223e-03,  3.99923418e-03, ...,\n",
      "           6.77478383e-04, -3.73818986e-02, -4.42513786e-02],\n",
      "         ...,\n",
      "         [-7.72081595e-03,  1.61212459e-02, -2.33788902e-04, ...,\n",
      "           5.24966195e-02,  3.93734090e-02, -3.33874635e-02],\n",
      "         [-5.70915714e-02, -3.09786834e-02, -5.70499562e-02, ...,\n",
      "           1.05198286e-02, -2.37385370e-02, -2.35158894e-02],\n",
      "         [ 1.51711302e-02, -7.76264444e-02, -9.78938770e-03, ...,\n",
      "          -4.02566902e-02,  1.06477914e-02,  3.12511921e-02]]],\n",
      "\n",
      "\n",
      "       [[[-6.29603118e-03, -1.46356714e-03, -1.89644881e-02, ...,\n",
      "          -5.83188087e-02,  8.18272382e-02,  3.50248143e-02],\n",
      "         [-3.00673507e-02,  3.97930779e-02,  4.76158932e-02, ...,\n",
      "           2.43429728e-02, -1.36833359e-02, -1.65178422e-02],\n",
      "         [-2.58426666e-02, -2.74374206e-02, -5.80658717e-03, ...,\n",
      "           2.89750975e-02, -1.73217729e-02,  2.14330684e-02],\n",
      "         ...,\n",
      "         [-1.24214892e-03,  1.54051566e-02,  3.44868973e-02, ...,\n",
      "          -6.54805859e-04,  4.41360325e-02, -6.13643825e-02],\n",
      "         [-3.07753161e-02, -5.87827191e-02,  2.43548807e-02, ...,\n",
      "           9.75516718e-03,  1.52094355e-02, -5.37273521e-03],\n",
      "         [-4.68473509e-03,  1.14472890e-02,  4.11555506e-02, ...,\n",
      "          -5.76347709e-02, -4.16369438e-02, -6.99654818e-02]],\n",
      "\n",
      "        [[-4.06004936e-02,  2.00646184e-03,  8.48921575e-03, ...,\n",
      "          -4.14568968e-02,  2.07487009e-02,  3.36613804e-02],\n",
      "         [ 9.92879085e-03, -4.07602265e-02, -6.59500249e-03, ...,\n",
      "           3.69242281e-02, -2.84387264e-02, -1.31232236e-02],\n",
      "         [-9.86905396e-03, -3.79426703e-02, -3.54602523e-02, ...,\n",
      "          -2.01975163e-02,  4.83480319e-02, -8.82679306e-05],\n",
      "         ...,\n",
      "         [ 4.65058871e-02, -4.50583845e-02, -5.12769632e-03, ...,\n",
      "          -2.64858566e-02, -6.10730797e-02, -2.50086673e-02],\n",
      "         [ 4.59303148e-02,  1.46147860e-02,  5.06088920e-02, ...,\n",
      "           4.01934162e-02, -3.25675048e-02,  2.74060238e-02],\n",
      "         [ 4.38407296e-03,  6.82252878e-03,  1.71459001e-02, ...,\n",
      "          -6.95297122e-02,  6.16614427e-03, -4.47268002e-02]],\n",
      "\n",
      "        [[-5.49489707e-02, -4.04805392e-02, -2.54223272e-02, ...,\n",
      "           1.18390529e-03,  4.55327258e-02,  2.28428245e-02],\n",
      "         [ 8.20420012e-02,  1.80138145e-02,  2.27339957e-02, ...,\n",
      "          -2.52790470e-02,  2.17362605e-02, -4.11601774e-02],\n",
      "         [ 3.39893950e-03, -6.28153905e-02,  2.77948380e-02, ...,\n",
      "          -1.24421176e-02,  8.76780748e-02, -6.05732854e-03],\n",
      "         ...,\n",
      "         [ 3.49410810e-02, -6.11218028e-02,  4.96039689e-02, ...,\n",
      "           3.99806872e-02, -4.24199626e-02,  1.20723061e-02],\n",
      "         [-7.07760779e-03,  3.52738537e-02, -1.41849220e-02, ...,\n",
      "          -7.60862976e-03, -8.53006393e-02, -1.19528286e-02],\n",
      "         [ 3.95385511e-02, -1.81033462e-02, -7.16205612e-02, ...,\n",
      "           4.01011705e-02,  6.91255461e-03, -4.91508059e-02]],\n",
      "\n",
      "        [[-8.37799981e-02, -2.87067909e-02,  2.22447403e-02, ...,\n",
      "          -3.25364759e-03,  8.43638703e-02, -2.32978538e-03],\n",
      "         [ 2.51424983e-02,  1.97814740e-02, -2.30980641e-03, ...,\n",
      "           4.48851213e-02,  1.16648525e-02,  1.79512575e-02],\n",
      "         [ 1.24454256e-02, -1.79077871e-02, -2.95521747e-02, ...,\n",
      "          -1.06222533e-01, -1.36271529e-02, -4.23176773e-02],\n",
      "         ...,\n",
      "         [ 4.86354008e-02, -7.26180151e-02,  5.23548760e-02, ...,\n",
      "           6.79813251e-02, -5.83773712e-03,  1.31673962e-02],\n",
      "         [ 4.83150370e-02,  1.19698991e-03, -3.99885848e-02, ...,\n",
      "          -7.25804344e-02,  3.34191183e-03,  2.19063368e-02],\n",
      "         [ 4.98361401e-02,  2.29002107e-02,  1.71194971e-02, ...,\n",
      "          -1.66008361e-02,  1.15927337e-02, -3.44795478e-03]],\n",
      "\n",
      "        [[-4.95510288e-02, -8.45064968e-02,  1.25992857e-02, ...,\n",
      "          -9.17053446e-02,  1.58037525e-02, -2.36519855e-02],\n",
      "         [ 1.70829371e-02, -4.28456292e-02, -7.40403961e-03, ...,\n",
      "           5.36066629e-02, -3.84449773e-02, -5.71310036e-02],\n",
      "         [ 2.47694869e-02, -5.28972968e-02,  1.11827732e-03, ...,\n",
      "          -8.78470764e-02,  7.45628104e-02, -2.52162721e-02],\n",
      "         ...,\n",
      "         [-1.36145949e-02, -1.40130781e-02,  6.98823994e-03, ...,\n",
      "           5.73817641e-02,  1.26267113e-02, -3.68064828e-02],\n",
      "         [-1.32044181e-02, -2.61804126e-02,  2.72836834e-02, ...,\n",
      "           2.86402553e-02, -4.77018207e-02,  2.17991769e-02],\n",
      "         [-1.16738407e-02,  7.78297288e-03, -7.72804543e-02, ...,\n",
      "          -1.17224082e-02, -2.20582839e-02,  3.21633474e-04]]],\n",
      "\n",
      "\n",
      "       [[[-3.93388979e-03,  6.21002391e-02,  2.57190038e-02, ...,\n",
      "          -1.61797423e-02, -7.11353542e-03,  8.26952141e-03],\n",
      "         [-2.31504068e-02,  1.78660136e-02,  1.40049635e-02, ...,\n",
      "          -2.06007306e-02,  2.04469380e-03, -1.51307303e-02],\n",
      "         [-8.48517381e-03, -4.51696515e-02,  4.24379744e-02, ...,\n",
      "           3.43813412e-02, -1.80770084e-02,  7.56502803e-03],\n",
      "         ...,\n",
      "         [ 3.15842368e-02, -2.01934837e-02, -1.19132344e-02, ...,\n",
      "          -3.19450013e-02, -4.13427912e-02, -5.05416840e-02],\n",
      "         [-1.07784616e-02, -3.67236845e-02, -3.52490917e-02, ...,\n",
      "          -6.42067846e-03,  1.81746893e-02, -4.96751927e-02],\n",
      "         [-6.43753633e-03, -9.75075085e-03,  6.00701198e-02, ...,\n",
      "           9.31382366e-03, -3.21083106e-02,  9.39026196e-03]],\n",
      "\n",
      "        [[ 6.25738874e-02, -3.56050320e-02, -1.25618943e-03, ...,\n",
      "          -1.28025180e-02, -2.27023307e-02, -4.23951894e-02],\n",
      "         [-3.54895890e-02,  2.98926570e-02,  3.11266482e-02, ...,\n",
      "           8.62199906e-03, -2.73083001e-02,  6.72857463e-02],\n",
      "         [-1.15915283e-03, -5.71644818e-03, -2.85565834e-02, ...,\n",
      "          -8.98781419e-03,  9.83127952e-03,  6.92333132e-02],\n",
      "         ...,\n",
      "         [ 1.65780149e-02, -2.08509881e-02, -1.96902938e-02, ...,\n",
      "          -2.75658742e-02, -5.99534623e-02,  4.44485061e-02],\n",
      "         [-4.71673422e-02, -3.27319652e-02, -1.76966209e-02, ...,\n",
      "           1.49282088e-04, -1.81983504e-02,  4.62053083e-02],\n",
      "         [ 6.53857365e-02, -3.30702364e-02, -2.39838753e-03, ...,\n",
      "          -2.51198485e-02,  1.53332381e-02,  9.80235729e-03]],\n",
      "\n",
      "        [[ 5.59843741e-02, -1.90815702e-02, -5.25684692e-02, ...,\n",
      "           7.84832984e-03, -4.29142974e-02,  6.43753409e-02],\n",
      "         [-3.11727617e-02,  2.45954618e-02, -1.73262693e-02, ...,\n",
      "           7.86664709e-02,  5.83341829e-02, -1.01852398e-02],\n",
      "         [-2.45011188e-02, -4.34138104e-02, -7.08879158e-02, ...,\n",
      "           1.85553208e-02,  3.23433317e-02, -4.08553034e-02],\n",
      "         ...,\n",
      "         [-1.53178060e-02,  1.64187402e-02, -6.96772784e-02, ...,\n",
      "          -2.18740441e-02, -4.38101850e-02, -4.97084036e-02],\n",
      "         [ 8.67610425e-03, -8.86951536e-02, -3.22420746e-02, ...,\n",
      "           2.19646692e-02, -1.93644706e-02,  2.92167929e-03],\n",
      "         [ 9.21670794e-02,  8.26828927e-03,  4.84323874e-02, ...,\n",
      "          -6.91541582e-02, -1.63901988e-02, -6.13588747e-03]],\n",
      "\n",
      "        [[-2.38347761e-02, -4.42975797e-02,  3.04754358e-02, ...,\n",
      "          -7.12009193e-03,  7.12047666e-02,  3.63971703e-02],\n",
      "         [-4.57282476e-02,  4.31556962e-02,  5.41801564e-03, ...,\n",
      "           2.44959388e-02, -3.04832160e-02, -4.35751444e-03],\n",
      "         [-7.82648474e-02, -4.86595742e-02,  5.03754355e-02, ...,\n",
      "           2.75012199e-02,  3.68066616e-02,  2.46008355e-02],\n",
      "         ...,\n",
      "         [ 1.34429522e-02,  2.13772878e-02,  2.83391960e-03, ...,\n",
      "          -5.62886596e-02, -2.10388694e-02, -1.09767169e-03],\n",
      "         [ 4.08490598e-02, -5.24860099e-02, -5.43470122e-02, ...,\n",
      "           2.81880740e-02, -6.26480067e-03, -1.73163172e-02],\n",
      "         [ 5.91459163e-02,  4.75697638e-03,  7.28767291e-02, ...,\n",
      "           3.67906168e-02, -4.40017618e-02,  1.36741791e-02]],\n",
      "\n",
      "        [[-5.27761020e-02, -6.29283711e-02,  4.56530340e-02, ...,\n",
      "          -8.34636986e-02,  6.85230456e-03,  1.07727861e-02],\n",
      "         [ 3.74236284e-03, -2.24618278e-02,  1.40629932e-02, ...,\n",
      "           7.90901762e-03,  1.91327240e-02, -2.52820253e-02],\n",
      "         [-2.96878554e-02, -5.62152714e-02, -1.72879007e-02, ...,\n",
      "          -1.44511303e-02,  2.36639921e-02,  1.61462333e-02],\n",
      "         ...,\n",
      "         [ 3.41035351e-02,  2.63570249e-02,  3.11271660e-02, ...,\n",
      "          -1.44714387e-02,  3.02327573e-02, -1.99582409e-02],\n",
      "         [ 1.02407429e-02,  2.45405212e-02,  4.33608964e-02, ...,\n",
      "          -4.85539548e-02, -3.37718911e-02, -2.95630116e-02],\n",
      "         [ 1.63309071e-02, -4.51661181e-03,  2.08141301e-02, ...,\n",
      "          -2.07941085e-02,  3.99791673e-02, -3.97420228e-02]]],\n",
      "\n",
      "\n",
      "       [[[-2.99163368e-02, -4.01600488e-02,  4.22443151e-02, ...,\n",
      "           3.04312166e-02,  3.37830302e-03, -6.28497824e-02],\n",
      "         [-2.86173318e-02,  2.18030959e-02, -4.51885583e-03, ...,\n",
      "           1.12827141e-02,  1.77723467e-02, -1.03327325e-02],\n",
      "         [-2.97770519e-02,  5.56500852e-02,  4.26375233e-02, ...,\n",
      "          -4.79886914e-03,  8.99582915e-03,  1.08926371e-03],\n",
      "         ...,\n",
      "         [ 1.69321746e-02, -1.47117423e-02,  4.47804704e-02, ...,\n",
      "          -6.66253567e-02, -2.99202241e-02,  5.14369048e-02],\n",
      "         [-2.80945115e-02, -2.78469473e-02, -3.35404016e-02, ...,\n",
      "          -4.45691906e-02,  6.40116781e-02, -4.33437862e-02],\n",
      "         [-3.30663398e-02,  8.49181321e-03, -2.69027855e-02, ...,\n",
      "          -2.16219053e-02, -9.32350289e-04, -2.46073585e-02]],\n",
      "\n",
      "        [[-1.89239997e-02,  2.66285371e-02,  1.55267278e-02, ...,\n",
      "           2.67559960e-02,  7.51756206e-02,  2.87209712e-02],\n",
      "         [ 8.58830661e-03, -4.32155170e-02, -3.82922702e-02, ...,\n",
      "           7.56082404e-03,  3.07270768e-03, -3.65182497e-02],\n",
      "         [ 1.01956343e-02,  3.67560908e-02,  2.37785727e-02, ...,\n",
      "          -4.94407453e-02, -8.36216751e-03, -4.37900387e-02],\n",
      "         ...,\n",
      "         [-5.81878982e-02,  2.54597645e-02,  7.46464217e-03, ...,\n",
      "           2.30935216e-02, -3.10730729e-02,  1.73375681e-02],\n",
      "         [-6.02679774e-02, -8.68771784e-03, -3.77154797e-02, ...,\n",
      "           2.79254112e-02,  5.79721741e-02, -2.37081405e-02],\n",
      "         [-1.15892626e-02,  2.01006196e-02, -3.80755849e-02, ...,\n",
      "           2.80490443e-02,  2.55193398e-03,  4.22198474e-02]],\n",
      "\n",
      "        [[-1.21565182e-02, -5.39261550e-02,  6.68600248e-03, ...,\n",
      "          -3.80908744e-03,  3.64557952e-02, -3.21020707e-02],\n",
      "         [ 1.28214573e-02, -2.58319266e-02, -2.40692198e-02, ...,\n",
      "           5.69690056e-02,  3.92962620e-02, -1.83679033e-02],\n",
      "         [-1.98181849e-02,  2.24040523e-02, -3.69752869e-02, ...,\n",
      "           3.38045247e-02,  1.46248995e-03,  4.78708260e-02],\n",
      "         ...,\n",
      "         [-3.28142308e-02, -8.21509771e-03, -3.31184790e-02, ...,\n",
      "          -1.85886864e-02,  1.82920154e-02, -2.28560232e-02],\n",
      "         [-3.00092828e-02,  4.45084423e-02,  2.45411787e-03, ...,\n",
      "           3.55053619e-02,  1.62352007e-02, -1.30996928e-02],\n",
      "         [-7.59198470e-03,  3.14454245e-03,  3.00192833e-03, ...,\n",
      "          -5.30751906e-02,  9.79865436e-03,  8.94655101e-03]],\n",
      "\n",
      "        [[-1.49211194e-02,  4.95158844e-02,  3.13472971e-02, ...,\n",
      "           8.53400677e-03,  1.27558094e-02, -3.34343687e-02],\n",
      "         [-3.79114109e-03, -3.54967602e-02, -1.12908706e-02, ...,\n",
      "          -3.59633565e-02,  5.79072442e-03,  4.56666239e-02],\n",
      "         [-7.55672250e-03,  3.21155484e-03,  1.94254853e-02, ...,\n",
      "          -7.05288202e-02,  5.27297147e-02, -2.44653970e-03],\n",
      "         ...,\n",
      "         [ 2.54891738e-02, -1.70492921e-02,  2.60835718e-02, ...,\n",
      "           1.02799935e-02,  1.37670133e-02,  6.85521737e-02],\n",
      "         [-9.90331266e-03, -3.22238309e-03,  4.19132821e-02, ...,\n",
      "          -4.93862107e-02,  2.49283835e-02, -2.11411938e-02],\n",
      "         [-5.54386787e-02,  1.32005913e-02,  2.23362111e-02, ...,\n",
      "          -4.40148897e-02,  3.86097073e-03,  1.01816759e-03]],\n",
      "\n",
      "        [[-1.50822466e-02, -7.43595650e-04,  3.20834555e-02, ...,\n",
      "           1.70058422e-02,  2.13129073e-02, -6.31283820e-02],\n",
      "         [ 8.07366520e-02, -1.50027610e-02,  3.66771035e-02, ...,\n",
      "           4.83328803e-03,  3.22226621e-02,  8.42572376e-03],\n",
      "         [-2.82056211e-03,  3.77720930e-02, -4.38290052e-02, ...,\n",
      "           1.07009048e-02,  2.00531725e-03,  5.11304650e-04],\n",
      "         ...,\n",
      "         [-5.62394597e-02,  4.89953570e-02,  4.00308110e-02, ...,\n",
      "           3.30266496e-03,  1.97874550e-02,  3.47912265e-03],\n",
      "         [ 6.68601505e-03,  6.45924658e-02,  1.80717502e-02, ...,\n",
      "           2.13031434e-02, -7.78217055e-03, -3.19480300e-02],\n",
      "         [-5.62549233e-02,  4.32520360e-02, -1.70833860e-02, ...,\n",
      "          -3.84767167e-02,  1.66571755e-02,  4.98002917e-02]]],\n",
      "\n",
      "\n",
      "       [[[-5.27777001e-02,  7.34026060e-02,  3.00370809e-03, ...,\n",
      "           7.02487007e-02, -4.93501127e-02,  1.23418598e-02],\n",
      "         [-4.55007255e-02, -6.66138008e-02,  5.30273318e-02, ...,\n",
      "          -9.82030397e-05, -2.93444321e-02,  1.73905473e-02],\n",
      "         [ 1.95508767e-02, -9.63007286e-03,  2.26354785e-03, ...,\n",
      "          -5.58229797e-02, -4.13649343e-02, -1.93512661e-03],\n",
      "         ...,\n",
      "         [ 3.78293991e-02, -4.63524126e-02,  2.43217195e-03, ...,\n",
      "          -6.02803007e-02,  5.35811670e-02,  1.33248325e-02],\n",
      "         [-3.59853059e-02, -2.72463206e-02,  5.28614707e-02, ...,\n",
      "           2.96507515e-02, -1.96854789e-02, -2.91702803e-02],\n",
      "         [-1.07141556e-02,  4.77129817e-02, -1.44023420e-02, ...,\n",
      "           4.85343151e-02,  3.04429792e-02, -7.10032787e-03]],\n",
      "\n",
      "        [[ 1.54887363e-02, -2.76606344e-03,  2.15050299e-03, ...,\n",
      "           4.96814288e-02,  1.02419285e-02,  5.45107061e-03],\n",
      "         [ 1.63998362e-02,  4.55942601e-02, -1.71429217e-02, ...,\n",
      "          -9.83922463e-03,  3.51908989e-02, -1.79637019e-02],\n",
      "         [-4.56930511e-02, -2.13217083e-02, -3.11463363e-02, ...,\n",
      "          -3.60953771e-02,  4.63864319e-02,  2.62360573e-02],\n",
      "         ...,\n",
      "         [-2.65593510e-02,  1.19339675e-02,  2.31107976e-02, ...,\n",
      "          -5.61372079e-02, -3.08290799e-03, -3.01165506e-02],\n",
      "         [-3.15955840e-02, -8.89539067e-03,  2.23602797e-03, ...,\n",
      "          -4.60316017e-02, -3.89769077e-02, -3.03114746e-02],\n",
      "         [ 1.92117263e-02, -1.34930899e-02, -6.50097281e-02, ...,\n",
      "          -1.54371317e-02,  1.48019269e-02,  4.59382534e-02]],\n",
      "\n",
      "        [[ 9.76101011e-02, -1.50894960e-02,  1.97447576e-02, ...,\n",
      "          -1.40522262e-02, -5.51425340e-03, -2.37993477e-03],\n",
      "         [-2.16122307e-02,  3.75849046e-02,  4.29719388e-02, ...,\n",
      "          -1.44047923e-02,  2.73075048e-02,  2.58653294e-02],\n",
      "         [-2.73028575e-02,  3.72421406e-02,  3.84140015e-02, ...,\n",
      "           1.80779193e-02,  7.54533568e-03, -4.34997771e-03],\n",
      "         ...,\n",
      "         [ 6.15276992e-02, -1.77844204e-02, -2.30727158e-02, ...,\n",
      "           1.21876495e-02,  6.89055473e-02,  4.00513411e-02],\n",
      "         [-7.30795506e-03, -3.82898338e-02,  4.57459167e-02, ...,\n",
      "          -7.05877244e-02, -6.23573959e-02, -5.07217012e-02],\n",
      "         [-3.82763818e-02,  4.14072834e-02, -4.09416482e-02, ...,\n",
      "           4.98859547e-02,  3.95347998e-02, -2.71501336e-02]],\n",
      "\n",
      "        [[ 3.65261957e-02,  4.32313792e-02,  4.06764261e-03, ...,\n",
      "           4.42499332e-02,  4.33795201e-03,  6.08190289e-03],\n",
      "         [-8.73174425e-03, -7.28825927e-02,  6.34499080e-03, ...,\n",
      "          -3.65202799e-02,  4.03735191e-02, -3.04018473e-03],\n",
      "         [-3.14856023e-02,  7.50980980e-04, -3.19771208e-02, ...,\n",
      "          -3.91969942e-02, -4.37253416e-02,  3.89160844e-03],\n",
      "         ...,\n",
      "         [-3.45565611e-03,  6.16055690e-02,  5.61553473e-03, ...,\n",
      "          -1.44223338e-02, -1.23263672e-02,  1.44539569e-02],\n",
      "         [-1.95708349e-02, -3.88811082e-02, -2.93857651e-03, ...,\n",
      "          -8.70401412e-02,  1.25565659e-02, -4.54739742e-02],\n",
      "         [-3.59017365e-02,  1.27488170e-02, -4.28609215e-02, ...,\n",
      "          -2.62814593e-02, -1.56252328e-02,  1.24236168e-02]],\n",
      "\n",
      "        [[ 5.42458482e-02,  5.60844243e-02,  8.41987785e-03, ...,\n",
      "           3.29576433e-02, -1.30951749e-02, -4.76957820e-02],\n",
      "         [ 6.60370570e-03,  1.87571831e-02, -3.16511951e-02, ...,\n",
      "          -3.36020291e-02,  6.83669373e-02,  4.05913815e-02],\n",
      "         [-6.71383068e-02,  3.70351709e-02, -1.50972474e-02, ...,\n",
      "          -7.04028783e-03, -2.70178150e-02,  3.61404084e-02],\n",
      "         ...,\n",
      "         [-5.59544424e-03, -5.16303536e-03,  9.44344886e-03, ...,\n",
      "           1.14531415e-02, -3.74723114e-02,  3.78251486e-02],\n",
      "         [-7.45815923e-03, -8.13273154e-03,  3.12584988e-03, ...,\n",
      "          -6.20160960e-02, -7.78620988e-02,  2.93051060e-02],\n",
      "         [ 4.16422151e-02, -1.55453826e-03,  2.08883695e-02, ...,\n",
      "           5.31763062e-02,  6.35308400e-03,  3.03083118e-02]]]],\n",
      "      dtype=float32), array([-0.02280284, -0.01474273, -0.00420499, -0.01197216, -0.02339649,\n",
      "       -0.03227406, -0.02127228, -0.01983516, -0.00782365, -0.04196557,\n",
      "        0.01017329, -0.00470914, -0.01351956,  0.01481548, -0.02034098,\n",
      "       -0.04147461, -0.01058164, -0.01355284, -0.0102788 , -0.02976199,\n",
      "       -0.03899811, -0.01626113, -0.01615101, -0.03292324, -0.00706607,\n",
      "        0.01014561, -0.01796513, -0.04445757, -0.01937626, -0.00795585,\n",
      "       -0.01990213, -0.01900016,  0.00159178, -0.05497962,  0.00015365,\n",
      "        0.02839392,  0.00433693, -0.0202602 , -0.00569807, -0.00368694,\n",
      "       -0.00610003, -0.02399696,  0.00562486, -0.02285723, -0.01504613,\n",
      "       -0.031444  , -0.00938   ,  0.00322778], dtype=float32)]\n",
      "[array([1.1903589 , 1.0247258 , 1.008313  , 0.9965062 , 1.1214424 ,\n",
      "       1.057982  , 0.99144787, 1.007753  , 0.9469155 , 1.1317514 ,\n",
      "       1.00907   , 0.9942606 , 0.99885535, 0.9907688 , 0.97629935,\n",
      "       1.0858123 , 0.96544313, 1.0275099 , 0.9735407 , 1.1401454 ,\n",
      "       1.0694687 , 0.9694367 , 0.95879006, 1.1197362 , 0.97324854,\n",
      "       1.0063505 , 1.0288643 , 1.1233096 , 1.073094  , 1.0767059 ,\n",
      "       1.0414306 , 1.0684855 , 0.9970268 , 1.0864699 , 0.9781464 ,\n",
      "       0.96409583, 0.9287677 , 1.0748775 , 0.97527105, 0.96394235,\n",
      "       0.95055705, 1.0123041 , 1.0460237 , 1.0108473 , 0.96540433,\n",
      "       1.1339055 , 1.0653007 , 1.00519   ], dtype=float32), array([-0.01668772, -0.01263255, -0.01401742, -0.02655476,  0.00263472,\n",
      "       -0.00901311, -0.03787959, -0.02345342, -0.01510484, -0.00310886,\n",
      "       -0.00200213,  0.00260874, -0.01229479, -0.04288351, -0.03391803,\n",
      "       -0.01898898, -0.01552179, -0.01711732,  0.00248259, -0.03129249,\n",
      "       -0.02779576, -0.02596545, -0.03561084, -0.01752863, -0.02989848,\n",
      "       -0.03371051, -0.0512163 , -0.01001022, -0.01462463,  0.00448211,\n",
      "       -0.02967638, -0.01221793, -0.0148143 , -0.02152556, -0.01011301,\n",
      "       -0.007882  , -0.01676113,  0.00363317, -0.02240608, -0.0225732 ,\n",
      "       -0.03228478, -0.01922527, -0.03288501, -0.01771819, -0.02860916,\n",
      "       -0.03467015, -0.00742317, -0.01729688], dtype=float32), array([0.15018517, 0.17141207, 0.28423932, 0.22138913, 0.06715434,\n",
      "       0.08379275, 0.45798305, 0.24180655, 0.34956893, 0.25465924,\n",
      "       0.22399293, 0.21989553, 0.28686905, 0.2292981 , 0.39182082,\n",
      "       0.13681547, 0.26903817, 0.05781287, 0.70520604, 0.18951891,\n",
      "       0.1743887 , 0.3135884 , 0.58715314, 0.20788734, 0.8815887 ,\n",
      "       0.30908522, 0.49503127, 0.07640258, 0.1419616 , 0.15698846,\n",
      "       0.20740423, 0.21672496, 0.7557438 , 0.14007646, 0.20212753,\n",
      "       0.2898618 , 1.7603692 , 0.2056615 , 0.6649048 , 0.29336765,\n",
      "       0.57861847, 0.15014067, 0.24344657, 0.31832185, 0.43751246,\n",
      "       0.21435654, 0.25996318, 0.60836077], dtype=float32), array([0.37764728, 0.4588872 , 0.5454076 , 0.48233536, 0.20714878,\n",
      "       0.23481251, 0.76996666, 0.61158067, 0.72090477, 0.40865818,\n",
      "       0.58385426, 0.22710429, 0.459075  , 0.42967463, 0.9155816 ,\n",
      "       0.3252884 , 0.50254947, 0.13973661, 1.7285649 , 0.47252443,\n",
      "       0.34614158, 0.6663137 , 1.5050049 , 0.5575396 , 1.0956155 ,\n",
      "       0.5637387 , 0.9763444 , 0.22961   , 0.32296598, 0.22309995,\n",
      "       0.33698085, 0.39751825, 1.4845577 , 0.3278722 , 0.2234634 ,\n",
      "       0.3476828 , 4.775992  , 0.6923861 , 1.2588509 , 0.33525684,\n",
      "       1.1525513 , 0.45889786, 0.4250459 , 0.839942  , 1.3102887 ,\n",
      "       0.33749261, 0.39577472, 0.9223028 ], dtype=float32)]\n",
      "[]\n",
      "[]\n",
      "[array([[ 0.04970691, -0.04448522, -0.01881781, ..., -0.04042488,\n",
      "        -0.0036926 , -0.03557941],\n",
      "       [ 0.01159345,  0.02345532, -0.03644028, ...,  0.02153164,\n",
      "        -0.00057414,  0.02227051],\n",
      "       [-0.0629172 ,  0.00368669, -0.04945921, ...,  0.05756026,\n",
      "        -0.02064406, -0.015093  ],\n",
      "       ...,\n",
      "       [-0.00365728, -0.03618271,  0.01998069, ..., -0.06606477,\n",
      "        -0.03684571, -0.0357057 ],\n",
      "       [ 0.04443177, -0.015413  , -0.0350078 , ..., -0.0571544 ,\n",
      "         0.06147446,  0.01485964],\n",
      "       [ 0.03510783,  0.05859754, -0.04830632, ...,  0.01917393,\n",
      "         0.05079778, -0.05871829]], dtype=float32), array([-0.00209912, -0.001865  , -0.00868807, -0.00079757,  0.00114019,\n",
      "       -0.00377593,  0.00709143, -0.0066455 ,  0.00838496,  0.00419792,\n",
      "        0.00106097, -0.0028084 ,  0.00612869,  0.00035788,  0.00349989,\n",
      "       -0.00243065, -0.0002505 , -0.0081816 , -0.01085627,  0.00123045,\n",
      "       -0.00403247, -0.00111887,  0.00081376, -0.00516983,  0.00011592,\n",
      "        0.00158459, -0.00449985,  0.00173417, -0.00199075, -0.00076902,\n",
      "       -0.00382321,  0.00061637, -0.00866577, -0.00694563, -0.00583572,\n",
      "       -0.00722554,  0.00047958,  0.00332472, -0.00195413, -0.01055972,\n",
      "        0.00161383, -0.00324914, -0.00309704, -0.00182685,  0.00554199,\n",
      "       -0.00171311,  0.00513811,  0.00866742, -0.00260412,  0.00800427,\n",
      "       -0.00954287, -0.00066874,  0.00204351,  0.0053894 , -0.00463967,\n",
      "       -0.00082491, -0.00886217,  0.00016154,  0.00378367, -0.00161737,\n",
      "        0.0019814 , -0.00648997, -0.00107252,  0.01013296], dtype=float32)]\n",
      "[]\n",
      "[array([[ 0.16225302,  0.00510032, -0.01251794, ...,  0.0600709 ,\n",
      "        -0.09607568,  0.06485357],\n",
      "       [ 0.1043802 ,  0.0903971 ,  0.03572106, ..., -0.12344847,\n",
      "         0.16071314,  0.17963108],\n",
      "       [-0.1683408 ,  0.09556998, -0.12301347, ..., -0.095362  ,\n",
      "         0.15064375, -0.06985371],\n",
      "       ...,\n",
      "       [ 0.00695278, -0.13067152,  0.03793769, ..., -0.17263378,\n",
      "        -0.12483014,  0.06639306],\n",
      "       [ 0.01880714,  0.11094748,  0.01149488, ...,  0.0840482 ,\n",
      "        -0.16379729,  0.02430042],\n",
      "       [ 0.03223965, -0.02566149,  0.12594646, ..., -0.06806481,\n",
      "         0.0696744 , -0.06484409]], dtype=float32), array([ 2.71821320e-02,  1.06191030e-02,  2.15328149e-02, -1.00724178e-03,\n",
      "        1.07554505e-02,  1.41409049e-02,  3.78127694e-02,  4.62465733e-02,\n",
      "        8.96290317e-03,  4.75028157e-02, -2.22018617e-03, -1.12296911e-02,\n",
      "        9.12013352e-02,  5.25603443e-02, -1.87779274e-02, -6.54936943e-04,\n",
      "        2.73620822e-02,  1.52158421e-02,  2.60678753e-02,  4.01268480e-03,\n",
      "        5.56325354e-02,  1.03241792e-02, -3.56772132e-02, -9.37113538e-03,\n",
      "        5.68804098e-03, -9.43301991e-03,  5.57812443e-03, -9.26378998e-04,\n",
      "        1.70059148e-02,  3.11601739e-02, -8.31552502e-03, -1.16046323e-02,\n",
      "        1.30993072e-02,  2.25773584e-02, -7.21764145e-03,  4.85980809e-02,\n",
      "        7.26201525e-03, -1.16206221e-02, -1.32935552e-03, -2.33389530e-02,\n",
      "        2.01678649e-02, -9.80971102e-03, -8.93590879e-03, -1.47667620e-02,\n",
      "        6.46897033e-02,  1.04528908e-02, -2.25427449e-02,  7.93198310e-03,\n",
      "       -4.38946998e-03,  8.50105938e-03, -1.82833965e-03,  8.60019475e-02,\n",
      "       -2.49540322e-02,  3.26727740e-02, -8.23828951e-03, -3.79734626e-03,\n",
      "        1.87135004e-02,  4.41771969e-02,  3.78981903e-02, -3.71667696e-03,\n",
      "        3.00654415e-02,  2.93950792e-02, -1.94430239e-02,  1.62595753e-02,\n",
      "        5.25307879e-02,  4.24763598e-02, -1.99671295e-02,  5.66477887e-03,\n",
      "        2.75627039e-02, -6.00509113e-03,  8.11551977e-03, -2.32091006e-02,\n",
      "        1.18828621e-02,  1.33536058e-02,  1.21677116e-01,  7.70759629e-03,\n",
      "       -4.53109993e-03, -1.31211441e-03,  2.30145603e-02,  3.63788307e-02,\n",
      "        9.96963307e-03,  5.56416847e-02,  8.48241244e-03,  5.19247502e-02,\n",
      "       -3.20872013e-03,  2.33735871e-02, -1.13702891e-02, -7.60549866e-03,\n",
      "        1.29138185e-02,  8.11252557e-03,  6.97776489e-03,  4.14839126e-02,\n",
      "        5.73488288e-02,  1.42968167e-02, -1.46786096e-02,  3.00212018e-02,\n",
      "        6.09757192e-02,  1.84483007e-02, -4.99956822e-03, -9.45284497e-03,\n",
      "        8.29626340e-03,  5.13734110e-03, -9.66584776e-03,  2.70950608e-02,\n",
      "        1.37535542e-01, -1.62962452e-02,  4.44310755e-02, -9.54449642e-03,\n",
      "        2.98063699e-02, -1.92114823e-02,  5.18182945e-03, -1.68438873e-03,\n",
      "       -1.53199174e-02,  2.91824806e-02,  5.09247370e-02,  4.71787229e-02,\n",
      "        1.55497054e-02, -1.31095219e-02, -3.57131958e-02, -3.05544529e-02,\n",
      "        2.55728569e-02,  2.29916424e-02, -2.86994346e-05,  1.00461118e-01,\n",
      "        5.57427062e-03, -1.83679890e-02,  1.94170931e-03,  6.90119043e-02],\n",
      "      dtype=float32)]\n",
      "[array([[-1.18113786e-01, -8.20877552e-02,  8.85227174e-02,\n",
      "        -2.13178188e-01, -1.64443165e-01],\n",
      "       [-5.43603301e-02,  3.12374175e-01,  9.13146436e-02,\n",
      "        -2.27131933e-01,  1.43193081e-01],\n",
      "       [-1.06276885e-01,  3.35917443e-01, -5.38303517e-02,\n",
      "         2.26786420e-01, -1.82681590e-01],\n",
      "       [-1.73548654e-01,  1.03381358e-01, -1.00461684e-01,\n",
      "         7.01295212e-02, -1.15976125e-01],\n",
      "       [ 1.45108327e-01,  2.11192682e-01, -1.66520581e-01,\n",
      "        -1.81507155e-01, -1.74425349e-01],\n",
      "       [ 1.27451479e-01,  5.08601405e-02,  1.62543148e-01,\n",
      "        -9.69377235e-02,  1.50413260e-01],\n",
      "       [-3.94420512e-02, -2.45504916e-01, -3.01224440e-02,\n",
      "         2.78696388e-01, -2.08237977e-03],\n",
      "       [ 3.30287009e-01, -1.89002603e-01, -1.51903480e-01,\n",
      "         1.83626384e-01, -1.73148569e-02],\n",
      "       [ 1.23469479e-01, -4.76494282e-02, -8.82515013e-02,\n",
      "        -1.96054652e-01, -3.55137959e-02],\n",
      "       [ 5.41049875e-02, -1.65046826e-01,  9.91381258e-02,\n",
      "         1.70711607e-01, -7.71496594e-02],\n",
      "       [-8.91644210e-02,  1.67002439e-01, -8.24831128e-02,\n",
      "        -1.61213160e-01, -1.43541172e-01],\n",
      "       [-8.69232118e-02,  1.54497344e-02, -8.86263847e-02,\n",
      "        -9.34186131e-02, -5.93888462e-02],\n",
      "       [-2.06750408e-01, -2.56992459e-01,  2.98671871e-01,\n",
      "         9.68019664e-02, -9.50150043e-02],\n",
      "       [ 2.03328758e-01,  1.14865765e-01,  1.20206371e-01,\n",
      "         1.39223114e-01, -2.02467859e-01],\n",
      "       [-1.43236443e-01,  1.78528622e-01, -1.16098657e-01,\n",
      "         1.34488091e-01,  1.10652886e-01],\n",
      "       [-2.03378007e-01,  4.06703316e-02, -1.25958696e-01,\n",
      "        -2.54327238e-01, -1.01842880e-01],\n",
      "       [-1.52951300e-01, -1.65571854e-01, -1.80403143e-01,\n",
      "         2.76354313e-01,  1.19534925e-01],\n",
      "       [ 7.11132446e-03, -8.10626298e-02,  6.38617575e-02,\n",
      "         1.03859380e-01, -5.52697368e-02],\n",
      "       [ 1.61223993e-01,  5.81509545e-02,  1.67442724e-01,\n",
      "        -1.59694180e-01,  1.83418602e-01],\n",
      "       [ 3.06663532e-02, -1.52997732e-01,  1.08912207e-01,\n",
      "         1.05197400e-01,  9.60539952e-02],\n",
      "       [-1.87130347e-01, -2.27478743e-01,  2.77614325e-01,\n",
      "        -1.10319108e-02, -5.33387288e-02],\n",
      "       [-2.34516069e-01, -1.83391511e-01, -1.91116855e-01,\n",
      "         1.12719245e-01,  3.66124213e-01],\n",
      "       [-1.64946809e-01, -2.76071243e-02, -1.11997575e-01,\n",
      "        -1.43903390e-01,  1.23297885e-01],\n",
      "       [-7.18663782e-02,  1.25730425e-01, -2.62069970e-01,\n",
      "        -2.87429523e-03, -1.10170813e-02],\n",
      "       [-2.50468701e-01, -1.86952338e-01, -4.10543829e-02,\n",
      "        -8.50174390e-03, -3.93623002e-02],\n",
      "       [-1.32539108e-01,  2.77412891e-01,  4.15212288e-02,\n",
      "         1.80946246e-01, -1.30069405e-01],\n",
      "       [ 7.28890970e-02, -2.49659661e-02,  9.54690215e-04,\n",
      "        -2.52515733e-01,  3.48071568e-02],\n",
      "       [-2.06715658e-01,  2.36914754e-02,  1.06651515e-01,\n",
      "        -1.41475320e-01,  9.24960673e-02],\n",
      "       [ 6.22917414e-02, -1.48719043e-01,  1.41240850e-01,\n",
      "         1.78181261e-01,  1.41947865e-01],\n",
      "       [ 1.44029945e-01, -1.92795753e-01,  1.26039132e-01,\n",
      "         4.97524999e-02,  1.89222783e-01],\n",
      "       [ 1.32345140e-01,  9.86679643e-02, -3.19818333e-02,\n",
      "         5.36624081e-02,  2.26624697e-01],\n",
      "       [-1.52924865e-01, -6.99431822e-02, -1.52617604e-01,\n",
      "         4.59660068e-02,  1.44144997e-01],\n",
      "       [ 2.25516900e-01,  9.63030234e-02, -1.60698295e-02,\n",
      "        -1.54819712e-01, -1.95905734e-02],\n",
      "       [ 1.26534868e-02, -2.82165378e-01,  5.84416278e-02,\n",
      "        -6.74670041e-02,  3.38738292e-01],\n",
      "       [-1.67849194e-02, -2.49981340e-02, -6.87786937e-02,\n",
      "        -1.79538146e-01,  9.57484692e-02],\n",
      "       [ 1.91015586e-01, -1.77696701e-02, -4.31208536e-02,\n",
      "         1.59637168e-01, -2.13026807e-01],\n",
      "       [ 2.47166064e-02,  1.71796724e-01, -6.75547794e-02,\n",
      "        -6.34569302e-02, -2.12013453e-01],\n",
      "       [-9.73761678e-02,  1.40635461e-01, -1.63819879e-01,\n",
      "         4.68083583e-02, -5.41268140e-02],\n",
      "       [ 1.15685761e-01,  1.42863348e-01,  1.53375089e-01,\n",
      "         9.57257152e-02,  3.54089066e-02],\n",
      "       [-1.56355590e-01, -4.56675440e-02, -2.37096101e-01,\n",
      "        -9.25517902e-02,  2.43970692e-01],\n",
      "       [ 2.86307577e-02, -6.42054901e-02, -6.90697208e-02,\n",
      "        -1.97262168e-01, -1.34406731e-01],\n",
      "       [ 5.23786284e-02,  2.38809228e-01, -5.28813526e-02,\n",
      "        -1.47950083e-01,  6.30747080e-02],\n",
      "       [-1.77396804e-01,  2.41660595e-01, -6.69141188e-02,\n",
      "        -2.49761641e-01, -2.24651280e-03],\n",
      "       [-1.63955674e-01,  1.70035481e-01, -1.29127428e-01,\n",
      "         1.76800177e-01,  1.82042103e-02],\n",
      "       [ 4.65002954e-02,  3.46899703e-02,  1.78404287e-01,\n",
      "        -1.68179914e-01, -2.75872558e-01],\n",
      "       [ 6.53996021e-02,  1.18431054e-01,  1.40896827e-01,\n",
      "        -1.41597420e-01, -1.46637447e-02],\n",
      "       [-3.02044339e-02,  1.20824948e-01, -2.42825672e-01,\n",
      "        -1.11995757e-01, -1.21950962e-01],\n",
      "       [-1.58639997e-01,  3.84253785e-02,  6.33287728e-02,\n",
      "         1.65077806e-01,  4.31316830e-02],\n",
      "       [ 2.26213206e-02,  3.53825569e-01, -2.55987853e-01,\n",
      "         1.76414236e-01,  1.65758118e-01],\n",
      "       [-2.54200231e-02, -8.96307975e-02,  7.31029585e-02,\n",
      "         1.91344246e-01,  2.35658940e-02],\n",
      "       [-1.41853467e-01, -6.46125525e-02, -3.90240029e-02,\n",
      "         9.09366682e-02, -1.50361598e-01],\n",
      "       [ 2.76072204e-01, -2.20009863e-01,  9.64980945e-02,\n",
      "         1.68532506e-01, -2.23003224e-01],\n",
      "       [-2.18187094e-01,  1.57846674e-01, -1.36165023e-01,\n",
      "         1.10154979e-01,  1.31331757e-01],\n",
      "       [ 3.12584564e-02, -2.05660481e-02,  8.12612101e-02,\n",
      "         1.50198534e-01, -1.47004724e-01],\n",
      "       [ 9.24538746e-02, -1.29084453e-01, -6.05273992e-02,\n",
      "         5.64601049e-02,  1.38143793e-01],\n",
      "       [-9.08529237e-02,  8.55254903e-02,  1.10906754e-02,\n",
      "        -1.23237006e-01,  7.84148648e-02],\n",
      "       [ 6.81637451e-02,  3.22431833e-01, -2.37555970e-02,\n",
      "         1.92702189e-02, -2.20885277e-01],\n",
      "       [ 2.87389666e-01,  8.45813565e-03, -2.89490279e-02,\n",
      "        -1.40360236e-01, -7.24912658e-02],\n",
      "       [-2.33249702e-02, -1.81363672e-01,  2.16949850e-01,\n",
      "        -2.00326324e-01,  2.46667340e-01],\n",
      "       [-4.50590029e-02, -2.07594782e-01, -1.20802067e-01,\n",
      "        -6.24502115e-02,  2.19057128e-02],\n",
      "       [ 1.90294415e-01, -2.12861180e-01, -1.28890639e-02,\n",
      "         2.39714280e-01,  1.13517515e-01],\n",
      "       [-1.26547933e-01, -4.86164615e-02,  1.16031393e-01,\n",
      "        -1.42319292e-01, -1.29996374e-01],\n",
      "       [-1.41532600e-01,  1.35812685e-01,  1.38833791e-01,\n",
      "         1.22907788e-01,  2.05711201e-01],\n",
      "       [ 1.50150374e-01,  1.66709781e-01,  1.31243482e-01,\n",
      "         1.71619341e-01, -7.04512075e-02],\n",
      "       [ 1.92710251e-01, -1.90889686e-01,  1.50908798e-01,\n",
      "         2.21026689e-01, -9.30162221e-02],\n",
      "       [-9.76059586e-02,  2.66378522e-02,  2.17515364e-01,\n",
      "        -1.65003717e-01, -3.15907635e-02],\n",
      "       [ 1.74821783e-02,  1.98165819e-01, -9.76756662e-02,\n",
      "        -1.24308206e-01, -3.03839962e-03],\n",
      "       [-1.82180107e-01,  5.33957854e-02,  3.56180146e-02,\n",
      "         1.61258548e-01, -1.07023440e-01],\n",
      "       [ 1.77057058e-01,  9.04453397e-02,  2.41378382e-01,\n",
      "        -2.49187663e-01,  1.41723156e-01],\n",
      "       [ 4.76467833e-02,  1.18709341e-01, -2.00229093e-01,\n",
      "         1.10673010e-01,  8.31246749e-02],\n",
      "       [ 1.15322709e-01,  7.95074478e-02,  1.81687236e-01,\n",
      "         1.64192736e-01,  9.52429995e-02],\n",
      "       [ 3.06088328e-02,  9.37311724e-02, -1.74706519e-01,\n",
      "         1.35173529e-01,  6.96805492e-02],\n",
      "       [-9.39289331e-02, -1.19134359e-01,  4.01428640e-02,\n",
      "         1.07970059e-01, -1.38325036e-01],\n",
      "       [ 7.48307928e-02,  9.63096023e-02, -2.55620003e-01,\n",
      "         1.24298081e-01,  1.81279436e-01],\n",
      "       [ 4.50134337e-01, -2.31215551e-01, -5.79730831e-02,\n",
      "        -2.48319447e-01, -2.91160733e-01],\n",
      "       [ 1.53728753e-01,  1.46623507e-01,  2.04687610e-01,\n",
      "        -8.38554874e-02,  1.44813925e-01],\n",
      "       [-9.85513628e-02,  1.18575186e-01,  2.75243148e-02,\n",
      "         4.64029722e-02, -1.53186902e-01],\n",
      "       [ 1.18172117e-01,  8.07821751e-02, -1.32828146e-01,\n",
      "        -9.50782374e-03,  7.84925744e-02],\n",
      "       [ 7.76748583e-02,  1.17678568e-01, -2.63384730e-01,\n",
      "         2.65657961e-01,  1.04658574e-01],\n",
      "       [ 1.31609440e-01, -1.23425402e-01, -8.01152587e-02,\n",
      "         1.36023551e-01, -1.32507116e-01],\n",
      "       [-8.59902240e-03,  2.41339710e-02,  1.59844831e-01,\n",
      "         1.76797509e-01, -8.52511972e-02],\n",
      "       [ 1.36909857e-01, -2.19931155e-01,  2.09348112e-01,\n",
      "         1.12242684e-01,  1.99563444e-01],\n",
      "       [-1.37045845e-01, -1.82941169e-01,  7.47585483e-03,\n",
      "        -7.68450350e-02, -4.27821092e-02],\n",
      "       [ 1.12528428e-01, -3.09007373e-02,  2.07324505e-01,\n",
      "         5.90867773e-02, -1.31060898e-01],\n",
      "       [-8.69585499e-02,  1.17760517e-01,  7.08426312e-02,\n",
      "        -1.67389244e-01,  5.46139367e-02],\n",
      "       [-9.04882476e-02, -4.65122983e-02,  3.84339504e-02,\n",
      "         9.68181193e-02, -1.83819517e-01],\n",
      "       [ 1.29513415e-02, -3.45963389e-02, -9.16807428e-02,\n",
      "        -1.90227374e-01,  1.26546204e-01],\n",
      "       [-2.71256953e-01, -2.28293061e-01, -4.48100492e-02,\n",
      "        -1.52378276e-01,  2.51763552e-01],\n",
      "       [-7.89890885e-02,  2.32607741e-02, -8.90772864e-02,\n",
      "        -1.34194449e-01, -2.28435755e-01],\n",
      "       [-1.01821579e-01, -7.29498789e-02,  4.41999063e-02,\n",
      "        -1.71534002e-01, -5.02421036e-02],\n",
      "       [-1.34918913e-01,  2.09645778e-01, -4.66546714e-02,\n",
      "        -2.06185639e-01, -1.85515895e-01],\n",
      "       [-1.88345298e-01, -1.35305896e-01,  8.70603472e-02,\n",
      "         1.47810593e-01, -1.50434196e-01],\n",
      "       [ 5.64082265e-02,  1.46835029e-01, -2.63191998e-01,\n",
      "         2.58843243e-01, -2.25417763e-01],\n",
      "       [ 6.12423904e-02, -1.43091381e-02, -1.59839377e-01,\n",
      "         1.75502189e-02, -1.24416068e-01],\n",
      "       [-1.67289451e-01, -3.05178594e-02, -1.24356054e-01,\n",
      "         5.91736892e-03, -3.46127222e-03],\n",
      "       [-2.20148042e-01, -8.09305906e-02,  1.32912919e-01,\n",
      "         6.58820421e-02, -3.87548245e-02],\n",
      "       [ 2.61950672e-01,  2.45740801e-01, -7.02815652e-02,\n",
      "        -3.27020317e-01, -2.01451048e-01],\n",
      "       [ 1.27600014e-01, -3.25117670e-02, -2.41584799e-04,\n",
      "        -1.93162486e-01,  1.58551917e-03],\n",
      "       [-7.86477402e-02, -1.53466329e-01, -9.48201418e-02,\n",
      "         2.06182525e-01,  7.15155303e-02],\n",
      "       [-5.31472005e-02,  1.14017993e-01,  8.64333734e-02,\n",
      "         1.22864425e-01,  1.58781826e-01],\n",
      "       [ 7.92290717e-02,  3.50948311e-02, -4.60527353e-02,\n",
      "         1.91098481e-01,  5.25444970e-02],\n",
      "       [ 1.61394373e-01, -1.39386088e-01, -1.23647697e-01,\n",
      "        -6.56595686e-03,  2.87445903e-01],\n",
      "       [ 4.74597216e-02,  2.56095290e-01,  1.57852143e-01,\n",
      "         1.53235450e-01,  1.93656728e-01],\n",
      "       [-3.72983217e-02, -1.59348696e-01, -1.18287086e-01,\n",
      "         1.63498566e-01, -2.23342583e-01],\n",
      "       [-2.39904910e-01, -2.06909359e-01,  3.89495879e-01,\n",
      "         1.04462914e-01, -2.94389516e-01],\n",
      "       [-2.59813964e-02, -3.11518088e-02, -1.41728178e-01,\n",
      "         1.04313649e-01, -5.06759882e-02],\n",
      "       [ 9.83995274e-02, -2.74123073e-01, -2.84039408e-01,\n",
      "         1.99144214e-01,  3.34281981e-01],\n",
      "       [-8.12984407e-02,  1.46743819e-01, -5.81330247e-02,\n",
      "        -2.77717803e-02,  2.07820758e-01],\n",
      "       [ 2.98559457e-01,  1.25344172e-01, -9.76191834e-03,\n",
      "         1.42350256e-01, -2.06775531e-01],\n",
      "       [-1.12780198e-01, -1.67485610e-01,  1.55363744e-02,\n",
      "         1.01271808e-01,  1.40534446e-01],\n",
      "       [-1.73663646e-01, -2.09431490e-03,  2.34065484e-02,\n",
      "        -2.52117842e-01, -7.74585009e-02],\n",
      "       [ 2.77890354e-01, -7.98099414e-02, -1.86357021e-01,\n",
      "         4.56017442e-02,  1.30730584e-01],\n",
      "       [-2.79328883e-01,  1.71914712e-01,  1.01956837e-01,\n",
      "         1.11225925e-01,  5.94500042e-02],\n",
      "       [ 1.38589337e-01, -3.08804493e-02, -7.90067296e-03,\n",
      "        -6.76335469e-02, -2.61806175e-02],\n",
      "       [-1.16346195e-01, -4.12211753e-02,  1.82875156e-01,\n",
      "        -8.28445181e-02, -6.27300590e-02],\n",
      "       [ 3.00516337e-02, -2.29823947e-01,  1.19798765e-01,\n",
      "         2.64481157e-01,  6.64983317e-02],\n",
      "       [-7.31585920e-02,  4.19264399e-02,  1.07740678e-01,\n",
      "        -6.02428913e-02,  5.94494864e-02],\n",
      "       [-1.64384767e-01,  1.43858239e-01,  1.12680987e-01,\n",
      "        -1.50492713e-01,  1.24875821e-01],\n",
      "       [-1.83806077e-01,  1.74169376e-01, -1.62220344e-01,\n",
      "        -1.33527726e-01,  1.68297052e-01],\n",
      "       [-9.50416550e-02,  1.18793555e-01, -1.01939030e-01,\n",
      "        -1.75586656e-01,  9.89140794e-02],\n",
      "       [ 9.11412537e-02, -2.31791705e-01, -1.53296366e-01,\n",
      "        -1.21080436e-01, -3.92613485e-02],\n",
      "       [-1.04622066e-01, -4.49468642e-02,  1.50397971e-01,\n",
      "         5.75038083e-02,  1.65848453e-02],\n",
      "       [ 1.15758263e-01,  1.63680911e-01,  1.17072344e-01,\n",
      "         1.76718920e-01,  1.56571150e-01],\n",
      "       [ 1.44428417e-01, -1.69619486e-01,  2.85365254e-01,\n",
      "         1.29430443e-01, -1.73946142e-01],\n",
      "       [-8.13890889e-04,  4.47661690e-02, -1.70903251e-01,\n",
      "        -1.11127302e-01, -1.60415694e-01],\n",
      "       [-1.46481588e-01, -1.06244415e-01,  2.42877491e-02,\n",
      "         1.89611185e-02,  4.69225906e-02],\n",
      "       [-3.42323296e-02,  2.82120127e-02, -2.64450368e-02,\n",
      "         7.83260539e-02, -3.73468250e-02],\n",
      "       [-3.41863036e-02,  1.11543395e-01,  7.07098320e-02,\n",
      "         2.72275567e-01, -2.53229022e-01]], dtype=float32), array([ 0.12893993, -0.13758488,  0.18670021,  0.01603852, -0.19409275],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for layer in Model_CNN_2D_saved.layers:\n",
    "    print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 13652
    },
    "colab_type": "code",
    "id": "fIDuoBKNFu9Q",
    "outputId": "5329416e-8b59-4453-ac94-c4dd6247960f"
   },
   "source": [
    "## Metrics for the classifiers\n",
    "\n",
    "\n",
    "1. Accuracy: Accuracy is a measure of how many correct predictions a model makes overall, i.e., the ratio of correct predictions to the total number of predictions. It's a commonly used metric for evaluating models, but it may not be suitable in certain situations.\n",
    "\n",
    "2. Precision: Precision measures the ratio of true positives (correctly predicted positive instances) to all instances predicted as positive. It focuses on the accuracy of positive predictions.\n",
    "\n",
    "3. Recall: Recall, also known as sensitivity or true positive rate, measures the ratio of true positives to all actual positive instances. It focuses on how well a model captures all the positive instances.\n",
    "\n",
    "4. F1 Score: The F1 score is the harmonic mean of precision and recall. It provides a balanced measure that takes into account both false positives and false negatives. The F1 score is especially useful when you want to strike a balance between precision and recall.\n",
    "\n",
    "\n",
    "The F1 score is a metric that combines precision and recall, and it is particularly useful in situations where class imbalance or unequal misclassification costs are present. In such contexts, the F1 score can be more informative and meaningful than accuracy.\n",
    "\n",
    "A context where considering the F1 score makes more sense than accuracy:\n",
    "\n",
    "**Medical Diagnosis:**\n",
    "\n",
    "Imagine you're developing a model to diagnose a rare disease, and only 5% of the population has this disease. In this case, you have a significant class imbalance, where the majority of cases are negative (non-disease) and only a small fraction are positive (disease). If you were to use accuracy as the evaluation metric, the model could achieve a high accuracy by simply predicting \"negative\" for every case, because it would be correct 95% of the time due to the class imbalance. However, this would be entirely useless for detecting the actual disease.\n",
    "\n",
    "In this scenario, you'd be more interested in the F1 score. The F1 score considers both precision and recall, helping you find a balance between correctly identifying the disease (high recall) and not making too many false positive predictions (high precision). A high F1 score in this context indicates that your model is effective at correctly identifying the disease while minimizing false alarms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['Model_CNN_2D_Su', 'Model_CNN_2D_Luz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline to run the classifiers and their metrics\n",
    "\n",
    "def model_classifiers(classifiers:list, db: pd.DataFrame):\n",
    "    \n",
    "    # Clear the session to start a new training\n",
    "    K.clear_session()\n",
    "                      \n",
    "    monitor = EarlyStopping(monitor='val_accuracy', \n",
    "                        min_delta = 0.0001, \n",
    "                        patience = 20, \n",
    "                        verbose = 1, \n",
    "                        mode = 'auto', \n",
    "                        restore_best_weights = True)\n",
    "                      \n",
    "    count       = 1\n",
    "    verbose     = True\n",
    "    models      = []\n",
    "    acc_set     = pd.DataFrame(index=None, columns=['Model',\n",
    "                                                    'Fold',\n",
    "                                                    'Accuracy(Train)',\n",
    "                                                    'Accuracy(Val)',\n",
    "                                                    'F1(Train)',\n",
    "                                                    'F1(Val)', \n",
    "                                                    'Precision(Train)',\n",
    "                                                    'Precision(Val)', \n",
    "                                                    'Recall(Train)',\n",
    "                                                    'Recall(Val)', \n",
    "                                                    'Conf_M',\n",
    "                                                    'Process_time',                                                     \n",
    "                                                    'Class_report(Val)'])\n",
    "                      \n",
    "    for fold in np.unique(db['Fold']):\n",
    "        print(f\"\\nValidation fold: {fold}\")\n",
    "\n",
    "        DB_VAL = db[db['Fold'] == fold]\n",
    "        DB_TRN = db[db['Fold'] != fold]\n",
    "\n",
    "        X      = DB_TRN['features'].to_numpy()\n",
    "        y      = np.array(DB_TRN.Class_categorical.to_list())\n",
    "        y_OHEV = np.array(DB_TRN.Class_OHEV.to_list())\n",
    "\n",
    "        X_val      = DB_VAL['features'].to_numpy()\n",
    "        y_val      = np.array(DB_VAL.Class_categorical.to_list())\n",
    "        y_OHEV_val = np.array(DB_VAL.Class_OHEV.to_list())\n",
    "\n",
    "\n",
    "        # Stackup and pass all values to float32\n",
    "        X = np.stack(X)\n",
    "        X = np.asarray(X).astype(np.float32)\n",
    "\n",
    "        X_val = np.stack(X_val)\n",
    "        X_val = np.asarray(X_val).astype(np.float32)\n",
    "\n",
    "        y_OHEV     = np.asarray(y_OHEV).astype(np.float32)\n",
    "        y_OHEV_val = np.asarray(y_OHEV_val).astype(np.float32)\n",
    "\n",
    "        X_train_final, X_test, y_train_final, y_test = train_test_split(X,\n",
    "                                                                        y_OHEV, \n",
    "                                                                        test_size = 0.1, \n",
    "                                                                        random_state = 100, \n",
    "                                                                        stratify = y_OHEV)\n",
    "        \n",
    "        print(\"\\n========================================================================\")\n",
    "        print(\"Training set\\n\")\n",
    "\n",
    "        print(f'X_train.........: {np.shape(X_train_final)} ...type: {type(X_train_final[0][0][0][0])}')\n",
    "        print(f'y_train_OHEV....: {np.shape(y_train_final)} ............type: {type(y_train_final[0][0])}')\n",
    "\n",
    "        print(\"\\n========================================================================\")\n",
    "        print(\"Testing set\\n\")\n",
    "\n",
    "        print(f'X_test..........: {np.shape(X_test)} ....type: {type(X_test[0][0][0][0])}')\n",
    "        print(f'y_test_OHEV.....: {np.shape(y_test)} .............type: {type(y_test[0][0])}')\n",
    "\n",
    "        print(\"\\n========================================================================\")\n",
    "        print(\"Validation set\\n\")\n",
    "\n",
    "        print(f'X_val...........: {np.shape(X_val)} ....type: {type(X_val[0][0][0][0])}')\n",
    "        print(f'y_OHEV_val......: {np.shape(y_OHEV_val)} .............type: {type(y_OHEV_val[0][0])}')\n",
    "        print()\n",
    "\n",
    "        \n",
    "        for i in tqdm(range(len(classifiers))):\n",
    "            \n",
    "            name         = classifiers[i]\n",
    "            model_name   = (classifiers[i] + '_' + str(count))\n",
    "            count        = count + 1\n",
    "            \n",
    "            if not os.path.exists(path_models):\n",
    "                os.makedirs(path_models)\n",
    "\n",
    "            filepath       = os.path.join(path_models, classifiers[i] + '_weights_0_best' + model_surname + '.hdf5')\n",
    "            checkpoint     = ModelCheckpoint(filepath, \n",
    "                                             monitor = 'val_accuracy', \n",
    "                                             verbose = 1, \n",
    "                                             save_best_only = True, \n",
    "                                             mode = 'max')\n",
    "            callbacks_list = [checkpoint, monitor]\n",
    "\n",
    "            if classifiers[i] == 'Model_CNN_2D_Su':\n",
    "                model = basemodel_Su(classifiers[i])\n",
    "                model.summary()\n",
    "                print(model_name)\n",
    "            \n",
    "            elif classifiers[i] == 'Model_CNN_2D_Luz':\n",
    "                model = basemodel_Luz(classifiers[i])\n",
    "                model.summary()\n",
    "                print(model_name)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "            model.fit(X_train_final, \n",
    "                      y_train_final,\n",
    "                      batch_size          = batch_size,\n",
    "                      epochs              = epochs,\n",
    "                      verbose             = 1,\n",
    "                      validation_data     = (X_test, y_test),\n",
    "                      steps_per_epoch     = int(np.ceil(X_train_final.shape[0] / float(batch_size))),\n",
    "                      callbacks           = callbacks_list,\n",
    "                      use_multiprocessing = True)\n",
    "                      \n",
    "            # Get the model predictions\n",
    "            y_train_enc = np.argmax(y_train_final, axis=1)\n",
    "            y_val_enc   = np.argmax(y_OHEV_val, axis=1)\n",
    "\n",
    "            y_train_predicted = np.argmax(model.predict(X_train_final), axis=1)\n",
    "\n",
    "            t_srt             = time.process_time_ns()\n",
    "            y_val_predicted   = np.argmax(model.predict(X_val), axis=1)\n",
    "            t_end             = time.process_time_ns()\n",
    "            proc_time         = ((t_end - t_srt) / 1000000)   \n",
    "            \n",
    "            # Compute the classifier metrics\n",
    "            accuracy_train = metrics.accuracy_score(y_train_enc, y_train_predicted)\n",
    "            accuracy_val   = metrics.accuracy_score(y_val_enc,  y_val_predicted)\n",
    "\n",
    "            f1_Score_train = metrics.f1_score(y_train_enc, y_train_predicted, average = 'weighted')\n",
    "            f1_Score_val   = metrics.f1_score(y_val_enc,  y_val_predicted,  average = 'weighted')\n",
    "\n",
    "            precision_score_train = metrics.precision_score(y_train_enc, y_train_predicted, average = 'weighted')\n",
    "            precision_score_val   = metrics.precision_score(y_val_enc,  y_val_predicted,  average = 'weighted')\n",
    "\n",
    "            recall_score_train = metrics.recall_score(y_train_enc, y_train_predicted, average = 'weighted')\n",
    "            recall_score_val   = metrics.recall_score(y_val_enc,  y_val_predicted,  average = 'weighted')\n",
    "\n",
    "            class_report_val = classification_report(y_val_enc, y_val_predicted, target_names = nom_classes)\n",
    "            print(class_report_val)\n",
    "            \n",
    "            # Compute the confusion matrix\n",
    "            CM = metrics.confusion_matrix(y_val_enc, y_val_predicted)\n",
    "            y_val_enc       = []\n",
    "            y_val_predicted = []\n",
    "\n",
    "            # Store the name, test accuracy results and model\n",
    "            models.append((name, accuracy_val, model))\n",
    "            \n",
    "            K.clear_session()\n",
    "            del model\n",
    "                    \n",
    "            acc_set = pd.concat([acc_set, pd.DataFrame({'Model': [name],\n",
    "                                                        'Fold': [fold],\n",
    "                                                        'Accuracy(Train)': [accuracy_train],\n",
    "                                                        'Accuracy(Val)': [accuracy_val],\n",
    "                                                        'F1(Train)': [f1_Score_train],\n",
    "                                                        'F1(Val)': [f1_Score_val],\n",
    "                                                        'Precision(Train)': [precision_score_train],\n",
    "                                                        'Precision(Val)': [precision_score_val],\n",
    "                                                        'Recall(Train)': [recall_score_train],\n",
    "                                                        'Recall(Val)': [recall_score_val],\n",
    "                                                        'Conf_M': [CM],\n",
    "                                                        'Process_time': [proc_time],\n",
    "                                                        'Class_report(Val)': class_report_val})], ignore_index = True)\n",
    "                   \n",
    "    return acc_set, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation fold: 1\n",
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21211, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21211, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2357, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2357, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2580, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2580, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_1\n",
      "Epoch 1/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 1.2225 - accuracy: 0.6021\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69453, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 17s 25ms/step - loss: 1.2225 - accuracy: 0.6021 - val_loss: 0.8207 - val_accuracy: 0.6945\n",
      "Epoch 2/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.7504 - accuracy: 0.7313\n",
      "Epoch 00002: val_accuracy improved from 0.69453 to 0.76623, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.7505 - accuracy: 0.7313 - val_loss: 0.6139 - val_accuracy: 0.7662\n",
      "Epoch 3/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.6281 - accuracy: 0.7750\n",
      "Epoch 00003: val_accuracy improved from 0.76623 to 0.78871, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.6280 - accuracy: 0.7751 - val_loss: 0.6104 - val_accuracy: 0.7887\n",
      "Epoch 4/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.8059\n",
      "Epoch 00004: val_accuracy improved from 0.78871 to 0.79126, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.5468 - accuracy: 0.8059 - val_loss: 0.6640 - val_accuracy: 0.7913\n",
      "Epoch 5/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.4958 - accuracy: 0.8229\n",
      "Epoch 00005: val_accuracy improved from 0.79126 to 0.83029, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.4957 - accuracy: 0.8230 - val_loss: 0.4973 - val_accuracy: 0.8303\n",
      "Epoch 6/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.8414\n",
      "Epoch 00006: val_accuracy improved from 0.83029 to 0.88333, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.4357 - accuracy: 0.8414 - val_loss: 0.3567 - val_accuracy: 0.8833\n",
      "Epoch 7/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.3932 - accuracy: 0.8572\n",
      "Epoch 00007: val_accuracy did not improve from 0.88333\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.3931 - accuracy: 0.8572 - val_loss: 0.4648 - val_accuracy: 0.8553\n",
      "Epoch 8/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.3629 - accuracy: 0.8706\n",
      "Epoch 00008: val_accuracy improved from 0.88333 to 0.89733, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.3629 - accuracy: 0.8706 - val_loss: 0.3083 - val_accuracy: 0.8973\n",
      "Epoch 9/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.3409 - accuracy: 0.8788\n",
      "Epoch 00009: val_accuracy did not improve from 0.89733\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.3409 - accuracy: 0.8788 - val_loss: 0.3440 - val_accuracy: 0.8905\n",
      "Epoch 10/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.3088 - accuracy: 0.8871\n",
      "Epoch 00010: val_accuracy improved from 0.89733 to 0.90412, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.3087 - accuracy: 0.8872 - val_loss: 0.2836 - val_accuracy: 0.9041\n",
      "Epoch 11/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.2865 - accuracy: 0.8968\n",
      "Epoch 00011: val_accuracy improved from 0.90412 to 0.91260, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.2863 - accuracy: 0.8969 - val_loss: 0.2602 - val_accuracy: 0.9126\n",
      "Epoch 12/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2720 - accuracy: 0.9018\n",
      "Epoch 00012: val_accuracy improved from 0.91260 to 0.91854, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.2721 - accuracy: 0.9017 - val_loss: 0.2583 - val_accuracy: 0.9185\n",
      "Epoch 13/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.2504 - accuracy: 0.9090\n",
      "Epoch 00013: val_accuracy did not improve from 0.91854\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.2503 - accuracy: 0.9090 - val_loss: 0.3124 - val_accuracy: 0.8990\n",
      "Epoch 14/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2403 - accuracy: 0.9144\n",
      "Epoch 00014: val_accuracy improved from 0.91854 to 0.93636, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.2403 - accuracy: 0.9144 - val_loss: 0.1943 - val_accuracy: 0.9364\n",
      "Epoch 15/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.2225 - accuracy: 0.9211\n",
      "Epoch 00015: val_accuracy improved from 0.93636 to 0.94951, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.2224 - accuracy: 0.9211 - val_loss: 0.1624 - val_accuracy: 0.9495\n",
      "Epoch 16/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2106 - accuracy: 0.9232\n",
      "Epoch 00016: val_accuracy did not improve from 0.94951\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.2104 - accuracy: 0.9232 - val_loss: 0.1955 - val_accuracy: 0.9393\n",
      "Epoch 17/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2024 - accuracy: 0.9287\n",
      "Epoch 00017: val_accuracy did not improve from 0.94951\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.2021 - accuracy: 0.9288 - val_loss: 0.2049 - val_accuracy: 0.9368\n",
      "Epoch 18/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.1852 - accuracy: 0.9333\n",
      "Epoch 00018: val_accuracy did not improve from 0.94951\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1851 - accuracy: 0.9333 - val_loss: 0.1628 - val_accuracy: 0.9474\n",
      "Epoch 19/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1765 - accuracy: 0.9360\n",
      "Epoch 00019: val_accuracy improved from 0.94951 to 0.95291, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1766 - accuracy: 0.9360 - val_loss: 0.1493 - val_accuracy: 0.9529\n",
      "Epoch 20/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1711 - accuracy: 0.9375\n",
      "Epoch 00020: val_accuracy improved from 0.95291 to 0.95460, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1714 - accuracy: 0.9375 - val_loss: 0.1518 - val_accuracy: 0.9546\n",
      "Epoch 21/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1661 - accuracy: 0.9389\n",
      "Epoch 00021: val_accuracy did not improve from 0.95460\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1661 - accuracy: 0.9389 - val_loss: 0.2148 - val_accuracy: 0.9334\n",
      "Epoch 22/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.1546 - accuracy: 0.9434\n",
      "Epoch 00022: val_accuracy improved from 0.95460 to 0.96182, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1546 - accuracy: 0.9434 - val_loss: 0.1234 - val_accuracy: 0.9618\n",
      "Epoch 23/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1440 - accuracy: 0.9476\n",
      "Epoch 00023: val_accuracy did not improve from 0.96182\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1440 - accuracy: 0.9476 - val_loss: 0.2352 - val_accuracy: 0.9308\n",
      "Epoch 24/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9484\n",
      "Epoch 00024: val_accuracy did not improve from 0.96182\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1423 - accuracy: 0.9484 - val_loss: 0.1351 - val_accuracy: 0.9605\n",
      "Epoch 25/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1324 - accuracy: 0.9518\n",
      "Epoch 00025: val_accuracy improved from 0.96182 to 0.96266, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1324 - accuracy: 0.9518 - val_loss: 0.1328 - val_accuracy: 0.9627\n",
      "Epoch 26/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1284 - accuracy: 0.9547\n",
      "Epoch 00026: val_accuracy did not improve from 0.96266\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1285 - accuracy: 0.9548 - val_loss: 0.1464 - val_accuracy: 0.9542\n",
      "Epoch 27/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1200 - accuracy: 0.9565\n",
      "Epoch 00027: val_accuracy did not improve from 0.96266\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1200 - accuracy: 0.9564 - val_loss: 0.1383 - val_accuracy: 0.9571\n",
      "Epoch 28/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9574\n",
      "Epoch 00028: val_accuracy improved from 0.96266 to 0.96436, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1164 - accuracy: 0.9574 - val_loss: 0.1226 - val_accuracy: 0.9644\n",
      "Epoch 29/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9597\n",
      "Epoch 00029: val_accuracy did not improve from 0.96436\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1110 - accuracy: 0.9597 - val_loss: 0.1407 - val_accuracy: 0.9597\n",
      "Epoch 30/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1072 - accuracy: 0.9615\n",
      "Epoch 00030: val_accuracy improved from 0.96436 to 0.97242, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1071 - accuracy: 0.9615 - val_loss: 0.0956 - val_accuracy: 0.9724\n",
      "Epoch 31/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1085 - accuracy: 0.9606\n",
      "Epoch 00031: val_accuracy did not improve from 0.97242\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.1086 - accuracy: 0.9605 - val_loss: 0.1149 - val_accuracy: 0.9678\n",
      "Epoch 32/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9628\n",
      "Epoch 00032: val_accuracy improved from 0.97242 to 0.97667, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.1021 - accuracy: 0.9628 - val_loss: 0.0943 - val_accuracy: 0.9767\n",
      "Epoch 33/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9648\n",
      "Epoch 00033: val_accuracy did not improve from 0.97667\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0966 - accuracy: 0.9648 - val_loss: 0.1232 - val_accuracy: 0.9699\n",
      "Epoch 34/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0881 - accuracy: 0.9673\n",
      "Epoch 00034: val_accuracy improved from 0.97667 to 0.98006, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0881 - accuracy: 0.9673 - val_loss: 0.0917 - val_accuracy: 0.9801\n",
      "Epoch 35/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0881 - accuracy: 0.9678\n",
      "Epoch 00035: val_accuracy did not improve from 0.98006\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0879 - accuracy: 0.9679 - val_loss: 0.1074 - val_accuracy: 0.9690\n",
      "Epoch 36/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0825 - accuracy: 0.9705\n",
      "Epoch 00036: val_accuracy did not improve from 0.98006\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0824 - accuracy: 0.9705 - val_loss: 0.1054 - val_accuracy: 0.9699\n",
      "Epoch 37/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.9704\n",
      "Epoch 00037: val_accuracy improved from 0.98006 to 0.98345, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0825 - accuracy: 0.9704 - val_loss: 0.0720 - val_accuracy: 0.9835\n",
      "Epoch 38/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 0.9701\n",
      "Epoch 00038: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0809 - accuracy: 0.9701 - val_loss: 0.0996 - val_accuracy: 0.9733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9732\n",
      "Epoch 00039: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0748 - accuracy: 0.9732 - val_loss: 0.0900 - val_accuracy: 0.9784\n",
      "Epoch 40/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0731 - accuracy: 0.9737\n",
      "Epoch 00040: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0732 - accuracy: 0.9736 - val_loss: 0.0754 - val_accuracy: 0.9830\n",
      "Epoch 41/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0751 - accuracy: 0.9737\n",
      "Epoch 00041: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0752 - accuracy: 0.9736 - val_loss: 0.0921 - val_accuracy: 0.9762\n",
      "Epoch 42/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9759\n",
      "Epoch 00042: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0689 - accuracy: 0.9759 - val_loss: 0.0732 - val_accuracy: 0.9826\n",
      "Epoch 43/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9755\n",
      "Epoch 00043: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0692 - accuracy: 0.9755 - val_loss: 0.0858 - val_accuracy: 0.9805\n",
      "Epoch 44/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9761\n",
      "Epoch 00044: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0677 - accuracy: 0.9761 - val_loss: 0.0784 - val_accuracy: 0.9801\n",
      "Epoch 45/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9780\n",
      "Epoch 00045: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0633 - accuracy: 0.9780 - val_loss: 0.0835 - val_accuracy: 0.9796\n",
      "Epoch 46/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9786\n",
      "Epoch 00046: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0630 - accuracy: 0.9785 - val_loss: 0.0819 - val_accuracy: 0.9818\n",
      "Epoch 47/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9771\n",
      "Epoch 00047: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0644 - accuracy: 0.9771 - val_loss: 0.0801 - val_accuracy: 0.9771\n",
      "Epoch 48/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.9795\n",
      "Epoch 00048: val_accuracy improved from 0.98345 to 0.98812, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0598 - accuracy: 0.9795 - val_loss: 0.0683 - val_accuracy: 0.9881\n",
      "Epoch 49/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.9800\n",
      "Epoch 00049: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0565 - accuracy: 0.9800 - val_loss: 0.0734 - val_accuracy: 0.9818\n",
      "Epoch 50/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 0.9792\n",
      "Epoch 00050: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 17s 25ms/step - loss: 0.0599 - accuracy: 0.9792 - val_loss: 0.0647 - val_accuracy: 0.9852\n",
      "Epoch 51/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9812\n",
      "Epoch 00051: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 17s 25ms/step - loss: 0.0537 - accuracy: 0.9811 - val_loss: 0.0717 - val_accuracy: 0.9826\n",
      "Epoch 52/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.9797\n",
      "Epoch 00052: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0581 - accuracy: 0.9797 - val_loss: 0.0630 - val_accuracy: 0.9864\n",
      "Epoch 53/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9813\n",
      "Epoch 00053: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0525 - accuracy: 0.9812 - val_loss: 0.0712 - val_accuracy: 0.9839\n",
      "Epoch 54/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9809\n",
      "Epoch 00054: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0513 - accuracy: 0.9809 - val_loss: 0.0717 - val_accuracy: 0.9843\n",
      "Epoch 55/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9823\n",
      "Epoch 00055: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0498 - accuracy: 0.9823 - val_loss: 0.0711 - val_accuracy: 0.9860\n",
      "Epoch 56/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.9822\n",
      "Epoch 00056: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0499 - accuracy: 0.9822 - val_loss: 0.0786 - val_accuracy: 0.9822\n",
      "Epoch 57/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9833\n",
      "Epoch 00057: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0477 - accuracy: 0.9833 - val_loss: 0.0660 - val_accuracy: 0.9873\n",
      "Epoch 58/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0455 - accuracy: 0.9836\n",
      "Epoch 00058: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0455 - accuracy: 0.9836 - val_loss: 0.0638 - val_accuracy: 0.9868\n",
      "Epoch 59/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0419 - accuracy: 0.9848\n",
      "Epoch 00059: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0420 - accuracy: 0.9847 - val_loss: 0.0756 - val_accuracy: 0.9813\n",
      "Epoch 60/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9845\n",
      "Epoch 00060: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0460 - accuracy: 0.9845 - val_loss: 0.0777 - val_accuracy: 0.9830\n",
      "Epoch 61/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 0.9863\n",
      "Epoch 00061: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0435 - accuracy: 0.9862 - val_loss: 0.0902 - val_accuracy: 0.9758\n",
      "Epoch 62/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9855\n",
      "Epoch 00062: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0429 - accuracy: 0.9855 - val_loss: 0.0763 - val_accuracy: 0.9818\n",
      "Epoch 63/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9864\n",
      "Epoch 00063: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0379 - accuracy: 0.9863 - val_loss: 0.0684 - val_accuracy: 0.9835\n",
      "Epoch 64/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9852\n",
      "Epoch 00064: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0403 - accuracy: 0.9852 - val_loss: 0.0745 - val_accuracy: 0.9847\n",
      "Epoch 65/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 0.9866\n",
      "Epoch 00065: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 24ms/step - loss: 0.0388 - accuracy: 0.9866 - val_loss: 0.0716 - val_accuracy: 0.9847\n",
      "Epoch 66/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9856\n",
      "Epoch 00066: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0383 - accuracy: 0.9856 - val_loss: 0.0643 - val_accuracy: 0.9873\n",
      "Epoch 67/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.9866\n",
      "Epoch 00067: val_accuracy did not improve from 0.98812\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0375 - accuracy: 0.9866 - val_loss: 0.0655 - val_accuracy: 0.9852\n",
      "Epoch 68/100\n",
      "662/663 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9864\n",
      "Epoch 00068: val_accuracy did not improve from 0.98812\n",
      "Restoring model weights from the end of the best epoch.\n",
      "663/663 [==============================] - 16s 25ms/step - loss: 0.0388 - accuracy: 0.9864 - val_loss: 0.0574 - val_accuracy: 0.9881\n",
      "Epoch 00068: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [18:32<18:32, 1112.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.92      0.86      0.89       648\n",
      "        car_horn       0.92      0.92      0.92       216\n",
      "children_playing       0.77      0.91      0.83       600\n",
      "        dog_bark       0.89      0.86      0.87       600\n",
      "           siren       0.93      0.84      0.88       516\n",
      "\n",
      "        accuracy                           0.87      2580\n",
      "       macro avg       0.88      0.88      0.88      2580\n",
      "    weighted avg       0.88      0.87      0.87      2580\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_2\n",
      "Epoch 1/100\n",
      "  2/663 [..............................] - ETA: 22s - loss: 1.9557 - accuracy: 0.2344WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0241s vs `on_train_batch_end` time: 0.0437s). Check your callbacks.\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.9451 - accuracy: 0.6451\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80441, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.9451 - accuracy: 0.6451 - val_loss: 0.5418 - val_accuracy: 0.8044\n",
      "Epoch 2/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.5576 - accuracy: 0.8035\n",
      "Epoch 00002: val_accuracy improved from 0.80441 to 0.88417, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.5576 - accuracy: 0.8035 - val_loss: 0.3475 - val_accuracy: 0.8842\n",
      "Epoch 3/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.4051 - accuracy: 0.8590\n",
      "Epoch 00003: val_accuracy improved from 0.88417 to 0.91387, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.4051 - accuracy: 0.8590 - val_loss: 0.2694 - val_accuracy: 0.9139\n",
      "Epoch 4/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.8908\n",
      "Epoch 00004: val_accuracy did not improve from 0.91387\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.3072 - accuracy: 0.8908 - val_loss: 0.2377 - val_accuracy: 0.9079\n",
      "Epoch 5/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2575 - accuracy: 0.9109\n",
      "Epoch 00005: val_accuracy did not improve from 0.91387\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.2575 - accuracy: 0.9109 - val_loss: 0.3472 - val_accuracy: 0.8787\n",
      "Epoch 6/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.9300\n",
      "Epoch 00006: val_accuracy improved from 0.91387 to 0.95206, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.2016 - accuracy: 0.9300 - val_loss: 0.1489 - val_accuracy: 0.9521\n",
      "Epoch 7/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.9383\n",
      "Epoch 00007: val_accuracy improved from 0.95206 to 0.95418, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.1785 - accuracy: 0.9383 - val_loss: 0.1321 - val_accuracy: 0.9542\n",
      "Epoch 8/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.9480\n",
      "Epoch 00008: val_accuracy did not improve from 0.95418\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.1522 - accuracy: 0.9480 - val_loss: 0.1705 - val_accuracy: 0.9482\n",
      "Epoch 9/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.9552\n",
      "Epoch 00009: val_accuracy did not improve from 0.95418\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.1252 - accuracy: 0.9552 - val_loss: 0.1469 - val_accuracy: 0.9504\n",
      "Epoch 10/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9638\n",
      "Epoch 00010: val_accuracy improved from 0.95418 to 0.96054, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.1068 - accuracy: 0.9638 - val_loss: 0.1194 - val_accuracy: 0.9605\n",
      "Epoch 11/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9659\n",
      "Epoch 00011: val_accuracy improved from 0.96054 to 0.97497, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 46s 69ms/step - loss: 0.0983 - accuracy: 0.9659 - val_loss: 0.0705 - val_accuracy: 0.9750\n",
      "Epoch 12/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9728\n",
      "Epoch 00012: val_accuracy did not improve from 0.97497\n",
      "663/663 [==============================] - 44s 67ms/step - loss: 0.0795 - accuracy: 0.9728 - val_loss: 0.1132 - val_accuracy: 0.9597\n",
      "Epoch 13/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 0.9741\n",
      "Epoch 00013: val_accuracy did not improve from 0.97497\n",
      "663/663 [==============================] - 44s 67ms/step - loss: 0.0734 - accuracy: 0.9741 - val_loss: 0.1244 - val_accuracy: 0.9593\n",
      "Epoch 14/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9779\n",
      "Epoch 00014: val_accuracy did not improve from 0.97497\n",
      "663/663 [==============================] - 42s 64ms/step - loss: 0.0668 - accuracy: 0.9779 - val_loss: 0.1134 - val_accuracy: 0.9665\n",
      "Epoch 15/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.9806\n",
      "Epoch 00015: val_accuracy improved from 0.97497 to 0.98345, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 42s 64ms/step - loss: 0.0568 - accuracy: 0.9806 - val_loss: 0.0586 - val_accuracy: 0.9835\n",
      "Epoch 16/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9824\n",
      "Epoch 00016: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 43s 65ms/step - loss: 0.0512 - accuracy: 0.9824 - val_loss: 0.0766 - val_accuracy: 0.9762\n",
      "Epoch 17/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.9818\n",
      "Epoch 00017: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0531 - accuracy: 0.9818 - val_loss: 0.0530 - val_accuracy: 0.9822\n",
      "Epoch 18/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9854\n",
      "Epoch 00018: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0448 - accuracy: 0.9854 - val_loss: 0.0783 - val_accuracy: 0.9784\n",
      "Epoch 19/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9845\n",
      "Epoch 00019: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0449 - accuracy: 0.9845 - val_loss: 0.0646 - val_accuracy: 0.9809\n",
      "Epoch 20/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 0.9877\n",
      "Epoch 00020: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0379 - accuracy: 0.9877 - val_loss: 0.0844 - val_accuracy: 0.9767\n",
      "Epoch 21/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9891\n",
      "Epoch 00021: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0338 - accuracy: 0.9891 - val_loss: 0.0710 - val_accuracy: 0.9775\n",
      "Epoch 22/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9909\n",
      "Epoch 00022: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0268 - accuracy: 0.9909 - val_loss: 0.0779 - val_accuracy: 0.9835\n",
      "Epoch 23/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9903\n",
      "Epoch 00023: val_accuracy did not improve from 0.98345\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0299 - accuracy: 0.9903 - val_loss: 0.0839 - val_accuracy: 0.9809\n",
      "Epoch 24/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9917\n",
      "Epoch 00024: val_accuracy improved from 0.98345 to 0.98473, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.0679 - val_accuracy: 0.9847\n",
      "Epoch 25/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9916\n",
      "Epoch 00025: val_accuracy did not improve from 0.98473\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.1120 - val_accuracy: 0.9711\n",
      "Epoch 26/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9926\n",
      "Epoch 00026: val_accuracy did not improve from 0.98473\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0813 - val_accuracy: 0.9801\n",
      "Epoch 27/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9917\n",
      "Epoch 00027: val_accuracy improved from 0.98473 to 0.98515, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.0525 - val_accuracy: 0.9852\n",
      "Epoch 28/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9940\n",
      "Epoch 00028: val_accuracy did not improve from 0.98515\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0180 - accuracy: 0.9940 - val_loss: 0.3735 - val_accuracy: 0.9317\n",
      "Epoch 29/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9933\n",
      "Epoch 00029: val_accuracy did not improve from 0.98515\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0737 - val_accuracy: 0.9826\n",
      "Epoch 30/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9949\n",
      "Epoch 00030: val_accuracy did not improve from 0.98515\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0663 - val_accuracy: 0.9839\n",
      "Epoch 31/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9949\n",
      "Epoch 00031: val_accuracy improved from 0.98515 to 0.98685, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0551 - val_accuracy: 0.9868\n",
      "Epoch 32/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9956\n",
      "Epoch 00032: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0148 - accuracy: 0.9956 - val_loss: 0.0543 - val_accuracy: 0.9860\n",
      "Epoch 33/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9969\n",
      "Epoch 00033: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.1217 - val_accuracy: 0.9758\n",
      "Epoch 34/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 0.9958\n",
      "Epoch 00034: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0122 - accuracy: 0.9958 - val_loss: 0.0642 - val_accuracy: 0.9847\n",
      "Epoch 35/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9951\n",
      "Epoch 00035: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.1502 - val_accuracy: 0.9716\n",
      "Epoch 36/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9965\n",
      "Epoch 00036: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0702 - val_accuracy: 0.9860\n",
      "Epoch 37/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9953\n",
      "Epoch 00037: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.0676 - val_accuracy: 0.9835\n",
      "Epoch 38/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9968\n",
      "Epoch 00038: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0119 - accuracy: 0.9968 - val_loss: 0.1001 - val_accuracy: 0.9835\n",
      "Epoch 39/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9958\n",
      "Epoch 00039: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.1063 - val_accuracy: 0.9767\n",
      "Epoch 40/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9963\n",
      "Epoch 00040: val_accuracy did not improve from 0.98685\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0691 - val_accuracy: 0.9864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9969\n",
      "Epoch 00041: val_accuracy improved from 0.98685 to 0.98939, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0521 - val_accuracy: 0.9894\n",
      "Epoch 42/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9971\n",
      "Epoch 00042: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.0491 - val_accuracy: 0.9860\n",
      "Epoch 43/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9969\n",
      "Epoch 00043: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0616 - val_accuracy: 0.9873\n",
      "Epoch 44/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9972\n",
      "Epoch 00044: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0114 - accuracy: 0.9972 - val_loss: 0.0624 - val_accuracy: 0.9868\n",
      "Epoch 45/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9966\n",
      "Epoch 00045: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0525 - val_accuracy: 0.9873\n",
      "Epoch 46/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9975\n",
      "Epoch 00046: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0067 - accuracy: 0.9975 - val_loss: 0.0943 - val_accuracy: 0.9835\n",
      "Epoch 47/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 00047: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0971 - val_accuracy: 0.9809\n",
      "Epoch 48/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 00048: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.1108 - val_accuracy: 0.9796\n",
      "Epoch 49/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9966\n",
      "Epoch 00049: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.0928 - val_accuracy: 0.9843\n",
      "Epoch 50/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9971\n",
      "Epoch 00050: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0926 - val_accuracy: 0.9835\n",
      "Epoch 51/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9969\n",
      "Epoch 00051: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0656 - val_accuracy: 0.9890\n",
      "Epoch 52/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9973\n",
      "Epoch 00052: val_accuracy did not improve from 0.98939\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0604 - val_accuracy: 0.9856\n",
      "Epoch 53/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 00053: val_accuracy improved from 0.98939 to 0.99024, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0608 - val_accuracy: 0.9902\n",
      "Epoch 54/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 00054: val_accuracy did not improve from 0.99024\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0572 - val_accuracy: 0.9881\n",
      "Epoch 55/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 00055: val_accuracy did not improve from 0.99024\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0664 - val_accuracy: 0.9885\n",
      "Epoch 56/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 00056: val_accuracy did not improve from 0.99024\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0585 - val_accuracy: 0.9902\n",
      "Epoch 57/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980\n",
      "Epoch 00057: val_accuracy did not improve from 0.99024\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 0.0596 - val_accuracy: 0.9898\n",
      "Epoch 58/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9982\n",
      "Epoch 00058: val_accuracy did not improve from 0.99024\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0047 - accuracy: 0.9982 - val_loss: 0.0556 - val_accuracy: 0.9873\n",
      "Epoch 59/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9983\n",
      "Epoch 00059: val_accuracy improved from 0.99024 to 0.99109, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0435 - val_accuracy: 0.9911\n",
      "Epoch 60/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9979\n",
      "Epoch 00060: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 0.0467 - val_accuracy: 0.9890\n",
      "Epoch 61/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 00061: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0530 - val_accuracy: 0.9894\n",
      "Epoch 62/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9975\n",
      "Epoch 00062: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.0564 - val_accuracy: 0.9885\n",
      "Epoch 63/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9980\n",
      "Epoch 00063: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0063 - accuracy: 0.9980 - val_loss: 0.1835 - val_accuracy: 0.9699\n",
      "Epoch 64/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 00064: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0383 - val_accuracy: 0.9902\n",
      "Epoch 65/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9985\n",
      "Epoch 00065: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0039 - accuracy: 0.9985 - val_loss: 0.0727 - val_accuracy: 0.9843\n",
      "Epoch 66/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 00066: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0489 - val_accuracy: 0.9907\n",
      "Epoch 67/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 00067: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0531 - val_accuracy: 0.9898\n",
      "Epoch 68/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 00068: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0852 - val_accuracy: 0.9881\n",
      "Epoch 69/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9978\n",
      "Epoch 00069: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0545 - val_accuracy: 0.9902\n",
      "Epoch 70/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9987\n",
      "Epoch 00070: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.0612 - val_accuracy: 0.9864\n",
      "Epoch 71/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 00071: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0823 - val_accuracy: 0.9860\n",
      "Epoch 72/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9983\n",
      "Epoch 00072: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 42s 63ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0541 - val_accuracy: 0.9907\n",
      "Epoch 73/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9988\n",
      "Epoch 00073: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.0454 - val_accuracy: 0.9907\n",
      "Epoch 74/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 00074: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0727 - val_accuracy: 0.9881\n",
      "Epoch 75/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 00075: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0531 - val_accuracy: 0.9902\n",
      "Epoch 76/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 00076: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0622 - val_accuracy: 0.9877\n",
      "Epoch 77/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9980\n",
      "Epoch 00077: val_accuracy improved from 0.99109 to 0.99236, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0438 - val_accuracy: 0.9924\n",
      "Epoch 78/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9988\n",
      "Epoch 00078: val_accuracy did not improve from 0.99236\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0525 - val_accuracy: 0.9911\n",
      "Epoch 79/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch 00079: val_accuracy did not improve from 0.99236\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0804 - val_accuracy: 0.9852\n",
      "Epoch 80/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 00080: val_accuracy did not improve from 0.99236\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0632 - val_accuracy: 0.9877\n",
      "Epoch 81/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00081: val_accuracy did not improve from 0.99236\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0479 - val_accuracy: 0.9924\n",
      "Epoch 82/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00082: val_accuracy did not improve from 0.99236\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0500 - val_accuracy: 0.9919\n",
      "Epoch 83/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 00083: val_accuracy improved from 0.99236 to 0.99279, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 63ms/step - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.0469 - val_accuracy: 0.9928\n",
      "Epoch 84/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 00084: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0672 - val_accuracy: 0.9890\n",
      "Epoch 85/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 00085: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0576 - val_accuracy: 0.9902\n",
      "Epoch 86/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 00086: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0543 - val_accuracy: 0.9898\n",
      "Epoch 87/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 00087: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0483 - val_accuracy: 0.9894\n",
      "Epoch 88/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00088: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0528 - val_accuracy: 0.9902\n",
      "Epoch 89/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 00089: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0560 - val_accuracy: 0.9885\n",
      "Epoch 90/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 0.9985\n",
      "Epoch 00090: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0641 - val_accuracy: 0.9881\n",
      "Epoch 91/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 00091: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0603 - val_accuracy: 0.9890\n",
      "Epoch 92/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00092: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0526 - val_accuracy: 0.9898\n",
      "Epoch 93/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00093: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0676 - val_accuracy: 0.9902\n",
      "Epoch 94/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00094: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0572 - val_accuracy: 0.9902\n",
      "Epoch 95/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00095: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0692 - val_accuracy: 0.9915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00096: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0988 - val_accuracy: 0.9830\n",
      "Epoch 97/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 00097: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0707 - val_accuracy: 0.9911\n",
      "Epoch 98/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00098: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0613 - val_accuracy: 0.9911\n",
      "Epoch 99/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9990\n",
      "Epoch 00099: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0668 - val_accuracy: 0.9915\n",
      "Epoch 100/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 00100: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0555 - val_accuracy: 0.9915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:28:47<00:00, 2663.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.89      0.86      0.87       648\n",
      "        car_horn       0.99      0.85      0.91       216\n",
      "children_playing       0.86      0.93      0.89       600\n",
      "        dog_bark       0.89      0.95      0.92       600\n",
      "           siren       0.94      0.86      0.90       516\n",
      "\n",
      "        accuracy                           0.90      2580\n",
      "       macro avg       0.91      0.89      0.90      2580\n",
      "    weighted avg       0.90      0.90      0.90      2580\n",
      "\n",
      "\n",
      "Validation fold: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21270, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21270, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2364, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2364, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2514, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2514, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_3\n",
      "Epoch 1/100\n",
      "  1/665 [..............................] - ETA: 0s - loss: 5.0364 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0093s vs `on_train_batch_end` time: 0.0140s). Check your callbacks.\n",
      "665/665 [==============================] - ETA: 0s - loss: 1.1992 - accuracy: 0.6101\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76438, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 1.1992 - accuracy: 0.6101 - val_loss: 0.6803 - val_accuracy: 0.7644\n",
      "Epoch 2/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.7183 - accuracy: 0.7414\n",
      "Epoch 00002: val_accuracy improved from 0.76438 to 0.79695, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.7179 - accuracy: 0.7415 - val_loss: 0.5719 - val_accuracy: 0.7970\n",
      "Epoch 3/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.6108 - accuracy: 0.7794\n",
      "Epoch 00003: val_accuracy did not improve from 0.79695\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.6112 - accuracy: 0.7793 - val_loss: 0.6360 - val_accuracy: 0.7851\n",
      "Epoch 4/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.5406 - accuracy: 0.8026\n",
      "Epoch 00004: val_accuracy improved from 0.79695 to 0.85998, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.5405 - accuracy: 0.8026 - val_loss: 0.3966 - val_accuracy: 0.8600\n",
      "Epoch 5/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.4825 - accuracy: 0.8245\n",
      "Epoch 00005: val_accuracy improved from 0.85998 to 0.87606, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.4831 - accuracy: 0.8244 - val_loss: 0.3365 - val_accuracy: 0.8761\n",
      "Epoch 6/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.4452 - accuracy: 0.8391\n",
      "Epoch 00006: val_accuracy did not improve from 0.87606\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.4449 - accuracy: 0.8392 - val_loss: 0.3868 - val_accuracy: 0.8723\n",
      "Epoch 7/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.4081 - accuracy: 0.8518\n",
      "Epoch 00007: val_accuracy did not improve from 0.87606\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.4085 - accuracy: 0.8517 - val_loss: 0.3424 - val_accuracy: 0.8761\n",
      "Epoch 8/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.3671 - accuracy: 0.8675\n",
      "Epoch 00008: val_accuracy improved from 0.87606 to 0.90863, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.3669 - accuracy: 0.8676 - val_loss: 0.2472 - val_accuracy: 0.9086\n",
      "Epoch 9/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.3472 - accuracy: 0.8740\n",
      "Epoch 00009: val_accuracy improved from 0.90863 to 0.92090, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.3474 - accuracy: 0.8739 - val_loss: 0.2229 - val_accuracy: 0.9209\n",
      "Epoch 10/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.3252 - accuracy: 0.8819\n",
      "Epoch 00010: val_accuracy improved from 0.92090 to 0.92724, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.3250 - accuracy: 0.8820 - val_loss: 0.2135 - val_accuracy: 0.9272\n",
      "Epoch 11/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2979 - accuracy: 0.8906\n",
      "Epoch 00011: val_accuracy did not improve from 0.92724\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.2979 - accuracy: 0.8906 - val_loss: 0.3484 - val_accuracy: 0.8875\n",
      "Epoch 12/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2783 - accuracy: 0.8992\n",
      "Epoch 00012: val_accuracy improved from 0.92724 to 0.92936, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.2785 - accuracy: 0.8992 - val_loss: 0.1977 - val_accuracy: 0.9294\n",
      "Epoch 13/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2631 - accuracy: 0.9026\n",
      "Epoch 00013: val_accuracy improved from 0.92936 to 0.93697, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.2632 - accuracy: 0.9026 - val_loss: 0.1966 - val_accuracy: 0.9370\n",
      "Epoch 14/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2558 - accuracy: 0.9070\n",
      "Epoch 00014: val_accuracy did not improve from 0.93697\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.2556 - accuracy: 0.9071 - val_loss: 0.2625 - val_accuracy: 0.9192\n",
      "Epoch 15/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.2399 - accuracy: 0.9145\n",
      "Epoch 00015: val_accuracy did not improve from 0.93697\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.2397 - accuracy: 0.9145 - val_loss: 0.4134 - val_accuracy: 0.8761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2257 - accuracy: 0.9153\n",
      "Epoch 00016: val_accuracy did not improve from 0.93697\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.2256 - accuracy: 0.9154 - val_loss: 0.2120 - val_accuracy: 0.9272\n",
      "Epoch 17/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.9235\n",
      "Epoch 00017: val_accuracy did not improve from 0.93697\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.2119 - accuracy: 0.9235 - val_loss: 0.1901 - val_accuracy: 0.9349\n",
      "Epoch 18/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2065 - accuracy: 0.9262\n",
      "Epoch 00018: val_accuracy improved from 0.93697 to 0.95008, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.2065 - accuracy: 0.9261 - val_loss: 0.1416 - val_accuracy: 0.9501\n",
      "Epoch 19/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.1889 - accuracy: 0.9315\n",
      "Epoch 00019: val_accuracy improved from 0.95008 to 0.95601, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1889 - accuracy: 0.9315 - val_loss: 0.1285 - val_accuracy: 0.9560\n",
      "Epoch 20/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.1805 - accuracy: 0.9341\n",
      "Epoch 00020: val_accuracy improved from 0.95601 to 0.96066, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1809 - accuracy: 0.9340 - val_loss: 0.1185 - val_accuracy: 0.9607\n",
      "Epoch 21/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.9354\n",
      "Epoch 00021: val_accuracy did not improve from 0.96066\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1769 - accuracy: 0.9354 - val_loss: 0.2663 - val_accuracy: 0.9192\n",
      "Epoch 22/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1648 - accuracy: 0.9407\n",
      "Epoch 00022: val_accuracy did not improve from 0.96066\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1647 - accuracy: 0.9407 - val_loss: 0.1592 - val_accuracy: 0.9514\n",
      "Epoch 23/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1657 - accuracy: 0.9403\n",
      "Epoch 00023: val_accuracy improved from 0.96066 to 0.96954, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1657 - accuracy: 0.9403 - val_loss: 0.0977 - val_accuracy: 0.9695\n",
      "Epoch 24/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1584 - accuracy: 0.9432\n",
      "Epoch 00024: val_accuracy did not improve from 0.96954\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1585 - accuracy: 0.9431 - val_loss: 0.0991 - val_accuracy: 0.9670\n",
      "Epoch 25/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1466 - accuracy: 0.9479\n",
      "Epoch 00025: val_accuracy did not improve from 0.96954\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1464 - accuracy: 0.9480 - val_loss: 0.1055 - val_accuracy: 0.9640\n",
      "Epoch 26/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1445 - accuracy: 0.9475\n",
      "Epoch 00026: val_accuracy improved from 0.96954 to 0.97208, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 16s 23ms/step - loss: 0.1444 - accuracy: 0.9475 - val_loss: 0.0997 - val_accuracy: 0.9721\n",
      "Epoch 27/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1359 - accuracy: 0.9525\n",
      "Epoch 00027: val_accuracy did not improve from 0.97208\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1359 - accuracy: 0.9525 - val_loss: 0.0968 - val_accuracy: 0.9674\n",
      "Epoch 28/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1255 - accuracy: 0.9550\n",
      "Epoch 00028: val_accuracy did not improve from 0.97208\n",
      "665/665 [==============================] - 16s 24ms/step - loss: 0.1255 - accuracy: 0.9550 - val_loss: 0.1138 - val_accuracy: 0.9615\n",
      "Epoch 29/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.1302 - accuracy: 0.9527\n",
      "Epoch 00029: val_accuracy did not improve from 0.97208\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1303 - accuracy: 0.9527 - val_loss: 0.1524 - val_accuracy: 0.9514\n",
      "Epoch 30/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.1224 - accuracy: 0.9553\n",
      "Epoch 00030: val_accuracy did not improve from 0.97208\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1224 - accuracy: 0.9554 - val_loss: 0.0996 - val_accuracy: 0.9691\n",
      "Epoch 31/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.1228 - accuracy: 0.9554\n",
      "Epoch 00031: val_accuracy did not improve from 0.97208\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1229 - accuracy: 0.9552 - val_loss: 0.0877 - val_accuracy: 0.9712\n",
      "Epoch 32/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9588\n",
      "Epoch 00032: val_accuracy improved from 0.97208 to 0.97462, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 16s 23ms/step - loss: 0.1175 - accuracy: 0.9588 - val_loss: 0.0768 - val_accuracy: 0.9746\n",
      "Epoch 33/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.9588\n",
      "Epoch 00033: val_accuracy did not improve from 0.97462\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1131 - accuracy: 0.9588 - val_loss: 0.0810 - val_accuracy: 0.9734\n",
      "Epoch 34/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1074 - accuracy: 0.9617\n",
      "Epoch 00034: val_accuracy did not improve from 0.97462\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1075 - accuracy: 0.9617 - val_loss: 0.0811 - val_accuracy: 0.9746\n",
      "Epoch 35/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.9641\n",
      "Epoch 00035: val_accuracy improved from 0.97462 to 0.97758, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.1011 - accuracy: 0.9642 - val_loss: 0.0740 - val_accuracy: 0.9776\n",
      "Epoch 36/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.9658\n",
      "Epoch 00036: val_accuracy did not improve from 0.97758\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0962 - accuracy: 0.9658 - val_loss: 0.0836 - val_accuracy: 0.9763\n",
      "Epoch 37/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0912 - accuracy: 0.9673\n",
      "Epoch 00037: val_accuracy did not improve from 0.97758\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0912 - accuracy: 0.9673 - val_loss: 0.0723 - val_accuracy: 0.9759\n",
      "Epoch 38/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.9652\n",
      "Epoch 00038: val_accuracy improved from 0.97758 to 0.98181, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 16s 24ms/step - loss: 0.0956 - accuracy: 0.9652 - val_loss: 0.0621 - val_accuracy: 0.9818\n",
      "Epoch 39/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 0.9690\n",
      "Epoch 00039: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 16s 24ms/step - loss: 0.0872 - accuracy: 0.9690 - val_loss: 0.1144 - val_accuracy: 0.9624\n",
      "Epoch 40/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9688\n",
      "Epoch 00040: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0846 - accuracy: 0.9688 - val_loss: 0.0841 - val_accuracy: 0.9750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0851 - accuracy: 0.9704\n",
      "Epoch 00041: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0851 - accuracy: 0.9704 - val_loss: 0.0651 - val_accuracy: 0.9788\n",
      "Epoch 42/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9705\n",
      "Epoch 00042: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0803 - accuracy: 0.9705 - val_loss: 0.0842 - val_accuracy: 0.9725\n",
      "Epoch 43/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 0.9702\n",
      "Epoch 00043: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 22ms/step - loss: 0.0821 - accuracy: 0.9702 - val_loss: 0.0564 - val_accuracy: 0.9818\n",
      "Epoch 44/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0810 - accuracy: 0.9702\n",
      "Epoch 00044: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0812 - accuracy: 0.9701 - val_loss: 0.0715 - val_accuracy: 0.9793\n",
      "Epoch 45/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0775 - accuracy: 0.9729\n",
      "Epoch 00045: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0774 - accuracy: 0.9730 - val_loss: 0.0641 - val_accuracy: 0.9776\n",
      "Epoch 46/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9735\n",
      "Epoch 00046: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 17s 25ms/step - loss: 0.0736 - accuracy: 0.9735 - val_loss: 0.0673 - val_accuracy: 0.9801\n",
      "Epoch 47/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.9741\n",
      "Epoch 00047: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0746 - accuracy: 0.9741 - val_loss: 0.0870 - val_accuracy: 0.9725\n",
      "Epoch 48/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 0.9752\n",
      "Epoch 00048: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0691 - accuracy: 0.9752 - val_loss: 0.0689 - val_accuracy: 0.9801\n",
      "Epoch 49/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9757\n",
      "Epoch 00049: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0692 - accuracy: 0.9758 - val_loss: 0.0592 - val_accuracy: 0.9810\n",
      "Epoch 50/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0630 - accuracy: 0.9775\n",
      "Epoch 00050: val_accuracy did not improve from 0.98181\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0630 - accuracy: 0.9775 - val_loss: 0.1168 - val_accuracy: 0.9653\n",
      "Epoch 51/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9769\n",
      "Epoch 00051: val_accuracy improved from 0.98181 to 0.98393, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0643 - accuracy: 0.9770 - val_loss: 0.0536 - val_accuracy: 0.9839\n",
      "Epoch 52/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0637 - accuracy: 0.9777\n",
      "Epoch 00052: val_accuracy did not improve from 0.98393\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0637 - accuracy: 0.9777 - val_loss: 0.0633 - val_accuracy: 0.9810\n",
      "Epoch 53/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0634 - accuracy: 0.9778\n",
      "Epoch 00053: val_accuracy did not improve from 0.98393\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0635 - accuracy: 0.9779 - val_loss: 0.0714 - val_accuracy: 0.9776\n",
      "Epoch 54/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9787\n",
      "Epoch 00054: val_accuracy did not improve from 0.98393\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0589 - accuracy: 0.9787 - val_loss: 0.0654 - val_accuracy: 0.9818\n",
      "Epoch 55/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9778\n",
      "Epoch 00055: val_accuracy did not improve from 0.98393\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0626 - accuracy: 0.9779 - val_loss: 0.0532 - val_accuracy: 0.9835\n",
      "Epoch 56/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0607 - accuracy: 0.9780\n",
      "Epoch 00056: val_accuracy improved from 0.98393 to 0.98562, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0607 - accuracy: 0.9780 - val_loss: 0.0498 - val_accuracy: 0.9856\n",
      "Epoch 57/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9812\n",
      "Epoch 00057: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0539 - accuracy: 0.9812 - val_loss: 0.0473 - val_accuracy: 0.9848\n",
      "Epoch 58/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9788\n",
      "Epoch 00058: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0578 - accuracy: 0.9787 - val_loss: 0.0555 - val_accuracy: 0.9827\n",
      "Epoch 59/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9802\n",
      "Epoch 00059: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0556 - accuracy: 0.9803 - val_loss: 0.0491 - val_accuracy: 0.9852\n",
      "Epoch 60/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0525 - accuracy: 0.9814\n",
      "Epoch 00060: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0525 - accuracy: 0.9814 - val_loss: 0.0471 - val_accuracy: 0.9856\n",
      "Epoch 61/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0504 - accuracy: 0.9826\n",
      "Epoch 00061: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0504 - accuracy: 0.9826 - val_loss: 0.0561 - val_accuracy: 0.9835\n",
      "Epoch 62/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0560 - accuracy: 0.9806\n",
      "Epoch 00062: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0560 - accuracy: 0.9806 - val_loss: 0.0448 - val_accuracy: 0.9835\n",
      "Epoch 63/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9820\n",
      "Epoch 00063: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0511 - accuracy: 0.9819 - val_loss: 0.0606 - val_accuracy: 0.9810\n",
      "Epoch 64/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0506 - accuracy: 0.9828\n",
      "Epoch 00064: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0505 - accuracy: 0.9828 - val_loss: 0.0432 - val_accuracy: 0.9856\n",
      "Epoch 65/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9828\n",
      "Epoch 00065: val_accuracy did not improve from 0.98562\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0472 - accuracy: 0.9828 - val_loss: 0.0534 - val_accuracy: 0.9843\n",
      "Epoch 66/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9848\n",
      "Epoch 00066: val_accuracy improved from 0.98562 to 0.98773, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0424 - accuracy: 0.9849 - val_loss: 0.0392 - val_accuracy: 0.9877\n",
      "Epoch 67/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9833\n",
      "Epoch 00067: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0464 - accuracy: 0.9833 - val_loss: 0.0521 - val_accuracy: 0.9865\n",
      "Epoch 68/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9837\n",
      "Epoch 00068: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0463 - accuracy: 0.9836 - val_loss: 0.0411 - val_accuracy: 0.9869\n",
      "Epoch 69/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9850\n",
      "Epoch 00069: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0418 - accuracy: 0.9850 - val_loss: 0.0442 - val_accuracy: 0.9865\n",
      "Epoch 70/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0450 - accuracy: 0.9839\n",
      "Epoch 00070: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0451 - accuracy: 0.9838 - val_loss: 0.0672 - val_accuracy: 0.9818\n",
      "Epoch 71/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9838\n",
      "Epoch 00071: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0471 - accuracy: 0.9836 - val_loss: 0.0549 - val_accuracy: 0.9835\n",
      "Epoch 72/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9852\n",
      "Epoch 00072: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0428 - accuracy: 0.9852 - val_loss: 0.0435 - val_accuracy: 0.9852\n",
      "Epoch 73/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0453 - accuracy: 0.9842\n",
      "Epoch 00073: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0452 - accuracy: 0.9843 - val_loss: 0.0550 - val_accuracy: 0.9822\n",
      "Epoch 74/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9861\n",
      "Epoch 00074: val_accuracy did not improve from 0.98773\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0403 - accuracy: 0.9861 - val_loss: 0.0495 - val_accuracy: 0.9860\n",
      "Epoch 75/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 0.9865\n",
      "Epoch 00075: val_accuracy improved from 0.98773 to 0.98816, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0389 - accuracy: 0.9865 - val_loss: 0.0393 - val_accuracy: 0.9882\n",
      "Epoch 76/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0413 - accuracy: 0.9854\n",
      "Epoch 00076: val_accuracy did not improve from 0.98816\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0414 - accuracy: 0.9854 - val_loss: 0.0421 - val_accuracy: 0.9882\n",
      "Epoch 77/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9859\n",
      "Epoch 00077: val_accuracy did not improve from 0.98816\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0411 - accuracy: 0.9859 - val_loss: 0.0525 - val_accuracy: 0.9848\n",
      "Epoch 78/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0384 - accuracy: 0.9875\n",
      "Epoch 00078: val_accuracy improved from 0.98816 to 0.99069, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0384 - accuracy: 0.9875 - val_loss: 0.0419 - val_accuracy: 0.9907\n",
      "Epoch 79/100\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9888\n",
      "Epoch 00079: val_accuracy did not improve from 0.99069\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0343 - accuracy: 0.9888 - val_loss: 0.0393 - val_accuracy: 0.9890\n",
      "Epoch 80/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9882\n",
      "Epoch 00080: val_accuracy improved from 0.99069 to 0.99112, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0340 - accuracy: 0.9882 - val_loss: 0.0365 - val_accuracy: 0.9911\n",
      "Epoch 81/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9884\n",
      "Epoch 00081: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0354 - accuracy: 0.9884 - val_loss: 0.0430 - val_accuracy: 0.9886\n",
      "Epoch 82/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0333 - accuracy: 0.9885\n",
      "Epoch 00082: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0334 - accuracy: 0.9884 - val_loss: 0.0385 - val_accuracy: 0.9886\n",
      "Epoch 83/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9881\n",
      "Epoch 00083: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0353 - accuracy: 0.9882 - val_loss: 0.0471 - val_accuracy: 0.9869\n",
      "Epoch 84/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9875\n",
      "Epoch 00084: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0352 - accuracy: 0.9874 - val_loss: 0.0463 - val_accuracy: 0.9865\n",
      "Epoch 85/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9884\n",
      "Epoch 00085: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0343 - accuracy: 0.9884 - val_loss: 0.0355 - val_accuracy: 0.9911\n",
      "Epoch 86/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9885\n",
      "Epoch 00086: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0329 - accuracy: 0.9885 - val_loss: 0.0377 - val_accuracy: 0.9907\n",
      "Epoch 87/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9882\n",
      "Epoch 00087: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.0360 - val_accuracy: 0.9894\n",
      "Epoch 88/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0336 - accuracy: 0.9888\n",
      "Epoch 00088: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0336 - accuracy: 0.9888 - val_loss: 0.0421 - val_accuracy: 0.9877\n",
      "Epoch 89/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9883\n",
      "Epoch 00089: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0334 - accuracy: 0.9883 - val_loss: 0.0466 - val_accuracy: 0.9873\n",
      "Epoch 90/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9906\n",
      "Epoch 00090: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 0.0372 - val_accuracy: 0.9882\n",
      "Epoch 91/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.9904\n",
      "Epoch 00091: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0304 - accuracy: 0.9904 - val_loss: 0.0399 - val_accuracy: 0.9882\n",
      "Epoch 92/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9893\n",
      "Epoch 00092: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0323 - accuracy: 0.9893 - val_loss: 0.0419 - val_accuracy: 0.9877\n",
      "Epoch 93/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9886\n",
      "Epoch 00093: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0315 - accuracy: 0.9886 - val_loss: 0.0414 - val_accuracy: 0.9877\n",
      "Epoch 94/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9895\n",
      "Epoch 00094: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0300 - accuracy: 0.9894 - val_loss: 0.0374 - val_accuracy: 0.9894\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/665 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9898\n",
      "Epoch 00095: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0291 - accuracy: 0.9898 - val_loss: 0.0416 - val_accuracy: 0.9865\n",
      "Epoch 96/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9902\n",
      "Epoch 00096: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0281 - accuracy: 0.9902 - val_loss: 0.0381 - val_accuracy: 0.9894\n",
      "Epoch 97/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9912\n",
      "Epoch 00097: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0263 - accuracy: 0.9913 - val_loss: 0.0378 - val_accuracy: 0.9898\n",
      "Epoch 98/100\n",
      "663/665 [============================>.] - ETA: 0s - loss: 0.0260 - accuracy: 0.9904\n",
      "Epoch 00098: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0259 - accuracy: 0.9904 - val_loss: 0.0357 - val_accuracy: 0.9898\n",
      "Epoch 99/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9913\n",
      "Epoch 00099: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0248 - accuracy: 0.9913 - val_loss: 0.0302 - val_accuracy: 0.9907\n",
      "Epoch 100/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9909\n",
      "Epoch 00100: val_accuracy did not improve from 0.99112\n",
      "Restoring model weights from the end of the best epoch.\n",
      "665/665 [==============================] - 15s 23ms/step - loss: 0.0279 - accuracy: 0.9909 - val_loss: 0.0429 - val_accuracy: 0.9869\n",
      "Epoch 00100: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [25:27<25:27, 1527.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.84      0.91      0.88       618\n",
      "        car_horn       0.86      0.93      0.90       198\n",
      "children_playing       0.75      0.90      0.82       600\n",
      "        dog_bark       0.77      0.79      0.78       600\n",
      "           siren       0.91      0.56      0.69       498\n",
      "\n",
      "        accuracy                           0.81      2514\n",
      "       macro avg       0.83      0.82      0.81      2514\n",
      "    weighted avg       0.82      0.81      0.80      2514\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_4\n",
      "Epoch 1/100\n",
      "  2/665 [..............................] - ETA: 20s - loss: 2.1798 - accuracy: 0.1719WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0219s vs `on_train_batch_end` time: 0.0399s). Check your callbacks.\n",
      "665/665 [==============================] - ETA: 0s - loss: 0.9484 - accuracy: 0.6404\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79653, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 43s 65ms/step - loss: 0.9484 - accuracy: 0.6404 - val_loss: 0.5621 - val_accuracy: 0.7965\n",
      "Epoch 2/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.5603 - accuracy: 0.7998\n",
      "Epoch 00002: val_accuracy improved from 0.79653 to 0.79865, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 42s 63ms/step - loss: 0.5605 - accuracy: 0.7997 - val_loss: 0.5843 - val_accuracy: 0.7986\n",
      "Epoch 3/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.3974 - accuracy: 0.8586\n",
      "Epoch 00003: val_accuracy improved from 0.79865 to 0.82149, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 42s 63ms/step - loss: 0.3971 - accuracy: 0.8588 - val_loss: 0.4691 - val_accuracy: 0.8215\n",
      "Epoch 4/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.3111 - accuracy: 0.8913\n",
      "Epoch 00004: val_accuracy improved from 0.82149 to 0.87775, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 42s 64ms/step - loss: 0.3110 - accuracy: 0.8914 - val_loss: 0.3458 - val_accuracy: 0.8777\n",
      "Epoch 5/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.2490 - accuracy: 0.9156\n",
      "Epoch 00005: val_accuracy improved from 0.87775 to 0.92682, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 42s 63ms/step - loss: 0.2491 - accuracy: 0.9156 - val_loss: 0.2224 - val_accuracy: 0.9268\n",
      "Epoch 6/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1919 - accuracy: 0.9347\n",
      "Epoch 00006: val_accuracy improved from 0.92682 to 0.95770, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 42s 62ms/step - loss: 0.1919 - accuracy: 0.9346 - val_loss: 0.1379 - val_accuracy: 0.9577\n",
      "Epoch 7/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1667 - accuracy: 0.9427\n",
      "Epoch 00007: val_accuracy did not improve from 0.95770\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.1666 - accuracy: 0.9428 - val_loss: 0.1734 - val_accuracy: 0.9425\n",
      "Epoch 8/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1376 - accuracy: 0.9512\n",
      "Epoch 00008: val_accuracy improved from 0.95770 to 0.95939, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.1377 - accuracy: 0.9511 - val_loss: 0.1267 - val_accuracy: 0.9594\n",
      "Epoch 9/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1192 - accuracy: 0.9599\n",
      "Epoch 00009: val_accuracy improved from 0.95939 to 0.96108, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.1192 - accuracy: 0.9598 - val_loss: 0.1180 - val_accuracy: 0.9611\n",
      "Epoch 10/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.9647\n",
      "Epoch 00010: val_accuracy improved from 0.96108 to 0.96362, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.1011 - accuracy: 0.9648 - val_loss: 0.1212 - val_accuracy: 0.9636\n",
      "Epoch 11/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0924 - accuracy: 0.9683\n",
      "Epoch 00011: val_accuracy did not improve from 0.96362\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0923 - accuracy: 0.9684 - val_loss: 0.1375 - val_accuracy: 0.9581\n",
      "Epoch 12/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 0.9744\n",
      "Epoch 00012: val_accuracy improved from 0.96362 to 0.96447, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0760 - accuracy: 0.9744 - val_loss: 0.1138 - val_accuracy: 0.9645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0655 - accuracy: 0.9779\n",
      "Epoch 00013: val_accuracy improved from 0.96447 to 0.97885, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0655 - accuracy: 0.9779 - val_loss: 0.0656 - val_accuracy: 0.9788\n",
      "Epoch 14/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9804\n",
      "Epoch 00014: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 42s 63ms/step - loss: 0.0589 - accuracy: 0.9804 - val_loss: 0.1003 - val_accuracy: 0.9691\n",
      "Epoch 15/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0559 - accuracy: 0.9812\n",
      "Epoch 00015: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0559 - accuracy: 0.9812 - val_loss: 0.0944 - val_accuracy: 0.9700\n",
      "Epoch 16/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9848\n",
      "Epoch 00016: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0466 - accuracy: 0.9849 - val_loss: 0.0780 - val_accuracy: 0.9780\n",
      "Epoch 17/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 0.9860\n",
      "Epoch 00017: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0442 - accuracy: 0.9860 - val_loss: 0.0794 - val_accuracy: 0.9750\n",
      "Epoch 18/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 0.9864\n",
      "Epoch 00018: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0389 - accuracy: 0.9863 - val_loss: 0.0828 - val_accuracy: 0.9772\n",
      "Epoch 19/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9905\n",
      "Epoch 00019: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0300 - accuracy: 0.9906 - val_loss: 0.0766 - val_accuracy: 0.9780\n",
      "Epoch 20/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9903\n",
      "Epoch 00020: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0291 - accuracy: 0.9903 - val_loss: 0.1505 - val_accuracy: 0.9636\n",
      "Epoch 21/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9890\n",
      "Epoch 00021: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0316 - accuracy: 0.9890 - val_loss: 0.0976 - val_accuracy: 0.9763\n",
      "Epoch 22/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9906\n",
      "Epoch 00022: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 42s 64ms/step - loss: 0.0280 - accuracy: 0.9906 - val_loss: 0.2378 - val_accuracy: 0.9564\n",
      "Epoch 23/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9920\n",
      "Epoch 00023: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.0810 - val_accuracy: 0.9784\n",
      "Epoch 24/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9911\n",
      "Epoch 00024: val_accuracy did not improve from 0.97885\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 0.0716 - val_accuracy: 0.9780\n",
      "Epoch 25/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9916\n",
      "Epoch 00025: val_accuracy improved from 0.97885 to 0.98012, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.0916 - val_accuracy: 0.9801\n",
      "Epoch 26/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9928\n",
      "Epoch 00026: val_accuracy improved from 0.98012 to 0.98096, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.0677 - val_accuracy: 0.9810\n",
      "Epoch 27/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9924\n",
      "Epoch 00027: val_accuracy did not improve from 0.98096\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.0723 - val_accuracy: 0.9810\n",
      "Epoch 28/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9947\n",
      "Epoch 00028: val_accuracy did not improve from 0.98096\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.1165 - val_accuracy: 0.9717\n",
      "Epoch 29/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9933\n",
      "Epoch 00029: val_accuracy improved from 0.98096 to 0.98858, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.0499 - val_accuracy: 0.9886\n",
      "Epoch 30/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9947\n",
      "Epoch 00030: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 42s 64ms/step - loss: 0.0153 - accuracy: 0.9947 - val_loss: 0.0618 - val_accuracy: 0.9860\n",
      "Epoch 31/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9933\n",
      "Epoch 00031: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0188 - accuracy: 0.9933 - val_loss: 0.0793 - val_accuracy: 0.9805\n",
      "Epoch 32/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9962\n",
      "Epoch 00032: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.0589 - val_accuracy: 0.9865\n",
      "Epoch 33/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9933\n",
      "Epoch 00033: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.0877 - val_accuracy: 0.9827\n",
      "Epoch 34/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9950\n",
      "Epoch 00034: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 43s 64ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.2457 - val_accuracy: 0.9475\n",
      "Epoch 35/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9944\n",
      "Epoch 00035: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 42s 64ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.0907 - val_accuracy: 0.9814\n",
      "Epoch 36/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9963\n",
      "Epoch 00036: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 42s 64ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.0585 - val_accuracy: 0.9856\n",
      "Epoch 37/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9971\n",
      "Epoch 00037: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.0818 - val_accuracy: 0.9839\n",
      "Epoch 38/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9962\n",
      "Epoch 00038: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.1121 - val_accuracy: 0.9759\n",
      "Epoch 39/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9961\n",
      "Epoch 00039: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0466 - val_accuracy: 0.9877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 00040: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0744 - val_accuracy: 0.9805\n",
      "Epoch 41/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9976\n",
      "Epoch 00041: val_accuracy did not improve from 0.98858\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0088 - accuracy: 0.9976 - val_loss: 0.0585 - val_accuracy: 0.9860\n",
      "Epoch 42/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9963\n",
      "Epoch 00042: val_accuracy improved from 0.98858 to 0.98900, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0118 - accuracy: 0.9963 - val_loss: 0.0482 - val_accuracy: 0.9890\n",
      "Epoch 43/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9970\n",
      "Epoch 00043: val_accuracy did not improve from 0.98900\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.0573 - val_accuracy: 0.9852\n",
      "Epoch 44/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 00044: val_accuracy did not improve from 0.98900\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.0946 - val_accuracy: 0.9831\n",
      "Epoch 45/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9978\n",
      "Epoch 00045: val_accuracy did not improve from 0.98900\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0644 - val_accuracy: 0.9869\n",
      "Epoch 46/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9972\n",
      "Epoch 00046: val_accuracy did not improve from 0.98900\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0109 - accuracy: 0.9972 - val_loss: 0.1069 - val_accuracy: 0.9772\n",
      "Epoch 47/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9973\n",
      "Epoch 00047: val_accuracy improved from 0.98900 to 0.98942, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0477 - val_accuracy: 0.9894\n",
      "Epoch 48/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9969\n",
      "Epoch 00048: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.1111 - val_accuracy: 0.9793\n",
      "Epoch 49/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9960\n",
      "Epoch 00049: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.1171 - val_accuracy: 0.9759\n",
      "Epoch 50/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9961\n",
      "Epoch 00050: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0106 - accuracy: 0.9961 - val_loss: 0.1910 - val_accuracy: 0.9662\n",
      "Epoch 51/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9964\n",
      "Epoch 00051: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0495 - val_accuracy: 0.9856\n",
      "Epoch 52/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 00052: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0553 - val_accuracy: 0.9860\n",
      "Epoch 53/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9969\n",
      "Epoch 00053: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.0468 - val_accuracy: 0.9873\n",
      "Epoch 54/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9979\n",
      "Epoch 00054: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.0645 - val_accuracy: 0.9839\n",
      "Epoch 55/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9975\n",
      "Epoch 00055: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.1327 - val_accuracy: 0.9755\n",
      "Epoch 56/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9975\n",
      "Epoch 00056: val_accuracy did not improve from 0.98942\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0074 - accuracy: 0.9975 - val_loss: 0.0642 - val_accuracy: 0.9869\n",
      "Epoch 57/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch 00057: val_accuracy improved from 0.98942 to 0.99112, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0468 - val_accuracy: 0.9911\n",
      "Epoch 58/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9984\n",
      "Epoch 00058: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0580 - val_accuracy: 0.9894\n",
      "Epoch 59/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9983\n",
      "Epoch 00059: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 0.0535 - val_accuracy: 0.9898\n",
      "Epoch 60/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 00060: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0614 - val_accuracy: 0.9873\n",
      "Epoch 61/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 00061: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0660 - val_accuracy: 0.9890\n",
      "Epoch 62/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 00062: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 42s 62ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0686 - val_accuracy: 0.9869\n",
      "Epoch 63/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 00063: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0578 - val_accuracy: 0.9882\n",
      "Epoch 64/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 00064: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0657 - val_accuracy: 0.9877\n",
      "Epoch 65/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 00065: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.1094 - val_accuracy: 0.9822\n",
      "Epoch 66/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00066: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0660 - val_accuracy: 0.9886\n",
      "Epoch 67/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 00067: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.1791 - val_accuracy: 0.9712\n",
      "Epoch 68/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 00068: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0702 - val_accuracy: 0.9890\n",
      "Epoch 69/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 00069: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0690 - val_accuracy: 0.9869\n",
      "Epoch 70/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 00070: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0502 - val_accuracy: 0.9903\n",
      "Epoch 71/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 00071: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0577 - val_accuracy: 0.9882\n",
      "Epoch 72/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 00072: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0654 - val_accuracy: 0.9877\n",
      "Epoch 73/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00073: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0612 - val_accuracy: 0.9890\n",
      "Epoch 74/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9982\n",
      "Epoch 00074: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.0714 - val_accuracy: 0.9860\n",
      "Epoch 75/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 00075: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0586 - val_accuracy: 0.9882\n",
      "Epoch 76/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 00076: val_accuracy did not improve from 0.99112\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0758 - val_accuracy: 0.9843\n",
      "Epoch 77/100\n",
      "664/665 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 00077: val_accuracy did not improve from 0.99112\n",
      "Restoring model weights from the end of the best epoch.\n",
      "665/665 [==============================] - 41s 62ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0630 - val_accuracy: 0.9882\n",
      "Epoch 00077: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:19:26<00:00, 2383.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.89      0.88      0.88       618\n",
      "        car_horn       0.84      0.95      0.89       198\n",
      "children_playing       0.90      0.91      0.90       600\n",
      "        dog_bark       0.74      0.89      0.81       600\n",
      "           siren       0.91      0.63      0.75       498\n",
      "\n",
      "        accuracy                           0.85      2514\n",
      "       macro avg       0.85      0.85      0.85      2514\n",
      "    weighted avg       0.85      0.85      0.84      2514\n",
      "\n",
      "\n",
      "Validation fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21216, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21216, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2358, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2358, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2574, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2574, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_5\n",
      "Epoch 1/100\n",
      "  1/663 [..............................] - ETA: 0s - loss: 4.3012 - accuracy: 0.3125WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0040s vs `on_train_batch_end` time: 0.0190s). Check your callbacks.\n",
      "661/663 [============================>.] - ETA: 0s - loss: 1.1228 - accuracy: 0.6314\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74258, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 1.1216 - accuracy: 0.6316 - val_loss: 0.7131 - val_accuracy: 0.7426\n",
      "Epoch 2/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.7025 - accuracy: 0.7508\n",
      "Epoch 00002: val_accuracy improved from 0.74258 to 0.76845, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.7035 - accuracy: 0.7504 - val_loss: 0.6438 - val_accuracy: 0.7684\n",
      "Epoch 3/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.5925 - accuracy: 0.7850\n",
      "Epoch 00003: val_accuracy improved from 0.76845 to 0.78456, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.5923 - accuracy: 0.7850 - val_loss: 0.5791 - val_accuracy: 0.7846\n",
      "Epoch 4/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.5153 - accuracy: 0.8141\n",
      "Epoch 00004: val_accuracy improved from 0.78456 to 0.83673, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.5147 - accuracy: 0.8143 - val_loss: 0.4892 - val_accuracy: 0.8367\n",
      "Epoch 5/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.4656 - accuracy: 0.8306\n",
      "Epoch 00005: val_accuracy improved from 0.83673 to 0.88592, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.4653 - accuracy: 0.8308 - val_loss: 0.3171 - val_accuracy: 0.8859\n",
      "Epoch 6/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.4257 - accuracy: 0.8450\n",
      "Epoch 00006: val_accuracy improved from 0.88592 to 0.88762, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.4253 - accuracy: 0.8452 - val_loss: 0.3238 - val_accuracy: 0.8876\n",
      "Epoch 7/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.3766 - accuracy: 0.8637\n",
      "Epoch 00007: val_accuracy improved from 0.88762 to 0.89355, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.3765 - accuracy: 0.8636 - val_loss: 0.2958 - val_accuracy: 0.8936\n",
      "Epoch 8/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.3528 - accuracy: 0.8741\n",
      "Epoch 00008: val_accuracy did not improve from 0.89355\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.3533 - accuracy: 0.8739 - val_loss: 0.2949 - val_accuracy: 0.8927\n",
      "Epoch 9/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.8829\n",
      "Epoch 00009: val_accuracy improved from 0.89355 to 0.90119, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.3300 - accuracy: 0.8826 - val_loss: 0.2829 - val_accuracy: 0.9012\n",
      "Epoch 10/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.3015 - accuracy: 0.8913\n",
      "Epoch 00010: val_accuracy improved from 0.90119 to 0.90840, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.3016 - accuracy: 0.8912 - val_loss: 0.2588 - val_accuracy: 0.9084\n",
      "Epoch 11/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2848 - accuracy: 0.8978\n",
      "Epoch 00011: val_accuracy improved from 0.90840 to 0.92791, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.2849 - accuracy: 0.8978 - val_loss: 0.2163 - val_accuracy: 0.9279\n",
      "Epoch 12/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.9028\n",
      "Epoch 00012: val_accuracy did not improve from 0.92791\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.2656 - accuracy: 0.9029 - val_loss: 0.2080 - val_accuracy: 0.9271\n",
      "Epoch 13/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.9103\n",
      "Epoch 00013: val_accuracy did not improve from 0.92791\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.2463 - accuracy: 0.9101 - val_loss: 0.2243 - val_accuracy: 0.9211\n",
      "Epoch 14/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2303 - accuracy: 0.9162\n",
      "Epoch 00014: val_accuracy improved from 0.92791 to 0.93299, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.2303 - accuracy: 0.9162 - val_loss: 0.1929 - val_accuracy: 0.9330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9221\n",
      "Epoch 00015: val_accuracy improved from 0.93299 to 0.95759, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.2195 - accuracy: 0.9220 - val_loss: 0.1287 - val_accuracy: 0.9576\n",
      "Epoch 16/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.2042 - accuracy: 0.9248\n",
      "Epoch 00016: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.2040 - accuracy: 0.9249 - val_loss: 0.1999 - val_accuracy: 0.9288\n",
      "Epoch 17/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1993 - accuracy: 0.9258\n",
      "Epoch 00017: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1988 - accuracy: 0.9260 - val_loss: 0.1394 - val_accuracy: 0.9542\n",
      "Epoch 18/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1873 - accuracy: 0.9317\n",
      "Epoch 00018: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1874 - accuracy: 0.9317 - val_loss: 0.2049 - val_accuracy: 0.9326\n",
      "Epoch 19/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1761 - accuracy: 0.9366\n",
      "Epoch 00019: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1764 - accuracy: 0.9365 - val_loss: 0.1320 - val_accuracy: 0.9559\n",
      "Epoch 20/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9375\n",
      "Epoch 00020: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1714 - accuracy: 0.9376 - val_loss: 0.1520 - val_accuracy: 0.9449\n",
      "Epoch 21/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1572 - accuracy: 0.9433\n",
      "Epoch 00021: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1571 - accuracy: 0.9434 - val_loss: 0.2149 - val_accuracy: 0.9173\n",
      "Epoch 22/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1498 - accuracy: 0.9461\n",
      "Epoch 00022: val_accuracy did not improve from 0.95759\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1497 - accuracy: 0.9461 - val_loss: 0.1461 - val_accuracy: 0.9512\n",
      "Epoch 23/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1453 - accuracy: 0.9477\n",
      "Epoch 00023: val_accuracy improved from 0.95759 to 0.96480, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1451 - accuracy: 0.9477 - val_loss: 0.1089 - val_accuracy: 0.9648\n",
      "Epoch 24/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 0.9516\n",
      "Epoch 00024: val_accuracy did not improve from 0.96480\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1298 - accuracy: 0.9517 - val_loss: 0.1038 - val_accuracy: 0.9648\n",
      "Epoch 25/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1330 - accuracy: 0.9522\n",
      "Epoch 00025: val_accuracy did not improve from 0.96480\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1330 - accuracy: 0.9522 - val_loss: 0.1074 - val_accuracy: 0.9635\n",
      "Epoch 26/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1281 - accuracy: 0.9536\n",
      "Epoch 00026: val_accuracy did not improve from 0.96480\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1282 - accuracy: 0.9536 - val_loss: 0.1022 - val_accuracy: 0.9631\n",
      "Epoch 27/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1271 - accuracy: 0.9543\n",
      "Epoch 00027: val_accuracy did not improve from 0.96480\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1270 - accuracy: 0.9544 - val_loss: 0.1094 - val_accuracy: 0.9606\n",
      "Epoch 28/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 0.9596\n",
      "Epoch 00028: val_accuracy did not improve from 0.96480\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1158 - accuracy: 0.9597 - val_loss: 0.1149 - val_accuracy: 0.9606\n",
      "Epoch 29/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1169 - accuracy: 0.9570\n",
      "Epoch 00029: val_accuracy improved from 0.96480 to 0.97243, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1167 - accuracy: 0.9571 - val_loss: 0.0760 - val_accuracy: 0.9724\n",
      "Epoch 30/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1053 - accuracy: 0.9621\n",
      "Epoch 00030: val_accuracy improved from 0.97243 to 0.97540, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1054 - accuracy: 0.9620 - val_loss: 0.0885 - val_accuracy: 0.9754\n",
      "Epoch 31/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1032 - accuracy: 0.9633\n",
      "Epoch 00031: val_accuracy improved from 0.97540 to 0.97668, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1030 - accuracy: 0.9634 - val_loss: 0.0715 - val_accuracy: 0.9767\n",
      "Epoch 32/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1036 - accuracy: 0.9624\n",
      "Epoch 00032: val_accuracy did not improve from 0.97668\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1035 - accuracy: 0.9625 - val_loss: 0.1393 - val_accuracy: 0.9559\n",
      "Epoch 33/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.1004 - accuracy: 0.9651\n",
      "Epoch 00033: val_accuracy did not improve from 0.97668\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.1006 - accuracy: 0.9650 - val_loss: 0.2678 - val_accuracy: 0.9279\n",
      "Epoch 34/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0945 - accuracy: 0.9652\n",
      "Epoch 00034: val_accuracy did not improve from 0.97668\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0943 - accuracy: 0.9652 - val_loss: 0.1152 - val_accuracy: 0.9635\n",
      "Epoch 35/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0898 - accuracy: 0.9673\n",
      "Epoch 00035: val_accuracy improved from 0.97668 to 0.97795, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0897 - accuracy: 0.9673 - val_loss: 0.0674 - val_accuracy: 0.9779\n",
      "Epoch 36/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0919 - accuracy: 0.9663\n",
      "Epoch 00036: val_accuracy did not improve from 0.97795\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0922 - accuracy: 0.9663 - val_loss: 0.0921 - val_accuracy: 0.9656\n",
      "Epoch 37/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0854 - accuracy: 0.9707\n",
      "Epoch 00037: val_accuracy improved from 0.97795 to 0.98092, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0858 - accuracy: 0.9706 - val_loss: 0.0613 - val_accuracy: 0.9809\n",
      "Epoch 38/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0807 - accuracy: 0.9721\n",
      "Epoch 00038: val_accuracy did not improve from 0.98092\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0808 - accuracy: 0.9720 - val_loss: 0.0639 - val_accuracy: 0.9801\n",
      "Epoch 39/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0784 - accuracy: 0.9728\n",
      "Epoch 00039: val_accuracy improved from 0.98092 to 0.98176, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0788 - accuracy: 0.9728 - val_loss: 0.0578 - val_accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9726\n",
      "Epoch 00040: val_accuracy did not improve from 0.98176\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0778 - accuracy: 0.9726 - val_loss: 0.0791 - val_accuracy: 0.9716\n",
      "Epoch 41/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0787 - accuracy: 0.9729\n",
      "Epoch 00041: val_accuracy improved from 0.98176 to 0.98388, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0788 - accuracy: 0.9729 - val_loss: 0.0587 - val_accuracy: 0.9839\n",
      "Epoch 42/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0742 - accuracy: 0.9732\n",
      "Epoch 00042: val_accuracy improved from 0.98388 to 0.98728, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0747 - accuracy: 0.9731 - val_loss: 0.0520 - val_accuracy: 0.9873\n",
      "Epoch 43/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9755\n",
      "Epoch 00043: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0677 - accuracy: 0.9755 - val_loss: 0.0619 - val_accuracy: 0.9771\n",
      "Epoch 44/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 0.9761\n",
      "Epoch 00044: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0691 - accuracy: 0.9761 - val_loss: 0.0576 - val_accuracy: 0.9843\n",
      "Epoch 45/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0701 - accuracy: 0.9749\n",
      "Epoch 00045: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 14s 22ms/step - loss: 0.0701 - accuracy: 0.9749 - val_loss: 0.0486 - val_accuracy: 0.9869\n",
      "Epoch 46/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0627 - accuracy: 0.9766\n",
      "Epoch 00046: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0628 - accuracy: 0.9764 - val_loss: 0.0457 - val_accuracy: 0.9873\n",
      "Epoch 47/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9782\n",
      "Epoch 00047: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0614 - accuracy: 0.9782 - val_loss: 0.0970 - val_accuracy: 0.9678\n",
      "Epoch 48/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0578 - accuracy: 0.9792\n",
      "Epoch 00048: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0578 - accuracy: 0.9793 - val_loss: 0.0648 - val_accuracy: 0.9813\n",
      "Epoch 49/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0661 - accuracy: 0.9767\n",
      "Epoch 00049: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0660 - accuracy: 0.9767 - val_loss: 0.0560 - val_accuracy: 0.9822\n",
      "Epoch 50/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 0.9792\n",
      "Epoch 00050: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0592 - accuracy: 0.9793 - val_loss: 0.0771 - val_accuracy: 0.9746\n",
      "Epoch 51/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0598 - accuracy: 0.9789\n",
      "Epoch 00051: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0597 - accuracy: 0.9790 - val_loss: 0.0467 - val_accuracy: 0.9856\n",
      "Epoch 52/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9798\n",
      "Epoch 00052: val_accuracy did not improve from 0.98728\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0556 - accuracy: 0.9798 - val_loss: 0.0524 - val_accuracy: 0.9843\n",
      "Epoch 53/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0531 - accuracy: 0.9812\n",
      "Epoch 00053: val_accuracy improved from 0.98728 to 0.98897, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0531 - accuracy: 0.9812 - val_loss: 0.0343 - val_accuracy: 0.9890\n",
      "Epoch 54/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0528 - accuracy: 0.9817\n",
      "Epoch 00054: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0528 - accuracy: 0.9817 - val_loss: 0.0483 - val_accuracy: 0.9835\n",
      "Epoch 55/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0554 - accuracy: 0.9810\n",
      "Epoch 00055: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0554 - accuracy: 0.9809 - val_loss: 0.0381 - val_accuracy: 0.9881\n",
      "Epoch 56/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9824\n",
      "Epoch 00056: val_accuracy improved from 0.98897 to 0.99109, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0493 - accuracy: 0.9824 - val_loss: 0.0331 - val_accuracy: 0.9911\n",
      "Epoch 57/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9836\n",
      "Epoch 00057: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0467 - accuracy: 0.9836 - val_loss: 0.0447 - val_accuracy: 0.9869\n",
      "Epoch 58/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9831\n",
      "Epoch 00058: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0480 - accuracy: 0.9831 - val_loss: 0.0368 - val_accuracy: 0.9885\n",
      "Epoch 59/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9836\n",
      "Epoch 00059: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0473 - accuracy: 0.9837 - val_loss: 0.0520 - val_accuracy: 0.9839\n",
      "Epoch 60/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0454 - accuracy: 0.9839\n",
      "Epoch 00060: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0453 - accuracy: 0.9839 - val_loss: 0.0471 - val_accuracy: 0.9835\n",
      "Epoch 61/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 0.9850\n",
      "Epoch 00061: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0441 - accuracy: 0.9851 - val_loss: 0.0333 - val_accuracy: 0.9898\n",
      "Epoch 62/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9844\n",
      "Epoch 00062: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0463 - accuracy: 0.9844 - val_loss: 0.0479 - val_accuracy: 0.9852\n",
      "Epoch 63/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9864\n",
      "Epoch 00063: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0400 - accuracy: 0.9864 - val_loss: 0.0371 - val_accuracy: 0.9898\n",
      "Epoch 64/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0457 - accuracy: 0.9835\n",
      "Epoch 00064: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0456 - accuracy: 0.9835 - val_loss: 0.0332 - val_accuracy: 0.9907\n",
      "Epoch 65/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0427 - accuracy: 0.9854\n",
      "Epoch 00065: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0426 - accuracy: 0.9854 - val_loss: 0.0402 - val_accuracy: 0.9881\n",
      "Epoch 66/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9851\n",
      "Epoch 00066: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0398 - accuracy: 0.9852 - val_loss: 0.0375 - val_accuracy: 0.9894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9859\n",
      "Epoch 00067: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0413 - accuracy: 0.9859 - val_loss: 0.0658 - val_accuracy: 0.9754\n",
      "Epoch 68/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9871\n",
      "Epoch 00068: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 14s 22ms/step - loss: 0.0379 - accuracy: 0.9870 - val_loss: 0.0411 - val_accuracy: 0.9860\n",
      "Epoch 69/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9880\n",
      "Epoch 00069: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 14s 22ms/step - loss: 0.0349 - accuracy: 0.9880 - val_loss: 0.0388 - val_accuracy: 0.9885\n",
      "Epoch 70/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9876\n",
      "Epoch 00070: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0367 - accuracy: 0.9876 - val_loss: 0.0467 - val_accuracy: 0.9839\n",
      "Epoch 71/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9878\n",
      "Epoch 00071: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0374 - accuracy: 0.9879 - val_loss: 0.0368 - val_accuracy: 0.9881\n",
      "Epoch 72/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0376 - accuracy: 0.9862\n",
      "Epoch 00072: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0376 - accuracy: 0.9862 - val_loss: 0.0370 - val_accuracy: 0.9873\n",
      "Epoch 73/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0350 - accuracy: 0.9878\n",
      "Epoch 00073: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0351 - accuracy: 0.9877 - val_loss: 0.0305 - val_accuracy: 0.9890\n",
      "Epoch 74/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9904\n",
      "Epoch 00074: val_accuracy did not improve from 0.99109\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0296 - accuracy: 0.9903 - val_loss: 0.0347 - val_accuracy: 0.9894\n",
      "Epoch 75/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0364 - accuracy: 0.9868\n",
      "Epoch 00075: val_accuracy improved from 0.99109 to 0.99152, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0366 - accuracy: 0.9867 - val_loss: 0.0280 - val_accuracy: 0.9915\n",
      "Epoch 76/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0327 - accuracy: 0.9883\n",
      "Epoch 00076: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 14s 22ms/step - loss: 0.0327 - accuracy: 0.9884 - val_loss: 0.0281 - val_accuracy: 0.9915\n",
      "Epoch 77/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9883\n",
      "Epoch 00077: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0343 - accuracy: 0.9883 - val_loss: 0.0379 - val_accuracy: 0.9877\n",
      "Epoch 78/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9878\n",
      "Epoch 00078: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 0.0382 - val_accuracy: 0.9885\n",
      "Epoch 79/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9884\n",
      "Epoch 00079: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0329 - accuracy: 0.9884 - val_loss: 0.0294 - val_accuracy: 0.9898\n",
      "Epoch 80/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.9889\n",
      "Epoch 00080: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0320 - accuracy: 0.9889 - val_loss: 0.0241 - val_accuracy: 0.9915\n",
      "Epoch 81/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9889\n",
      "Epoch 00081: val_accuracy improved from 0.99152 to 0.99194, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0323 - accuracy: 0.9889 - val_loss: 0.0245 - val_accuracy: 0.9919\n",
      "Epoch 82/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9896\n",
      "Epoch 00082: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0288 - accuracy: 0.9896 - val_loss: 0.0380 - val_accuracy: 0.9864\n",
      "Epoch 83/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9899\n",
      "Epoch 00083: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0319 - accuracy: 0.9899 - val_loss: 0.0288 - val_accuracy: 0.9907\n",
      "Epoch 84/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9896\n",
      "Epoch 00084: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0302 - accuracy: 0.9895 - val_loss: 0.0409 - val_accuracy: 0.9860\n",
      "Epoch 85/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 0.9894\n",
      "Epoch 00085: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0296 - accuracy: 0.9893 - val_loss: 0.0398 - val_accuracy: 0.9881\n",
      "Epoch 86/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9892\n",
      "Epoch 00086: val_accuracy did not improve from 0.99194\n",
      "663/663 [==============================] - 14s 22ms/step - loss: 0.0295 - accuracy: 0.9892 - val_loss: 0.0288 - val_accuracy: 0.9894\n",
      "Epoch 87/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9902\n",
      "Epoch 00087: val_accuracy improved from 0.99194 to 0.99237, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.0274 - val_accuracy: 0.9924\n",
      "Epoch 88/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9902\n",
      "Epoch 00088: val_accuracy did not improve from 0.99237\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0265 - accuracy: 0.9902 - val_loss: 0.0294 - val_accuracy: 0.9915\n",
      "Epoch 89/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0281 - accuracy: 0.9899\n",
      "Epoch 00089: val_accuracy did not improve from 0.99237\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0282 - accuracy: 0.9899 - val_loss: 0.0280 - val_accuracy: 0.9898\n",
      "Epoch 90/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9903\n",
      "Epoch 00090: val_accuracy did not improve from 0.99237\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0279 - accuracy: 0.9902 - val_loss: 0.0461 - val_accuracy: 0.9864\n",
      "Epoch 91/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9908\n",
      "Epoch 00091: val_accuracy did not improve from 0.99237\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0257 - accuracy: 0.9908 - val_loss: 0.0293 - val_accuracy: 0.9898\n",
      "Epoch 92/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9904\n",
      "Epoch 00092: val_accuracy did not improve from 0.99237\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0286 - accuracy: 0.9903 - val_loss: 0.0328 - val_accuracy: 0.9898\n",
      "Epoch 93/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9919\n",
      "Epoch 00093: val_accuracy did not improve from 0.99237\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0381 - val_accuracy: 0.9864\n",
      "Epoch 94/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9901\n",
      "Epoch 00094: val_accuracy improved from 0.99237 to 0.99279, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0273 - accuracy: 0.9901 - val_loss: 0.0282 - val_accuracy: 0.9928\n",
      "Epoch 95/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9902\n",
      "Epoch 00095: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0276 - accuracy: 0.9902 - val_loss: 0.0249 - val_accuracy: 0.9924\n",
      "Epoch 96/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9908\n",
      "Epoch 00096: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0255 - accuracy: 0.9908 - val_loss: 0.0654 - val_accuracy: 0.9792\n",
      "Epoch 97/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9907\n",
      "Epoch 00097: val_accuracy did not improve from 0.99279\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0345 - val_accuracy: 0.9885\n",
      "Epoch 98/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.9923\n",
      "Epoch 00098: val_accuracy improved from 0.99279 to 0.99364, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0228 - accuracy: 0.9923 - val_loss: 0.0214 - val_accuracy: 0.9936\n",
      "Epoch 99/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9917\n",
      "Epoch 00099: val_accuracy did not improve from 0.99364\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.0212 - val_accuracy: 0.9932\n",
      "Epoch 100/100\n",
      "661/663 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9922\n",
      "Epoch 00100: val_accuracy did not improve from 0.99364\n",
      "663/663 [==============================] - 15s 22ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.0297 - val_accuracy: 0.9885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [24:23<24:23, 1463.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.78      0.92      0.84       576\n",
      "        car_horn       0.93      0.80      0.86       252\n",
      "children_playing       0.87      0.89      0.88       600\n",
      "        dog_bark       0.91      0.91      0.91       600\n",
      "           siren       0.96      0.79      0.87       546\n",
      "\n",
      "        accuracy                           0.87      2574\n",
      "       macro avg       0.89      0.86      0.87      2574\n",
      "    weighted avg       0.88      0.87      0.87      2574\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_6\n",
      "Epoch 1/100\n",
      "  2/663 [..............................] - ETA: 19s - loss: 2.4419 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0040s vs `on_train_batch_end` time: 0.0548s). Check your callbacks.\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.9050 - accuracy: 0.6623\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76081, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.9050 - accuracy: 0.6623 - val_loss: 0.6431 - val_accuracy: 0.7608\n",
      "Epoch 2/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.5370 - accuracy: 0.8138\n",
      "Epoch 00002: val_accuracy improved from 0.76081 to 0.77311, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.5370 - accuracy: 0.8138 - val_loss: 0.6772 - val_accuracy: 0.7731\n",
      "Epoch 3/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.4093 - accuracy: 0.8596\n",
      "Epoch 00003: val_accuracy improved from 0.77311 to 0.89822, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.4093 - accuracy: 0.8596 - val_loss: 0.2938 - val_accuracy: 0.8982\n",
      "Epoch 4/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.3148 - accuracy: 0.8889\n",
      "Epoch 00004: val_accuracy did not improve from 0.89822\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.3148 - accuracy: 0.8889 - val_loss: 0.3539 - val_accuracy: 0.8757\n",
      "Epoch 5/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.9097\n",
      "Epoch 00005: val_accuracy did not improve from 0.89822\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.2611 - accuracy: 0.9097 - val_loss: 0.6664 - val_accuracy: 0.8126\n",
      "Epoch 6/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.9262\n",
      "Epoch 00006: val_accuracy did not improve from 0.89822\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.2154 - accuracy: 0.9262 - val_loss: 0.3883 - val_accuracy: 0.8685\n",
      "Epoch 7/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.9398\n",
      "Epoch 00007: val_accuracy improved from 0.89822 to 0.95038, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.1785 - accuracy: 0.9398 - val_loss: 0.1401 - val_accuracy: 0.9504\n",
      "Epoch 8/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.9460\n",
      "Epoch 00008: val_accuracy did not improve from 0.95038\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.1557 - accuracy: 0.9460 - val_loss: 0.2771 - val_accuracy: 0.9037\n",
      "Epoch 9/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.9581\n",
      "Epoch 00009: val_accuracy did not improve from 0.95038\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.1269 - accuracy: 0.9581 - val_loss: 0.2098 - val_accuracy: 0.9300\n",
      "Epoch 10/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1158 - accuracy: 0.9615\n",
      "Epoch 00010: val_accuracy did not improve from 0.95038\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.1158 - accuracy: 0.9615 - val_loss: 0.3369 - val_accuracy: 0.8893\n",
      "Epoch 11/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.9676\n",
      "Epoch 00011: val_accuracy improved from 0.95038 to 0.95335, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0953 - accuracy: 0.9676 - val_loss: 0.1508 - val_accuracy: 0.9534\n",
      "Epoch 12/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9686\n",
      "Epoch 00012: val_accuracy did not improve from 0.95335\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0909 - accuracy: 0.9686 - val_loss: 1.1129 - val_accuracy: 0.7897\n",
      "Epoch 13/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9730\n",
      "Epoch 00013: val_accuracy did not improve from 0.95335\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0823 - accuracy: 0.9730 - val_loss: 0.2177 - val_accuracy: 0.9406\n",
      "Epoch 14/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.9759\n",
      "Epoch 00014: val_accuracy improved from 0.95335 to 0.97583, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0716 - accuracy: 0.9759 - val_loss: 0.0620 - val_accuracy: 0.9758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0544 - accuracy: 0.9815\n",
      "Epoch 00015: val_accuracy did not improve from 0.97583\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0544 - accuracy: 0.9815 - val_loss: 0.0832 - val_accuracy: 0.9737\n",
      "Epoch 16/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9825\n",
      "Epoch 00016: val_accuracy did not improve from 0.97583\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0549 - accuracy: 0.9825 - val_loss: 0.0980 - val_accuracy: 0.9699\n",
      "Epoch 17/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9833\n",
      "Epoch 00017: val_accuracy did not improve from 0.97583\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0496 - accuracy: 0.9833 - val_loss: 0.1420 - val_accuracy: 0.9589\n",
      "Epoch 18/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9835\n",
      "Epoch 00018: val_accuracy improved from 0.97583 to 0.97837, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0515 - accuracy: 0.9835 - val_loss: 0.0722 - val_accuracy: 0.9784\n",
      "Epoch 19/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9866\n",
      "Epoch 00019: val_accuracy did not improve from 0.97837\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0422 - accuracy: 0.9866 - val_loss: 0.0917 - val_accuracy: 0.9724\n",
      "Epoch 20/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 0.9874\n",
      "Epoch 00020: val_accuracy did not improve from 0.97837\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0409 - accuracy: 0.9874 - val_loss: 0.0798 - val_accuracy: 0.9763\n",
      "Epoch 21/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.9894\n",
      "Epoch 00021: val_accuracy improved from 0.97837 to 0.97964, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0324 - accuracy: 0.9894 - val_loss: 0.0649 - val_accuracy: 0.9796\n",
      "Epoch 22/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9914\n",
      "Epoch 00022: val_accuracy improved from 0.97964 to 0.98388, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 0.0429 - val_accuracy: 0.9839\n",
      "Epoch 23/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9897\n",
      "Epoch 00023: val_accuracy did not improve from 0.98388\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0327 - accuracy: 0.9897 - val_loss: 0.0805 - val_accuracy: 0.9746\n",
      "Epoch 24/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9927\n",
      "Epoch 00024: val_accuracy did not improve from 0.98388\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0232 - accuracy: 0.9927 - val_loss: 0.0748 - val_accuracy: 0.9796\n",
      "Epoch 25/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9924\n",
      "Epoch 00025: val_accuracy did not improve from 0.98388\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0236 - accuracy: 0.9924 - val_loss: 0.0541 - val_accuracy: 0.9835\n",
      "Epoch 26/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9919\n",
      "Epoch 00026: val_accuracy did not improve from 0.98388\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 0.0732 - val_accuracy: 0.9822\n",
      "Epoch 27/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9917\n",
      "Epoch 00027: val_accuracy did not improve from 0.98388\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0236 - accuracy: 0.9917 - val_loss: 0.0940 - val_accuracy: 0.9750\n",
      "Epoch 28/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 0.9926\n",
      "Epoch 00028: val_accuracy did not improve from 0.98388\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.0850 - val_accuracy: 0.9801\n",
      "Epoch 29/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9931\n",
      "Epoch 00029: val_accuracy improved from 0.98388 to 0.98473, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.0610 - val_accuracy: 0.9847\n",
      "Epoch 30/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9929\n",
      "Epoch 00030: val_accuracy did not improve from 0.98473\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.2120 - val_accuracy: 0.9474\n",
      "Epoch 31/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9942\n",
      "Epoch 00031: val_accuracy improved from 0.98473 to 0.98516, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0547 - val_accuracy: 0.9852\n",
      "Epoch 32/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9942\n",
      "Epoch 00032: val_accuracy did not improve from 0.98516\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.1153 - val_accuracy: 0.9669\n",
      "Epoch 33/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9939\n",
      "Epoch 00033: val_accuracy did not improve from 0.98516\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0188 - accuracy: 0.9939 - val_loss: 0.0657 - val_accuracy: 0.9818\n",
      "Epoch 34/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9932\n",
      "Epoch 00034: val_accuracy did not improve from 0.98516\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.1637 - val_accuracy: 0.9640\n",
      "Epoch 35/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9959\n",
      "Epoch 00035: val_accuracy did not improve from 0.98516\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0983 - val_accuracy: 0.9792\n",
      "Epoch 36/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9957\n",
      "Epoch 00036: val_accuracy did not improve from 0.98516\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0138 - accuracy: 0.9957 - val_loss: 0.1146 - val_accuracy: 0.9746\n",
      "Epoch 37/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9970\n",
      "Epoch 00037: val_accuracy improved from 0.98516 to 0.98601, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0774 - val_accuracy: 0.9860\n",
      "Epoch 38/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9968\n",
      "Epoch 00038: val_accuracy did not improve from 0.98601\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.0836 - val_accuracy: 0.9813\n",
      "Epoch 39/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9948\n",
      "Epoch 00039: val_accuracy did not improve from 0.98601\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.0837 - val_accuracy: 0.9796\n",
      "Epoch 40/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9940\n",
      "Epoch 00040: val_accuracy did not improve from 0.98601\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.0624 - val_accuracy: 0.9860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9966\n",
      "Epoch 00041: val_accuracy improved from 0.98601 to 0.98855, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.0497 - val_accuracy: 0.9885\n",
      "Epoch 42/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 0.9971\n",
      "Epoch 00042: val_accuracy improved from 0.98855 to 0.98897, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.0536 - val_accuracy: 0.9890\n",
      "Epoch 43/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9953\n",
      "Epoch 00043: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0695 - val_accuracy: 0.9856\n",
      "Epoch 44/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 0.9970\n",
      "Epoch 00044: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0588 - val_accuracy: 0.9873\n",
      "Epoch 45/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9960\n",
      "Epoch 00045: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0119 - accuracy: 0.9960 - val_loss: 0.0468 - val_accuracy: 0.9869\n",
      "Epoch 46/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9972\n",
      "Epoch 00046: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0078 - accuracy: 0.9972 - val_loss: 0.0500 - val_accuracy: 0.9877\n",
      "Epoch 47/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9959\n",
      "Epoch 00047: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0747 - val_accuracy: 0.9830\n",
      "Epoch 48/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9964\n",
      "Epoch 00048: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0709 - val_accuracy: 0.9843\n",
      "Epoch 49/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9951\n",
      "Epoch 00049: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0152 - accuracy: 0.9951 - val_loss: 0.0753 - val_accuracy: 0.9801\n",
      "Epoch 50/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9970\n",
      "Epoch 00050: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.0825 - val_accuracy: 0.9818\n",
      "Epoch 51/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 00051: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.1011 - val_accuracy: 0.9775\n",
      "Epoch 52/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9973\n",
      "Epoch 00052: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.1867 - val_accuracy: 0.9606\n",
      "Epoch 53/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9957\n",
      "Epoch 00053: val_accuracy did not improve from 0.98897\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0433 - val_accuracy: 0.9890\n",
      "Epoch 54/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9978\n",
      "Epoch 00054: val_accuracy improved from 0.98897 to 0.98940, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0415 - val_accuracy: 0.9894\n",
      "Epoch 55/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 0.9981\n",
      "Epoch 00055: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0600 - val_accuracy: 0.9860\n",
      "Epoch 56/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 00056: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0541 - val_accuracy: 0.9864\n",
      "Epoch 57/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9978\n",
      "Epoch 00057: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0565 - val_accuracy: 0.9860\n",
      "Epoch 58/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9973\n",
      "Epoch 00058: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0556 - val_accuracy: 0.9885\n",
      "Epoch 59/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9976\n",
      "Epoch 00059: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0618 - val_accuracy: 0.9869\n",
      "Epoch 60/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9975\n",
      "Epoch 00060: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0569 - val_accuracy: 0.9864\n",
      "Epoch 61/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 00061: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0569 - val_accuracy: 0.9881\n",
      "Epoch 62/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 00062: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0514 - val_accuracy: 0.9894\n",
      "Epoch 63/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9980\n",
      "Epoch 00063: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0884 - val_accuracy: 0.9822\n",
      "Epoch 64/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 00064: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0516 - val_accuracy: 0.9860\n",
      "Epoch 65/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch 00065: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0564 - val_accuracy: 0.9843\n",
      "Epoch 66/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9985\n",
      "Epoch 00066: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0050 - accuracy: 0.9985 - val_loss: 0.0408 - val_accuracy: 0.9881\n",
      "Epoch 67/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 00067: val_accuracy did not improve from 0.98940\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0557 - val_accuracy: 0.9856\n",
      "Epoch 68/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 0.9990\n",
      "Epoch 00068: val_accuracy improved from 0.98940 to 0.99152, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0429 - val_accuracy: 0.9915\n",
      "Epoch 69/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982\n",
      "Epoch 00069: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0988 - val_accuracy: 0.9796\n",
      "Epoch 70/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9978\n",
      "Epoch 00070: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0057 - accuracy: 0.9978 - val_loss: 0.0717 - val_accuracy: 0.9852\n",
      "Epoch 71/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 0.9983\n",
      "Epoch 00071: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.0588 - val_accuracy: 0.9852\n",
      "Epoch 72/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9982\n",
      "Epoch 00072: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 0.0539 - val_accuracy: 0.9860\n",
      "Epoch 73/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 00073: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0623 - val_accuracy: 0.9869\n",
      "Epoch 74/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 00074: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0514 - val_accuracy: 0.9877\n",
      "Epoch 75/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 00075: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 0.0820 - val_accuracy: 0.9826\n",
      "Epoch 76/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 00076: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0452 - val_accuracy: 0.9885\n",
      "Epoch 77/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 00077: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0616 - val_accuracy: 0.9894\n",
      "Epoch 78/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 00078: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0635 - val_accuracy: 0.9877\n",
      "Epoch 79/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 00079: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0439 - val_accuracy: 0.9907\n",
      "Epoch 80/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00080: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0466 - val_accuracy: 0.9877\n",
      "Epoch 81/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 0.9988\n",
      "Epoch 00081: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0479 - val_accuracy: 0.9860\n",
      "Epoch 82/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 00082: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0472 - val_accuracy: 0.9864\n",
      "Epoch 83/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00083: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 61ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0699 - val_accuracy: 0.9852\n",
      "Epoch 84/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 00084: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.1095 - val_accuracy: 0.9809\n",
      "Epoch 85/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 00085: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0404 - val_accuracy: 0.9907\n",
      "Epoch 86/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00086: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0539 - val_accuracy: 0.9885\n",
      "Epoch 87/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 00087: val_accuracy did not improve from 0.99152\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0466 - val_accuracy: 0.9885\n",
      "Epoch 88/100\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 00088: val_accuracy did not improve from 0.99152\n",
      "Restoring model weights from the end of the best epoch.\n",
      "663/663 [==============================] - 41s 62ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0536 - val_accuracy: 0.9881\n",
      "Epoch 00088: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:24:38<00:00, 2539.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.91      0.88      0.89       576\n",
      "        car_horn       0.84      0.78      0.81       252\n",
      "children_playing       0.83      0.95      0.89       600\n",
      "        dog_bark       0.93      0.95      0.94       600\n",
      "           siren       1.00      0.89      0.94       546\n",
      "\n",
      "        accuracy                           0.90      2574\n",
      "       macro avg       0.90      0.89      0.89      2574\n",
      "    weighted avg       0.91      0.90      0.90      2574\n",
      "\n",
      "\n",
      "Validation fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (20930, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (20930, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2326, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2326, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2892, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2892, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_7\n",
      "Epoch 1/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 1.1723 - accuracy: 0.6122\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73431, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 23ms/step - loss: 1.1723 - accuracy: 0.6122 - val_loss: 0.7568 - val_accuracy: 0.7343\n",
      "Epoch 2/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.7315 - accuracy: 0.7369\n",
      "Epoch 00002: val_accuracy improved from 0.73431 to 0.81126, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.7315 - accuracy: 0.7369 - val_loss: 0.5454 - val_accuracy: 0.8113\n",
      "Epoch 3/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.6183 - accuracy: 0.7781\n",
      "Epoch 00003: val_accuracy improved from 0.81126 to 0.84996, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.6173 - accuracy: 0.7785 - val_loss: 0.4158 - val_accuracy: 0.8500\n",
      "Epoch 4/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.8084\n",
      "Epoch 00004: val_accuracy did not improve from 0.84996\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.5312 - accuracy: 0.8084 - val_loss: 0.4500 - val_accuracy: 0.8353\n",
      "Epoch 5/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.5081 - accuracy: 0.8160\n",
      "Epoch 00005: val_accuracy did not improve from 0.84996\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.5075 - accuracy: 0.8161 - val_loss: 0.5080 - val_accuracy: 0.8121\n",
      "Epoch 6/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.4316 - accuracy: 0.8413\n",
      "Epoch 00006: val_accuracy did not improve from 0.84996\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.4316 - accuracy: 0.8413 - val_loss: 0.4500 - val_accuracy: 0.8285\n",
      "Epoch 7/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.3914 - accuracy: 0.8563\n",
      "Epoch 00007: val_accuracy improved from 0.84996 to 0.85082, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.3914 - accuracy: 0.8563 - val_loss: 0.4203 - val_accuracy: 0.8508\n",
      "Epoch 8/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.8724\n",
      "Epoch 00008: val_accuracy improved from 0.85082 to 0.90843, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.3511 - accuracy: 0.8724 - val_loss: 0.2514 - val_accuracy: 0.9084\n",
      "Epoch 9/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.8812\n",
      "Epoch 00009: val_accuracy improved from 0.90843 to 0.91788, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.3330 - accuracy: 0.8813 - val_loss: 0.2110 - val_accuracy: 0.9179\n",
      "Epoch 10/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.8904\n",
      "Epoch 00010: val_accuracy did not improve from 0.91788\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.3064 - accuracy: 0.8904 - val_loss: 0.4517 - val_accuracy: 0.8362\n",
      "Epoch 11/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.2917 - accuracy: 0.8919\n",
      "Epoch 00011: val_accuracy did not improve from 0.91788\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.2917 - accuracy: 0.8919 - val_loss: 0.2010 - val_accuracy: 0.9175\n",
      "Epoch 12/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.2626 - accuracy: 0.9028\n",
      "Epoch 00012: val_accuracy did not improve from 0.91788\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.2629 - accuracy: 0.9027 - val_loss: 0.2678 - val_accuracy: 0.9127\n",
      "Epoch 13/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.9102\n",
      "Epoch 00013: val_accuracy did not improve from 0.91788\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.2460 - accuracy: 0.9102 - val_loss: 0.2167 - val_accuracy: 0.9170\n",
      "Epoch 14/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.9105\n",
      "Epoch 00014: val_accuracy improved from 0.91788 to 0.93981, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.2390 - accuracy: 0.9105 - val_loss: 0.1535 - val_accuracy: 0.9398\n",
      "Epoch 15/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.9212\n",
      "Epoch 00015: val_accuracy improved from 0.93981 to 0.95099, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.2177 - accuracy: 0.9212 - val_loss: 0.1387 - val_accuracy: 0.9510\n",
      "Epoch 16/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.1963 - accuracy: 0.9292\n",
      "Epoch 00016: val_accuracy did not improve from 0.95099\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1963 - accuracy: 0.9292 - val_loss: 0.1271 - val_accuracy: 0.9497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.1919 - accuracy: 0.9301\n",
      "Epoch 00017: val_accuracy did not improve from 0.95099\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1918 - accuracy: 0.9302 - val_loss: 0.1572 - val_accuracy: 0.9411\n",
      "Epoch 18/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.1840 - accuracy: 0.9336\n",
      "Epoch 00018: val_accuracy improved from 0.95099 to 0.96733, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1839 - accuracy: 0.9335 - val_loss: 0.0976 - val_accuracy: 0.9673\n",
      "Epoch 19/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 0.9379\n",
      "Epoch 00019: val_accuracy did not improve from 0.96733\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1681 - accuracy: 0.9379 - val_loss: 0.1472 - val_accuracy: 0.9475\n",
      "Epoch 20/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.9358\n",
      "Epoch 00020: val_accuracy improved from 0.96733 to 0.96819, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1745 - accuracy: 0.9358 - val_loss: 0.0846 - val_accuracy: 0.9682\n",
      "Epoch 21/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1556 - accuracy: 0.9438\n",
      "Epoch 00021: val_accuracy did not improve from 0.96819\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1556 - accuracy: 0.9438 - val_loss: 0.1863 - val_accuracy: 0.9347\n",
      "Epoch 22/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.1508 - accuracy: 0.9467\n",
      "Epoch 00022: val_accuracy did not improve from 0.96819\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1510 - accuracy: 0.9465 - val_loss: 0.2663 - val_accuracy: 0.9175\n",
      "Epoch 23/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9495\n",
      "Epoch 00023: val_accuracy did not improve from 0.96819\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1466 - accuracy: 0.9495 - val_loss: 0.1093 - val_accuracy: 0.9596\n",
      "Epoch 24/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.1363 - accuracy: 0.9502\n",
      "Epoch 00024: val_accuracy improved from 0.96819 to 0.96991, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1361 - accuracy: 0.9503 - val_loss: 0.0820 - val_accuracy: 0.9699\n",
      "Epoch 25/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9519\n",
      "Epoch 00025: val_accuracy improved from 0.96991 to 0.97377, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1294 - accuracy: 0.9519 - val_loss: 0.0692 - val_accuracy: 0.9738\n",
      "Epoch 26/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9556\n",
      "Epoch 00026: val_accuracy did not improve from 0.97377\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.1226 - accuracy: 0.9556 - val_loss: 0.1391 - val_accuracy: 0.9523\n",
      "Epoch 27/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.9575\n",
      "Epoch 00027: val_accuracy improved from 0.97377 to 0.97678, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1127 - accuracy: 0.9575 - val_loss: 0.0613 - val_accuracy: 0.9768\n",
      "Epoch 28/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9566\n",
      "Epoch 00028: val_accuracy improved from 0.97678 to 0.97807, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1195 - accuracy: 0.9566 - val_loss: 0.0606 - val_accuracy: 0.9781\n",
      "Epoch 29/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1092 - accuracy: 0.9613\n",
      "Epoch 00029: val_accuracy did not improve from 0.97807\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.1092 - accuracy: 0.9613 - val_loss: 0.0702 - val_accuracy: 0.9725\n",
      "Epoch 30/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9625\n",
      "Epoch 00030: val_accuracy improved from 0.97807 to 0.97893, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1041 - accuracy: 0.9625 - val_loss: 0.0633 - val_accuracy: 0.9789\n",
      "Epoch 31/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9634\n",
      "Epoch 00031: val_accuracy improved from 0.97893 to 0.98022, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1007 - accuracy: 0.9634 - val_loss: 0.0577 - val_accuracy: 0.9802\n",
      "Epoch 32/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.9623\n",
      "Epoch 00032: val_accuracy did not improve from 0.98022\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.1035 - accuracy: 0.9623 - val_loss: 0.0514 - val_accuracy: 0.9802\n",
      "Epoch 33/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0951 - accuracy: 0.9661\n",
      "Epoch 00033: val_accuracy did not improve from 0.98022\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.0951 - accuracy: 0.9661 - val_loss: 0.0653 - val_accuracy: 0.9759\n",
      "Epoch 34/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0910 - accuracy: 0.9675\n",
      "Epoch 00034: val_accuracy did not improve from 0.98022\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0908 - accuracy: 0.9675 - val_loss: 0.0578 - val_accuracy: 0.9785\n",
      "Epoch 35/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0841 - accuracy: 0.9700\n",
      "Epoch 00035: val_accuracy improved from 0.98022 to 0.98280, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0841 - accuracy: 0.9700 - val_loss: 0.0492 - val_accuracy: 0.9828\n",
      "Epoch 36/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0863 - accuracy: 0.9690\n",
      "Epoch 00036: val_accuracy did not improve from 0.98280\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0863 - accuracy: 0.9690 - val_loss: 0.0597 - val_accuracy: 0.9785\n",
      "Epoch 37/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0841 - accuracy: 0.9704\n",
      "Epoch 00037: val_accuracy did not improve from 0.98280\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.0842 - accuracy: 0.9703 - val_loss: 0.0609 - val_accuracy: 0.9768\n",
      "Epoch 38/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0766 - accuracy: 0.9727\n",
      "Epoch 00038: val_accuracy improved from 0.98280 to 0.98495, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0766 - accuracy: 0.9727 - val_loss: 0.0447 - val_accuracy: 0.9850\n",
      "Epoch 39/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9736\n",
      "Epoch 00039: val_accuracy did not improve from 0.98495\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0749 - accuracy: 0.9736 - val_loss: 0.1395 - val_accuracy: 0.9557\n",
      "Epoch 40/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0855 - accuracy: 0.9703\n",
      "Epoch 00040: val_accuracy did not improve from 0.98495\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0853 - accuracy: 0.9704 - val_loss: 0.0474 - val_accuracy: 0.9845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9750\n",
      "Epoch 00041: val_accuracy did not improve from 0.98495\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.0735 - accuracy: 0.9750 - val_loss: 0.2209 - val_accuracy: 0.9338\n",
      "Epoch 42/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9684\n",
      "Epoch 00042: val_accuracy improved from 0.98495 to 0.98538, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0923 - accuracy: 0.9684 - val_loss: 0.0406 - val_accuracy: 0.9854\n",
      "Epoch 43/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9737\n",
      "Epoch 00043: val_accuracy improved from 0.98538 to 0.98624, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0723 - accuracy: 0.9737 - val_loss: 0.0459 - val_accuracy: 0.9862\n",
      "Epoch 44/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9752\n",
      "Epoch 00044: val_accuracy improved from 0.98624 to 0.98667, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0686 - accuracy: 0.9752 - val_loss: 0.0465 - val_accuracy: 0.9867\n",
      "Epoch 45/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9774\n",
      "Epoch 00045: val_accuracy did not improve from 0.98667\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.0651 - accuracy: 0.9774 - val_loss: 0.0651 - val_accuracy: 0.9785\n",
      "Epoch 46/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9770\n",
      "Epoch 00046: val_accuracy did not improve from 0.98667\n",
      "655/655 [==============================] - 14s 22ms/step - loss: 0.0667 - accuracy: 0.9770 - val_loss: 0.0805 - val_accuracy: 0.9742\n",
      "Epoch 47/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9785\n",
      "Epoch 00047: val_accuracy did not improve from 0.98667\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0643 - accuracy: 0.9785 - val_loss: 0.0423 - val_accuracy: 0.9862\n",
      "Epoch 48/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9780\n",
      "Epoch 00048: val_accuracy did not improve from 0.98667\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0625 - accuracy: 0.9780 - val_loss: 0.0388 - val_accuracy: 0.9862\n",
      "Epoch 49/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0559 - accuracy: 0.9808\n",
      "Epoch 00049: val_accuracy did not improve from 0.98667\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0559 - accuracy: 0.9808 - val_loss: 0.0474 - val_accuracy: 0.9828\n",
      "Epoch 50/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0572 - accuracy: 0.9802\n",
      "Epoch 00050: val_accuracy improved from 0.98667 to 0.98968, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0572 - accuracy: 0.9802 - val_loss: 0.0290 - val_accuracy: 0.9897\n",
      "Epoch 51/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9810\n",
      "Epoch 00051: val_accuracy improved from 0.98968 to 0.99097, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0565 - accuracy: 0.9810 - val_loss: 0.0331 - val_accuracy: 0.9910\n",
      "Epoch 52/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0505 - accuracy: 0.9828\n",
      "Epoch 00052: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0504 - accuracy: 0.9828 - val_loss: 0.0318 - val_accuracy: 0.9897\n",
      "Epoch 53/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9811\n",
      "Epoch 00053: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0518 - accuracy: 0.9812 - val_loss: 0.0361 - val_accuracy: 0.9880\n",
      "Epoch 54/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9823\n",
      "Epoch 00054: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0514 - accuracy: 0.9823 - val_loss: 0.0447 - val_accuracy: 0.9828\n",
      "Epoch 55/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9834\n",
      "Epoch 00055: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0464 - accuracy: 0.9834 - val_loss: 0.0302 - val_accuracy: 0.9905\n",
      "Epoch 56/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9823\n",
      "Epoch 00056: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0511 - accuracy: 0.9823 - val_loss: 0.0329 - val_accuracy: 0.9884\n",
      "Epoch 57/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0532 - accuracy: 0.9819\n",
      "Epoch 00057: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0536 - accuracy: 0.9818 - val_loss: 0.0496 - val_accuracy: 0.9841\n",
      "Epoch 58/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9755\n",
      "Epoch 00058: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0680 - accuracy: 0.9755 - val_loss: 0.0347 - val_accuracy: 0.9875\n",
      "Epoch 59/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0530 - accuracy: 0.9813\n",
      "Epoch 00059: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0532 - accuracy: 0.9812 - val_loss: 0.0381 - val_accuracy: 0.9862\n",
      "Epoch 60/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9826\n",
      "Epoch 00060: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0501 - accuracy: 0.9827 - val_loss: 0.0369 - val_accuracy: 0.9884\n",
      "Epoch 61/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9844\n",
      "Epoch 00061: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0459 - accuracy: 0.9844 - val_loss: 0.0407 - val_accuracy: 0.9850\n",
      "Epoch 62/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9840\n",
      "Epoch 00062: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0469 - accuracy: 0.9840 - val_loss: 0.0536 - val_accuracy: 0.9832\n",
      "Epoch 63/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 0.9828\n",
      "Epoch 00063: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0476 - accuracy: 0.9828 - val_loss: 0.1008 - val_accuracy: 0.9699\n",
      "Epoch 64/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.9839\n",
      "Epoch 00064: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0428 - accuracy: 0.9839 - val_loss: 0.0450 - val_accuracy: 0.9867\n",
      "Epoch 65/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9849\n",
      "Epoch 00065: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0416 - accuracy: 0.9849 - val_loss: 0.0283 - val_accuracy: 0.9910\n",
      "Epoch 66/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9842\n",
      "Epoch 00066: val_accuracy did not improve from 0.99097\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0442 - accuracy: 0.9842 - val_loss: 0.0271 - val_accuracy: 0.9910\n",
      "Epoch 67/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9855\n",
      "Epoch 00067: val_accuracy improved from 0.99097 to 0.99140, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0411 - accuracy: 0.9855 - val_loss: 0.0253 - val_accuracy: 0.9914\n",
      "Epoch 68/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0431 - accuracy: 0.9847\n",
      "Epoch 00068: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0431 - accuracy: 0.9847 - val_loss: 0.0319 - val_accuracy: 0.9893\n",
      "Epoch 69/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9880\n",
      "Epoch 00069: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0368 - accuracy: 0.9881 - val_loss: 0.0361 - val_accuracy: 0.9884\n",
      "Epoch 70/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9860\n",
      "Epoch 00070: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0391 - accuracy: 0.9860 - val_loss: 0.0560 - val_accuracy: 0.9828\n",
      "Epoch 71/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9864\n",
      "Epoch 00071: val_accuracy improved from 0.99140 to 0.99312, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0356 - accuracy: 0.9864 - val_loss: 0.0228 - val_accuracy: 0.9931\n",
      "Epoch 72/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 0.9882\n",
      "Epoch 00072: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0356 - accuracy: 0.9882 - val_loss: 0.0210 - val_accuracy: 0.9931\n",
      "Epoch 73/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9879\n",
      "Epoch 00073: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0365 - accuracy: 0.9879 - val_loss: 0.0211 - val_accuracy: 0.9931\n",
      "Epoch 74/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9889\n",
      "Epoch 00074: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0321 - accuracy: 0.9889 - val_loss: 0.0250 - val_accuracy: 0.9914\n",
      "Epoch 75/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 0.9883\n",
      "Epoch 00075: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0339 - accuracy: 0.9883 - val_loss: 0.0316 - val_accuracy: 0.9875\n",
      "Epoch 76/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0319 - accuracy: 0.9896\n",
      "Epoch 00076: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.0309 - val_accuracy: 0.9910\n",
      "Epoch 77/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9879\n",
      "Epoch 00077: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0349 - accuracy: 0.9879 - val_loss: 0.0292 - val_accuracy: 0.9888\n",
      "Epoch 78/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 0.9874\n",
      "Epoch 00078: val_accuracy did not improve from 0.99312\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0375 - accuracy: 0.9874 - val_loss: 0.0213 - val_accuracy: 0.9927\n",
      "Epoch 79/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9878\n",
      "Epoch 00079: val_accuracy improved from 0.99312 to 0.99484, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0339 - accuracy: 0.9878 - val_loss: 0.0202 - val_accuracy: 0.9948\n",
      "Epoch 80/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9899\n",
      "Epoch 00080: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 0.0165 - val_accuracy: 0.9944\n",
      "Epoch 81/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9890\n",
      "Epoch 00081: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.0203 - val_accuracy: 0.9936\n",
      "Epoch 82/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9900\n",
      "Epoch 00082: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.0209 - val_accuracy: 0.9931\n",
      "Epoch 83/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9888\n",
      "Epoch 00083: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0303 - accuracy: 0.9888 - val_loss: 0.0227 - val_accuracy: 0.9936\n",
      "Epoch 84/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9893\n",
      "Epoch 00084: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0302 - accuracy: 0.9893 - val_loss: 0.0232 - val_accuracy: 0.9927\n",
      "Epoch 85/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9894\n",
      "Epoch 00085: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.0332 - val_accuracy: 0.9901\n",
      "Epoch 86/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9898\n",
      "Epoch 00086: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0306 - accuracy: 0.9898 - val_loss: 0.0307 - val_accuracy: 0.9918\n",
      "Epoch 87/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9899\n",
      "Epoch 00087: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0293 - accuracy: 0.9899 - val_loss: 0.0294 - val_accuracy: 0.9914\n",
      "Epoch 88/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 0.9910\n",
      "Epoch 00088: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0264 - accuracy: 0.9910 - val_loss: 0.0217 - val_accuracy: 0.9940\n",
      "Epoch 89/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9912\n",
      "Epoch 00089: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 0.0225 - val_accuracy: 0.9936\n",
      "Epoch 90/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9905\n",
      "Epoch 00090: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0263 - accuracy: 0.9905 - val_loss: 0.0225 - val_accuracy: 0.9940\n",
      "Epoch 91/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9910\n",
      "Epoch 00091: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0256 - accuracy: 0.9909 - val_loss: 0.0223 - val_accuracy: 0.9948\n",
      "Epoch 92/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9898\n",
      "Epoch 00092: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0302 - accuracy: 0.9898 - val_loss: 0.0577 - val_accuracy: 0.9858\n",
      "Epoch 93/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9902\n",
      "Epoch 00093: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0276 - accuracy: 0.9902 - val_loss: 0.0225 - val_accuracy: 0.9936\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655/655 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9917\n",
      "Epoch 00094: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.0241 - val_accuracy: 0.9914\n",
      "Epoch 95/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9913\n",
      "Epoch 00095: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0250 - accuracy: 0.9913 - val_loss: 0.0244 - val_accuracy: 0.9944\n",
      "Epoch 96/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9914\n",
      "Epoch 00096: val_accuracy did not improve from 0.99484\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.0192 - val_accuracy: 0.9948\n",
      "Epoch 97/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9909\n",
      "Epoch 00097: val_accuracy improved from 0.99484 to 0.99527, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 0.0237 - val_accuracy: 0.9953\n",
      "Epoch 98/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0262 - accuracy: 0.9915\n",
      "Epoch 00098: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.0187 - val_accuracy: 0.9944\n",
      "Epoch 99/100\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9925\n",
      "Epoch 00099: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0218 - accuracy: 0.9925 - val_loss: 0.0228 - val_accuracy: 0.9931\n",
      "Epoch 100/100\n",
      "652/655 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9926\n",
      "Epoch 00100: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 15s 22ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 0.0192 - val_accuracy: 0.9953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [24:25<24:25, 1465.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.77      0.85      0.81       720\n",
      "        car_horn       0.76      1.00      0.86       258\n",
      "children_playing       0.89      0.89      0.89       600\n",
      "        dog_bark       0.90      0.83      0.86       600\n",
      "           siren       0.95      0.81      0.87       714\n",
      "\n",
      "        accuracy                           0.86      2892\n",
      "       macro avg       0.85      0.87      0.86      2892\n",
      "    weighted avg       0.86      0.86      0.86      2892\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_8\n",
      "Epoch 1/100\n",
      "  2/655 [..............................] - ETA: 19s - loss: 2.0967 - accuracy: 0.2656WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0209s vs `on_train_batch_end` time: 0.0390s). Check your callbacks.\n",
      "655/655 [==============================] - ETA: 0s - loss: 0.9256 - accuracy: 0.6535\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73775, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.9256 - accuracy: 0.6535 - val_loss: 0.6589 - val_accuracy: 0.7377\n",
      "Epoch 2/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.5580 - accuracy: 0.8101\n",
      "Epoch 00002: val_accuracy improved from 0.73775 to 0.84351, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.5580 - accuracy: 0.8101 - val_loss: 0.4540 - val_accuracy: 0.8435\n",
      "Epoch 3/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.3949 - accuracy: 0.8659\n",
      "Epoch 00003: val_accuracy improved from 0.84351 to 0.86242, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.3951 - accuracy: 0.8658 - val_loss: 0.4197 - val_accuracy: 0.8624\n",
      "Epoch 4/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.3082 - accuracy: 0.8964\n",
      "Epoch 00004: val_accuracy improved from 0.86242 to 0.88822, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.3081 - accuracy: 0.8964 - val_loss: 0.3262 - val_accuracy: 0.8882\n",
      "Epoch 5/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.2356 - accuracy: 0.9216\n",
      "Epoch 00005: val_accuracy improved from 0.88822 to 0.91702, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.2358 - accuracy: 0.9215 - val_loss: 0.2431 - val_accuracy: 0.9170\n",
      "Epoch 6/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.9187\n",
      "Epoch 00006: val_accuracy did not improve from 0.91702\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.2416 - accuracy: 0.9186 - val_loss: 0.7839 - val_accuracy: 0.7605\n",
      "Epoch 7/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.2008 - accuracy: 0.9319\n",
      "Epoch 00007: val_accuracy improved from 0.91702 to 0.94798, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.2008 - accuracy: 0.9319 - val_loss: 0.1471 - val_accuracy: 0.9480\n",
      "Epoch 8/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1379 - accuracy: 0.9521\n",
      "Epoch 00008: val_accuracy did not improve from 0.94798\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.1381 - accuracy: 0.9521 - val_loss: 0.2681 - val_accuracy: 0.9153\n",
      "Epoch 9/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1297 - accuracy: 0.9559\n",
      "Epoch 00009: val_accuracy improved from 0.94798 to 0.96217, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.1297 - accuracy: 0.9559 - val_loss: 0.1123 - val_accuracy: 0.9622\n",
      "Epoch 10/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1081 - accuracy: 0.9644\n",
      "Epoch 00010: val_accuracy did not improve from 0.96217\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.1081 - accuracy: 0.9645 - val_loss: 0.1136 - val_accuracy: 0.9596\n",
      "Epoch 11/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0872 - accuracy: 0.9695\n",
      "Epoch 00011: val_accuracy did not improve from 0.96217\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0872 - accuracy: 0.9695 - val_loss: 0.1523 - val_accuracy: 0.9501\n",
      "Epoch 12/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9744\n",
      "Epoch 00012: val_accuracy did not improve from 0.96217\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0755 - accuracy: 0.9744 - val_loss: 0.1393 - val_accuracy: 0.9531\n",
      "Epoch 13/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0749 - accuracy: 0.9741\n",
      "Epoch 00013: val_accuracy improved from 0.96217 to 0.96389, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0749 - accuracy: 0.9742 - val_loss: 0.1096 - val_accuracy: 0.9639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0567 - accuracy: 0.9812\n",
      "Epoch 00014: val_accuracy did not improve from 0.96389\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0567 - accuracy: 0.9812 - val_loss: 0.1470 - val_accuracy: 0.9570\n",
      "Epoch 15/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9818\n",
      "Epoch 00015: val_accuracy did not improve from 0.96389\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0536 - accuracy: 0.9818 - val_loss: 0.2255 - val_accuracy: 0.9372\n",
      "Epoch 16/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.9682\n",
      "Epoch 00016: val_accuracy improved from 0.96389 to 0.97206, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.1012 - accuracy: 0.9682 - val_loss: 0.0878 - val_accuracy: 0.9721\n",
      "Epoch 17/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.9836\n",
      "Epoch 00017: val_accuracy improved from 0.97206 to 0.97463, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0523 - accuracy: 0.9836 - val_loss: 0.0973 - val_accuracy: 0.9746\n",
      "Epoch 18/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0417 - accuracy: 0.9867\n",
      "Epoch 00018: val_accuracy did not improve from 0.97463\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0419 - accuracy: 0.9866 - val_loss: 0.1027 - val_accuracy: 0.9682\n",
      "Epoch 19/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0968 - accuracy: 0.9688\n",
      "Epoch 00019: val_accuracy improved from 0.97463 to 0.98022, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0968 - accuracy: 0.9688 - val_loss: 0.0679 - val_accuracy: 0.9802\n",
      "Epoch 20/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9864\n",
      "Epoch 00020: val_accuracy improved from 0.98022 to 0.98495, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0422 - accuracy: 0.9864 - val_loss: 0.0542 - val_accuracy: 0.9850\n",
      "Epoch 21/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9875\n",
      "Epoch 00021: val_accuracy did not improve from 0.98495\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.6719 - val_accuracy: 0.8624\n",
      "Epoch 22/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1332 - accuracy: 0.9562\n",
      "Epoch 00022: val_accuracy did not improve from 0.98495\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.1332 - accuracy: 0.9562 - val_loss: 0.1315 - val_accuracy: 0.9669\n",
      "Epoch 23/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0487 - accuracy: 0.9830\n",
      "Epoch 00023: val_accuracy did not improve from 0.98495\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0487 - accuracy: 0.9830 - val_loss: 0.6522 - val_accuracy: 0.8551\n",
      "Epoch 24/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9881\n",
      "Epoch 00024: val_accuracy improved from 0.98495 to 0.98796, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0355 - accuracy: 0.9882 - val_loss: 0.0463 - val_accuracy: 0.9880\n",
      "Epoch 25/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9883\n",
      "Epoch 00025: val_accuracy did not improve from 0.98796\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0352 - accuracy: 0.9883 - val_loss: 0.0456 - val_accuracy: 0.9858\n",
      "Epoch 26/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9893\n",
      "Epoch 00026: val_accuracy did not improve from 0.98796\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0315 - accuracy: 0.9893 - val_loss: 0.0821 - val_accuracy: 0.9802\n",
      "Epoch 27/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9936\n",
      "Epoch 00027: val_accuracy did not improve from 0.98796\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0196 - accuracy: 0.9936 - val_loss: 0.0627 - val_accuracy: 0.9815\n",
      "Epoch 28/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9921\n",
      "Epoch 00028: val_accuracy improved from 0.98796 to 0.98925, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0215 - accuracy: 0.9921 - val_loss: 0.0409 - val_accuracy: 0.9893\n",
      "Epoch 29/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9945\n",
      "Epoch 00029: val_accuracy did not improve from 0.98925\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.0553 - val_accuracy: 0.9845\n",
      "Epoch 30/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9946\n",
      "Epoch 00030: val_accuracy did not improve from 0.98925\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.0616 - val_accuracy: 0.9850\n",
      "Epoch 31/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9925\n",
      "Epoch 00031: val_accuracy improved from 0.98925 to 0.98968, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 0.0416 - val_accuracy: 0.9897\n",
      "Epoch 32/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9950\n",
      "Epoch 00032: val_accuracy did not improve from 0.98968\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0164 - accuracy: 0.9950 - val_loss: 0.0502 - val_accuracy: 0.9854\n",
      "Epoch 33/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9948\n",
      "Epoch 00033: val_accuracy did not improve from 0.98968\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.0659 - val_accuracy: 0.9858\n",
      "Epoch 34/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9953\n",
      "Epoch 00034: val_accuracy improved from 0.98968 to 0.99011, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0151 - accuracy: 0.9953 - val_loss: 0.0451 - val_accuracy: 0.9901\n",
      "Epoch 35/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9962\n",
      "Epoch 00035: val_accuracy did not improve from 0.99011\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.1212 - val_accuracy: 0.9729\n",
      "Epoch 36/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9953\n",
      "Epoch 00036: val_accuracy did not improve from 0.99011\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0136 - accuracy: 0.9953 - val_loss: 0.0898 - val_accuracy: 0.9789\n",
      "Epoch 37/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9945\n",
      "Epoch 00037: val_accuracy improved from 0.99011 to 0.99140, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.0349 - val_accuracy: 0.9914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9964\n",
      "Epoch 00038: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.1030 - val_accuracy: 0.9772\n",
      "Epoch 39/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9920\n",
      "Epoch 00039: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0266 - accuracy: 0.9920 - val_loss: 0.0863 - val_accuracy: 0.9824\n",
      "Epoch 40/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9952\n",
      "Epoch 00040: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.0642 - val_accuracy: 0.9858\n",
      "Epoch 41/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9968\n",
      "Epoch 00041: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.0439 - val_accuracy: 0.9893\n",
      "Epoch 42/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0674 - accuracy: 0.9794\n",
      "Epoch 00042: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0674 - accuracy: 0.9794 - val_loss: 0.0626 - val_accuracy: 0.9841\n",
      "Epoch 43/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9931\n",
      "Epoch 00043: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.0411 - val_accuracy: 0.9897\n",
      "Epoch 44/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9950\n",
      "Epoch 00044: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.0732 - val_accuracy: 0.9828\n",
      "Epoch 45/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9958\n",
      "Epoch 00045: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.1534 - val_accuracy: 0.9652\n",
      "Epoch 46/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.1015 - accuracy: 0.9693\n",
      "Epoch 00046: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.1015 - accuracy: 0.9693 - val_loss: 0.0626 - val_accuracy: 0.9794\n",
      "Epoch 47/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9912\n",
      "Epoch 00047: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
      "Epoch 48/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9939\n",
      "Epoch 00048: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.0553 - val_accuracy: 0.9858\n",
      "Epoch 49/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9958\n",
      "Epoch 00049: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0136 - accuracy: 0.9958 - val_loss: 0.0443 - val_accuracy: 0.9893\n",
      "Epoch 50/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9965\n",
      "Epoch 00050: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.0424 - val_accuracy: 0.9893\n",
      "Epoch 51/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9959\n",
      "Epoch 00051: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 0.1779 - val_accuracy: 0.9643\n",
      "Epoch 52/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9957\n",
      "Epoch 00052: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.0389 - val_accuracy: 0.9893\n",
      "Epoch 53/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9964\n",
      "Epoch 00053: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.0406 - val_accuracy: 0.9897\n",
      "Epoch 54/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9971\n",
      "Epoch 00054: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0416 - val_accuracy: 0.9893\n",
      "Epoch 55/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9974\n",
      "Epoch 00055: val_accuracy did not improve from 0.99140\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.0583 - val_accuracy: 0.9884\n",
      "Epoch 56/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 00056: val_accuracy improved from 0.99140 to 0.99269, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0322 - val_accuracy: 0.9927\n",
      "Epoch 57/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0085 - accuracy: 0.9976\n",
      "Epoch 00057: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.0730 - val_accuracy: 0.9841\n",
      "Epoch 58/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0403 - accuracy: 0.9892\n",
      "Epoch 00058: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0403 - accuracy: 0.9892 - val_loss: 0.0439 - val_accuracy: 0.9884\n",
      "Epoch 59/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9963\n",
      "Epoch 00059: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.0421 - val_accuracy: 0.9897\n",
      "Epoch 60/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9976\n",
      "Epoch 00060: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0086 - accuracy: 0.9976 - val_loss: 0.0443 - val_accuracy: 0.9905\n",
      "Epoch 61/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9980\n",
      "Epoch 00061: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0467 - val_accuracy: 0.9914\n",
      "Epoch 62/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9978\n",
      "Epoch 00062: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.0429 - val_accuracy: 0.9897\n",
      "Epoch 63/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979\n",
      "Epoch 00063: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0414 - val_accuracy: 0.9910\n",
      "Epoch 64/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9974\n",
      "Epoch 00064: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.0402 - val_accuracy: 0.9893\n",
      "Epoch 65/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch 00065: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0365 - val_accuracy: 0.9910\n",
      "Epoch 66/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9988\n",
      "Epoch 00066: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0574 - val_accuracy: 0.9828\n",
      "Epoch 67/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 00067: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0054 - accuracy: 0.9986 - val_loss: 0.0450 - val_accuracy: 0.9905\n",
      "Epoch 68/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9989\n",
      "Epoch 00068: val_accuracy did not improve from 0.99269\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0434 - val_accuracy: 0.9914\n",
      "Epoch 69/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982\n",
      "Epoch 00069: val_accuracy improved from 0.99269 to 0.99355, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0370 - val_accuracy: 0.9936\n",
      "Epoch 70/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9982\n",
      "Epoch 00070: val_accuracy did not improve from 0.99355\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 0.0455 - val_accuracy: 0.9888\n",
      "Epoch 71/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9979\n",
      "Epoch 00071: val_accuracy did not improve from 0.99355\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0366 - val_accuracy: 0.9927\n",
      "Epoch 72/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00072: val_accuracy improved from 0.99355 to 0.99527, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0278 - val_accuracy: 0.9953\n",
      "Epoch 73/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9986\n",
      "Epoch 00073: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0314 - val_accuracy: 0.9944\n",
      "Epoch 74/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 00074: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0318 - val_accuracy: 0.9940\n",
      "Epoch 75/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 00075: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0321 - val_accuracy: 0.9948\n",
      "Epoch 76/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 00076: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0419 - val_accuracy: 0.9914\n",
      "Epoch 77/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 00077: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1995 - val_accuracy: 0.9635\n",
      "Epoch 78/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9906\n",
      "Epoch 00078: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0347 - accuracy: 0.9906 - val_loss: 0.0435 - val_accuracy: 0.9893\n",
      "Epoch 79/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9983\n",
      "Epoch 00079: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.0413 - val_accuracy: 0.9918\n",
      "Epoch 80/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 00080: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0307 - val_accuracy: 0.9931\n",
      "Epoch 81/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9983\n",
      "Epoch 00081: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0332 - val_accuracy: 0.9927\n",
      "Epoch 82/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 00082: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0399 - val_accuracy: 0.9918\n",
      "Epoch 83/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 00083: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0380 - val_accuracy: 0.9914\n",
      "Epoch 84/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 00084: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0353 - val_accuracy: 0.9936\n",
      "Epoch 85/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 00085: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.0358 - val_accuracy: 0.9927\n",
      "Epoch 86/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 00086: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0373 - val_accuracy: 0.9931\n",
      "Epoch 87/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 00087: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 0.0495 - val_accuracy: 0.9910\n",
      "Epoch 88/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00088: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0348 - val_accuracy: 0.9931\n",
      "Epoch 89/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 00089: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0387 - val_accuracy: 0.9931\n",
      "Epoch 90/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9991\n",
      "Epoch 00090: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0559 - val_accuracy: 0.9893\n",
      "Epoch 91/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 00091: val_accuracy did not improve from 0.99527\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.0413 - val_accuracy: 0.9931\n",
      "Epoch 92/100\n",
      "654/655 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 00092: val_accuracy did not improve from 0.99527\n",
      "Restoring model weights from the end of the best epoch.\n",
      "655/655 [==============================] - 41s 62ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0546 - val_accuracy: 0.9880\n",
      "Epoch 00092: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:27:00<00:00, 2610.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.80      0.91      0.85       720\n",
      "        car_horn       0.93      0.98      0.95       258\n",
      "children_playing       0.91      0.84      0.87       600\n",
      "        dog_bark       0.89      0.92      0.90       600\n",
      "           siren       0.98      0.87      0.92       714\n",
      "\n",
      "        accuracy                           0.89      2892\n",
      "       macro avg       0.90      0.90      0.90      2892\n",
      "    weighted avg       0.90      0.89      0.89      2892\n",
      "\n",
      "\n",
      "Validation fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (20622, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (20622, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2292, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2292, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (3234, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (3234, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_9\n",
      "Epoch 1/100\n",
      "645/645 [==============================] - ETA: 0s - loss: 1.2299 - accuracy: 0.5786\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65314, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 1.2299 - accuracy: 0.5786 - val_loss: 0.8969 - val_accuracy: 0.6531\n",
      "Epoch 2/100\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.7735 - accuracy: 0.7166\n",
      "Epoch 00002: val_accuracy improved from 0.65314 to 0.66449, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.7735 - accuracy: 0.7166 - val_loss: 0.9292 - val_accuracy: 0.6645\n",
      "Epoch 3/100\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.6401 - accuracy: 0.7658\n",
      "Epoch 00003: val_accuracy improved from 0.66449 to 0.79799, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.6401 - accuracy: 0.7658 - val_loss: 0.5326 - val_accuracy: 0.7980\n",
      "Epoch 4/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.5653 - accuracy: 0.7949\n",
      "Epoch 00004: val_accuracy improved from 0.79799 to 0.80977, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.5650 - accuracy: 0.7951 - val_loss: 0.5199 - val_accuracy: 0.8098\n",
      "Epoch 5/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.5082 - accuracy: 0.8154\n",
      "Epoch 00005: val_accuracy improved from 0.80977 to 0.84468, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.5079 - accuracy: 0.8154 - val_loss: 0.4258 - val_accuracy: 0.8447\n",
      "Epoch 6/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.4577 - accuracy: 0.8361\n",
      "Epoch 00006: val_accuracy did not improve from 0.84468\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.4574 - accuracy: 0.8362 - val_loss: 0.7110 - val_accuracy: 0.7901\n",
      "Epoch 7/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.4117 - accuracy: 0.8524\n",
      "Epoch 00007: val_accuracy improved from 0.84468 to 0.88307, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.4117 - accuracy: 0.8524 - val_loss: 0.3243 - val_accuracy: 0.8831\n",
      "Epoch 8/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3797 - accuracy: 0.8623\n",
      "Epoch 00008: val_accuracy did not improve from 0.88307\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.3795 - accuracy: 0.8624 - val_loss: 0.4702 - val_accuracy: 0.8360\n",
      "Epoch 9/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3428 - accuracy: 0.8774\n",
      "Epoch 00009: val_accuracy did not improve from 0.88307\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.3434 - accuracy: 0.8774 - val_loss: 0.7325 - val_accuracy: 0.7818\n",
      "Epoch 10/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.3209 - accuracy: 0.8850\n",
      "Epoch 00010: val_accuracy did not improve from 0.88307\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.3206 - accuracy: 0.8851 - val_loss: 0.4385 - val_accuracy: 0.8543\n",
      "Epoch 11/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2961 - accuracy: 0.8905\n",
      "Epoch 00011: val_accuracy did not improve from 0.88307\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.2962 - accuracy: 0.8905 - val_loss: 0.3881 - val_accuracy: 0.8700\n",
      "Epoch 12/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2787 - accuracy: 0.8995\n",
      "Epoch 00012: val_accuracy did not improve from 0.88307\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.2784 - accuracy: 0.8996 - val_loss: 0.5613 - val_accuracy: 0.7849\n",
      "Epoch 13/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2634 - accuracy: 0.9058\n",
      "Epoch 00013: val_accuracy improved from 0.88307 to 0.92888, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.2632 - accuracy: 0.9058 - val_loss: 0.2054 - val_accuracy: 0.9289\n",
      "Epoch 14/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2426 - accuracy: 0.9127\n",
      "Epoch 00014: val_accuracy did not improve from 0.92888\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.2426 - accuracy: 0.9128 - val_loss: 0.1964 - val_accuracy: 0.9271\n",
      "Epoch 15/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2258 - accuracy: 0.9215\n",
      "Epoch 00015: val_accuracy improved from 0.92888 to 0.94241, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.2255 - accuracy: 0.9216 - val_loss: 0.1607 - val_accuracy: 0.9424\n",
      "Epoch 16/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2159 - accuracy: 0.9220\n",
      "Epoch 00016: val_accuracy did not improve from 0.94241\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.2158 - accuracy: 0.9221 - val_loss: 0.3006 - val_accuracy: 0.8953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.2010 - accuracy: 0.9268\n",
      "Epoch 00017: val_accuracy did not improve from 0.94241\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.2010 - accuracy: 0.9268 - val_loss: 0.1592 - val_accuracy: 0.9415\n",
      "Epoch 18/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9309\n",
      "Epoch 00018: val_accuracy improved from 0.94241 to 0.95070, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.1930 - accuracy: 0.9310 - val_loss: 0.1357 - val_accuracy: 0.9507\n",
      "Epoch 19/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.9341\n",
      "Epoch 00019: val_accuracy did not improve from 0.95070\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1813 - accuracy: 0.9341 - val_loss: 0.1621 - val_accuracy: 0.9367\n",
      "Epoch 20/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1712 - accuracy: 0.9362\n",
      "Epoch 00020: val_accuracy improved from 0.95070 to 0.96161, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.1714 - accuracy: 0.9361 - val_loss: 0.1067 - val_accuracy: 0.9616\n",
      "Epoch 21/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9416\n",
      "Epoch 00021: val_accuracy did not improve from 0.96161\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1667 - accuracy: 0.9415 - val_loss: 0.1726 - val_accuracy: 0.9433\n",
      "Epoch 22/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1548 - accuracy: 0.9436\n",
      "Epoch 00022: val_accuracy did not improve from 0.96161\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1546 - accuracy: 0.9436 - val_loss: 0.1345 - val_accuracy: 0.9516\n",
      "Epoch 23/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1437 - accuracy: 0.9492\n",
      "Epoch 00023: val_accuracy improved from 0.96161 to 0.96990, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.1436 - accuracy: 0.9492 - val_loss: 0.0881 - val_accuracy: 0.9699\n",
      "Epoch 24/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1423 - accuracy: 0.9468\n",
      "Epoch 00024: val_accuracy did not improve from 0.96990\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1421 - accuracy: 0.9469 - val_loss: 0.1021 - val_accuracy: 0.9642\n",
      "Epoch 25/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1394 - accuracy: 0.9498\n",
      "Epoch 00025: val_accuracy did not improve from 0.96990\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1395 - accuracy: 0.9498 - val_loss: 0.0912 - val_accuracy: 0.9682\n",
      "Epoch 26/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1281 - accuracy: 0.9548\n",
      "Epoch 00026: val_accuracy did not improve from 0.96990\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1281 - accuracy: 0.9547 - val_loss: 0.1181 - val_accuracy: 0.9625\n",
      "Epoch 27/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1226 - accuracy: 0.9551\n",
      "Epoch 00027: val_accuracy improved from 0.96990 to 0.97251, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.1226 - accuracy: 0.9551 - val_loss: 0.0795 - val_accuracy: 0.9725\n",
      "Epoch 28/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9581\n",
      "Epoch 00028: val_accuracy did not improve from 0.97251\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1163 - accuracy: 0.9581 - val_loss: 0.0818 - val_accuracy: 0.9716\n",
      "Epoch 29/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1139 - accuracy: 0.9583\n",
      "Epoch 00029: val_accuracy did not improve from 0.97251\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1139 - accuracy: 0.9582 - val_loss: 0.1191 - val_accuracy: 0.9638\n",
      "Epoch 30/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1065 - accuracy: 0.9613\n",
      "Epoch 00030: val_accuracy improved from 0.97251 to 0.97295, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.1067 - accuracy: 0.9613 - val_loss: 0.0772 - val_accuracy: 0.9729\n",
      "Epoch 31/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1102 - accuracy: 0.9610\n",
      "Epoch 00031: val_accuracy improved from 0.97295 to 0.97949, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.1100 - accuracy: 0.9611 - val_loss: 0.0626 - val_accuracy: 0.9795\n",
      "Epoch 32/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.1030 - accuracy: 0.9627\n",
      "Epoch 00032: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.1030 - accuracy: 0.9627 - val_loss: 0.0853 - val_accuracy: 0.9708\n",
      "Epoch 33/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0993 - accuracy: 0.9653\n",
      "Epoch 00033: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0991 - accuracy: 0.9654 - val_loss: 0.1304 - val_accuracy: 0.9603\n",
      "Epoch 34/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9660\n",
      "Epoch 00034: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0942 - accuracy: 0.9660 - val_loss: 0.0832 - val_accuracy: 0.9725\n",
      "Epoch 35/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0887 - accuracy: 0.9679\n",
      "Epoch 00035: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0885 - accuracy: 0.9679 - val_loss: 0.1079 - val_accuracy: 0.9677\n",
      "Epoch 36/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0926 - accuracy: 0.9666\n",
      "Epoch 00036: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0924 - accuracy: 0.9666 - val_loss: 0.0971 - val_accuracy: 0.9725\n",
      "Epoch 37/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9680\n",
      "Epoch 00037: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0860 - accuracy: 0.9681 - val_loss: 0.1084 - val_accuracy: 0.9642\n",
      "Epoch 38/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0841 - accuracy: 0.9698\n",
      "Epoch 00038: val_accuracy did not improve from 0.97949\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0841 - accuracy: 0.9699 - val_loss: 0.0654 - val_accuracy: 0.9782\n",
      "Epoch 39/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0787 - accuracy: 0.9711\n",
      "Epoch 00039: val_accuracy improved from 0.97949 to 0.98473, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.0786 - accuracy: 0.9711 - val_loss: 0.0580 - val_accuracy: 0.9847\n",
      "Epoch 40/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9738\n",
      "Epoch 00040: val_accuracy did not improve from 0.98473\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0747 - accuracy: 0.9738 - val_loss: 0.1057 - val_accuracy: 0.9664\n",
      "Epoch 41/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0745 - accuracy: 0.9730\n",
      "Epoch 00041: val_accuracy did not improve from 0.98473\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0744 - accuracy: 0.9730 - val_loss: 0.0566 - val_accuracy: 0.9817\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643/645 [============================>.] - ETA: 0s - loss: 0.0707 - accuracy: 0.9746\n",
      "Epoch 00042: val_accuracy did not improve from 0.98473\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0706 - accuracy: 0.9746 - val_loss: 0.1027 - val_accuracy: 0.9673\n",
      "Epoch 43/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0691 - accuracy: 0.9750\n",
      "Epoch 00043: val_accuracy did not improve from 0.98473\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0691 - accuracy: 0.9750 - val_loss: 0.0701 - val_accuracy: 0.9786\n",
      "Epoch 44/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0720 - accuracy: 0.9747\n",
      "Epoch 00044: val_accuracy did not improve from 0.98473\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0719 - accuracy: 0.9747 - val_loss: 0.0621 - val_accuracy: 0.9812\n",
      "Epoch 45/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9768\n",
      "Epoch 00045: val_accuracy did not improve from 0.98473\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0684 - accuracy: 0.9767 - val_loss: 0.0919 - val_accuracy: 0.9703\n",
      "Epoch 46/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0674 - accuracy: 0.9754\n",
      "Epoch 00046: val_accuracy improved from 0.98473 to 0.98735, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.0674 - accuracy: 0.9754 - val_loss: 0.0435 - val_accuracy: 0.9873\n",
      "Epoch 47/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0636 - accuracy: 0.9774\n",
      "Epoch 00047: val_accuracy did not improve from 0.98735\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0635 - accuracy: 0.9774 - val_loss: 0.0750 - val_accuracy: 0.9773\n",
      "Epoch 48/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9787\n",
      "Epoch 00048: val_accuracy did not improve from 0.98735\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0617 - accuracy: 0.9787 - val_loss: 0.0422 - val_accuracy: 0.9852\n",
      "Epoch 49/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0600 - accuracy: 0.9780\n",
      "Epoch 00049: val_accuracy improved from 0.98735 to 0.98778, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.0599 - accuracy: 0.9780 - val_loss: 0.0433 - val_accuracy: 0.9878\n",
      "Epoch 50/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 0.9804\n",
      "Epoch 00050: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0574 - accuracy: 0.9804 - val_loss: 0.0471 - val_accuracy: 0.9860\n",
      "Epoch 51/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0539 - accuracy: 0.9809\n",
      "Epoch 00051: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0538 - accuracy: 0.9809 - val_loss: 0.0537 - val_accuracy: 0.9830\n",
      "Epoch 52/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9805\n",
      "Epoch 00052: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0532 - accuracy: 0.9805 - val_loss: 0.0476 - val_accuracy: 0.9869\n",
      "Epoch 53/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9813\n",
      "Epoch 00053: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0512 - accuracy: 0.9813 - val_loss: 0.0624 - val_accuracy: 0.9843\n",
      "Epoch 54/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0535 - accuracy: 0.9807\n",
      "Epoch 00054: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0534 - accuracy: 0.9807 - val_loss: 0.0591 - val_accuracy: 0.9821\n",
      "Epoch 55/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9827\n",
      "Epoch 00055: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0508 - accuracy: 0.9827 - val_loss: 0.0623 - val_accuracy: 0.9843\n",
      "Epoch 56/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0485 - accuracy: 0.9825\n",
      "Epoch 00056: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0484 - accuracy: 0.9825 - val_loss: 0.0943 - val_accuracy: 0.9729\n",
      "Epoch 57/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0492 - accuracy: 0.9830\n",
      "Epoch 00057: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0491 - accuracy: 0.9830 - val_loss: 0.0446 - val_accuracy: 0.9856\n",
      "Epoch 58/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9834\n",
      "Epoch 00058: val_accuracy did not improve from 0.98778\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0474 - accuracy: 0.9834 - val_loss: 0.0487 - val_accuracy: 0.9830\n",
      "Epoch 59/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0505 - accuracy: 0.9819\n",
      "Epoch 00059: val_accuracy improved from 0.98778 to 0.98822, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.0504 - accuracy: 0.9820 - val_loss: 0.0473 - val_accuracy: 0.9882\n",
      "Epoch 60/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9839\n",
      "Epoch 00060: val_accuracy improved from 0.98822 to 0.98997, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 0.0371 - val_accuracy: 0.9900\n",
      "Epoch 61/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9840\n",
      "Epoch 00061: val_accuracy did not improve from 0.98997\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0448 - accuracy: 0.9840 - val_loss: 0.0538 - val_accuracy: 0.9812\n",
      "Epoch 62/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9835\n",
      "Epoch 00062: val_accuracy did not improve from 0.98997\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0468 - accuracy: 0.9835 - val_loss: 0.0582 - val_accuracy: 0.9830\n",
      "Epoch 63/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9832\n",
      "Epoch 00063: val_accuracy did not improve from 0.98997\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0475 - accuracy: 0.9832 - val_loss: 0.0535 - val_accuracy: 0.9830\n",
      "Epoch 64/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9856\n",
      "Epoch 00064: val_accuracy improved from 0.98997 to 0.99084, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 15s 23ms/step - loss: 0.0421 - accuracy: 0.9856 - val_loss: 0.0307 - val_accuracy: 0.9908\n",
      "Epoch 65/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9855\n",
      "Epoch 00065: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0420 - accuracy: 0.9855 - val_loss: 0.0578 - val_accuracy: 0.9817\n",
      "Epoch 66/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.9865\n",
      "Epoch 00066: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0387 - accuracy: 0.9866 - val_loss: 0.0599 - val_accuracy: 0.9847\n",
      "Epoch 67/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0400 - accuracy: 0.9853\n",
      "Epoch 00067: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0399 - accuracy: 0.9853 - val_loss: 0.0337 - val_accuracy: 0.9882\n",
      "Epoch 68/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9867\n",
      "Epoch 00068: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0390 - accuracy: 0.9867 - val_loss: 0.0496 - val_accuracy: 0.9865\n",
      "Epoch 69/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9861\n",
      "Epoch 00069: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0391 - accuracy: 0.9861 - val_loss: 0.0415 - val_accuracy: 0.9873\n",
      "Epoch 70/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 0.9864\n",
      "Epoch 00070: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0389 - accuracy: 0.9864 - val_loss: 0.0340 - val_accuracy: 0.9904\n",
      "Epoch 71/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9866\n",
      "Epoch 00071: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0370 - accuracy: 0.9866 - val_loss: 0.0341 - val_accuracy: 0.9900\n",
      "Epoch 72/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9878\n",
      "Epoch 00072: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0363 - accuracy: 0.9878 - val_loss: 0.0329 - val_accuracy: 0.9900\n",
      "Epoch 73/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9889\n",
      "Epoch 00073: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0317 - accuracy: 0.9889 - val_loss: 0.0358 - val_accuracy: 0.9887\n",
      "Epoch 74/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0388 - accuracy: 0.9866\n",
      "Epoch 00074: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 0.0444 - val_accuracy: 0.9860\n",
      "Epoch 75/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9870\n",
      "Epoch 00075: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0364 - accuracy: 0.9871 - val_loss: 0.0668 - val_accuracy: 0.9825\n",
      "Epoch 76/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9878\n",
      "Epoch 00076: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 0.0359 - val_accuracy: 0.9895\n",
      "Epoch 77/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9895\n",
      "Epoch 00077: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0325 - accuracy: 0.9895 - val_loss: 0.0359 - val_accuracy: 0.9904\n",
      "Epoch 78/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0324 - accuracy: 0.9893\n",
      "Epoch 00078: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0325 - accuracy: 0.9892 - val_loss: 0.0296 - val_accuracy: 0.9908\n",
      "Epoch 79/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9888\n",
      "Epoch 00079: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0346 - accuracy: 0.9888 - val_loss: 0.0351 - val_accuracy: 0.9900\n",
      "Epoch 80/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9899\n",
      "Epoch 00080: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0287 - accuracy: 0.9899 - val_loss: 0.0335 - val_accuracy: 0.9908\n",
      "Epoch 81/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9875\n",
      "Epoch 00081: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0330 - accuracy: 0.9875 - val_loss: 0.0444 - val_accuracy: 0.9878\n",
      "Epoch 82/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9905\n",
      "Epoch 00082: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0286 - accuracy: 0.9905 - val_loss: 0.0349 - val_accuracy: 0.9900\n",
      "Epoch 83/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9909\n",
      "Epoch 00083: val_accuracy did not improve from 0.99084\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.0337 - val_accuracy: 0.9891\n",
      "Epoch 84/100\n",
      "643/645 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9889\n",
      "Epoch 00084: val_accuracy did not improve from 0.99084\n",
      "Restoring model weights from the end of the best epoch.\n",
      "645/645 [==============================] - 14s 22ms/step - loss: 0.0323 - accuracy: 0.9888 - val_loss: 0.0388 - val_accuracy: 0.9904\n",
      "Epoch 00084: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [20:23<20:23, 1223.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.72      0.86      0.78       684\n",
      "        car_horn       0.93      0.69      0.80       354\n",
      "children_playing       0.73      0.76      0.74       600\n",
      "        dog_bark       0.87      0.88      0.87       600\n",
      "           siren       0.94      0.87      0.91       996\n",
      "\n",
      "        accuracy                           0.83      3234\n",
      "       macro avg       0.84      0.81      0.82      3234\n",
      "    weighted avg       0.84      0.83      0.83      3234\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_10\n",
      "Epoch 1/100\n",
      "  2/645 [..............................] - ETA: 19s - loss: 2.2981 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0229s vs `on_train_batch_end` time: 0.0379s). Check your callbacks.\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.9244 - accuracy: 0.6568\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79145, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 63ms/step - loss: 0.9244 - accuracy: 0.6568 - val_loss: 0.5658 - val_accuracy: 0.7914\n",
      "Epoch 2/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5679 - accuracy: 0.7966\n",
      "Epoch 00002: val_accuracy did not improve from 0.79145\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.5677 - accuracy: 0.7966 - val_loss: 0.8435 - val_accuracy: 0.7417\n",
      "Epoch 3/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4173 - accuracy: 0.8561\n",
      "Epoch 00003: val_accuracy improved from 0.79145 to 0.85689, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.4172 - accuracy: 0.8561 - val_loss: 0.3759 - val_accuracy: 0.8569\n",
      "Epoch 4/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.8902\n",
      "Epoch 00004: val_accuracy improved from 0.85689 to 0.90794, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 41s 63ms/step - loss: 0.3232 - accuracy: 0.8902 - val_loss: 0.2575 - val_accuracy: 0.9079\n",
      "Epoch 5/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2451 - accuracy: 0.9136\n",
      "Epoch 00005: val_accuracy improved from 0.90794 to 0.92845, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.2453 - accuracy: 0.9136 - val_loss: 0.2020 - val_accuracy: 0.9284\n",
      "Epoch 6/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.2022 - accuracy: 0.9312\n",
      "Epoch 00006: val_accuracy improved from 0.92845 to 0.93979, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.2021 - accuracy: 0.9312 - val_loss: 0.1787 - val_accuracy: 0.9398\n",
      "Epoch 7/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.1714 - accuracy: 0.9421\n",
      "Epoch 00007: val_accuracy did not improve from 0.93979\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.1713 - accuracy: 0.9421 - val_loss: 0.6428 - val_accuracy: 0.8259\n",
      "Epoch 8/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.1437 - accuracy: 0.9512\n",
      "Epoch 00008: val_accuracy improved from 0.93979 to 0.94503, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.1437 - accuracy: 0.9512 - val_loss: 0.1647 - val_accuracy: 0.9450\n",
      "Epoch 9/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.1196 - accuracy: 0.9593\n",
      "Epoch 00009: val_accuracy did not improve from 0.94503\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.1197 - accuracy: 0.9594 - val_loss: 0.2831 - val_accuracy: 0.9158\n",
      "Epoch 10/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9631\n",
      "Epoch 00010: val_accuracy improved from 0.94503 to 0.96073, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.1111 - accuracy: 0.9630 - val_loss: 0.1291 - val_accuracy: 0.9607\n",
      "Epoch 11/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9678\n",
      "Epoch 00011: val_accuracy did not improve from 0.96073\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0930 - accuracy: 0.9678 - val_loss: 0.1341 - val_accuracy: 0.9529\n",
      "Epoch 12/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0811 - accuracy: 0.9727\n",
      "Epoch 00012: val_accuracy did not improve from 0.96073\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0810 - accuracy: 0.9727 - val_loss: 0.1648 - val_accuracy: 0.9568\n",
      "Epoch 13/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0653 - accuracy: 0.9769\n",
      "Epoch 00013: val_accuracy improved from 0.96073 to 0.96117, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0652 - accuracy: 0.9769 - val_loss: 0.1308 - val_accuracy: 0.9612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.9795\n",
      "Epoch 00014: val_accuracy improved from 0.96117 to 0.96466, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0613 - accuracy: 0.9795 - val_loss: 0.1246 - val_accuracy: 0.9647\n",
      "Epoch 15/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0551 - accuracy: 0.9816\n",
      "Epoch 00015: val_accuracy did not improve from 0.96466\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0551 - accuracy: 0.9816 - val_loss: 0.1684 - val_accuracy: 0.9520\n",
      "Epoch 16/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0490 - accuracy: 0.9830\n",
      "Epoch 00016: val_accuracy improved from 0.96466 to 0.97688, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0490 - accuracy: 0.9830 - val_loss: 0.0862 - val_accuracy: 0.9769\n",
      "Epoch 17/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9864\n",
      "Epoch 00017: val_accuracy did not improve from 0.97688\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0420 - accuracy: 0.9864 - val_loss: 0.1468 - val_accuracy: 0.9568\n",
      "Epoch 18/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9861\n",
      "Epoch 00018: val_accuracy did not improve from 0.97688\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0410 - accuracy: 0.9861 - val_loss: 0.1016 - val_accuracy: 0.9664\n",
      "Epoch 19/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9875\n",
      "Epoch 00019: val_accuracy did not improve from 0.97688\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0367 - accuracy: 0.9875 - val_loss: 0.1638 - val_accuracy: 0.9620\n",
      "Epoch 20/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9898\n",
      "Epoch 00020: val_accuracy improved from 0.97688 to 0.97993, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0302 - accuracy: 0.9898 - val_loss: 0.0794 - val_accuracy: 0.9799\n",
      "Epoch 21/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9903\n",
      "Epoch 00021: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0287 - accuracy: 0.9903 - val_loss: 0.9667 - val_accuracy: 0.8298\n",
      "Epoch 22/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9896\n",
      "Epoch 00022: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0318 - accuracy: 0.9896 - val_loss: 0.0935 - val_accuracy: 0.9777\n",
      "Epoch 23/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0309 - accuracy: 0.9896\n",
      "Epoch 00023: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.0936 - val_accuracy: 0.9782\n",
      "Epoch 24/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9924\n",
      "Epoch 00024: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 0.2351 - val_accuracy: 0.9468\n",
      "Epoch 25/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9917\n",
      "Epoch 00025: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.1547 - val_accuracy: 0.9651\n",
      "Epoch 26/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9919\n",
      "Epoch 00026: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0261 - accuracy: 0.9919 - val_loss: 0.3995 - val_accuracy: 0.9293\n",
      "Epoch 27/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9926\n",
      "Epoch 00027: val_accuracy did not improve from 0.97993\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.2758 - val_accuracy: 0.9346\n",
      "Epoch 28/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9930\n",
      "Epoch 00028: val_accuracy improved from 0.97993 to 0.98429, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 0.0598 - val_accuracy: 0.9843\n",
      "Epoch 29/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9956\n",
      "Epoch 00029: val_accuracy did not improve from 0.98429\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0965 - val_accuracy: 0.9751\n",
      "Epoch 30/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9940\n",
      "Epoch 00030: val_accuracy did not improve from 0.98429\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0169 - accuracy: 0.9939 - val_loss: 0.1933 - val_accuracy: 0.9577\n",
      "Epoch 31/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9947\n",
      "Epoch 00031: val_accuracy did not improve from 0.98429\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 0.0756 - val_accuracy: 0.9817\n",
      "Epoch 32/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9953\n",
      "Epoch 00032: val_accuracy did not improve from 0.98429\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0907 - val_accuracy: 0.9760\n",
      "Epoch 33/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9954\n",
      "Epoch 00033: val_accuracy did not improve from 0.98429\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0728 - val_accuracy: 0.9804\n",
      "Epoch 34/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9950\n",
      "Epoch 00034: val_accuracy did not improve from 0.98429\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.1162 - val_accuracy: 0.9777\n",
      "Epoch 35/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9959\n",
      "Epoch 00035: val_accuracy improved from 0.98429 to 0.98647, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0141 - accuracy: 0.9959 - val_loss: 0.0524 - val_accuracy: 0.9865\n",
      "Epoch 36/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9968\n",
      "Epoch 00036: val_accuracy improved from 0.98647 to 0.98735, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0563 - val_accuracy: 0.9873\n",
      "Epoch 37/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9963\n",
      "Epoch 00037: val_accuracy did not improve from 0.98735\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0958 - val_accuracy: 0.9795\n",
      "Epoch 38/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9956\n",
      "Epoch 00038: val_accuracy did not improve from 0.98735\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0156 - accuracy: 0.9956 - val_loss: 0.0462 - val_accuracy: 0.9869\n",
      "Epoch 39/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9965\n",
      "Epoch 00039: val_accuracy improved from 0.98735 to 0.98997, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0435 - val_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9978\n",
      "Epoch 00040: val_accuracy improved from 0.98997 to 0.99127, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.0411 - val_accuracy: 0.9913\n",
      "Epoch 41/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 00041: val_accuracy improved from 0.99127 to 0.99171, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0346 - val_accuracy: 0.9917\n",
      "Epoch 42/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9981\n",
      "Epoch 00042: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0408 - val_accuracy: 0.9913\n",
      "Epoch 43/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9973\n",
      "Epoch 00043: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.0431 - val_accuracy: 0.9882\n",
      "Epoch 44/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 00044: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0462 - val_accuracy: 0.9887\n",
      "Epoch 45/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0110 - accuracy: 0.9963\n",
      "Epoch 00045: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0569 - val_accuracy: 0.9878\n",
      "Epoch 46/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9982\n",
      "Epoch 00046: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0645 - val_accuracy: 0.9860\n",
      "Epoch 47/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9969\n",
      "Epoch 00047: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0464 - val_accuracy: 0.9873\n",
      "Epoch 48/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9965\n",
      "Epoch 00048: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0096 - accuracy: 0.9965 - val_loss: 0.0779 - val_accuracy: 0.9834\n",
      "Epoch 49/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9973\n",
      "Epoch 00049: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.0619 - val_accuracy: 0.9856\n",
      "Epoch 50/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 00050: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0333 - val_accuracy: 0.9913\n",
      "Epoch 51/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9976\n",
      "Epoch 00051: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.0799 - val_accuracy: 0.9830\n",
      "Epoch 52/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9981\n",
      "Epoch 00052: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0052 - accuracy: 0.9981 - val_loss: 0.0507 - val_accuracy: 0.9913\n",
      "Epoch 53/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9975\n",
      "Epoch 00053: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.1567 - val_accuracy: 0.9747\n",
      "Epoch 54/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9973\n",
      "Epoch 00054: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.1344 - val_accuracy: 0.9703\n",
      "Epoch 55/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0087 - accuracy: 0.9970\n",
      "Epoch 00055: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0087 - accuracy: 0.9970 - val_loss: 0.0906 - val_accuracy: 0.9830\n",
      "Epoch 56/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0086 - accuracy: 0.9972\n",
      "Epoch 00056: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0709 - val_accuracy: 0.9847\n",
      "Epoch 57/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 00057: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0494 - val_accuracy: 0.9882\n",
      "Epoch 58/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9989\n",
      "Epoch 00058: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0660 - val_accuracy: 0.9847\n",
      "Epoch 59/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9991\n",
      "Epoch 00059: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0512 - val_accuracy: 0.9882\n",
      "Epoch 60/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9975\n",
      "Epoch 00060: val_accuracy did not improve from 0.99171\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.0479 - val_accuracy: 0.9891\n",
      "Epoch 61/100\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9980\n",
      "Epoch 00061: val_accuracy did not improve from 0.99171\n",
      "Restoring model weights from the end of the best epoch.\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 0.0442 - val_accuracy: 0.9900\n",
      "Epoch 00061: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:01:30<00:00, 1845.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.72      0.88      0.79       684\n",
      "        car_horn       0.97      0.65      0.78       354\n",
      "children_playing       0.81      0.79      0.80       600\n",
      "        dog_bark       0.87      0.89      0.88       600\n",
      "           siren       0.95      0.92      0.93       996\n",
      "\n",
      "        accuracy                           0.85      3234\n",
      "       macro avg       0.86      0.83      0.84      3234\n",
      "    weighted avg       0.86      0.85      0.85      3234\n",
      "\n",
      "\n",
      "Validation fold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21006, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21006, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2334, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2334, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2808, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2808, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_11\n",
      "Epoch 1/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 1.1997 - accuracy: 0.6154\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73350, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 1.1993 - accuracy: 0.6154 - val_loss: 0.7456 - val_accuracy: 0.7335\n",
      "Epoch 2/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.7324 - accuracy: 0.7385\n",
      "Epoch 00002: val_accuracy improved from 0.73350 to 0.76435, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.7325 - accuracy: 0.7385 - val_loss: 0.6386 - val_accuracy: 0.7644\n",
      "Epoch 3/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.6152 - accuracy: 0.7781\n",
      "Epoch 00003: val_accuracy improved from 0.76435 to 0.80377, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.6148 - accuracy: 0.7783 - val_loss: 0.5902 - val_accuracy: 0.8038\n",
      "Epoch 4/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.5399 - accuracy: 0.8041\n",
      "Epoch 00004: val_accuracy improved from 0.80377 to 0.83805, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.5399 - accuracy: 0.8040 - val_loss: 0.5179 - val_accuracy: 0.8380\n",
      "Epoch 5/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.4744 - accuracy: 0.8275\n",
      "Epoch 00005: val_accuracy improved from 0.83805 to 0.88732, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.4742 - accuracy: 0.8275 - val_loss: 0.3088 - val_accuracy: 0.8873\n",
      "Epoch 6/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.4231 - accuracy: 0.8454\n",
      "Epoch 00006: val_accuracy did not improve from 0.88732\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.4231 - accuracy: 0.8452 - val_loss: 0.4493 - val_accuracy: 0.8410\n",
      "Epoch 7/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.3851 - accuracy: 0.8625\n",
      "Epoch 00007: val_accuracy did not improve from 0.88732\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.3851 - accuracy: 0.8626 - val_loss: 0.3781 - val_accuracy: 0.8715\n",
      "Epoch 8/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.3620 - accuracy: 0.8683\n",
      "Epoch 00008: val_accuracy improved from 0.88732 to 0.90103, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.3620 - accuracy: 0.8684 - val_loss: 0.2947 - val_accuracy: 0.9010\n",
      "Epoch 9/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.3281 - accuracy: 0.8825\n",
      "Epoch 00009: val_accuracy improved from 0.90103 to 0.91345, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.3279 - accuracy: 0.8826 - val_loss: 0.2347 - val_accuracy: 0.9135\n",
      "Epoch 10/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.3043 - accuracy: 0.8895\n",
      "Epoch 00010: val_accuracy did not improve from 0.91345\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.3040 - accuracy: 0.8897 - val_loss: 0.3364 - val_accuracy: 0.8715\n",
      "Epoch 11/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.8953\n",
      "Epoch 00011: val_accuracy did not improve from 0.91345\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.2896 - accuracy: 0.8954 - val_loss: 0.2481 - val_accuracy: 0.9135\n",
      "Epoch 12/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.2649 - accuracy: 0.9036\n",
      "Epoch 00012: val_accuracy improved from 0.91345 to 0.91731, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.2649 - accuracy: 0.9036 - val_loss: 0.2292 - val_accuracy: 0.9173\n",
      "Epoch 13/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.2545 - accuracy: 0.9060\n",
      "Epoch 00013: val_accuracy did not improve from 0.91731\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.2551 - accuracy: 0.9057 - val_loss: 0.3112 - val_accuracy: 0.8985\n",
      "Epoch 14/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.9124\n",
      "Epoch 00014: val_accuracy improved from 0.91731 to 0.92931, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.2416 - accuracy: 0.9123 - val_loss: 0.1945 - val_accuracy: 0.9293\n",
      "Epoch 15/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.9224\n",
      "Epoch 00015: val_accuracy improved from 0.92931 to 0.93016, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.2143 - accuracy: 0.9225 - val_loss: 0.1877 - val_accuracy: 0.9302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.2092 - accuracy: 0.9231\n",
      "Epoch 00016: val_accuracy improved from 0.93016 to 0.93488, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.2094 - accuracy: 0.9229 - val_loss: 0.1776 - val_accuracy: 0.9349\n",
      "Epoch 17/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1982 - accuracy: 0.9265\n",
      "Epoch 00017: val_accuracy improved from 0.93488 to 0.94944, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.1987 - accuracy: 0.9264 - val_loss: 0.1575 - val_accuracy: 0.9494\n",
      "Epoch 18/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1859 - accuracy: 0.9303\n",
      "Epoch 00018: val_accuracy did not improve from 0.94944\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1859 - accuracy: 0.9304 - val_loss: 0.1637 - val_accuracy: 0.9456\n",
      "Epoch 19/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1813 - accuracy: 0.9330\n",
      "Epoch 00019: val_accuracy did not improve from 0.94944\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1818 - accuracy: 0.9328 - val_loss: 0.1568 - val_accuracy: 0.9482\n",
      "Epoch 20/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1696 - accuracy: 0.9377\n",
      "Epoch 00020: val_accuracy improved from 0.94944 to 0.96230, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.1698 - accuracy: 0.9377 - val_loss: 0.1188 - val_accuracy: 0.9623\n",
      "Epoch 21/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1620 - accuracy: 0.9406\n",
      "Epoch 00021: val_accuracy improved from 0.96230 to 0.96872, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.1619 - accuracy: 0.9405 - val_loss: 0.0988 - val_accuracy: 0.9687\n",
      "Epoch 22/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1525 - accuracy: 0.9448\n",
      "Epoch 00022: val_accuracy did not improve from 0.96872\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1524 - accuracy: 0.9447 - val_loss: 0.1476 - val_accuracy: 0.9464\n",
      "Epoch 23/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1470 - accuracy: 0.9453\n",
      "Epoch 00023: val_accuracy did not improve from 0.96872\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1469 - accuracy: 0.9453 - val_loss: 0.0926 - val_accuracy: 0.9666\n",
      "Epoch 24/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1416 - accuracy: 0.9488\n",
      "Epoch 00024: val_accuracy did not improve from 0.96872\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1422 - accuracy: 0.9486 - val_loss: 0.1071 - val_accuracy: 0.9640\n",
      "Epoch 25/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1366 - accuracy: 0.9508\n",
      "Epoch 00025: val_accuracy improved from 0.96872 to 0.97087, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.1364 - accuracy: 0.9509 - val_loss: 0.0970 - val_accuracy: 0.9709\n",
      "Epoch 26/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9539\n",
      "Epoch 00026: val_accuracy improved from 0.97087 to 0.97686, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.1285 - accuracy: 0.9539 - val_loss: 0.0802 - val_accuracy: 0.9769\n",
      "Epoch 27/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1203 - accuracy: 0.9558\n",
      "Epoch 00027: val_accuracy did not improve from 0.97686\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1202 - accuracy: 0.9559 - val_loss: 0.0872 - val_accuracy: 0.9739\n",
      "Epoch 28/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1174 - accuracy: 0.9570\n",
      "Epoch 00028: val_accuracy did not improve from 0.97686\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1175 - accuracy: 0.9571 - val_loss: 0.0785 - val_accuracy: 0.9743\n",
      "Epoch 29/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1140 - accuracy: 0.9583\n",
      "Epoch 00029: val_accuracy did not improve from 0.97686\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1141 - accuracy: 0.9583 - val_loss: 0.0732 - val_accuracy: 0.9764\n",
      "Epoch 30/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9590\n",
      "Epoch 00030: val_accuracy did not improve from 0.97686\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1109 - accuracy: 0.9591 - val_loss: 0.0903 - val_accuracy: 0.9726\n",
      "Epoch 31/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.1045 - accuracy: 0.9632\n",
      "Epoch 00031: val_accuracy did not improve from 0.97686\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.1044 - accuracy: 0.9632 - val_loss: 0.1031 - val_accuracy: 0.9692\n",
      "Epoch 32/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 0.9660\n",
      "Epoch 00032: val_accuracy did not improve from 0.97686\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0960 - accuracy: 0.9660 - val_loss: 0.0760 - val_accuracy: 0.9751\n",
      "Epoch 33/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0974 - accuracy: 0.9656\n",
      "Epoch 00033: val_accuracy improved from 0.97686 to 0.97943, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0973 - accuracy: 0.9657 - val_loss: 0.0627 - val_accuracy: 0.9794\n",
      "Epoch 34/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0938 - accuracy: 0.9658\n",
      "Epoch 00034: val_accuracy did not improve from 0.97943\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0938 - accuracy: 0.9658 - val_loss: 0.0655 - val_accuracy: 0.9781\n",
      "Epoch 35/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0886 - accuracy: 0.9691\n",
      "Epoch 00035: val_accuracy did not improve from 0.97943\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0888 - accuracy: 0.9691 - val_loss: 0.0715 - val_accuracy: 0.9756\n",
      "Epoch 36/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9656\n",
      "Epoch 00036: val_accuracy did not improve from 0.97943\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0900 - accuracy: 0.9656 - val_loss: 0.1132 - val_accuracy: 0.9614\n",
      "Epoch 37/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9693\n",
      "Epoch 00037: val_accuracy did not improve from 0.97943\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0872 - accuracy: 0.9692 - val_loss: 0.0710 - val_accuracy: 0.9786\n",
      "Epoch 38/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0805 - accuracy: 0.9702\n",
      "Epoch 00038: val_accuracy improved from 0.97943 to 0.98372, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0805 - accuracy: 0.9702 - val_loss: 0.0533 - val_accuracy: 0.9837\n",
      "Epoch 39/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0776 - accuracy: 0.9724\n",
      "Epoch 00039: val_accuracy did not improve from 0.98372\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0776 - accuracy: 0.9724 - val_loss: 0.0567 - val_accuracy: 0.9811\n",
      "Epoch 40/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.9737\n",
      "Epoch 00040: val_accuracy improved from 0.98372 to 0.98415, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0728 - accuracy: 0.9737 - val_loss: 0.0520 - val_accuracy: 0.9841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0755 - accuracy: 0.9732\n",
      "Epoch 00041: val_accuracy did not improve from 0.98415\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0753 - accuracy: 0.9733 - val_loss: 0.0552 - val_accuracy: 0.9803\n",
      "Epoch 42/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9743\n",
      "Epoch 00042: val_accuracy did not improve from 0.98415\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0686 - accuracy: 0.9742 - val_loss: 0.0614 - val_accuracy: 0.9824\n",
      "Epoch 43/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0722 - accuracy: 0.9742\n",
      "Epoch 00043: val_accuracy did not improve from 0.98415\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0722 - accuracy: 0.9742 - val_loss: 0.0600 - val_accuracy: 0.9833\n",
      "Epoch 44/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0651 - accuracy: 0.9768\n",
      "Epoch 00044: val_accuracy did not improve from 0.98415\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0649 - accuracy: 0.9768 - val_loss: 0.0547 - val_accuracy: 0.9833\n",
      "Epoch 45/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0684 - accuracy: 0.9745\n",
      "Epoch 00045: val_accuracy did not improve from 0.98415\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0684 - accuracy: 0.9744 - val_loss: 0.0516 - val_accuracy: 0.9833\n",
      "Epoch 46/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0660 - accuracy: 0.9757\n",
      "Epoch 00046: val_accuracy did not improve from 0.98415\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0659 - accuracy: 0.9758 - val_loss: 0.0605 - val_accuracy: 0.9816\n",
      "Epoch 47/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9790\n",
      "Epoch 00047: val_accuracy improved from 0.98415 to 0.98715, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0581 - accuracy: 0.9790 - val_loss: 0.0345 - val_accuracy: 0.9871\n",
      "Epoch 48/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0624 - accuracy: 0.9776\n",
      "Epoch 00048: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0625 - accuracy: 0.9776 - val_loss: 0.0483 - val_accuracy: 0.9820\n",
      "Epoch 49/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 0.9789\n",
      "Epoch 00049: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0595 - accuracy: 0.9789 - val_loss: 0.0506 - val_accuracy: 0.9854\n",
      "Epoch 50/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 0.9784\n",
      "Epoch 00050: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0594 - accuracy: 0.9784 - val_loss: 0.0497 - val_accuracy: 0.9807\n",
      "Epoch 51/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9792\n",
      "Epoch 00051: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0577 - accuracy: 0.9791 - val_loss: 0.0685 - val_accuracy: 0.9781\n",
      "Epoch 52/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9814\n",
      "Epoch 00052: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0524 - accuracy: 0.9813 - val_loss: 0.0557 - val_accuracy: 0.9820\n",
      "Epoch 53/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 0.9806\n",
      "Epoch 00053: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0551 - accuracy: 0.9806 - val_loss: 0.0440 - val_accuracy: 0.9833\n",
      "Epoch 54/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0510 - accuracy: 0.9824\n",
      "Epoch 00054: val_accuracy did not improve from 0.98715\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0512 - accuracy: 0.9824 - val_loss: 0.0464 - val_accuracy: 0.9841\n",
      "Epoch 55/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0530 - accuracy: 0.9808\n",
      "Epoch 00055: val_accuracy improved from 0.98715 to 0.98800, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0529 - accuracy: 0.9809 - val_loss: 0.0420 - val_accuracy: 0.9880\n",
      "Epoch 56/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0481 - accuracy: 0.9823\n",
      "Epoch 00056: val_accuracy did not improve from 0.98800\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0481 - accuracy: 0.9823 - val_loss: 0.0439 - val_accuracy: 0.9863\n",
      "Epoch 57/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9821\n",
      "Epoch 00057: val_accuracy improved from 0.98800 to 0.98843, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0501 - accuracy: 0.9821 - val_loss: 0.0364 - val_accuracy: 0.9884\n",
      "Epoch 58/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0458 - accuracy: 0.9839\n",
      "Epoch 00058: val_accuracy improved from 0.98843 to 0.98972, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0458 - accuracy: 0.9839 - val_loss: 0.0326 - val_accuracy: 0.9897\n",
      "Epoch 59/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 0.9820\n",
      "Epoch 00059: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0513 - accuracy: 0.9820 - val_loss: 0.0366 - val_accuracy: 0.9889\n",
      "Epoch 60/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0454 - accuracy: 0.9839\n",
      "Epoch 00060: val_accuracy improved from 0.98972 to 0.99057, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0454 - accuracy: 0.9840 - val_loss: 0.0342 - val_accuracy: 0.9906\n",
      "Epoch 61/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0433 - accuracy: 0.9846\n",
      "Epoch 00061: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0432 - accuracy: 0.9846 - val_loss: 0.0331 - val_accuracy: 0.9906\n",
      "Epoch 62/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0415 - accuracy: 0.9863\n",
      "Epoch 00062: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0415 - accuracy: 0.9863 - val_loss: 0.0394 - val_accuracy: 0.9880\n",
      "Epoch 63/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9831\n",
      "Epoch 00063: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0448 - accuracy: 0.9831 - val_loss: 0.0369 - val_accuracy: 0.9859\n",
      "Epoch 64/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9851\n",
      "Epoch 00064: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0402 - accuracy: 0.9851 - val_loss: 0.0486 - val_accuracy: 0.9863\n",
      "Epoch 65/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9855\n",
      "Epoch 00065: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0408 - accuracy: 0.9855 - val_loss: 0.0333 - val_accuracy: 0.9906\n",
      "Epoch 66/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9849\n",
      "Epoch 00066: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0414 - accuracy: 0.9850 - val_loss: 0.0371 - val_accuracy: 0.9867\n",
      "Epoch 67/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9876\n",
      "Epoch 00067: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0367 - accuracy: 0.9876 - val_loss: 0.0387 - val_accuracy: 0.9884\n",
      "Epoch 68/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.9868\n",
      "Epoch 00068: val_accuracy did not improve from 0.99057\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0387 - accuracy: 0.9868 - val_loss: 0.0321 - val_accuracy: 0.9897\n",
      "Epoch 69/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9865\n",
      "Epoch 00069: val_accuracy improved from 0.99057 to 0.99229, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0366 - accuracy: 0.9865 - val_loss: 0.0274 - val_accuracy: 0.9923\n",
      "Epoch 70/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9875\n",
      "Epoch 00070: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0353 - accuracy: 0.9876 - val_loss: 0.0423 - val_accuracy: 0.9876\n",
      "Epoch 71/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9861\n",
      "Epoch 00071: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0380 - accuracy: 0.9861 - val_loss: 0.0355 - val_accuracy: 0.9884\n",
      "Epoch 72/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9879\n",
      "Epoch 00072: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0343 - accuracy: 0.9879 - val_loss: 0.0274 - val_accuracy: 0.9901\n",
      "Epoch 73/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9881\n",
      "Epoch 00073: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0357 - accuracy: 0.9881 - val_loss: 0.0299 - val_accuracy: 0.9897\n",
      "Epoch 74/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9879\n",
      "Epoch 00074: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 0.0310 - val_accuracy: 0.9914\n",
      "Epoch 75/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9883\n",
      "Epoch 00075: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0337 - accuracy: 0.9883 - val_loss: 0.0340 - val_accuracy: 0.9889\n",
      "Epoch 76/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9884\n",
      "Epoch 00076: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0319 - accuracy: 0.9883 - val_loss: 0.0454 - val_accuracy: 0.9880\n",
      "Epoch 77/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9884\n",
      "Epoch 00077: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0330 - accuracy: 0.9883 - val_loss: 0.0517 - val_accuracy: 0.9807\n",
      "Epoch 78/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0309 - accuracy: 0.9896\n",
      "Epoch 00078: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0310 - accuracy: 0.9894 - val_loss: 0.0344 - val_accuracy: 0.9901\n",
      "Epoch 79/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0316 - accuracy: 0.9888\n",
      "Epoch 00079: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0316 - accuracy: 0.9889 - val_loss: 0.0333 - val_accuracy: 0.9893\n",
      "Epoch 80/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9871\n",
      "Epoch 00080: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0343 - accuracy: 0.9871 - val_loss: 0.0339 - val_accuracy: 0.9880\n",
      "Epoch 81/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9899\n",
      "Epoch 00081: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0292 - accuracy: 0.9899 - val_loss: 0.0295 - val_accuracy: 0.9914\n",
      "Epoch 82/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9900\n",
      "Epoch 00082: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0292 - accuracy: 0.9900 - val_loss: 0.0279 - val_accuracy: 0.9914\n",
      "Epoch 83/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9897\n",
      "Epoch 00083: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0303 - accuracy: 0.9897 - val_loss: 0.0286 - val_accuracy: 0.9901\n",
      "Epoch 84/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9907\n",
      "Epoch 00084: val_accuracy did not improve from 0.99229\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0295 - accuracy: 0.9907 - val_loss: 0.0532 - val_accuracy: 0.9867\n",
      "Epoch 85/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9910\n",
      "Epoch 00085: val_accuracy improved from 0.99229 to 0.99314, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0276 - accuracy: 0.9910 - val_loss: 0.0221 - val_accuracy: 0.9931\n",
      "Epoch 86/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9896\n",
      "Epoch 00086: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0299 - accuracy: 0.9895 - val_loss: 0.0338 - val_accuracy: 0.9901\n",
      "Epoch 87/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0273 - accuracy: 0.9900\n",
      "Epoch 00087: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0273 - accuracy: 0.9900 - val_loss: 0.0352 - val_accuracy: 0.9906\n",
      "Epoch 88/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9904\n",
      "Epoch 00088: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0291 - accuracy: 0.9904 - val_loss: 0.0251 - val_accuracy: 0.9910\n",
      "Epoch 89/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0280 - accuracy: 0.9904\n",
      "Epoch 00089: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0280 - accuracy: 0.9904 - val_loss: 0.0262 - val_accuracy: 0.9914\n",
      "Epoch 90/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9913\n",
      "Epoch 00090: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.0302 - val_accuracy: 0.9919\n",
      "Epoch 91/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9905\n",
      "Epoch 00091: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0280 - accuracy: 0.9905 - val_loss: 0.0559 - val_accuracy: 0.9837\n",
      "Epoch 92/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0264 - accuracy: 0.9909\n",
      "Epoch 00092: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0264 - accuracy: 0.9909 - val_loss: 0.0288 - val_accuracy: 0.9923\n",
      "Epoch 93/100\n",
      "657/657 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9903\n",
      "Epoch 00093: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.0266 - val_accuracy: 0.9931\n",
      "Epoch 94/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9919\n",
      "Epoch 00094: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0371 - val_accuracy: 0.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9895\n",
      "Epoch 00095: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.0345 - val_accuracy: 0.9910\n",
      "Epoch 96/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9913\n",
      "Epoch 00096: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0249 - accuracy: 0.9912 - val_loss: 0.0290 - val_accuracy: 0.9914\n",
      "Epoch 97/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9917\n",
      "Epoch 00097: val_accuracy improved from 0.99314 to 0.99357, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 15s 23ms/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0249 - val_accuracy: 0.9936\n",
      "Epoch 98/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9915\n",
      "Epoch 00098: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.0246 - val_accuracy: 0.9927\n",
      "Epoch 99/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9919\n",
      "Epoch 00099: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0289 - val_accuracy: 0.9910\n",
      "Epoch 100/100\n",
      "655/657 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9912\n",
      "Epoch 00100: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 15s 22ms/step - loss: 0.0271 - accuracy: 0.9912 - val_loss: 0.0341 - val_accuracy: 0.9914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [24:42<24:42, 1482.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.74      0.94      0.83       594\n",
      "        car_horn       0.97      0.88      0.92       588\n",
      "children_playing       0.84      0.83      0.84       600\n",
      "        dog_bark       0.89      0.81      0.85       600\n",
      "           siren       0.98      0.85      0.91       426\n",
      "\n",
      "        accuracy                           0.86      2808\n",
      "       macro avg       0.88      0.86      0.87      2808\n",
      "    weighted avg       0.88      0.86      0.87      2808\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_12\n",
      "Epoch 1/100\n",
      "  2/657 [..............................] - ETA: 19s - loss: 2.3862 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0220s vs `on_train_batch_end` time: 0.0379s). Check your callbacks.\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.9370 - accuracy: 0.6512\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78706, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 63ms/step - loss: 0.9369 - accuracy: 0.6512 - val_loss: 0.5781 - val_accuracy: 0.7871\n",
      "Epoch 2/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.5702 - accuracy: 0.7954\n",
      "Epoch 00002: val_accuracy improved from 0.78706 to 0.83205, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.5702 - accuracy: 0.7954 - val_loss: 0.4484 - val_accuracy: 0.8320\n",
      "Epoch 3/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.4218 - accuracy: 0.8528\n",
      "Epoch 00003: val_accuracy did not improve from 0.83205\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.4220 - accuracy: 0.8529 - val_loss: 0.6764 - val_accuracy: 0.7288\n",
      "Epoch 4/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.3312 - accuracy: 0.8851\n",
      "Epoch 00004: val_accuracy improved from 0.83205 to 0.91003, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.3312 - accuracy: 0.8851 - val_loss: 0.2753 - val_accuracy: 0.9100\n",
      "Epoch 5/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2669 - accuracy: 0.9105\n",
      "Epoch 00005: val_accuracy did not improve from 0.91003\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.2670 - accuracy: 0.9105 - val_loss: 0.3063 - val_accuracy: 0.8942\n",
      "Epoch 6/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.2106 - accuracy: 0.9269\n",
      "Epoch 00006: val_accuracy did not improve from 0.91003\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.2105 - accuracy: 0.9269 - val_loss: 0.4081 - val_accuracy: 0.8736\n",
      "Epoch 7/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1778 - accuracy: 0.9412\n",
      "Epoch 00007: val_accuracy improved from 0.91003 to 0.95673, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.1779 - accuracy: 0.9412 - val_loss: 0.1287 - val_accuracy: 0.9567\n",
      "Epoch 8/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1448 - accuracy: 0.9502\n",
      "Epoch 00008: val_accuracy did not improve from 0.95673\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.1447 - accuracy: 0.9502 - val_loss: 0.2124 - val_accuracy: 0.9327\n",
      "Epoch 9/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1296 - accuracy: 0.9562\n",
      "Epoch 00009: val_accuracy improved from 0.95673 to 0.96444, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.1296 - accuracy: 0.9562 - val_loss: 0.1016 - val_accuracy: 0.9644\n",
      "Epoch 10/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 0.9609\n",
      "Epoch 00010: val_accuracy did not improve from 0.96444\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.1161 - accuracy: 0.9609 - val_loss: 0.1109 - val_accuracy: 0.9550\n",
      "Epoch 11/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0994 - accuracy: 0.9670\n",
      "Epoch 00011: val_accuracy did not improve from 0.96444\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0995 - accuracy: 0.9670 - val_loss: 0.1314 - val_accuracy: 0.9563\n",
      "Epoch 12/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0843 - accuracy: 0.9713\n",
      "Epoch 00012: val_accuracy did not improve from 0.96444\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0844 - accuracy: 0.9712 - val_loss: 0.2747 - val_accuracy: 0.9126\n",
      "Epoch 13/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0750 - accuracy: 0.9753\n",
      "Epoch 00013: val_accuracy did not improve from 0.96444\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0749 - accuracy: 0.9753 - val_loss: 0.2901 - val_accuracy: 0.9165\n",
      "Epoch 14/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0713 - accuracy: 0.9762\n",
      "Epoch 00014: val_accuracy improved from 0.96444 to 0.96872, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0713 - accuracy: 0.9762 - val_loss: 0.0908 - val_accuracy: 0.9687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9789\n",
      "Epoch 00015: val_accuracy improved from 0.96872 to 0.97301, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0617 - accuracy: 0.9789 - val_loss: 0.0855 - val_accuracy: 0.9730\n",
      "Epoch 16/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0533 - accuracy: 0.9816\n",
      "Epoch 00016: val_accuracy improved from 0.97301 to 0.97515, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0533 - accuracy: 0.9816 - val_loss: 0.0671 - val_accuracy: 0.9751\n",
      "Epoch 17/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0459 - accuracy: 0.9838\n",
      "Epoch 00017: val_accuracy did not improve from 0.97515\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0460 - accuracy: 0.9837 - val_loss: 0.5212 - val_accuracy: 0.8650\n",
      "Epoch 18/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9857\n",
      "Epoch 00018: val_accuracy did not improve from 0.97515\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 0.1239 - val_accuracy: 0.9640\n",
      "Epoch 19/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9851\n",
      "Epoch 00019: val_accuracy improved from 0.97515 to 0.97901, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0449 - accuracy: 0.9851 - val_loss: 0.0717 - val_accuracy: 0.9790\n",
      "Epoch 20/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0387 - accuracy: 0.9873\n",
      "Epoch 00020: val_accuracy improved from 0.97901 to 0.98372, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0388 - accuracy: 0.9873 - val_loss: 0.0697 - val_accuracy: 0.9837\n",
      "Epoch 21/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9883\n",
      "Epoch 00021: val_accuracy did not improve from 0.98372\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0344 - accuracy: 0.9883 - val_loss: 0.0636 - val_accuracy: 0.9829\n",
      "Epoch 22/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9902\n",
      "Epoch 00022: val_accuracy did not improve from 0.98372\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.0565 - val_accuracy: 0.9811\n",
      "Epoch 23/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0265 - accuracy: 0.9909\n",
      "Epoch 00023: val_accuracy did not improve from 0.98372\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 0.0715 - val_accuracy: 0.9833\n",
      "Epoch 24/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9922\n",
      "Epoch 00024: val_accuracy did not improve from 0.98372\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 0.2346 - val_accuracy: 0.9370\n",
      "Epoch 25/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9886\n",
      "Epoch 00025: val_accuracy did not improve from 0.98372\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0343 - accuracy: 0.9886 - val_loss: 0.0803 - val_accuracy: 0.9764\n",
      "Epoch 26/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9907\n",
      "Epoch 00026: val_accuracy improved from 0.98372 to 0.98886, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0272 - accuracy: 0.9907 - val_loss: 0.0398 - val_accuracy: 0.9889\n",
      "Epoch 27/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9932\n",
      "Epoch 00027: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0736 - val_accuracy: 0.9824\n",
      "Epoch 28/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9924\n",
      "Epoch 00028: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0216 - accuracy: 0.9924 - val_loss: 0.0609 - val_accuracy: 0.9841\n",
      "Epoch 29/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9945\n",
      "Epoch 00029: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0439 - val_accuracy: 0.9880\n",
      "Epoch 30/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9945\n",
      "Epoch 00030: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.1025 - val_accuracy: 0.9709\n",
      "Epoch 31/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9942\n",
      "Epoch 00031: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0497 - val_accuracy: 0.9889\n",
      "Epoch 32/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9942\n",
      "Epoch 00032: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.3929 - val_accuracy: 0.9083\n",
      "Epoch 33/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9936\n",
      "Epoch 00033: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.1297 - val_accuracy: 0.9657\n",
      "Epoch 34/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9941\n",
      "Epoch 00034: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0569 - val_accuracy: 0.9867\n",
      "Epoch 35/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9957\n",
      "Epoch 00035: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0134 - accuracy: 0.9957 - val_loss: 0.0436 - val_accuracy: 0.9876\n",
      "Epoch 36/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9954\n",
      "Epoch 00036: val_accuracy did not improve from 0.98886\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0524 - val_accuracy: 0.9876\n",
      "Epoch 37/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9946\n",
      "Epoch 00037: val_accuracy improved from 0.98886 to 0.98972, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.0401 - val_accuracy: 0.9897\n",
      "Epoch 38/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9946\n",
      "Epoch 00038: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.0563 - val_accuracy: 0.9820\n",
      "Epoch 39/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9943\n",
      "Epoch 00039: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.0461 - val_accuracy: 0.9880\n",
      "Epoch 40/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9972\n",
      "Epoch 00040: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.0633 - val_accuracy: 0.9867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9951\n",
      "Epoch 00041: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.0813 - val_accuracy: 0.9816\n",
      "Epoch 42/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9972\n",
      "Epoch 00042: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0506 - val_accuracy: 0.9884\n",
      "Epoch 43/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9974\n",
      "Epoch 00043: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0549 - val_accuracy: 0.9889\n",
      "Epoch 44/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0094 - accuracy: 0.9970\n",
      "Epoch 00044: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.1702 - val_accuracy: 0.9627\n",
      "Epoch 45/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9968\n",
      "Epoch 00045: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.0436 - val_accuracy: 0.9884\n",
      "Epoch 46/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 00046: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.8007 - val_accuracy: 0.8719\n",
      "Epoch 47/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9952\n",
      "Epoch 00047: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0148 - accuracy: 0.9952 - val_loss: 2.8722 - val_accuracy: 0.6997\n",
      "Epoch 48/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9964\n",
      "Epoch 00048: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0491 - val_accuracy: 0.9884\n",
      "Epoch 49/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9964\n",
      "Epoch 00049: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0128 - accuracy: 0.9964 - val_loss: 0.0624 - val_accuracy: 0.9846\n",
      "Epoch 50/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9975\n",
      "Epoch 00050: val_accuracy did not improve from 0.98972\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.0663 - val_accuracy: 0.9833\n",
      "Epoch 51/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 00051: val_accuracy improved from 0.98972 to 0.99143, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0367 - val_accuracy: 0.9914\n",
      "Epoch 52/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 00052: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.1093 - val_accuracy: 0.9756\n",
      "Epoch 53/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9971\n",
      "Epoch 00053: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 4.3032 - val_accuracy: 0.6765\n",
      "Epoch 54/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0093 - accuracy: 0.9971\n",
      "Epoch 00054: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0469 - val_accuracy: 0.9871\n",
      "Epoch 55/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9976\n",
      "Epoch 00055: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 0.0356 - val_accuracy: 0.9914\n",
      "Epoch 56/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 00056: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0673 - val_accuracy: 0.9841\n",
      "Epoch 57/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984\n",
      "Epoch 00057: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0457 - val_accuracy: 0.9906\n",
      "Epoch 58/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982\n",
      "Epoch 00058: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0470 - val_accuracy: 0.9897\n",
      "Epoch 59/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9978\n",
      "Epoch 00059: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0591 - val_accuracy: 0.9897\n",
      "Epoch 60/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 00060: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0649 - val_accuracy: 0.9889\n",
      "Epoch 61/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0099 - accuracy: 0.9970\n",
      "Epoch 00061: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0617 - val_accuracy: 0.9859\n",
      "Epoch 62/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 00062: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.0930 - val_accuracy: 0.9803\n",
      "Epoch 63/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9981\n",
      "Epoch 00063: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.0444 - val_accuracy: 0.9901\n",
      "Epoch 64/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 00064: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0475 - val_accuracy: 0.9893\n",
      "Epoch 65/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9980\n",
      "Epoch 00065: val_accuracy did not improve from 0.99143\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0761 - val_accuracy: 0.9829\n",
      "Epoch 66/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 00066: val_accuracy improved from 0.99143 to 0.99186, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.0417 - val_accuracy: 0.9919\n",
      "Epoch 67/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982\n",
      "Epoch 00067: val_accuracy did not improve from 0.99186\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 0.0453 - val_accuracy: 0.9880\n",
      "Epoch 68/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00068: val_accuracy did not improve from 0.99186\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.1768 - val_accuracy: 0.9687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 00069: val_accuracy improved from 0.99186 to 0.99314, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0384 - val_accuracy: 0.9931\n",
      "Epoch 70/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n",
      "Epoch 00070: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0405 - val_accuracy: 0.9927\n",
      "Epoch 71/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 00071: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0451 - val_accuracy: 0.9927\n",
      "Epoch 72/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 00072: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0532 - val_accuracy: 0.9919\n",
      "Epoch 73/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 00073: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0515 - val_accuracy: 0.9897\n",
      "Epoch 74/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 00074: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0439 - val_accuracy: 0.9906\n",
      "Epoch 75/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 00075: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0431 - val_accuracy: 0.9910\n",
      "Epoch 76/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9985\n",
      "Epoch 00076: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0425 - val_accuracy: 0.9919\n",
      "Epoch 77/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 00077: val_accuracy did not improve from 0.99314\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0463 - val_accuracy: 0.9923\n",
      "Epoch 78/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 00078: val_accuracy improved from 0.99314 to 0.99357, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0362 - val_accuracy: 0.9936\n",
      "Epoch 79/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 00079: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0760 - val_accuracy: 0.9863\n",
      "Epoch 80/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9973\n",
      "Epoch 00080: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0492 - val_accuracy: 0.9901\n",
      "Epoch 81/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 00081: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0553 - val_accuracy: 0.9910\n",
      "Epoch 82/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9985\n",
      "Epoch 00082: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.1491 - val_accuracy: 0.9739\n",
      "Epoch 83/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9984\n",
      "Epoch 00083: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0576 - val_accuracy: 0.9910\n",
      "Epoch 84/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 00084: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0432 - val_accuracy: 0.9919\n",
      "Epoch 85/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 00085: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.0414 - val_accuracy: 0.9910\n",
      "Epoch 86/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 00086: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.1666 - val_accuracy: 0.9743\n",
      "Epoch 87/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9982\n",
      "Epoch 00087: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.1232 - val_accuracy: 0.9751\n",
      "Epoch 88/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 00088: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0760 - val_accuracy: 0.9850\n",
      "Epoch 89/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9994\n",
      "Epoch 00089: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0448 - val_accuracy: 0.9919\n",
      "Epoch 90/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 00090: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0547 - val_accuracy: 0.9897\n",
      "Epoch 91/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
      "Epoch 00091: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0523 - val_accuracy: 0.9919\n",
      "Epoch 92/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 00092: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0453 - val_accuracy: 0.9923\n",
      "Epoch 93/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 00093: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0855 - val_accuracy: 0.9837\n",
      "Epoch 94/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 00094: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0525 - val_accuracy: 0.9906\n",
      "Epoch 95/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9980\n",
      "Epoch 00095: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.0612 - val_accuracy: 0.9914\n",
      "Epoch 96/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 00096: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0449 - val_accuracy: 0.9927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00097: val_accuracy did not improve from 0.99357\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0572 - val_accuracy: 0.9876\n",
      "Epoch 98/100\n",
      "656/657 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 00098: val_accuracy did not improve from 0.99357\n",
      "Restoring model weights from the end of the best epoch.\n",
      "657/657 [==============================] - 41s 62ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0683 - val_accuracy: 0.9893\n",
      "Epoch 00098: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:31:50<00:00, 2755.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.72      0.92      0.81       594\n",
      "        car_horn       0.97      0.89      0.93       588\n",
      "children_playing       0.89      0.78      0.83       600\n",
      "        dog_bark       0.88      0.87      0.87       600\n",
      "           siren       0.97      0.90      0.93       426\n",
      "\n",
      "        accuracy                           0.87      2808\n",
      "       macro avg       0.89      0.87      0.87      2808\n",
      "    weighted avg       0.88      0.87      0.87      2808\n",
      "\n",
      "\n",
      "Validation fold: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21373, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21373, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2375, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2375, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2400, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2400, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_13\n",
      "Epoch 1/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 1.1537 - accuracy: 0.6149\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70905, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 1.1537 - accuracy: 0.6149 - val_loss: 0.8128 - val_accuracy: 0.7091\n",
      "Epoch 2/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.7519 - accuracy: 0.7284\n",
      "Epoch 00002: val_accuracy improved from 0.70905 to 0.76168, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.7519 - accuracy: 0.7284 - val_loss: 0.6863 - val_accuracy: 0.7617\n",
      "Epoch 3/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.6325 - accuracy: 0.7700\n",
      "Epoch 00003: val_accuracy improved from 0.76168 to 0.77053, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.6327 - accuracy: 0.7699 - val_loss: 0.6473 - val_accuracy: 0.7705\n",
      "Epoch 4/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.5476 - accuracy: 0.7995\n",
      "Epoch 00004: val_accuracy improved from 0.77053 to 0.85558, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.5474 - accuracy: 0.7995 - val_loss: 0.4215 - val_accuracy: 0.8556\n",
      "Epoch 5/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.4887 - accuracy: 0.8221\n",
      "Epoch 00005: val_accuracy did not improve from 0.85558\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.4885 - accuracy: 0.8222 - val_loss: 0.5592 - val_accuracy: 0.8131\n",
      "Epoch 6/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.4492 - accuracy: 0.8385\n",
      "Epoch 00006: val_accuracy did not improve from 0.85558\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.4492 - accuracy: 0.8386 - val_loss: 0.5462 - val_accuracy: 0.8362\n",
      "Epoch 7/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.4022 - accuracy: 0.8525\n",
      "Epoch 00007: val_accuracy did not improve from 0.85558\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.4023 - accuracy: 0.8524 - val_loss: 0.5808 - val_accuracy: 0.8122\n",
      "Epoch 8/100\n",
      "666/668 [============================>.] - ETA: 0s - loss: 0.3699 - accuracy: 0.8638\n",
      "Epoch 00008: val_accuracy did not improve from 0.85558\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.3697 - accuracy: 0.8639 - val_loss: 0.6532 - val_accuracy: 0.7857\n",
      "Epoch 9/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3307 - accuracy: 0.8780\n",
      "Epoch 00009: val_accuracy improved from 0.85558 to 0.89474, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.3310 - accuracy: 0.8781 - val_loss: 0.3011 - val_accuracy: 0.8947\n",
      "Epoch 10/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3102 - accuracy: 0.8892\n",
      "Epoch 00010: val_accuracy improved from 0.89474 to 0.89895, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.3100 - accuracy: 0.8893 - val_loss: 0.2721 - val_accuracy: 0.8989\n",
      "Epoch 11/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2857 - accuracy: 0.8961\n",
      "Epoch 00011: val_accuracy improved from 0.89895 to 0.91958, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.2857 - accuracy: 0.8961 - val_loss: 0.2357 - val_accuracy: 0.9196\n",
      "Epoch 12/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.9014\n",
      "Epoch 00012: val_accuracy did not improve from 0.91958\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2660 - accuracy: 0.9014 - val_loss: 0.2675 - val_accuracy: 0.9006\n",
      "Epoch 13/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2501 - accuracy: 0.9071\n",
      "Epoch 00013: val_accuracy did not improve from 0.91958\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2500 - accuracy: 0.9071 - val_loss: 0.3156 - val_accuracy: 0.8981\n",
      "Epoch 14/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2347 - accuracy: 0.9127\n",
      "Epoch 00014: val_accuracy improved from 0.91958 to 0.93095, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.2347 - accuracy: 0.9126 - val_loss: 0.2014 - val_accuracy: 0.9309\n",
      "Epoch 15/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2290 - accuracy: 0.9171\n",
      "Epoch 00015: val_accuracy did not improve from 0.93095\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2289 - accuracy: 0.9171 - val_loss: 0.3201 - val_accuracy: 0.8947\n",
      "Epoch 16/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2109 - accuracy: 0.9215\n",
      "Epoch 00016: val_accuracy improved from 0.93095 to 0.93895, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.2109 - accuracy: 0.9215 - val_loss: 0.1844 - val_accuracy: 0.9389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2052 - accuracy: 0.9261\n",
      "Epoch 00017: val_accuracy improved from 0.93895 to 0.94147, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.2055 - accuracy: 0.9261 - val_loss: 0.1930 - val_accuracy: 0.9415\n",
      "Epoch 18/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1911 - accuracy: 0.9307\n",
      "Epoch 00018: val_accuracy did not improve from 0.94147\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1911 - accuracy: 0.9306 - val_loss: 0.2066 - val_accuracy: 0.9284\n",
      "Epoch 19/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.9324\n",
      "Epoch 00019: val_accuracy improved from 0.94147 to 0.95284, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1764 - accuracy: 0.9325 - val_loss: 0.1468 - val_accuracy: 0.9528\n",
      "Epoch 20/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1700 - accuracy: 0.9391\n",
      "Epoch 00020: val_accuracy did not improve from 0.95284\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1703 - accuracy: 0.9389 - val_loss: 0.1577 - val_accuracy: 0.9444\n",
      "Epoch 21/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1582 - accuracy: 0.9425\n",
      "Epoch 00021: val_accuracy did not improve from 0.95284\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1583 - accuracy: 0.9424 - val_loss: 0.1676 - val_accuracy: 0.9411\n",
      "Epoch 22/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1534 - accuracy: 0.9448\n",
      "Epoch 00022: val_accuracy improved from 0.95284 to 0.96000, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1535 - accuracy: 0.9448 - val_loss: 0.1288 - val_accuracy: 0.9600\n",
      "Epoch 23/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1463 - accuracy: 0.9482\n",
      "Epoch 00023: val_accuracy did not improve from 0.96000\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1465 - accuracy: 0.9482 - val_loss: 0.1594 - val_accuracy: 0.9495\n",
      "Epoch 24/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.9445\n",
      "Epoch 00024: val_accuracy did not improve from 0.96000\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1500 - accuracy: 0.9444 - val_loss: 0.1283 - val_accuracy: 0.9549\n",
      "Epoch 25/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1324 - accuracy: 0.9506\n",
      "Epoch 00025: val_accuracy did not improve from 0.96000\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1323 - accuracy: 0.9506 - val_loss: 0.1321 - val_accuracy: 0.9558\n",
      "Epoch 26/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1245 - accuracy: 0.9549\n",
      "Epoch 00026: val_accuracy did not improve from 0.96000\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1245 - accuracy: 0.9549 - val_loss: 0.1311 - val_accuracy: 0.9575\n",
      "Epoch 27/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1233 - accuracy: 0.9535\n",
      "Epoch 00027: val_accuracy improved from 0.96000 to 0.96632, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1232 - accuracy: 0.9536 - val_loss: 0.1086 - val_accuracy: 0.9663\n",
      "Epoch 28/100\n",
      "666/668 [============================>.] - ETA: 0s - loss: 0.1193 - accuracy: 0.9580\n",
      "Epoch 00028: val_accuracy improved from 0.96632 to 0.97137, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1192 - accuracy: 0.9580 - val_loss: 0.0910 - val_accuracy: 0.9714\n",
      "Epoch 29/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1177 - accuracy: 0.9580\n",
      "Epoch 00029: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1177 - accuracy: 0.9579 - val_loss: 0.1031 - val_accuracy: 0.9672\n",
      "Epoch 30/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1083 - accuracy: 0.9606\n",
      "Epoch 00030: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1084 - accuracy: 0.9605 - val_loss: 0.1354 - val_accuracy: 0.9604\n",
      "Epoch 31/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1031 - accuracy: 0.9628\n",
      "Epoch 00031: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1030 - accuracy: 0.9629 - val_loss: 0.1138 - val_accuracy: 0.9638\n",
      "Epoch 32/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1025 - accuracy: 0.9626\n",
      "Epoch 00032: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1024 - accuracy: 0.9627 - val_loss: 0.1081 - val_accuracy: 0.9672\n",
      "Epoch 33/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1001 - accuracy: 0.9639\n",
      "Epoch 00033: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1001 - accuracy: 0.9639 - val_loss: 0.1034 - val_accuracy: 0.9642\n",
      "Epoch 34/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9674\n",
      "Epoch 00034: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0929 - accuracy: 0.9675 - val_loss: 0.1476 - val_accuracy: 0.9503\n",
      "Epoch 35/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0886 - accuracy: 0.9678\n",
      "Epoch 00035: val_accuracy did not improve from 0.97137\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0886 - accuracy: 0.9679 - val_loss: 0.1049 - val_accuracy: 0.9642\n",
      "Epoch 36/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0863 - accuracy: 0.9698\n",
      "Epoch 00036: val_accuracy improved from 0.97137 to 0.97726, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0862 - accuracy: 0.9699 - val_loss: 0.0789 - val_accuracy: 0.9773\n",
      "Epoch 37/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0861 - accuracy: 0.9675\n",
      "Epoch 00037: val_accuracy did not improve from 0.97726\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0861 - accuracy: 0.9675 - val_loss: 0.1480 - val_accuracy: 0.9575\n",
      "Epoch 38/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0785 - accuracy: 0.9730\n",
      "Epoch 00038: val_accuracy improved from 0.97726 to 0.97979, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0785 - accuracy: 0.9730 - val_loss: 0.0674 - val_accuracy: 0.9798\n",
      "Epoch 39/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0803 - accuracy: 0.9703\n",
      "Epoch 00039: val_accuracy improved from 0.97979 to 0.98105, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0805 - accuracy: 0.9703 - val_loss: 0.0666 - val_accuracy: 0.9811\n",
      "Epoch 40/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0829 - accuracy: 0.9705\n",
      "Epoch 00040: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0828 - accuracy: 0.9705 - val_loss: 0.0904 - val_accuracy: 0.9739\n",
      "Epoch 41/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0779 - accuracy: 0.9725\n",
      "Epoch 00041: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0779 - accuracy: 0.9725 - val_loss: 0.0832 - val_accuracy: 0.9743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9746\n",
      "Epoch 00042: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0693 - accuracy: 0.9745 - val_loss: 0.0815 - val_accuracy: 0.9773\n",
      "Epoch 43/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9733\n",
      "Epoch 00043: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0711 - accuracy: 0.9733 - val_loss: 0.0882 - val_accuracy: 0.9739\n",
      "Epoch 44/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0704 - accuracy: 0.9745\n",
      "Epoch 00044: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0703 - accuracy: 0.9745 - val_loss: 0.0962 - val_accuracy: 0.9735\n",
      "Epoch 45/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0694 - accuracy: 0.9755\n",
      "Epoch 00045: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0693 - accuracy: 0.9755 - val_loss: 0.0570 - val_accuracy: 0.9806\n",
      "Epoch 46/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0633 - accuracy: 0.9774\n",
      "Epoch 00046: val_accuracy did not improve from 0.98105\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0634 - accuracy: 0.9774 - val_loss: 0.0605 - val_accuracy: 0.9802\n",
      "Epoch 47/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0618 - accuracy: 0.9786\n",
      "Epoch 00047: val_accuracy improved from 0.98105 to 0.98358, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0619 - accuracy: 0.9786 - val_loss: 0.0540 - val_accuracy: 0.9836\n",
      "Epoch 48/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0568 - accuracy: 0.9794\n",
      "Epoch 00048: val_accuracy did not improve from 0.98358\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0568 - accuracy: 0.9795 - val_loss: 0.0749 - val_accuracy: 0.9802\n",
      "Epoch 49/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0583 - accuracy: 0.9800\n",
      "Epoch 00049: val_accuracy improved from 0.98358 to 0.98653, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0583 - accuracy: 0.9800 - val_loss: 0.0522 - val_accuracy: 0.9865\n",
      "Epoch 50/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9798\n",
      "Epoch 00050: val_accuracy did not improve from 0.98653\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0579 - accuracy: 0.9798 - val_loss: 0.0547 - val_accuracy: 0.9857\n",
      "Epoch 51/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9781\n",
      "Epoch 00051: val_accuracy did not improve from 0.98653\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0587 - accuracy: 0.9781 - val_loss: 0.0702 - val_accuracy: 0.9798\n",
      "Epoch 52/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9803\n",
      "Epoch 00052: val_accuracy did not improve from 0.98653\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0565 - accuracy: 0.9803 - val_loss: 0.0619 - val_accuracy: 0.9827\n",
      "Epoch 53/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9792\n",
      "Epoch 00053: val_accuracy improved from 0.98653 to 0.98779, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0565 - accuracy: 0.9792 - val_loss: 0.0496 - val_accuracy: 0.9878\n",
      "Epoch 54/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0553 - accuracy: 0.9811\n",
      "Epoch 00054: val_accuracy did not improve from 0.98779\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0552 - accuracy: 0.9811 - val_loss: 0.0527 - val_accuracy: 0.9853\n",
      "Epoch 55/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0552 - accuracy: 0.9800\n",
      "Epoch 00055: val_accuracy improved from 0.98779 to 0.98821, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0551 - accuracy: 0.9800 - val_loss: 0.0420 - val_accuracy: 0.9882\n",
      "Epoch 56/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0515 - accuracy: 0.9810\n",
      "Epoch 00056: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0514 - accuracy: 0.9811 - val_loss: 0.0510 - val_accuracy: 0.9861\n",
      "Epoch 57/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9822\n",
      "Epoch 00057: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0495 - accuracy: 0.9823 - val_loss: 0.0473 - val_accuracy: 0.9840\n",
      "Epoch 58/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0489 - accuracy: 0.9830\n",
      "Epoch 00058: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0489 - accuracy: 0.9831 - val_loss: 0.1001 - val_accuracy: 0.9714\n",
      "Epoch 59/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 0.9821\n",
      "Epoch 00059: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0496 - accuracy: 0.9821 - val_loss: 0.0394 - val_accuracy: 0.9878\n",
      "Epoch 60/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9837\n",
      "Epoch 00060: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0465 - accuracy: 0.9837 - val_loss: 0.0496 - val_accuracy: 0.9853\n",
      "Epoch 61/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0467 - accuracy: 0.9830\n",
      "Epoch 00061: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0467 - accuracy: 0.9831 - val_loss: 0.0604 - val_accuracy: 0.9840\n",
      "Epoch 62/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0446 - accuracy: 0.9846\n",
      "Epoch 00062: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0446 - accuracy: 0.9846 - val_loss: 0.0523 - val_accuracy: 0.9844\n",
      "Epoch 63/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0476 - accuracy: 0.9829\n",
      "Epoch 00063: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0476 - accuracy: 0.9830 - val_loss: 0.0575 - val_accuracy: 0.9832\n",
      "Epoch 64/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0411 - accuracy: 0.9855\n",
      "Epoch 00064: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0411 - accuracy: 0.9855 - val_loss: 0.0616 - val_accuracy: 0.9823\n",
      "Epoch 65/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9860\n",
      "Epoch 00065: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0393 - accuracy: 0.9861 - val_loss: 0.0726 - val_accuracy: 0.9827\n",
      "Epoch 66/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9861\n",
      "Epoch 00066: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0414 - accuracy: 0.9861 - val_loss: 0.0583 - val_accuracy: 0.9836\n",
      "Epoch 67/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9863\n",
      "Epoch 00067: val_accuracy did not improve from 0.98821\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0399 - accuracy: 0.9863 - val_loss: 0.0397 - val_accuracy: 0.9882\n",
      "Epoch 68/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0420 - accuracy: 0.9863\n",
      "Epoch 00068: val_accuracy improved from 0.98821 to 0.98905, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0420 - accuracy: 0.9863 - val_loss: 0.0366 - val_accuracy: 0.9891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0427 - accuracy: 0.9855\n",
      "Epoch 00069: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0427 - accuracy: 0.9855 - val_loss: 0.0381 - val_accuracy: 0.9891\n",
      "Epoch 70/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0392 - accuracy: 0.9859\n",
      "Epoch 00070: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0391 - accuracy: 0.9860 - val_loss: 0.0859 - val_accuracy: 0.9722\n",
      "Epoch 71/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0361 - accuracy: 0.9874\n",
      "Epoch 00071: val_accuracy improved from 0.98905 to 0.98947, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0360 - accuracy: 0.9874 - val_loss: 0.0400 - val_accuracy: 0.9895\n",
      "Epoch 72/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9873\n",
      "Epoch 00072: val_accuracy did not improve from 0.98947\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0367 - accuracy: 0.9873 - val_loss: 0.0428 - val_accuracy: 0.9886\n",
      "Epoch 73/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0347 - accuracy: 0.9880\n",
      "Epoch 00073: val_accuracy did not improve from 0.98947\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0347 - accuracy: 0.9880 - val_loss: 0.0429 - val_accuracy: 0.9869\n",
      "Epoch 74/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0357 - accuracy: 0.9869\n",
      "Epoch 00074: val_accuracy did not improve from 0.98947\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0357 - accuracy: 0.9869 - val_loss: 0.0510 - val_accuracy: 0.9840\n",
      "Epoch 75/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9878\n",
      "Epoch 00075: val_accuracy did not improve from 0.98947\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0371 - accuracy: 0.9877 - val_loss: 0.0449 - val_accuracy: 0.9865\n",
      "Epoch 76/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0307 - accuracy: 0.9892\n",
      "Epoch 00076: val_accuracy did not improve from 0.98947\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.0420 - val_accuracy: 0.9874\n",
      "Epoch 77/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0352 - accuracy: 0.9877\n",
      "Epoch 00077: val_accuracy did not improve from 0.98947\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0352 - accuracy: 0.9877 - val_loss: 0.0405 - val_accuracy: 0.9886\n",
      "Epoch 78/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0318 - accuracy: 0.9890\n",
      "Epoch 00078: val_accuracy improved from 0.98947 to 0.99032, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0318 - accuracy: 0.9891 - val_loss: 0.0421 - val_accuracy: 0.9903\n",
      "Epoch 79/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9876\n",
      "Epoch 00079: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0338 - accuracy: 0.9876 - val_loss: 0.0429 - val_accuracy: 0.9874\n",
      "Epoch 80/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0326 - accuracy: 0.9884\n",
      "Epoch 00080: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0326 - accuracy: 0.9884 - val_loss: 0.0409 - val_accuracy: 0.9878\n",
      "Epoch 81/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0344 - accuracy: 0.9880\n",
      "Epoch 00081: val_accuracy improved from 0.99032 to 0.99074, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0344 - accuracy: 0.9880 - val_loss: 0.0340 - val_accuracy: 0.9907\n",
      "Epoch 82/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0328 - accuracy: 0.9882\n",
      "Epoch 00082: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0328 - accuracy: 0.9883 - val_loss: 0.0374 - val_accuracy: 0.9899\n",
      "Epoch 83/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9900\n",
      "Epoch 00083: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0287 - accuracy: 0.9900 - val_loss: 0.0409 - val_accuracy: 0.9869\n",
      "Epoch 84/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9891\n",
      "Epoch 00084: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0315 - accuracy: 0.9891 - val_loss: 0.0398 - val_accuracy: 0.9882\n",
      "Epoch 85/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9904\n",
      "Epoch 00085: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0279 - accuracy: 0.9904 - val_loss: 0.0507 - val_accuracy: 0.9865\n",
      "Epoch 86/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9897\n",
      "Epoch 00086: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0295 - accuracy: 0.9898 - val_loss: 0.0378 - val_accuracy: 0.9886\n",
      "Epoch 87/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9914\n",
      "Epoch 00087: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0251 - accuracy: 0.9914 - val_loss: 0.0568 - val_accuracy: 0.9836\n",
      "Epoch 88/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9904\n",
      "Epoch 00088: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0295 - accuracy: 0.9904 - val_loss: 0.0413 - val_accuracy: 0.9865\n",
      "Epoch 89/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9901\n",
      "Epoch 00089: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0281 - accuracy: 0.9901 - val_loss: 0.0509 - val_accuracy: 0.9844\n",
      "Epoch 90/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0289 - accuracy: 0.9906\n",
      "Epoch 00090: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0289 - accuracy: 0.9906 - val_loss: 0.0340 - val_accuracy: 0.9907\n",
      "Epoch 91/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9909\n",
      "Epoch 00091: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0276 - accuracy: 0.9909 - val_loss: 0.0420 - val_accuracy: 0.9895\n",
      "Epoch 92/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0295 - accuracy: 0.9895\n",
      "Epoch 00092: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0294 - accuracy: 0.9895 - val_loss: 0.0420 - val_accuracy: 0.9903\n",
      "Epoch 93/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0259 - accuracy: 0.9912\n",
      "Epoch 00093: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.0378 - val_accuracy: 0.9891\n",
      "Epoch 94/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9918\n",
      "Epoch 00094: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0240 - accuracy: 0.9918 - val_loss: 0.0292 - val_accuracy: 0.9903\n",
      "Epoch 95/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0258 - accuracy: 0.9903\n",
      "Epoch 00095: val_accuracy did not improve from 0.99074\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0260 - accuracy: 0.9903 - val_loss: 0.0380 - val_accuracy: 0.9886\n",
      "Epoch 96/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9911\n",
      "Epoch 00096: val_accuracy improved from 0.99074 to 0.99116, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0271 - accuracy: 0.9911 - val_loss: 0.0262 - val_accuracy: 0.9912\n",
      "Epoch 97/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9907\n",
      "Epoch 00097: val_accuracy did not improve from 0.99116\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0252 - accuracy: 0.9907 - val_loss: 0.0476 - val_accuracy: 0.9857\n",
      "Epoch 98/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9919\n",
      "Epoch 00098: val_accuracy did not improve from 0.99116\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0432 - val_accuracy: 0.9869\n",
      "Epoch 99/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9914\n",
      "Epoch 00099: val_accuracy improved from 0.99116 to 0.99284, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.0276 - val_accuracy: 0.9928\n",
      "Epoch 100/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9911\n",
      "Epoch 00100: val_accuracy did not improve from 0.99284\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.0443 - val_accuracy: 0.9827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [25:09<25:09, 1509.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.80      0.78      0.79       588\n",
      "        car_horn       0.76      0.88      0.81       168\n",
      "children_playing       0.87      0.94      0.91       600\n",
      "        dog_bark       0.92      0.92      0.92       600\n",
      "           siren       0.86      0.75      0.80       444\n",
      "\n",
      "        accuracy                           0.86      2400\n",
      "       macro avg       0.84      0.85      0.85      2400\n",
      "    weighted avg       0.86      0.86      0.86      2400\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_14\n",
      "Epoch 1/100\n",
      "  2/668 [..............................] - ETA: 20s - loss: 2.2205 - accuracy: 0.1406WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0220s vs `on_train_batch_end` time: 0.0382s). Check your callbacks.\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.9125 - accuracy: 0.6621\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76463, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 63ms/step - loss: 0.9125 - accuracy: 0.6621 - val_loss: 0.6816 - val_accuracy: 0.7646\n",
      "Epoch 2/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.8147\n",
      "Epoch 00002: val_accuracy improved from 0.76463 to 0.79747, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.5393 - accuracy: 0.8147 - val_loss: 0.5377 - val_accuracy: 0.7975\n",
      "Epoch 3/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.3991 - accuracy: 0.8633\n",
      "Epoch 00003: val_accuracy improved from 0.79747 to 0.82905, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.3991 - accuracy: 0.8633 - val_loss: 0.4842 - val_accuracy: 0.8291\n",
      "Epoch 4/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.8951\n",
      "Epoch 00004: val_accuracy improved from 0.82905 to 0.84168, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.3042 - accuracy: 0.8951 - val_loss: 0.4720 - val_accuracy: 0.8417\n",
      "Epoch 5/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.2486 - accuracy: 0.9145\n",
      "Epoch 00005: val_accuracy improved from 0.84168 to 0.91411, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.2486 - accuracy: 0.9145 - val_loss: 0.2490 - val_accuracy: 0.9141\n",
      "Epoch 6/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.9279\n",
      "Epoch 00006: val_accuracy improved from 0.91411 to 0.91621, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.2064 - accuracy: 0.9279 - val_loss: 0.2330 - val_accuracy: 0.9162\n",
      "Epoch 7/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.1622 - accuracy: 0.9450\n",
      "Epoch 00007: val_accuracy improved from 0.91621 to 0.95747, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1622 - accuracy: 0.9450 - val_loss: 0.1188 - val_accuracy: 0.9575\n",
      "Epoch 8/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.9513\n",
      "Epoch 00008: val_accuracy did not improve from 0.95747\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.1422 - accuracy: 0.9513 - val_loss: 0.2230 - val_accuracy: 0.9276\n",
      "Epoch 9/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9603\n",
      "Epoch 00009: val_accuracy did not improve from 0.95747\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1160 - accuracy: 0.9603 - val_loss: 0.1599 - val_accuracy: 0.9436\n",
      "Epoch 10/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.9646\n",
      "Epoch 00010: val_accuracy improved from 0.95747 to 0.96000, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1008 - accuracy: 0.9646 - val_loss: 0.1115 - val_accuracy: 0.9600\n",
      "Epoch 11/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.9707\n",
      "Epoch 00011: val_accuracy did not improve from 0.96000\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0848 - accuracy: 0.9707 - val_loss: 0.1267 - val_accuracy: 0.9583\n",
      "Epoch 12/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.9752\n",
      "Epoch 00012: val_accuracy improved from 0.96000 to 0.96379, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0773 - accuracy: 0.9752 - val_loss: 0.1144 - val_accuracy: 0.9638\n",
      "Epoch 13/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.9783\n",
      "Epoch 00013: val_accuracy did not improve from 0.96379\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0663 - accuracy: 0.9783 - val_loss: 0.4263 - val_accuracy: 0.8792\n",
      "Epoch 14/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0590 - accuracy: 0.9800\n",
      "Epoch 00014: val_accuracy improved from 0.96379 to 0.97095, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0590 - accuracy: 0.9800 - val_loss: 0.0932 - val_accuracy: 0.9709\n",
      "Epoch 15/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9798\n",
      "Epoch 00015: val_accuracy improved from 0.97095 to 0.97600, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0593 - accuracy: 0.9798 - val_loss: 0.0818 - val_accuracy: 0.9760\n",
      "Epoch 16/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9843\n",
      "Epoch 00016: val_accuracy did not improve from 0.97600\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0470 - accuracy: 0.9843 - val_loss: 0.1100 - val_accuracy: 0.9667\n",
      "Epoch 17/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 0.9848\n",
      "Epoch 00017: val_accuracy did not improve from 0.97600\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0470 - accuracy: 0.9848 - val_loss: 0.0889 - val_accuracy: 0.9731\n",
      "Epoch 18/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9846\n",
      "Epoch 00018: val_accuracy did not improve from 0.97600\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0429 - accuracy: 0.9846 - val_loss: 0.0803 - val_accuracy: 0.9747\n",
      "Epoch 19/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9873\n",
      "Epoch 00019: val_accuracy did not improve from 0.97600\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0369 - accuracy: 0.9873 - val_loss: 0.1176 - val_accuracy: 0.9642\n",
      "Epoch 20/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9885\n",
      "Epoch 00020: val_accuracy improved from 0.97600 to 0.98442, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 0.0586 - val_accuracy: 0.9844\n",
      "Epoch 21/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 0.9870\n",
      "Epoch 00021: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0386 - accuracy: 0.9870 - val_loss: 0.1284 - val_accuracy: 0.9621\n",
      "Epoch 22/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 0.9884\n",
      "Epoch 00022: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.0903 - val_accuracy: 0.9752\n",
      "Epoch 23/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9896\n",
      "Epoch 00023: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0310 - accuracy: 0.9896 - val_loss: 0.0888 - val_accuracy: 0.9760\n",
      "Epoch 24/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9921\n",
      "Epoch 00024: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.1653 - val_accuracy: 0.9579\n",
      "Epoch 25/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9936\n",
      "Epoch 00025: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0181 - accuracy: 0.9936 - val_loss: 0.0724 - val_accuracy: 0.9819\n",
      "Epoch 26/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9910\n",
      "Epoch 00026: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0254 - accuracy: 0.9910 - val_loss: 0.1132 - val_accuracy: 0.9718\n",
      "Epoch 27/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9933\n",
      "Epoch 00027: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.0781 - val_accuracy: 0.9823\n",
      "Epoch 28/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9935\n",
      "Epoch 00028: val_accuracy did not improve from 0.98442\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.0640 - val_accuracy: 0.9827\n",
      "Epoch 29/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9952\n",
      "Epoch 00029: val_accuracy improved from 0.98442 to 0.98526, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0540 - val_accuracy: 0.9853\n",
      "Epoch 30/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 0.9956\n",
      "Epoch 00030: val_accuracy improved from 0.98526 to 0.98568, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 0.0696 - val_accuracy: 0.9857\n",
      "Epoch 31/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 0.9915\n",
      "Epoch 00031: val_accuracy did not improve from 0.98568\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0240 - accuracy: 0.9915 - val_loss: 0.1011 - val_accuracy: 0.9697\n",
      "Epoch 32/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9942\n",
      "Epoch 00032: val_accuracy did not improve from 0.98568\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.0582 - val_accuracy: 0.9802\n",
      "Epoch 33/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9951\n",
      "Epoch 00033: val_accuracy improved from 0.98568 to 0.98737, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.0505 - val_accuracy: 0.9874\n",
      "Epoch 34/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9950\n",
      "Epoch 00034: val_accuracy did not improve from 0.98737\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 0.0790 - val_accuracy: 0.9789\n",
      "Epoch 35/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9941\n",
      "Epoch 00035: val_accuracy did not improve from 0.98737\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 0.1075 - val_accuracy: 0.9794\n",
      "Epoch 36/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9958\n",
      "Epoch 00036: val_accuracy did not improve from 0.98737\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0117 - accuracy: 0.9958 - val_loss: 0.0502 - val_accuracy: 0.9861\n",
      "Epoch 37/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9961\n",
      "Epoch 00037: val_accuracy did not improve from 0.98737\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0852 - val_accuracy: 0.9815\n",
      "Epoch 38/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9965\n",
      "Epoch 00038: val_accuracy improved from 0.98737 to 0.98863, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0533 - val_accuracy: 0.9886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9962\n",
      "Epoch 00039: val_accuracy did not improve from 0.98863\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.0673 - val_accuracy: 0.9823\n",
      "Epoch 40/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.9955\n",
      "Epoch 00040: val_accuracy did not improve from 0.98863\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.0546 - val_accuracy: 0.9865\n",
      "Epoch 41/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 0.9966\n",
      "Epoch 00041: val_accuracy did not improve from 0.98863\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0107 - accuracy: 0.9966 - val_loss: 0.0666 - val_accuracy: 0.9819\n",
      "Epoch 42/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 0.9969\n",
      "Epoch 00042: val_accuracy did not improve from 0.98863\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.0844 - val_accuracy: 0.9836\n",
      "Epoch 43/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 0.9958\n",
      "Epoch 00043: val_accuracy did not improve from 0.98863\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.0781 - val_accuracy: 0.9840\n",
      "Epoch 44/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9959\n",
      "Epoch 00044: val_accuracy did not improve from 0.98863\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0113 - accuracy: 0.9959 - val_loss: 0.0570 - val_accuracy: 0.9853\n",
      "Epoch 45/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 0.9966\n",
      "Epoch 00045: val_accuracy improved from 0.98863 to 0.98905, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0503 - val_accuracy: 0.9891\n",
      "Epoch 46/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 00046: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0513 - val_accuracy: 0.9891\n",
      "Epoch 47/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9971\n",
      "Epoch 00047: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0541 - val_accuracy: 0.9882\n",
      "Epoch 48/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9978\n",
      "Epoch 00048: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0517 - val_accuracy: 0.9865\n",
      "Epoch 49/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9987\n",
      "Epoch 00049: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0556 - val_accuracy: 0.9874\n",
      "Epoch 50/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9965\n",
      "Epoch 00050: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.0765 - val_accuracy: 0.9811\n",
      "Epoch 51/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9971\n",
      "Epoch 00051: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0827 - val_accuracy: 0.9861\n",
      "Epoch 52/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9978\n",
      "Epoch 00052: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0929 - val_accuracy: 0.9815\n",
      "Epoch 53/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9977\n",
      "Epoch 00053: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.0803 - val_accuracy: 0.9811\n",
      "Epoch 54/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9978\n",
      "Epoch 00054: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0664 - val_accuracy: 0.9891\n",
      "Epoch 55/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984\n",
      "Epoch 00055: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0653 - val_accuracy: 0.9857\n",
      "Epoch 56/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 00056: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0770 - val_accuracy: 0.9857\n",
      "Epoch 57/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 00057: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0967 - val_accuracy: 0.9794\n",
      "Epoch 58/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9967\n",
      "Epoch 00058: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0111 - accuracy: 0.9967 - val_loss: 0.0697 - val_accuracy: 0.9844\n",
      "Epoch 59/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 00059: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0584 - val_accuracy: 0.9891\n",
      "Epoch 60/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 0.9976\n",
      "Epoch 00060: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0071 - accuracy: 0.9976 - val_loss: 0.0952 - val_accuracy: 0.9811\n",
      "Epoch 61/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9971\n",
      "Epoch 00061: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 0.0656 - val_accuracy: 0.9882\n",
      "Epoch 62/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9980\n",
      "Epoch 00062: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.0498 - val_accuracy: 0.9891\n",
      "Epoch 63/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 00063: val_accuracy did not improve from 0.98905\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0583 - val_accuracy: 0.9886\n",
      "Epoch 64/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9990\n",
      "Epoch 00064: val_accuracy improved from 0.98905 to 0.99032, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0522 - val_accuracy: 0.9903\n",
      "Epoch 65/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 00065: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0682 - val_accuracy: 0.9869\n",
      "Epoch 66/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9985\n",
      "Epoch 00066: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 0.0572 - val_accuracy: 0.9886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9979\n",
      "Epoch 00067: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.0621 - val_accuracy: 0.9886\n",
      "Epoch 68/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 00068: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.0618 - val_accuracy: 0.9895\n",
      "Epoch 69/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
      "Epoch 00069: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0864 - val_accuracy: 0.9861\n",
      "Epoch 70/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 00070: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0722 - val_accuracy: 0.9836\n",
      "Epoch 71/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 00071: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0598 - val_accuracy: 0.9891\n",
      "Epoch 72/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 00072: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0615 - val_accuracy: 0.9891\n",
      "Epoch 73/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 00073: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0717 - val_accuracy: 0.9869\n",
      "Epoch 74/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 0.9988\n",
      "Epoch 00074: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0638 - val_accuracy: 0.9874\n",
      "Epoch 75/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 00075: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0036 - accuracy: 0.9986 - val_loss: 0.0595 - val_accuracy: 0.9878\n",
      "Epoch 76/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00076: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0623 - val_accuracy: 0.9891\n",
      "Epoch 77/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n",
      "Epoch 00077: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0671 - val_accuracy: 0.9903\n",
      "Epoch 78/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9990\n",
      "Epoch 00078: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.0630 - val_accuracy: 0.9903\n",
      "Epoch 79/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 00079: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0675 - val_accuracy: 0.9903\n",
      "Epoch 80/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 00080: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0716 - val_accuracy: 0.9903\n",
      "Epoch 81/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 00081: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0757 - val_accuracy: 0.9903\n",
      "Epoch 82/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989\n",
      "Epoch 00082: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0028 - accuracy: 0.9989 - val_loss: 0.0665 - val_accuracy: 0.9895\n",
      "Epoch 83/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 00083: val_accuracy did not improve from 0.99032\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0639 - val_accuracy: 0.9899\n",
      "Epoch 84/100\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 00084: val_accuracy did not improve from 0.99032\n",
      "Restoring model weights from the end of the best epoch.\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.1005 - val_accuracy: 0.9827\n",
      "Epoch 00084: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:23:39<00:00, 2509.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.81      0.83      0.82       588\n",
      "        car_horn       0.87      0.86      0.87       168\n",
      "children_playing       0.92      0.92      0.92       600\n",
      "        dog_bark       0.91      0.96      0.93       600\n",
      "           siren       0.92      0.81      0.86       444\n",
      "\n",
      "        accuracy                           0.88      2400\n",
      "       macro avg       0.88      0.88      0.88      2400\n",
      "    weighted avg       0.89      0.88      0.88      2400\n",
      "\n",
      "\n",
      "Validation fold: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21346, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21346, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2372, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2372, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2430, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2430, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_15\n",
      "Epoch 1/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 1.1518 - accuracy: 0.6182\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75337, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 1.1517 - accuracy: 0.6182 - val_loss: 0.7068 - val_accuracy: 0.7534\n",
      "Epoch 2/100\n",
      "666/668 [============================>.] - ETA: 0s - loss: 0.7252 - accuracy: 0.7411\n",
      "Epoch 00002: val_accuracy improved from 0.75337 to 0.79806, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.7252 - accuracy: 0.7411 - val_loss: 0.5650 - val_accuracy: 0.7981\n",
      "Epoch 3/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.6018 - accuracy: 0.7855\n",
      "Epoch 00003: val_accuracy improved from 0.79806 to 0.81535, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.6017 - accuracy: 0.7855 - val_loss: 0.5350 - val_accuracy: 0.8153\n",
      "Epoch 4/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.5260 - accuracy: 0.8103\n",
      "Epoch 00004: val_accuracy improved from 0.81535 to 0.84148, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.5259 - accuracy: 0.8103 - val_loss: 0.4476 - val_accuracy: 0.8415\n",
      "Epoch 5/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.4653 - accuracy: 0.8333\n",
      "Epoch 00005: val_accuracy improved from 0.84148 to 0.88406, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.4653 - accuracy: 0.8332 - val_loss: 0.3147 - val_accuracy: 0.8841\n",
      "Epoch 6/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.4184 - accuracy: 0.8511\n",
      "Epoch 00006: val_accuracy did not improve from 0.88406\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.4183 - accuracy: 0.8511 - val_loss: 0.6683 - val_accuracy: 0.7462\n",
      "Epoch 7/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3814 - accuracy: 0.8625\n",
      "Epoch 00007: val_accuracy did not improve from 0.88406\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.3814 - accuracy: 0.8626 - val_loss: 0.3577 - val_accuracy: 0.8744\n",
      "Epoch 8/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3500 - accuracy: 0.8728\n",
      "Epoch 00008: val_accuracy did not improve from 0.88406\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.3501 - accuracy: 0.8727 - val_loss: 0.3606 - val_accuracy: 0.8664\n",
      "Epoch 9/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3282 - accuracy: 0.8808\n",
      "Epoch 00009: val_accuracy improved from 0.88406 to 0.91400, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.3283 - accuracy: 0.8808 - val_loss: 0.2486 - val_accuracy: 0.9140\n",
      "Epoch 10/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3003 - accuracy: 0.8903\n",
      "Epoch 00010: val_accuracy improved from 0.91400 to 0.92707, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.3003 - accuracy: 0.8903 - val_loss: 0.2066 - val_accuracy: 0.9271\n",
      "Epoch 11/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2789 - accuracy: 0.8970\n",
      "Epoch 00011: val_accuracy improved from 0.92707 to 0.94224, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.2789 - accuracy: 0.8970 - val_loss: 0.1748 - val_accuracy: 0.9422\n",
      "Epoch 12/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2594 - accuracy: 0.9043\n",
      "Epoch 00012: val_accuracy did not improve from 0.94224\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2595 - accuracy: 0.9043 - val_loss: 0.2035 - val_accuracy: 0.9351\n",
      "Epoch 13/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.9079\n",
      "Epoch 00013: val_accuracy improved from 0.94224 to 0.95236, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.2554 - accuracy: 0.9079 - val_loss: 0.1443 - val_accuracy: 0.9524\n",
      "Epoch 14/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2281 - accuracy: 0.9182\n",
      "Epoch 00014: val_accuracy did not improve from 0.95236\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2280 - accuracy: 0.9182 - val_loss: 0.1920 - val_accuracy: 0.9347\n",
      "Epoch 15/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2212 - accuracy: 0.9207\n",
      "Epoch 00015: val_accuracy did not improve from 0.95236\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2212 - accuracy: 0.9207 - val_loss: 0.1661 - val_accuracy: 0.9397\n",
      "Epoch 16/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2096 - accuracy: 0.9244\n",
      "Epoch 00016: val_accuracy did not improve from 0.95236\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.2096 - accuracy: 0.9244 - val_loss: 0.1448 - val_accuracy: 0.9524\n",
      "Epoch 17/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1957 - accuracy: 0.9301\n",
      "Epoch 00017: val_accuracy did not improve from 0.95236\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1957 - accuracy: 0.9302 - val_loss: 0.1715 - val_accuracy: 0.9452\n",
      "Epoch 18/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1824 - accuracy: 0.9330\n",
      "Epoch 00018: val_accuracy improved from 0.95236 to 0.95911, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1824 - accuracy: 0.9330 - val_loss: 0.1296 - val_accuracy: 0.9591\n",
      "Epoch 19/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1737 - accuracy: 0.9365\n",
      "Epoch 00019: val_accuracy improved from 0.95911 to 0.95995, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1737 - accuracy: 0.9365 - val_loss: 0.1248 - val_accuracy: 0.9599\n",
      "Epoch 20/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9414\n",
      "Epoch 00020: val_accuracy improved from 0.95995 to 0.96585, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1617 - accuracy: 0.9414 - val_loss: 0.1100 - val_accuracy: 0.9659\n",
      "Epoch 21/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1621 - accuracy: 0.9406\n",
      "Epoch 00021: val_accuracy improved from 0.96585 to 0.97049, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1621 - accuracy: 0.9406 - val_loss: 0.0881 - val_accuracy: 0.9705\n",
      "Epoch 22/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1569 - accuracy: 0.9425\n",
      "Epoch 00022: val_accuracy did not improve from 0.97049\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1569 - accuracy: 0.9425 - val_loss: 0.0954 - val_accuracy: 0.9692\n",
      "Epoch 23/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1449 - accuracy: 0.9487\n",
      "Epoch 00023: val_accuracy improved from 0.97049 to 0.97175, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1449 - accuracy: 0.9487 - val_loss: 0.0873 - val_accuracy: 0.9718\n",
      "Epoch 24/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1407 - accuracy: 0.9496\n",
      "Epoch 00024: val_accuracy improved from 0.97175 to 0.97470, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1407 - accuracy: 0.9496 - val_loss: 0.0900 - val_accuracy: 0.9747\n",
      "Epoch 25/100\n",
      "666/668 [============================>.] - ETA: 0s - loss: 0.1320 - accuracy: 0.9515\n",
      "Epoch 00025: val_accuracy did not improve from 0.97470\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1324 - accuracy: 0.9515 - val_loss: 0.1150 - val_accuracy: 0.9604\n",
      "Epoch 26/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1450 - accuracy: 0.9452\n",
      "Epoch 00026: val_accuracy did not improve from 0.97470\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1450 - accuracy: 0.9452 - val_loss: 0.0882 - val_accuracy: 0.9709\n",
      "Epoch 27/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1255 - accuracy: 0.9547\n",
      "Epoch 00027: val_accuracy did not improve from 0.97470\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1254 - accuracy: 0.9547 - val_loss: 0.0897 - val_accuracy: 0.9726\n",
      "Epoch 28/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1165 - accuracy: 0.9570\n",
      "Epoch 00028: val_accuracy did not improve from 0.97470\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1165 - accuracy: 0.9570 - val_loss: 0.0820 - val_accuracy: 0.9743\n",
      "Epoch 29/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9589\n",
      "Epoch 00029: val_accuracy did not improve from 0.97470\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1156 - accuracy: 0.9589 - val_loss: 0.0906 - val_accuracy: 0.9680\n",
      "Epoch 30/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1098 - accuracy: 0.9606\n",
      "Epoch 00030: val_accuracy did not improve from 0.97470\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1098 - accuracy: 0.9606 - val_loss: 0.0884 - val_accuracy: 0.9709\n",
      "Epoch 31/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9617\n",
      "Epoch 00031: val_accuracy improved from 0.97470 to 0.98229, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1063 - accuracy: 0.9617 - val_loss: 0.0668 - val_accuracy: 0.9823\n",
      "Epoch 32/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9630\n",
      "Epoch 00032: val_accuracy did not improve from 0.98229\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1060 - accuracy: 0.9630 - val_loss: 0.0854 - val_accuracy: 0.9739\n",
      "Epoch 33/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1049 - accuracy: 0.9626\n",
      "Epoch 00033: val_accuracy did not improve from 0.98229\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.1049 - accuracy: 0.9626 - val_loss: 0.0730 - val_accuracy: 0.9777\n",
      "Epoch 34/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0935 - accuracy: 0.9672\n",
      "Epoch 00034: val_accuracy did not improve from 0.98229\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0937 - accuracy: 0.9671 - val_loss: 0.0915 - val_accuracy: 0.9705\n",
      "Epoch 35/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1098 - accuracy: 0.9610\n",
      "Epoch 00035: val_accuracy did not improve from 0.98229\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.1098 - accuracy: 0.9610 - val_loss: 0.0685 - val_accuracy: 0.9789\n",
      "Epoch 36/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0939 - accuracy: 0.9659\n",
      "Epoch 00036: val_accuracy did not improve from 0.98229\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0939 - accuracy: 0.9659 - val_loss: 0.0688 - val_accuracy: 0.9789\n",
      "Epoch 37/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 0.9710\n",
      "Epoch 00037: val_accuracy improved from 0.98229 to 0.98272, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0859 - accuracy: 0.9710 - val_loss: 0.0583 - val_accuracy: 0.9827\n",
      "Epoch 38/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0862 - accuracy: 0.9688\n",
      "Epoch 00038: val_accuracy improved from 0.98272 to 0.98609, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0862 - accuracy: 0.9688 - val_loss: 0.0507 - val_accuracy: 0.9861\n",
      "Epoch 39/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0823 - accuracy: 0.9711\n",
      "Epoch 00039: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0823 - accuracy: 0.9711 - val_loss: 0.0734 - val_accuracy: 0.9798\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "667/668 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9738\n",
      "Epoch 00040: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0740 - accuracy: 0.9738 - val_loss: 0.0761 - val_accuracy: 0.9777\n",
      "Epoch 41/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0725 - accuracy: 0.9738\n",
      "Epoch 00041: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0727 - accuracy: 0.9737 - val_loss: 0.0501 - val_accuracy: 0.9831\n",
      "Epoch 42/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0797 - accuracy: 0.9717\n",
      "Epoch 00042: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0797 - accuracy: 0.9717 - val_loss: 0.0785 - val_accuracy: 0.9726\n",
      "Epoch 43/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0736 - accuracy: 0.9732\n",
      "Epoch 00043: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0737 - accuracy: 0.9731 - val_loss: 0.0895 - val_accuracy: 0.9730\n",
      "Epoch 44/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9748\n",
      "Epoch 00044: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0723 - accuracy: 0.9748 - val_loss: 0.0656 - val_accuracy: 0.9810\n",
      "Epoch 45/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0679 - accuracy: 0.9762\n",
      "Epoch 00045: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0679 - accuracy: 0.9762 - val_loss: 0.0541 - val_accuracy: 0.9840\n",
      "Epoch 46/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 0.9765\n",
      "Epoch 00046: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0628 - accuracy: 0.9765 - val_loss: 0.0790 - val_accuracy: 0.9764\n",
      "Epoch 47/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0615 - accuracy: 0.9783\n",
      "Epoch 00047: val_accuracy did not improve from 0.98609\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0615 - accuracy: 0.9783 - val_loss: 0.0480 - val_accuracy: 0.9861\n",
      "Epoch 48/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 0.9772\n",
      "Epoch 00048: val_accuracy improved from 0.98609 to 0.98946, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0637 - accuracy: 0.9771 - val_loss: 0.0369 - val_accuracy: 0.9895\n",
      "Epoch 49/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9777\n",
      "Epoch 00049: val_accuracy did not improve from 0.98946\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0629 - accuracy: 0.9777 - val_loss: 0.0510 - val_accuracy: 0.9861\n",
      "Epoch 50/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0606 - accuracy: 0.9790\n",
      "Epoch 00050: val_accuracy did not improve from 0.98946\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0606 - accuracy: 0.9790 - val_loss: 0.0504 - val_accuracy: 0.9848\n",
      "Epoch 51/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0583 - accuracy: 0.9799\n",
      "Epoch 00051: val_accuracy did not improve from 0.98946\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0583 - accuracy: 0.9799 - val_loss: 0.0423 - val_accuracy: 0.9895\n",
      "Epoch 52/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0509 - accuracy: 0.9814\n",
      "Epoch 00052: val_accuracy did not improve from 0.98946\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0509 - accuracy: 0.9814 - val_loss: 0.0529 - val_accuracy: 0.9857\n",
      "Epoch 53/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9799\n",
      "Epoch 00053: val_accuracy did not improve from 0.98946\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0556 - accuracy: 0.9799 - val_loss: 0.0704 - val_accuracy: 0.9789\n",
      "Epoch 54/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0528 - accuracy: 0.9808\n",
      "Epoch 00054: val_accuracy did not improve from 0.98946\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0528 - accuracy: 0.9808 - val_loss: 0.0514 - val_accuracy: 0.9844\n",
      "Epoch 55/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0512 - accuracy: 0.9821\n",
      "Epoch 00055: val_accuracy improved from 0.98946 to 0.99030, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0512 - accuracy: 0.9821 - val_loss: 0.0395 - val_accuracy: 0.9903\n",
      "Epoch 56/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9810\n",
      "Epoch 00056: val_accuracy did not improve from 0.99030\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0538 - accuracy: 0.9809 - val_loss: 0.0394 - val_accuracy: 0.9869\n",
      "Epoch 57/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9819\n",
      "Epoch 00057: val_accuracy did not improve from 0.99030\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 0.0446 - val_accuracy: 0.9865\n",
      "Epoch 58/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9828\n",
      "Epoch 00058: val_accuracy improved from 0.99030 to 0.99115, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 15s 23ms/step - loss: 0.0494 - accuracy: 0.9828 - val_loss: 0.0403 - val_accuracy: 0.9911\n",
      "Epoch 59/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0477 - accuracy: 0.9837\n",
      "Epoch 00059: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0477 - accuracy: 0.9837 - val_loss: 0.0385 - val_accuracy: 0.9890\n",
      "Epoch 60/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0449 - accuracy: 0.9846\n",
      "Epoch 00060: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0449 - accuracy: 0.9846 - val_loss: 0.0448 - val_accuracy: 0.9869\n",
      "Epoch 61/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0448 - accuracy: 0.9834\n",
      "Epoch 00061: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0450 - accuracy: 0.9834 - val_loss: 0.0443 - val_accuracy: 0.9861\n",
      "Epoch 62/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0596 - accuracy: 0.9794\n",
      "Epoch 00062: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0596 - accuracy: 0.9793 - val_loss: 0.0352 - val_accuracy: 0.9903\n",
      "Epoch 63/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0466 - accuracy: 0.9836\n",
      "Epoch 00063: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0467 - accuracy: 0.9835 - val_loss: 0.0374 - val_accuracy: 0.9895\n",
      "Epoch 64/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0501 - accuracy: 0.9821\n",
      "Epoch 00064: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0501 - accuracy: 0.9821 - val_loss: 0.0381 - val_accuracy: 0.9874\n",
      "Epoch 65/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0451 - accuracy: 0.9834\n",
      "Epoch 00065: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0451 - accuracy: 0.9834 - val_loss: 0.0443 - val_accuracy: 0.9857\n",
      "Epoch 66/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0394 - accuracy: 0.9861\n",
      "Epoch 00066: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0394 - accuracy: 0.9861 - val_loss: 0.0424 - val_accuracy: 0.9895\n",
      "Epoch 67/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0404 - accuracy: 0.9857\n",
      "Epoch 00067: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0404 - accuracy: 0.9857 - val_loss: 0.0339 - val_accuracy: 0.9907\n",
      "Epoch 68/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9852\n",
      "Epoch 00068: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0407 - accuracy: 0.9852 - val_loss: 0.0391 - val_accuracy: 0.9899\n",
      "Epoch 69/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9856\n",
      "Epoch 00069: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0373 - accuracy: 0.9856 - val_loss: 0.0400 - val_accuracy: 0.9890\n",
      "Epoch 70/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9877\n",
      "Epoch 00070: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 0.0608 - val_accuracy: 0.9857\n",
      "Epoch 71/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0416 - accuracy: 0.9855\n",
      "Epoch 00071: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0416 - accuracy: 0.9855 - val_loss: 0.0476 - val_accuracy: 0.9869\n",
      "Epoch 72/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9868\n",
      "Epoch 00072: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0368 - accuracy: 0.9868 - val_loss: 0.0537 - val_accuracy: 0.9827\n",
      "Epoch 73/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9873\n",
      "Epoch 00073: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0365 - accuracy: 0.9873 - val_loss: 0.0316 - val_accuracy: 0.9903\n",
      "Epoch 74/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0351 - accuracy: 0.9873\n",
      "Epoch 00074: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0351 - accuracy: 0.9873 - val_loss: 0.0287 - val_accuracy: 0.9911\n",
      "Epoch 75/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0362 - accuracy: 0.9881\n",
      "Epoch 00075: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0362 - accuracy: 0.9881 - val_loss: 0.0319 - val_accuracy: 0.9907\n",
      "Epoch 76/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0342 - accuracy: 0.9886\n",
      "Epoch 00076: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0342 - accuracy: 0.9886 - val_loss: 0.0444 - val_accuracy: 0.9874\n",
      "Epoch 77/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0345 - accuracy: 0.9876\n",
      "Epoch 00077: val_accuracy did not improve from 0.99115\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0347 - accuracy: 0.9876 - val_loss: 0.0406 - val_accuracy: 0.9882\n",
      "Epoch 78/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.9828\n",
      "Epoch 00078: val_accuracy did not improve from 0.99115\n",
      "Restoring model weights from the end of the best epoch.\n",
      "668/668 [==============================] - 15s 22ms/step - loss: 0.0484 - accuracy: 0.9828 - val_loss: 0.0389 - val_accuracy: 0.9890\n",
      "Epoch 00078: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [19:38<19:38, 1178.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.77      0.79      0.78       600\n",
      "        car_horn       0.81      0.81      0.81       168\n",
      "children_playing       0.86      0.91      0.89       600\n",
      "        dog_bark       0.88      0.88      0.88       600\n",
      "           siren       0.85      0.77      0.81       462\n",
      "\n",
      "        accuracy                           0.84      2430\n",
      "       macro avg       0.83      0.83      0.83      2430\n",
      "    weighted avg       0.84      0.84      0.84      2430\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_16\n",
      "Epoch 1/100\n",
      "  2/668 [..............................] - ETA: 20s - loss: 2.1847 - accuracy: 0.2031WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0219s vs `on_train_batch_end` time: 0.0389s). Check your callbacks.\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.9219 - accuracy: 0.6600\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76307, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 63ms/step - loss: 0.9218 - accuracy: 0.6601 - val_loss: 0.6462 - val_accuracy: 0.7631\n",
      "Epoch 2/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.5619 - accuracy: 0.8046\n",
      "Epoch 00002: val_accuracy improved from 0.76307 to 0.81661, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.5619 - accuracy: 0.8046 - val_loss: 0.5377 - val_accuracy: 0.8166\n",
      "Epoch 3/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.4612 - accuracy: 0.8374\n",
      "Epoch 00003: val_accuracy did not improve from 0.81661\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.4612 - accuracy: 0.8374 - val_loss: 1.1384 - val_accuracy: 0.6197\n",
      "Epoch 4/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.3358 - accuracy: 0.8824\n",
      "Epoch 00004: val_accuracy improved from 0.81661 to 0.87985, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.3358 - accuracy: 0.8824 - val_loss: 0.3318 - val_accuracy: 0.8798\n",
      "Epoch 5/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2636 - accuracy: 0.9081\n",
      "Epoch 00005: val_accuracy improved from 0.87985 to 0.91821, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.2636 - accuracy: 0.9081 - val_loss: 0.2370 - val_accuracy: 0.9182\n",
      "Epoch 6/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2096 - accuracy: 0.9286\n",
      "Epoch 00006: val_accuracy did not improve from 0.91821\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.2096 - accuracy: 0.9286 - val_loss: 1.4145 - val_accuracy: 0.6627\n",
      "Epoch 7/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1803 - accuracy: 0.9397\n",
      "Epoch 00007: val_accuracy improved from 0.91821 to 0.96121, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1803 - accuracy: 0.9397 - val_loss: 0.1199 - val_accuracy: 0.9612\n",
      "Epoch 8/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1512 - accuracy: 0.9464\n",
      "Epoch 00008: val_accuracy did not improve from 0.96121\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1513 - accuracy: 0.9464 - val_loss: 0.3128 - val_accuracy: 0.8963\n",
      "Epoch 9/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.2536 - accuracy: 0.9122\n",
      "Epoch 00009: val_accuracy did not improve from 0.96121\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.2537 - accuracy: 0.9122 - val_loss: 0.1696 - val_accuracy: 0.9422\n",
      "Epoch 10/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1339 - accuracy: 0.9542\n",
      "Epoch 00010: val_accuracy did not improve from 0.96121\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1339 - accuracy: 0.9542 - val_loss: 0.1589 - val_accuracy: 0.9477\n",
      "Epoch 11/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1117 - accuracy: 0.9603\n",
      "Epoch 00011: val_accuracy did not improve from 0.96121\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1117 - accuracy: 0.9602 - val_loss: 0.1898 - val_accuracy: 0.9427\n",
      "Epoch 12/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1299 - accuracy: 0.9553\n",
      "Epoch 00012: val_accuracy improved from 0.96121 to 0.97218, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1298 - accuracy: 0.9553 - val_loss: 0.0948 - val_accuracy: 0.9722\n",
      "Epoch 13/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0905 - accuracy: 0.9690\n",
      "Epoch 00013: val_accuracy did not improve from 0.97218\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0905 - accuracy: 0.9690 - val_loss: 0.1021 - val_accuracy: 0.9692\n",
      "Epoch 14/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0729 - accuracy: 0.9742\n",
      "Epoch 00014: val_accuracy improved from 0.97218 to 0.97428, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0729 - accuracy: 0.9742 - val_loss: 0.0777 - val_accuracy: 0.9743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9795\n",
      "Epoch 00015: val_accuracy improved from 0.97428 to 0.97808, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0621 - accuracy: 0.9795 - val_loss: 0.0632 - val_accuracy: 0.9781\n",
      "Epoch 16/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0599 - accuracy: 0.9792\n",
      "Epoch 00016: val_accuracy did not improve from 0.97808\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0601 - accuracy: 0.9791 - val_loss: 0.5160 - val_accuracy: 0.8697\n",
      "Epoch 17/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0703 - accuracy: 0.9749\n",
      "Epoch 00017: val_accuracy improved from 0.97808 to 0.98019, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0703 - accuracy: 0.9749 - val_loss: 0.0765 - val_accuracy: 0.9802\n",
      "Epoch 18/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.9837\n",
      "Epoch 00018: val_accuracy did not improve from 0.98019\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0488 - accuracy: 0.9837 - val_loss: 0.0709 - val_accuracy: 0.9768\n",
      "Epoch 19/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0379 - accuracy: 0.9861\n",
      "Epoch 00019: val_accuracy did not improve from 0.98019\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0379 - accuracy: 0.9861 - val_loss: 0.0895 - val_accuracy: 0.9777\n",
      "Epoch 20/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0411 - accuracy: 0.9859\n",
      "Epoch 00020: val_accuracy did not improve from 0.98019\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0411 - accuracy: 0.9859 - val_loss: 0.2134 - val_accuracy: 0.9439\n",
      "Epoch 21/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 0.9868\n",
      "Epoch 00021: val_accuracy improved from 0.98019 to 0.98524, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0389 - accuracy: 0.9868 - val_loss: 0.0550 - val_accuracy: 0.9852\n",
      "Epoch 22/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0331 - accuracy: 0.9891\n",
      "Epoch 00022: val_accuracy did not improve from 0.98524\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.0661 - val_accuracy: 0.9810\n",
      "Epoch 23/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9871\n",
      "Epoch 00023: val_accuracy did not improve from 0.98524\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0365 - accuracy: 0.9871 - val_loss: 0.0729 - val_accuracy: 0.9785\n",
      "Epoch 24/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0241 - accuracy: 0.9923\n",
      "Epoch 00024: val_accuracy improved from 0.98524 to 0.98651, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0489 - val_accuracy: 0.9865\n",
      "Epoch 25/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9901\n",
      "Epoch 00025: val_accuracy did not improve from 0.98651\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0293 - accuracy: 0.9901 - val_loss: 0.0838 - val_accuracy: 0.9798\n",
      "Epoch 26/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9930\n",
      "Epoch 00026: val_accuracy improved from 0.98651 to 0.98735, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0205 - accuracy: 0.9930 - val_loss: 0.0543 - val_accuracy: 0.9874\n",
      "Epoch 27/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9924\n",
      "Epoch 00027: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.0737 - val_accuracy: 0.9823\n",
      "Epoch 28/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9929\n",
      "Epoch 00028: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.0703 - val_accuracy: 0.9827\n",
      "Epoch 29/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9928\n",
      "Epoch 00029: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0244 - accuracy: 0.9928 - val_loss: 0.0738 - val_accuracy: 0.9827\n",
      "Epoch 30/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9917\n",
      "Epoch 00030: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0244 - accuracy: 0.9917 - val_loss: 0.0608 - val_accuracy: 0.9861\n",
      "Epoch 31/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9947\n",
      "Epoch 00031: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0831 - val_accuracy: 0.9840\n",
      "Epoch 32/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9937\n",
      "Epoch 00032: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.1085 - val_accuracy: 0.9793\n",
      "Epoch 33/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9937\n",
      "Epoch 00033: val_accuracy did not improve from 0.98735\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0660 - val_accuracy: 0.9827\n",
      "Epoch 34/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9937\n",
      "Epoch 00034: val_accuracy improved from 0.98735 to 0.98820, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.0500 - val_accuracy: 0.9882\n",
      "Epoch 35/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9948\n",
      "Epoch 00035: val_accuracy did not improve from 0.98820\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.0745 - val_accuracy: 0.9810\n",
      "Epoch 36/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9957\n",
      "Epoch 00036: val_accuracy did not improve from 0.98820\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0607 - val_accuracy: 0.9861\n",
      "Epoch 37/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9959\n",
      "Epoch 00037: val_accuracy did not improve from 0.98820\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0978 - val_accuracy: 0.9785\n",
      "Epoch 38/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9960\n",
      "Epoch 00038: val_accuracy did not improve from 0.98820\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0694 - val_accuracy: 0.9840\n",
      "Epoch 39/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0106 - accuracy: 0.9965\n",
      "Epoch 00039: val_accuracy improved from 0.98820 to 0.98988, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 0.0488 - val_accuracy: 0.9899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9958\n",
      "Epoch 00040: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0608 - val_accuracy: 0.9865\n",
      "Epoch 41/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9942\n",
      "Epoch 00041: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.0555 - val_accuracy: 0.9844\n",
      "Epoch 42/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9962\n",
      "Epoch 00042: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0542 - val_accuracy: 0.9874\n",
      "Epoch 43/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9971\n",
      "Epoch 00043: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.0534 - val_accuracy: 0.9874\n",
      "Epoch 44/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0095 - accuracy: 0.9963\n",
      "Epoch 00044: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0095 - accuracy: 0.9963 - val_loss: 0.0924 - val_accuracy: 0.9798\n",
      "Epoch 45/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9970\n",
      "Epoch 00045: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0082 - accuracy: 0.9970 - val_loss: 0.0735 - val_accuracy: 0.9852\n",
      "Epoch 46/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9958\n",
      "Epoch 00046: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0759 - val_accuracy: 0.9840\n",
      "Epoch 47/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9970\n",
      "Epoch 00047: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.1349 - val_accuracy: 0.9755\n",
      "Epoch 48/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.1063 - accuracy: 0.9680\n",
      "Epoch 00048: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.1064 - accuracy: 0.9680 - val_loss: 0.0711 - val_accuracy: 0.9768\n",
      "Epoch 49/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0427 - accuracy: 0.9860\n",
      "Epoch 00049: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0427 - accuracy: 0.9860 - val_loss: 0.0598 - val_accuracy: 0.9827\n",
      "Epoch 50/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9952\n",
      "Epoch 00050: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 0.0585 - val_accuracy: 0.9844\n",
      "Epoch 51/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9955\n",
      "Epoch 00051: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.0801 - val_accuracy: 0.9806\n",
      "Epoch 52/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9952\n",
      "Epoch 00052: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0147 - accuracy: 0.9952 - val_loss: 0.0527 - val_accuracy: 0.9852\n",
      "Epoch 53/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9951\n",
      "Epoch 00053: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.0794 - val_accuracy: 0.9810\n",
      "Epoch 54/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9959\n",
      "Epoch 00054: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.0555 - val_accuracy: 0.9869\n",
      "Epoch 55/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9964\n",
      "Epoch 00055: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 0.0574 - val_accuracy: 0.9865\n",
      "Epoch 56/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9959\n",
      "Epoch 00056: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0973 - val_accuracy: 0.9789\n",
      "Epoch 57/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9940\n",
      "Epoch 00057: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 41s 62ms/step - loss: 0.0197 - accuracy: 0.9940 - val_loss: 0.0521 - val_accuracy: 0.9899\n",
      "Epoch 58/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9976\n",
      "Epoch 00058: val_accuracy did not improve from 0.98988\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0815 - val_accuracy: 0.9836\n",
      "Epoch 59/100\n",
      "667/668 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 00059: val_accuracy did not improve from 0.98988\n",
      "Restoring model weights from the end of the best epoch.\n",
      "668/668 [==============================] - 42s 62ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.0679 - val_accuracy: 0.9857\n",
      "Epoch 00059: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:00:46<00:00, 1823.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.78      0.83      0.80       600\n",
      "        car_horn       0.86      0.83      0.85       168\n",
      "children_playing       0.90      0.91      0.91       600\n",
      "        dog_bark       0.89      0.90      0.89       600\n",
      "           siren       0.87      0.77      0.82       462\n",
      "\n",
      "        accuracy                           0.86      2430\n",
      "       macro avg       0.86      0.85      0.85      2430\n",
      "    weighted avg       0.86      0.86      0.86      2430\n",
      "\n",
      "\n",
      "Validation fold: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21427, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21427, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2381, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2381, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2340, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2340, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_17\n",
      "Epoch 1/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 1.1884 - accuracy: 0.6029\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70097, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 16s 23ms/step - loss: 1.1884 - accuracy: 0.6029 - val_loss: 0.7925 - val_accuracy: 0.7010\n",
      "Epoch 2/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.7415 - accuracy: 0.7336\n",
      "Epoch 00002: val_accuracy improved from 0.70097 to 0.77110, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.7415 - accuracy: 0.7336 - val_loss: 0.6536 - val_accuracy: 0.7711\n",
      "Epoch 3/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.6275 - accuracy: 0.7718\n",
      "Epoch 00003: val_accuracy improved from 0.77110 to 0.79504, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.6275 - accuracy: 0.7718 - val_loss: 0.5613 - val_accuracy: 0.7950\n",
      "Epoch 4/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.8030\n",
      "Epoch 00004: val_accuracy improved from 0.79504 to 0.84124, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.5415 - accuracy: 0.8030 - val_loss: 0.4332 - val_accuracy: 0.8412\n",
      "Epoch 5/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.4857 - accuracy: 0.8272\n",
      "Epoch 00005: val_accuracy did not improve from 0.84124\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.4857 - accuracy: 0.8272 - val_loss: 0.4765 - val_accuracy: 0.8320\n",
      "Epoch 6/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.4315 - accuracy: 0.8453\n",
      "Epoch 00006: val_accuracy improved from 0.84124 to 0.87274, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.4315 - accuracy: 0.8453 - val_loss: 0.3863 - val_accuracy: 0.8727\n",
      "Epoch 7/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.8595\n",
      "Epoch 00007: val_accuracy improved from 0.87274 to 0.87778, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.3887 - accuracy: 0.8595 - val_loss: 0.3357 - val_accuracy: 0.8778\n",
      "Epoch 8/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.8711\n",
      "Epoch 00008: val_accuracy improved from 0.87778 to 0.89752, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.3607 - accuracy: 0.8711 - val_loss: 0.2866 - val_accuracy: 0.8975\n",
      "Epoch 9/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.8785\n",
      "Epoch 00009: val_accuracy did not improve from 0.89752\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.3333 - accuracy: 0.8785 - val_loss: 0.3016 - val_accuracy: 0.8904\n",
      "Epoch 10/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.8886\n",
      "Epoch 00010: val_accuracy did not improve from 0.89752\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.3076 - accuracy: 0.8886 - val_loss: 0.5569 - val_accuracy: 0.8404\n",
      "Epoch 11/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.8971\n",
      "Epoch 00011: val_accuracy improved from 0.89752 to 0.92188, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.2849 - accuracy: 0.8971 - val_loss: 0.2164 - val_accuracy: 0.9219\n",
      "Epoch 12/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.2599 - accuracy: 0.9056\n",
      "Epoch 00012: val_accuracy did not improve from 0.92188\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.2599 - accuracy: 0.9056 - val_loss: 0.2532 - val_accuracy: 0.9147\n",
      "Epoch 13/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.2461 - accuracy: 0.9104\n",
      "Epoch 00013: val_accuracy did not improve from 0.92188\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.2461 - accuracy: 0.9104 - val_loss: 0.2133 - val_accuracy: 0.9177\n",
      "Epoch 14/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.9145\n",
      "Epoch 00014: val_accuracy improved from 0.92188 to 0.92650, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.2335 - accuracy: 0.9145 - val_loss: 0.2053 - val_accuracy: 0.9265\n",
      "Epoch 15/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.9201\n",
      "Epoch 00015: val_accuracy did not improve from 0.92650\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.2161 - accuracy: 0.9201 - val_loss: 0.1936 - val_accuracy: 0.9240\n",
      "Epoch 16/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.9256\n",
      "Epoch 00016: val_accuracy improved from 0.92650 to 0.93952, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.2014 - accuracy: 0.9256 - val_loss: 0.1818 - val_accuracy: 0.9395\n",
      "Epoch 17/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1963 - accuracy: 0.9304\n",
      "Epoch 00017: val_accuracy improved from 0.93952 to 0.94582, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.1963 - accuracy: 0.9304 - val_loss: 0.1487 - val_accuracy: 0.9458\n",
      "Epoch 18/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.1860 - accuracy: 0.9316\n",
      "Epoch 00018: val_accuracy did not improve from 0.94582\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1860 - accuracy: 0.9316 - val_loss: 0.1532 - val_accuracy: 0.9429\n",
      "Epoch 19/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9349\n",
      "Epoch 00019: val_accuracy did not improve from 0.94582\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1798 - accuracy: 0.9349 - val_loss: 0.2741 - val_accuracy: 0.9105\n",
      "Epoch 20/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9394\n",
      "Epoch 00020: val_accuracy improved from 0.94582 to 0.96136, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.1659 - accuracy: 0.9394 - val_loss: 0.1129 - val_accuracy: 0.9614\n",
      "Epoch 21/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.9419\n",
      "Epoch 00021: val_accuracy did not improve from 0.96136\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1601 - accuracy: 0.9419 - val_loss: 0.1630 - val_accuracy: 0.9475\n",
      "Epoch 22/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1540 - accuracy: 0.9446\n",
      "Epoch 00022: val_accuracy did not improve from 0.96136\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1540 - accuracy: 0.9446 - val_loss: 0.1224 - val_accuracy: 0.9580\n",
      "Epoch 23/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.9471\n",
      "Epoch 00023: val_accuracy did not improve from 0.96136\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1456 - accuracy: 0.9471 - val_loss: 0.1700 - val_accuracy: 0.9429\n",
      "Epoch 24/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9490\n",
      "Epoch 00024: val_accuracy improved from 0.96136 to 0.96346, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.1403 - accuracy: 0.9490 - val_loss: 0.1088 - val_accuracy: 0.9635\n",
      "Epoch 25/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9485\n",
      "Epoch 00025: val_accuracy did not improve from 0.96346\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1396 - accuracy: 0.9485 - val_loss: 0.1934 - val_accuracy: 0.9324\n",
      "Epoch 26/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9523\n",
      "Epoch 00026: val_accuracy did not improve from 0.96346\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1346 - accuracy: 0.9523 - val_loss: 0.1396 - val_accuracy: 0.9513\n",
      "Epoch 27/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9540\n",
      "Epoch 00027: val_accuracy did not improve from 0.96346\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1280 - accuracy: 0.9540 - val_loss: 0.1339 - val_accuracy: 0.9563\n",
      "Epoch 28/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.9559\n",
      "Epoch 00028: val_accuracy improved from 0.96346 to 0.97438, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1199 - accuracy: 0.9559 - val_loss: 0.0872 - val_accuracy: 0.9744\n",
      "Epoch 29/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9595\n",
      "Epoch 00029: val_accuracy did not improve from 0.97438\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1139 - accuracy: 0.9595 - val_loss: 0.1021 - val_accuracy: 0.9647\n",
      "Epoch 30/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 0.9612\n",
      "Epoch 00030: val_accuracy did not improve from 0.97438\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1090 - accuracy: 0.9612 - val_loss: 0.1396 - val_accuracy: 0.9563\n",
      "Epoch 31/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.9631\n",
      "Epoch 00031: val_accuracy did not improve from 0.97438\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1028 - accuracy: 0.9631 - val_loss: 0.1079 - val_accuracy: 0.9639\n",
      "Epoch 32/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.1012 - accuracy: 0.9632\n",
      "Epoch 00032: val_accuracy did not improve from 0.97438\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1012 - accuracy: 0.9632 - val_loss: 0.1327 - val_accuracy: 0.9605\n",
      "Epoch 33/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.1009 - accuracy: 0.9637\n",
      "Epoch 00033: val_accuracy did not improve from 0.97438\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.1009 - accuracy: 0.9637 - val_loss: 0.0871 - val_accuracy: 0.9719\n",
      "Epoch 34/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.9681\n",
      "Epoch 00034: val_accuracy improved from 0.97438 to 0.97480, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0909 - accuracy: 0.9681 - val_loss: 0.0799 - val_accuracy: 0.9748\n",
      "Epoch 35/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9676\n",
      "Epoch 00035: val_accuracy did not improve from 0.97480\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0915 - accuracy: 0.9676 - val_loss: 0.1012 - val_accuracy: 0.9660\n",
      "Epoch 36/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9675\n",
      "Epoch 00036: val_accuracy improved from 0.97480 to 0.97564, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0901 - accuracy: 0.9675 - val_loss: 0.0856 - val_accuracy: 0.9756\n",
      "Epoch 37/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9689\n",
      "Epoch 00037: val_accuracy did not improve from 0.97564\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0864 - accuracy: 0.9689 - val_loss: 0.0849 - val_accuracy: 0.9744\n",
      "Epoch 38/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.9695\n",
      "Epoch 00038: val_accuracy did not improve from 0.97564\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0844 - accuracy: 0.9695 - val_loss: 0.0761 - val_accuracy: 0.9752\n",
      "Epoch 39/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.9698\n",
      "Epoch 00039: val_accuracy improved from 0.97564 to 0.97942, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0807 - accuracy: 0.9698 - val_loss: 0.0704 - val_accuracy: 0.9794\n",
      "Epoch 40/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9697\n",
      "Epoch 00040: val_accuracy did not improve from 0.97942\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0852 - accuracy: 0.9697 - val_loss: 0.0740 - val_accuracy: 0.9782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9739\n",
      "Epoch 00041: val_accuracy did not improve from 0.97942\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0751 - accuracy: 0.9739 - val_loss: 0.0927 - val_accuracy: 0.9748\n",
      "Epoch 42/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0800 - accuracy: 0.9709\n",
      "Epoch 00042: val_accuracy did not improve from 0.97942\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0800 - accuracy: 0.9709 - val_loss: 0.0615 - val_accuracy: 0.9794\n",
      "Epoch 43/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.9752\n",
      "Epoch 00043: val_accuracy improved from 0.97942 to 0.98026, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0703 - accuracy: 0.9752 - val_loss: 0.0602 - val_accuracy: 0.9803\n",
      "Epoch 44/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.9745\n",
      "Epoch 00044: val_accuracy did not improve from 0.98026\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0709 - accuracy: 0.9745 - val_loss: 0.0762 - val_accuracy: 0.9731\n",
      "Epoch 45/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.9758\n",
      "Epoch 00045: val_accuracy did not improve from 0.98026\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0680 - accuracy: 0.9758 - val_loss: 0.1029 - val_accuracy: 0.9719\n",
      "Epoch 46/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.9755\n",
      "Epoch 00046: val_accuracy did not improve from 0.98026\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0637 - accuracy: 0.9755 - val_loss: 0.0694 - val_accuracy: 0.9782\n",
      "Epoch 47/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9782\n",
      "Epoch 00047: val_accuracy improved from 0.98026 to 0.98194, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0631 - accuracy: 0.9782 - val_loss: 0.0669 - val_accuracy: 0.9819\n",
      "Epoch 48/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9765\n",
      "Epoch 00048: val_accuracy improved from 0.98194 to 0.98362, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0651 - accuracy: 0.9765 - val_loss: 0.0559 - val_accuracy: 0.9836\n",
      "Epoch 49/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9794\n",
      "Epoch 00049: val_accuracy did not improve from 0.98362\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0572 - accuracy: 0.9794 - val_loss: 0.0570 - val_accuracy: 0.9832\n",
      "Epoch 50/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0599 - accuracy: 0.9800\n",
      "Epoch 00050: val_accuracy did not improve from 0.98362\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0599 - accuracy: 0.9800 - val_loss: 0.0700 - val_accuracy: 0.9824\n",
      "Epoch 51/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9804\n",
      "Epoch 00051: val_accuracy improved from 0.98362 to 0.98614, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0546 - accuracy: 0.9804 - val_loss: 0.0508 - val_accuracy: 0.9861\n",
      "Epoch 52/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0566 - accuracy: 0.9795\n",
      "Epoch 00052: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0566 - accuracy: 0.9795 - val_loss: 0.1082 - val_accuracy: 0.9706\n",
      "Epoch 53/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9796\n",
      "Epoch 00053: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0576 - accuracy: 0.9796 - val_loss: 0.0701 - val_accuracy: 0.9773\n",
      "Epoch 54/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 0.9811\n",
      "Epoch 00054: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0526 - accuracy: 0.9811 - val_loss: 0.0560 - val_accuracy: 0.9824\n",
      "Epoch 55/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9799\n",
      "Epoch 00055: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0549 - accuracy: 0.9799 - val_loss: 0.0772 - val_accuracy: 0.9777\n",
      "Epoch 56/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0515 - accuracy: 0.9821\n",
      "Epoch 00056: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0515 - accuracy: 0.9821 - val_loss: 0.0787 - val_accuracy: 0.9765\n",
      "Epoch 57/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9831\n",
      "Epoch 00057: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0467 - accuracy: 0.9831 - val_loss: 0.0649 - val_accuracy: 0.9828\n",
      "Epoch 58/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0484 - accuracy: 0.9830\n",
      "Epoch 00058: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0484 - accuracy: 0.9831 - val_loss: 0.0533 - val_accuracy: 0.9845\n",
      "Epoch 59/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9843\n",
      "Epoch 00059: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0456 - accuracy: 0.9843 - val_loss: 0.0567 - val_accuracy: 0.9849\n",
      "Epoch 60/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 0.9842\n",
      "Epoch 00060: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0463 - accuracy: 0.9842 - val_loss: 0.0604 - val_accuracy: 0.9824\n",
      "Epoch 61/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9830\n",
      "Epoch 00061: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0487 - accuracy: 0.9830 - val_loss: 0.0711 - val_accuracy: 0.9811\n",
      "Epoch 62/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 0.9834\n",
      "Epoch 00062: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0465 - accuracy: 0.9834 - val_loss: 0.0852 - val_accuracy: 0.9761\n",
      "Epoch 63/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9841\n",
      "Epoch 00063: val_accuracy improved from 0.98614 to 0.98908, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0429 - accuracy: 0.9841 - val_loss: 0.0384 - val_accuracy: 0.9891\n",
      "Epoch 64/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9835\n",
      "Epoch 00064: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0475 - accuracy: 0.9835 - val_loss: 0.0498 - val_accuracy: 0.9853\n",
      "Epoch 65/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 0.9839\n",
      "Epoch 00065: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0424 - accuracy: 0.9839 - val_loss: 0.0455 - val_accuracy: 0.9874\n",
      "Epoch 66/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9860\n",
      "Epoch 00066: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0382 - accuracy: 0.9860 - val_loss: 0.0544 - val_accuracy: 0.9840\n",
      "Epoch 67/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9852\n",
      "Epoch 00067: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0404 - accuracy: 0.9852 - val_loss: 0.0456 - val_accuracy: 0.9878\n",
      "Epoch 68/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9865\n",
      "Epoch 00068: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0410 - accuracy: 0.9865 - val_loss: 0.0496 - val_accuracy: 0.9857\n",
      "Epoch 69/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9851\n",
      "Epoch 00069: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0414 - accuracy: 0.9851 - val_loss: 0.0651 - val_accuracy: 0.9824\n",
      "Epoch 70/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9864\n",
      "Epoch 00070: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0397 - accuracy: 0.9864 - val_loss: 0.0559 - val_accuracy: 0.9832\n",
      "Epoch 71/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9857\n",
      "Epoch 00071: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0383 - accuracy: 0.9857 - val_loss: 0.0552 - val_accuracy: 0.9853\n",
      "Epoch 72/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9860\n",
      "Epoch 00072: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0392 - accuracy: 0.9860 - val_loss: 0.0449 - val_accuracy: 0.9882\n",
      "Epoch 73/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9870\n",
      "Epoch 00073: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0373 - accuracy: 0.9870 - val_loss: 0.0439 - val_accuracy: 0.9861\n",
      "Epoch 74/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9871\n",
      "Epoch 00074: val_accuracy did not improve from 0.98908\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0358 - accuracy: 0.9871 - val_loss: 0.0470 - val_accuracy: 0.9887\n",
      "Epoch 75/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9847\n",
      "Epoch 00075: val_accuracy improved from 0.98908 to 0.98992, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0432 - accuracy: 0.9847 - val_loss: 0.0402 - val_accuracy: 0.9899\n",
      "Epoch 76/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9873\n",
      "Epoch 00076: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0353 - accuracy: 0.9873 - val_loss: 0.0421 - val_accuracy: 0.9882\n",
      "Epoch 77/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9884\n",
      "Epoch 00077: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0358 - accuracy: 0.9884 - val_loss: 0.0372 - val_accuracy: 0.9895\n",
      "Epoch 78/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9880\n",
      "Epoch 00078: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0346 - accuracy: 0.9880 - val_loss: 0.0466 - val_accuracy: 0.9887\n",
      "Epoch 79/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0336 - accuracy: 0.9879\n",
      "Epoch 00079: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0336 - accuracy: 0.9879 - val_loss: 0.0528 - val_accuracy: 0.9853\n",
      "Epoch 80/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9887\n",
      "Epoch 00080: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0312 - accuracy: 0.9887 - val_loss: 0.0468 - val_accuracy: 0.9891\n",
      "Epoch 81/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 0.9887\n",
      "Epoch 00081: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0325 - accuracy: 0.9887 - val_loss: 0.0802 - val_accuracy: 0.9811\n",
      "Epoch 82/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9888\n",
      "Epoch 00082: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0334 - accuracy: 0.9888 - val_loss: 0.0488 - val_accuracy: 0.9882\n",
      "Epoch 83/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0327 - accuracy: 0.9882\n",
      "Epoch 00083: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0327 - accuracy: 0.9882 - val_loss: 0.0566 - val_accuracy: 0.9874\n",
      "Epoch 84/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9896\n",
      "Epoch 00084: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 0.0465 - val_accuracy: 0.9870\n",
      "Epoch 85/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9901\n",
      "Epoch 00085: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0285 - accuracy: 0.9901 - val_loss: 0.0493 - val_accuracy: 0.9874\n",
      "Epoch 86/100\n",
      "668/670 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9898\n",
      "Epoch 00086: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0289 - accuracy: 0.9897 - val_loss: 0.0492 - val_accuracy: 0.9895\n",
      "Epoch 87/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9901\n",
      "Epoch 00087: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0277 - accuracy: 0.9901 - val_loss: 0.0535 - val_accuracy: 0.9882\n",
      "Epoch 88/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0301 - accuracy: 0.9898\n",
      "Epoch 00088: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0301 - accuracy: 0.9898 - val_loss: 0.0450 - val_accuracy: 0.9887\n",
      "Epoch 89/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9902\n",
      "Epoch 00089: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0265 - accuracy: 0.9902 - val_loss: 0.0372 - val_accuracy: 0.9895\n",
      "Epoch 90/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9896\n",
      "Epoch 00090: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0304 - accuracy: 0.9896 - val_loss: 0.0451 - val_accuracy: 0.9891\n",
      "Epoch 91/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9904\n",
      "Epoch 00091: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0287 - accuracy: 0.9904 - val_loss: 0.0443 - val_accuracy: 0.9891\n",
      "Epoch 92/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9916\n",
      "Epoch 00092: val_accuracy improved from 0.98992 to 0.99076, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 15s 23ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.0374 - val_accuracy: 0.9908\n",
      "Epoch 93/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9913\n",
      "Epoch 00093: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.0429 - val_accuracy: 0.9866\n",
      "Epoch 94/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9916\n",
      "Epoch 00094: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.0347 - val_accuracy: 0.9891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9917\n",
      "Epoch 00095: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0280 - accuracy: 0.9917 - val_loss: 0.0411 - val_accuracy: 0.9891\n",
      "Epoch 96/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9923\n",
      "Epoch 00096: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0396 - val_accuracy: 0.9887\n",
      "Epoch 97/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9906\n",
      "Epoch 00097: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0259 - accuracy: 0.9906 - val_loss: 0.0445 - val_accuracy: 0.9878\n",
      "Epoch 98/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9915\n",
      "Epoch 00098: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0266 - accuracy: 0.9916 - val_loss: 0.0427 - val_accuracy: 0.9857\n",
      "Epoch 99/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9912\n",
      "Epoch 00099: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.0400 - val_accuracy: 0.9882\n",
      "Epoch 100/100\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9924\n",
      "Epoch 00100: val_accuracy did not improve from 0.99076\n",
      "670/670 [==============================] - 15s 22ms/step - loss: 0.0214 - accuracy: 0.9924 - val_loss: 0.0511 - val_accuracy: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [25:10<25:10, 1510.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.51      0.88      0.65       480\n",
      "        car_horn       0.86      0.87      0.86       180\n",
      "children_playing       0.83      0.67      0.74       600\n",
      "        dog_bark       0.98      0.81      0.88       600\n",
      "           siren       0.78      0.58      0.67       480\n",
      "\n",
      "        accuracy                           0.74      2340\n",
      "       macro avg       0.79      0.76      0.76      2340\n",
      "    weighted avg       0.80      0.74      0.75      2340\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_18\n",
      "Epoch 1/100\n",
      "  2/670 [..............................] - ETA: 20s - loss: 2.4784 - accuracy: 0.2188WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0219s vs `on_train_batch_end` time: 0.0381s). Check your callbacks.\n",
      "670/670 [==============================] - ETA: 0s - loss: 0.9055 - accuracy: 0.6641\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78958, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.9055 - accuracy: 0.6641 - val_loss: 0.5994 - val_accuracy: 0.7896\n",
      "Epoch 2/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.5258 - accuracy: 0.8153\n",
      "Epoch 00002: val_accuracy improved from 0.78958 to 0.82948, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.5259 - accuracy: 0.8152 - val_loss: 0.4936 - val_accuracy: 0.8295\n",
      "Epoch 3/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8719\n",
      "Epoch 00003: val_accuracy did not improve from 0.82948\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.3787 - accuracy: 0.8720 - val_loss: 1.0330 - val_accuracy: 0.7098\n",
      "Epoch 4/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.3001 - accuracy: 0.8977\n",
      "Epoch 00004: val_accuracy improved from 0.82948 to 0.86266, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.3001 - accuracy: 0.8977 - val_loss: 0.3801 - val_accuracy: 0.8627\n",
      "Epoch 5/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.2350 - accuracy: 0.9205\n",
      "Epoch 00005: val_accuracy improved from 0.86266 to 0.92776, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.2350 - accuracy: 0.9206 - val_loss: 0.2213 - val_accuracy: 0.9278\n",
      "Epoch 6/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.1909 - accuracy: 0.9356\n",
      "Epoch 00006: val_accuracy improved from 0.92776 to 0.94582, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.1908 - accuracy: 0.9356 - val_loss: 0.1734 - val_accuracy: 0.9458\n",
      "Epoch 7/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.1553 - accuracy: 0.9467\n",
      "Epoch 00007: val_accuracy did not improve from 0.94582\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.1553 - accuracy: 0.9466 - val_loss: 0.1696 - val_accuracy: 0.9395\n",
      "Epoch 8/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.1319 - accuracy: 0.9566\n",
      "Epoch 00008: val_accuracy did not improve from 0.94582\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.1318 - accuracy: 0.9566 - val_loss: 0.1855 - val_accuracy: 0.9353\n",
      "Epoch 9/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.1094 - accuracy: 0.9631\n",
      "Epoch 00009: val_accuracy improved from 0.94582 to 0.96724, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.1095 - accuracy: 0.9630 - val_loss: 0.0920 - val_accuracy: 0.9672\n",
      "Epoch 10/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0906 - accuracy: 0.9686\n",
      "Epoch 00010: val_accuracy did not improve from 0.96724\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0905 - accuracy: 0.9686 - val_loss: 0.2362 - val_accuracy: 0.9257\n",
      "Epoch 11/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0851 - accuracy: 0.9726\n",
      "Epoch 00011: val_accuracy did not improve from 0.96724\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0853 - accuracy: 0.9726 - val_loss: 0.5279 - val_accuracy: 0.8555\n",
      "Epoch 12/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0705 - accuracy: 0.9753\n",
      "Epoch 00012: val_accuracy did not improve from 0.96724\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0705 - accuracy: 0.9753 - val_loss: 0.3900 - val_accuracy: 0.8929\n",
      "Epoch 13/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9783\n",
      "Epoch 00013: val_accuracy did not improve from 0.96724\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0604 - accuracy: 0.9783 - val_loss: 0.2665 - val_accuracy: 0.9223\n",
      "Epoch 14/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 0.9816\n",
      "Epoch 00014: val_accuracy improved from 0.96724 to 0.97396, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0558 - accuracy: 0.9816 - val_loss: 0.0842 - val_accuracy: 0.9740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0545 - accuracy: 0.9821\n",
      "Epoch 00015: val_accuracy improved from 0.97396 to 0.98152, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0546 - accuracy: 0.9821 - val_loss: 0.0633 - val_accuracy: 0.9815\n",
      "Epoch 16/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9841\n",
      "Epoch 00016: val_accuracy did not improve from 0.98152\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0479 - accuracy: 0.9841 - val_loss: 0.0952 - val_accuracy: 0.9693\n",
      "Epoch 17/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0433 - accuracy: 0.9858\n",
      "Epoch 00017: val_accuracy did not improve from 0.98152\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0433 - accuracy: 0.9858 - val_loss: 0.0953 - val_accuracy: 0.9727\n",
      "Epoch 18/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.9855\n",
      "Epoch 00018: val_accuracy did not improve from 0.98152\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0430 - accuracy: 0.9855 - val_loss: 0.0603 - val_accuracy: 0.9807\n",
      "Epoch 19/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9876\n",
      "Epoch 00019: val_accuracy improved from 0.98152 to 0.98320, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 0.0599 - val_accuracy: 0.9832\n",
      "Epoch 20/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9899\n",
      "Epoch 00020: val_accuracy did not improve from 0.98320\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0301 - accuracy: 0.9899 - val_loss: 0.0643 - val_accuracy: 0.9832\n",
      "Epoch 21/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9921\n",
      "Epoch 00021: val_accuracy improved from 0.98320 to 0.98614, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.0594 - val_accuracy: 0.9861\n",
      "Epoch 22/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9905\n",
      "Epoch 00022: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0297 - accuracy: 0.9905 - val_loss: 0.0884 - val_accuracy: 0.9765\n",
      "Epoch 23/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9929\n",
      "Epoch 00023: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.1059 - val_accuracy: 0.9735\n",
      "Epoch 24/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9926\n",
      "Epoch 00024: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 0.0670 - val_accuracy: 0.9803\n",
      "Epoch 25/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9937\n",
      "Epoch 00025: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0645 - val_accuracy: 0.9849\n",
      "Epoch 26/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9932\n",
      "Epoch 00026: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.0714 - val_accuracy: 0.9782\n",
      "Epoch 27/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9934\n",
      "Epoch 00027: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0948 - val_accuracy: 0.9740\n",
      "Epoch 28/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9940\n",
      "Epoch 00028: val_accuracy did not improve from 0.98614\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.0490 - val_accuracy: 0.9861\n",
      "Epoch 29/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9954\n",
      "Epoch 00029: val_accuracy improved from 0.98614 to 0.98740, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0149 - accuracy: 0.9954 - val_loss: 0.0604 - val_accuracy: 0.9874\n",
      "Epoch 30/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9937\n",
      "Epoch 00030: val_accuracy did not improve from 0.98740\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.0576 - val_accuracy: 0.9849\n",
      "Epoch 31/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9952\n",
      "Epoch 00031: val_accuracy did not improve from 0.98740\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 0.1327 - val_accuracy: 0.9677\n",
      "Epoch 32/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9932\n",
      "Epoch 00032: val_accuracy did not improve from 0.98740\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0525 - val_accuracy: 0.9866\n",
      "Epoch 33/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9959\n",
      "Epoch 00033: val_accuracy improved from 0.98740 to 0.98992, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0384 - val_accuracy: 0.9899\n",
      "Epoch 34/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9941\n",
      "Epoch 00034: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0609 - val_accuracy: 0.9811\n",
      "Epoch 35/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9948\n",
      "Epoch 00035: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0452 - val_accuracy: 0.9866\n",
      "Epoch 36/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9965\n",
      "Epoch 00036: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0119 - accuracy: 0.9965 - val_loss: 0.0512 - val_accuracy: 0.9861\n",
      "Epoch 37/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9958\n",
      "Epoch 00037: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0611 - val_accuracy: 0.9857\n",
      "Epoch 38/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9977\n",
      "Epoch 00038: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0557 - val_accuracy: 0.9857\n",
      "Epoch 39/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9969\n",
      "Epoch 00039: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.1007 - val_accuracy: 0.9740\n",
      "Epoch 40/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9971\n",
      "Epoch 00040: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.0532 - val_accuracy: 0.9866\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/670 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9952\n",
      "Epoch 00041: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.0721 - val_accuracy: 0.9798\n",
      "Epoch 42/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9963\n",
      "Epoch 00042: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.0619 - val_accuracy: 0.9803\n",
      "Epoch 43/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 00043: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 0.0906 - val_accuracy: 0.9773\n",
      "Epoch 44/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9973\n",
      "Epoch 00044: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.0429 - val_accuracy: 0.9882\n",
      "Epoch 45/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9973\n",
      "Epoch 00045: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.0520 - val_accuracy: 0.9866\n",
      "Epoch 46/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 00046: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0606 - val_accuracy: 0.9857\n",
      "Epoch 47/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9976\n",
      "Epoch 00047: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0501 - val_accuracy: 0.9882\n",
      "Epoch 48/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00048: val_accuracy did not improve from 0.98992\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0456 - val_accuracy: 0.9891\n",
      "Epoch 49/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9982\n",
      "Epoch 00049: val_accuracy improved from 0.98992 to 0.99118, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0442 - val_accuracy: 0.9912\n",
      "Epoch 50/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9985\n",
      "Epoch 00050: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0720 - val_accuracy: 0.9840\n",
      "Epoch 51/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9982\n",
      "Epoch 00051: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 0.0451 - val_accuracy: 0.9891\n",
      "Epoch 52/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9981\n",
      "Epoch 00052: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0557 - val_accuracy: 0.9870\n",
      "Epoch 53/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9971\n",
      "Epoch 00053: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0506 - val_accuracy: 0.9866\n",
      "Epoch 54/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 00054: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0780 - val_accuracy: 0.9836\n",
      "Epoch 55/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\n",
      "Epoch 00055: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0513 - val_accuracy: 0.9895\n",
      "Epoch 56/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00056: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0442 - val_accuracy: 0.9908\n",
      "Epoch 57/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9973\n",
      "Epoch 00057: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0100 - accuracy: 0.9973 - val_loss: 0.0604 - val_accuracy: 0.9853\n",
      "Epoch 58/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9979\n",
      "Epoch 00058: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0062 - accuracy: 0.9979 - val_loss: 0.0734 - val_accuracy: 0.9870\n",
      "Epoch 59/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 00059: val_accuracy did not improve from 0.99118\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0534 - val_accuracy: 0.9857\n",
      "Epoch 60/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 00060: val_accuracy improved from 0.99118 to 0.99202, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0400 - val_accuracy: 0.9920\n",
      "Epoch 61/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9983\n",
      "Epoch 00061: val_accuracy did not improve from 0.99202\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0529 - val_accuracy: 0.9899\n",
      "Epoch 62/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9972\n",
      "Epoch 00062: val_accuracy did not improve from 0.99202\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.0427 - val_accuracy: 0.9903\n",
      "Epoch 63/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0101 - accuracy: 0.9967\n",
      "Epoch 00063: val_accuracy did not improve from 0.99202\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0507 - val_accuracy: 0.9861\n",
      "Epoch 64/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9984\n",
      "Epoch 00064: val_accuracy did not improve from 0.99202\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0427 - val_accuracy: 0.9895\n",
      "Epoch 65/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 00065: val_accuracy did not improve from 0.99202\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0459 - val_accuracy: 0.9895\n",
      "Epoch 66/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 00066: val_accuracy did not improve from 0.99202\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0594 - val_accuracy: 0.9870\n",
      "Epoch 67/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9985\n",
      "Epoch 00067: val_accuracy improved from 0.99202 to 0.99286, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0042 - accuracy: 0.9985 - val_loss: 0.0383 - val_accuracy: 0.9929\n",
      "Epoch 68/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9978\n",
      "Epoch 00068: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0611 - val_accuracy: 0.9887\n",
      "Epoch 69/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9977\n",
      "Epoch 00069: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0637 - val_accuracy: 0.9866\n",
      "Epoch 70/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9982\n",
      "Epoch 00070: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0482 - val_accuracy: 0.9891\n",
      "Epoch 71/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 00071: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0374 - val_accuracy: 0.9924\n",
      "Epoch 72/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00072: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0455 - val_accuracy: 0.9891\n",
      "Epoch 73/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 00073: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.1124 - val_accuracy: 0.9744\n",
      "Epoch 74/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 00074: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0347 - val_accuracy: 0.9916\n",
      "Epoch 75/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 00075: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 62ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0381 - val_accuracy: 0.9920\n",
      "Epoch 76/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 00076: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.0549 - val_accuracy: 0.9891\n",
      "Epoch 77/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 00077: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0811 - val_accuracy: 0.9853\n",
      "Epoch 78/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 00078: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0508 - val_accuracy: 0.9895\n",
      "Epoch 79/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9991\n",
      "Epoch 00079: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0409 - val_accuracy: 0.9920\n",
      "Epoch 80/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 00080: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0461 - val_accuracy: 0.9912\n",
      "Epoch 81/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 00081: val_accuracy did not improve from 0.99286\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0398 - val_accuracy: 0.9924\n",
      "Epoch 82/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9990\n",
      "Epoch 00082: val_accuracy improved from 0.99286 to 0.99412, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0315 - val_accuracy: 0.9941\n",
      "Epoch 83/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 00083: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0314 - val_accuracy: 0.9937\n",
      "Epoch 84/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00084: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0509 - val_accuracy: 0.9899\n",
      "Epoch 85/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00085: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0395 - val_accuracy: 0.9912\n",
      "Epoch 86/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9985\n",
      "Epoch 00086: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0549 - val_accuracy: 0.9899\n",
      "Epoch 87/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 00087: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 0.0378 - val_accuracy: 0.9912\n",
      "Epoch 88/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 00088: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0441 - val_accuracy: 0.9874\n",
      "Epoch 89/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9991\n",
      "Epoch 00089: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0363 - val_accuracy: 0.9912\n",
      "Epoch 90/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0025 - accuracy: 0.9990\n",
      "Epoch 00090: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.0366 - val_accuracy: 0.9929\n",
      "Epoch 91/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9984\n",
      "Epoch 00091: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 0.0622 - val_accuracy: 0.9870\n",
      "Epoch 92/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9980\n",
      "Epoch 00092: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0387 - val_accuracy: 0.9903\n",
      "Epoch 93/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 00093: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0399 - val_accuracy: 0.9916\n",
      "Epoch 94/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 00094: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0367 - val_accuracy: 0.9912\n",
      "Epoch 95/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 00095: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 43s 64ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0400 - val_accuracy: 0.9916\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "669/670 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 00096: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0473 - val_accuracy: 0.9916\n",
      "Epoch 97/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 00097: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0594 - val_accuracy: 0.9929\n",
      "Epoch 98/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 00098: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0545 - val_accuracy: 0.9908\n",
      "Epoch 99/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 00099: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0453 - val_accuracy: 0.9912\n",
      "Epoch 100/100\n",
      "669/670 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 00100: val_accuracy did not improve from 0.99412\n",
      "670/670 [==============================] - 42s 63ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0505 - val_accuracy: 0.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:36:11<00:00, 2885.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.56      0.85      0.68       480\n",
      "        car_horn       0.88      0.89      0.89       180\n",
      "children_playing       0.86      0.79      0.82       600\n",
      "        dog_bark       0.90      0.86      0.88       600\n",
      "           siren       0.78      0.51      0.61       480\n",
      "\n",
      "        accuracy                           0.77      2340\n",
      "       macro avg       0.80      0.78      0.78      2340\n",
      "    weighted avg       0.80      0.77      0.77      2340\n",
      "\n",
      "\n",
      "Validation fold: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Training set\n",
      "\n",
      "X_train.........: (21394, 180, 173, 1) ...type: <class 'numpy.float32'>\n",
      "y_train_OHEV....: (21394, 5) ............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Testing set\n",
      "\n",
      "X_test..........: (2378, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_test_OHEV.....: (2378, 5) .............type: <class 'numpy.float32'>\n",
      "\n",
      "========================================================================\n",
      "Validation set\n",
      "\n",
      "X_val...........: (2376, 180, 173, 1) ....type: <class 'numpy.float32'>\n",
      "y_OHEV_val......: (2376, 5) .............type: <class 'numpy.float32'>\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model_CNN_2D_Su\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 90, 87, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 90, 87, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 44, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 44, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 22, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 21, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 7040)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              7209984   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 7,280,869\n",
      "Trainable params: 7,280,485\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Su_19\n",
      "Epoch 1/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 1.2094 - accuracy: 0.5976\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71026, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 16s 23ms/step - loss: 1.2094 - accuracy: 0.5976 - val_loss: 0.7778 - val_accuracy: 0.7103\n",
      "Epoch 2/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.7482 - accuracy: 0.7313\n",
      "Epoch 00002: val_accuracy improved from 0.71026 to 0.77292, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.7475 - accuracy: 0.7317 - val_loss: 0.6138 - val_accuracy: 0.7729\n",
      "Epoch 3/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.6326 - accuracy: 0.7737\n",
      "Epoch 00003: val_accuracy improved from 0.77292 to 0.78553, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.6325 - accuracy: 0.7739 - val_loss: 0.6278 - val_accuracy: 0.7855\n",
      "Epoch 4/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.5575 - accuracy: 0.7983\n",
      "Epoch 00004: val_accuracy improved from 0.78553 to 0.84777, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.5575 - accuracy: 0.7984 - val_loss: 0.4146 - val_accuracy: 0.8478\n",
      "Epoch 5/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.5039 - accuracy: 0.8172\n",
      "Epoch 00005: val_accuracy did not improve from 0.84777\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.5036 - accuracy: 0.8173 - val_loss: 0.5151 - val_accuracy: 0.8188\n",
      "Epoch 6/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.4475 - accuracy: 0.8383\n",
      "Epoch 00006: val_accuracy did not improve from 0.84777\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.4475 - accuracy: 0.8383 - val_loss: 0.5588 - val_accuracy: 0.7939\n",
      "Epoch 7/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.4106 - accuracy: 0.8513\n",
      "Epoch 00007: val_accuracy improved from 0.84777 to 0.87048, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.4106 - accuracy: 0.8514 - val_loss: 0.3609 - val_accuracy: 0.8705\n",
      "Epoch 8/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.3749 - accuracy: 0.8631\n",
      "Epoch 00008: val_accuracy improved from 0.87048 to 0.89487, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.3752 - accuracy: 0.8631 - val_loss: 0.2904 - val_accuracy: 0.8949\n",
      "Epoch 9/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.3549 - accuracy: 0.8715\n",
      "Epoch 00009: val_accuracy improved from 0.89487 to 0.90959, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.3549 - accuracy: 0.8715 - val_loss: 0.2684 - val_accuracy: 0.9096\n",
      "Epoch 10/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.3240 - accuracy: 0.8855\n",
      "Epoch 00010: val_accuracy did not improve from 0.90959\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.3239 - accuracy: 0.8855 - val_loss: 0.2624 - val_accuracy: 0.9058\n",
      "Epoch 11/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.3084 - accuracy: 0.8893\n",
      "Epoch 00011: val_accuracy improved from 0.90959 to 0.91758, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.3089 - accuracy: 0.8891 - val_loss: 0.2339 - val_accuracy: 0.9176\n",
      "Epoch 12/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.8991\n",
      "Epoch 00012: val_accuracy did not improve from 0.91758\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2784 - accuracy: 0.8989 - val_loss: 0.2493 - val_accuracy: 0.9113\n",
      "Epoch 13/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.2718 - accuracy: 0.9021\n",
      "Epoch 00013: val_accuracy did not improve from 0.91758\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2719 - accuracy: 0.9020 - val_loss: 0.2351 - val_accuracy: 0.9087\n",
      "Epoch 14/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.2595 - accuracy: 0.9049\n",
      "Epoch 00014: val_accuracy improved from 0.91758 to 0.92304, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2592 - accuracy: 0.9050 - val_loss: 0.2143 - val_accuracy: 0.9230\n",
      "Epoch 15/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.2422 - accuracy: 0.9152\n",
      "Epoch 00015: val_accuracy did not improve from 0.92304\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2419 - accuracy: 0.9153 - val_loss: 0.2314 - val_accuracy: 0.9201\n",
      "Epoch 16/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.2247 - accuracy: 0.9200\n",
      "Epoch 00016: val_accuracy did not improve from 0.92304\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2245 - accuracy: 0.9201 - val_loss: 0.2338 - val_accuracy: 0.9159\n",
      "Epoch 17/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.9215\n",
      "Epoch 00017: val_accuracy improved from 0.92304 to 0.92725, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2133 - accuracy: 0.9215 - val_loss: 0.2078 - val_accuracy: 0.9272\n",
      "Epoch 18/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.2071 - accuracy: 0.9248\n",
      "Epoch 00018: val_accuracy improved from 0.92725 to 0.94954, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.2074 - accuracy: 0.9247 - val_loss: 0.1360 - val_accuracy: 0.9495\n",
      "Epoch 19/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1948 - accuracy: 0.9298\n",
      "Epoch 00019: val_accuracy improved from 0.94954 to 0.95374, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1947 - accuracy: 0.9298 - val_loss: 0.1417 - val_accuracy: 0.9537\n",
      "Epoch 20/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1819 - accuracy: 0.9333\n",
      "Epoch 00020: val_accuracy did not improve from 0.95374\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1817 - accuracy: 0.9334 - val_loss: 0.1534 - val_accuracy: 0.9487\n",
      "Epoch 21/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9381\n",
      "Epoch 00021: val_accuracy improved from 0.95374 to 0.95669, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1721 - accuracy: 0.9381 - val_loss: 0.1307 - val_accuracy: 0.9567\n",
      "Epoch 22/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1737 - accuracy: 0.9388\n",
      "Epoch 00022: val_accuracy did not improve from 0.95669\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1738 - accuracy: 0.9388 - val_loss: 0.1611 - val_accuracy: 0.9424\n",
      "Epoch 23/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1588 - accuracy: 0.9415\n",
      "Epoch 00023: val_accuracy improved from 0.95669 to 0.96678, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1587 - accuracy: 0.9416 - val_loss: 0.1064 - val_accuracy: 0.9668\n",
      "Epoch 24/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1583 - accuracy: 0.9432\n",
      "Epoch 00024: val_accuracy did not improve from 0.96678\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1582 - accuracy: 0.9432 - val_loss: 0.1040 - val_accuracy: 0.9668\n",
      "Epoch 25/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.9473\n",
      "Epoch 00025: val_accuracy did not improve from 0.96678\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1485 - accuracy: 0.9473 - val_loss: 0.1413 - val_accuracy: 0.9605\n",
      "Epoch 26/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.1457 - accuracy: 0.9475\n",
      "Epoch 00026: val_accuracy improved from 0.96678 to 0.97056, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1457 - accuracy: 0.9475 - val_loss: 0.0953 - val_accuracy: 0.9706\n",
      "Epoch 27/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1422 - accuracy: 0.9482\n",
      "Epoch 00027: val_accuracy did not improve from 0.97056\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1421 - accuracy: 0.9482 - val_loss: 0.1320 - val_accuracy: 0.9567\n",
      "Epoch 28/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1338 - accuracy: 0.9528\n",
      "Epoch 00028: val_accuracy did not improve from 0.97056\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1340 - accuracy: 0.9526 - val_loss: 0.0915 - val_accuracy: 0.9685\n",
      "Epoch 29/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1273 - accuracy: 0.9540\n",
      "Epoch 00029: val_accuracy did not improve from 0.97056\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1275 - accuracy: 0.9540 - val_loss: 0.0962 - val_accuracy: 0.9680\n",
      "Epoch 30/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1195 - accuracy: 0.9568\n",
      "Epoch 00030: val_accuracy improved from 0.97056 to 0.97098, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1197 - accuracy: 0.9568 - val_loss: 0.0898 - val_accuracy: 0.9710\n",
      "Epoch 31/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1211 - accuracy: 0.9565\n",
      "Epoch 00031: val_accuracy did not improve from 0.97098\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1210 - accuracy: 0.9565 - val_loss: 0.1420 - val_accuracy: 0.9516\n",
      "Epoch 32/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9597\n",
      "Epoch 00032: val_accuracy improved from 0.97098 to 0.97477, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1116 - accuracy: 0.9596 - val_loss: 0.0798 - val_accuracy: 0.9748\n",
      "Epoch 33/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1064 - accuracy: 0.9616\n",
      "Epoch 00033: val_accuracy did not improve from 0.97477\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1067 - accuracy: 0.9615 - val_loss: 0.0879 - val_accuracy: 0.9735\n",
      "Epoch 34/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1107 - accuracy: 0.9595\n",
      "Epoch 00034: val_accuracy did not improve from 0.97477\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.1110 - accuracy: 0.9594 - val_loss: 0.0844 - val_accuracy: 0.9739\n",
      "Epoch 35/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.1004 - accuracy: 0.9644\n",
      "Epoch 00035: val_accuracy improved from 0.97477 to 0.97687, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.1005 - accuracy: 0.9645 - val_loss: 0.0786 - val_accuracy: 0.9769\n",
      "Epoch 36/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0988 - accuracy: 0.9642\n",
      "Epoch 00036: val_accuracy improved from 0.97687 to 0.98024, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0986 - accuracy: 0.9643 - val_loss: 0.0685 - val_accuracy: 0.9802\n",
      "Epoch 37/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0975 - accuracy: 0.9648\n",
      "Epoch 00037: val_accuracy improved from 0.98024 to 0.98402, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0974 - accuracy: 0.9648 - val_loss: 0.0628 - val_accuracy: 0.9840\n",
      "Epoch 38/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0942 - accuracy: 0.9666\n",
      "Epoch 00038: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0947 - accuracy: 0.9665 - val_loss: 0.0626 - val_accuracy: 0.9790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0891 - accuracy: 0.9682\n",
      "Epoch 00039: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0892 - accuracy: 0.9681 - val_loss: 0.0660 - val_accuracy: 0.9781\n",
      "Epoch 40/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9687\n",
      "Epoch 00040: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0874 - accuracy: 0.9686 - val_loss: 0.0637 - val_accuracy: 0.9798\n",
      "Epoch 41/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9701\n",
      "Epoch 00041: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0831 - accuracy: 0.9700 - val_loss: 0.0703 - val_accuracy: 0.9769\n",
      "Epoch 42/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9697\n",
      "Epoch 00042: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0841 - accuracy: 0.9698 - val_loss: 0.0745 - val_accuracy: 0.9743\n",
      "Epoch 43/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0783 - accuracy: 0.9708\n",
      "Epoch 00043: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0783 - accuracy: 0.9708 - val_loss: 0.0773 - val_accuracy: 0.9765\n",
      "Epoch 44/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.9739\n",
      "Epoch 00044: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0735 - accuracy: 0.9739 - val_loss: 0.1009 - val_accuracy: 0.9689\n",
      "Epoch 45/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0764 - accuracy: 0.9733\n",
      "Epoch 00045: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0763 - accuracy: 0.9734 - val_loss: 0.0523 - val_accuracy: 0.9840\n",
      "Epoch 46/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9732\n",
      "Epoch 00046: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0725 - accuracy: 0.9732 - val_loss: 0.0613 - val_accuracy: 0.9823\n",
      "Epoch 47/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9757\n",
      "Epoch 00047: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0710 - accuracy: 0.9757 - val_loss: 0.0608 - val_accuracy: 0.9828\n",
      "Epoch 48/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9767\n",
      "Epoch 00048: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0683 - accuracy: 0.9766 - val_loss: 0.0626 - val_accuracy: 0.9807\n",
      "Epoch 49/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0676 - accuracy: 0.9754\n",
      "Epoch 00049: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0676 - accuracy: 0.9754 - val_loss: 0.0601 - val_accuracy: 0.9823\n",
      "Epoch 50/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9769\n",
      "Epoch 00050: val_accuracy did not improve from 0.98402\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0667 - accuracy: 0.9769 - val_loss: 0.0503 - val_accuracy: 0.9828\n",
      "Epoch 51/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9764\n",
      "Epoch 00051: val_accuracy improved from 0.98402 to 0.98528, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0656 - accuracy: 0.9764 - val_loss: 0.0475 - val_accuracy: 0.9853\n",
      "Epoch 52/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9787\n",
      "Epoch 00052: val_accuracy did not improve from 0.98528\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0619 - accuracy: 0.9787 - val_loss: 0.0550 - val_accuracy: 0.9832\n",
      "Epoch 53/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0592 - accuracy: 0.9790\n",
      "Epoch 00053: val_accuracy did not improve from 0.98528\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0592 - accuracy: 0.9790 - val_loss: 0.0567 - val_accuracy: 0.9836\n",
      "Epoch 54/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9790\n",
      "Epoch 00054: val_accuracy improved from 0.98528 to 0.98612, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0604 - accuracy: 0.9790 - val_loss: 0.0486 - val_accuracy: 0.9861\n",
      "Epoch 55/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0542 - accuracy: 0.9808\n",
      "Epoch 00055: val_accuracy improved from 0.98612 to 0.98823, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0543 - accuracy: 0.9807 - val_loss: 0.0391 - val_accuracy: 0.9882\n",
      "Epoch 56/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 0.9774\n",
      "Epoch 00056: val_accuracy did not improve from 0.98823\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0638 - accuracy: 0.9774 - val_loss: 0.0427 - val_accuracy: 0.9874\n",
      "Epoch 57/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9809\n",
      "Epoch 00057: val_accuracy did not improve from 0.98823\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0540 - accuracy: 0.9809 - val_loss: 0.0449 - val_accuracy: 0.9882\n",
      "Epoch 58/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9812\n",
      "Epoch 00058: val_accuracy did not improve from 0.98823\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0521 - accuracy: 0.9812 - val_loss: 0.0484 - val_accuracy: 0.9857\n",
      "Epoch 59/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9812\n",
      "Epoch 00059: val_accuracy improved from 0.98823 to 0.99117, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0535 - accuracy: 0.9813 - val_loss: 0.0404 - val_accuracy: 0.9912\n",
      "Epoch 60/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9823\n",
      "Epoch 00060: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0471 - accuracy: 0.9823 - val_loss: 0.0382 - val_accuracy: 0.9891\n",
      "Epoch 61/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0511 - accuracy: 0.9816\n",
      "Epoch 00061: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0510 - accuracy: 0.9817 - val_loss: 0.0406 - val_accuracy: 0.9895\n",
      "Epoch 62/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0479 - accuracy: 0.9831\n",
      "Epoch 00062: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0479 - accuracy: 0.9830 - val_loss: 0.0565 - val_accuracy: 0.9828\n",
      "Epoch 63/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0483 - accuracy: 0.9838\n",
      "Epoch 00063: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0482 - accuracy: 0.9838 - val_loss: 0.0388 - val_accuracy: 0.9882\n",
      "Epoch 64/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0443 - accuracy: 0.9850\n",
      "Epoch 00064: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0443 - accuracy: 0.9850 - val_loss: 0.0682 - val_accuracy: 0.9861\n",
      "Epoch 65/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0464 - accuracy: 0.9837\n",
      "Epoch 00065: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0463 - accuracy: 0.9838 - val_loss: 0.0535 - val_accuracy: 0.9861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0441 - accuracy: 0.9845\n",
      "Epoch 00066: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0441 - accuracy: 0.9845 - val_loss: 0.0467 - val_accuracy: 0.9886\n",
      "Epoch 67/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.9859\n",
      "Epoch 00067: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0430 - accuracy: 0.9860 - val_loss: 0.0439 - val_accuracy: 0.9895\n",
      "Epoch 68/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0443 - accuracy: 0.9847\n",
      "Epoch 00068: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0443 - accuracy: 0.9847 - val_loss: 0.0416 - val_accuracy: 0.9882\n",
      "Epoch 69/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.9849\n",
      "Epoch 00069: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0433 - accuracy: 0.9849 - val_loss: 0.0419 - val_accuracy: 0.9899\n",
      "Epoch 70/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9846\n",
      "Epoch 00070: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0442 - accuracy: 0.9846 - val_loss: 0.0434 - val_accuracy: 0.9870\n",
      "Epoch 71/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.9848\n",
      "Epoch 00071: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0423 - accuracy: 0.9848 - val_loss: 0.0441 - val_accuracy: 0.9878\n",
      "Epoch 72/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9867\n",
      "Epoch 00072: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0371 - accuracy: 0.9867 - val_loss: 0.0406 - val_accuracy: 0.9903\n",
      "Epoch 73/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0378 - accuracy: 0.9863\n",
      "Epoch 00073: val_accuracy improved from 0.99117 to 0.99201, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0379 - accuracy: 0.9863 - val_loss: 0.0393 - val_accuracy: 0.9920\n",
      "Epoch 74/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9871\n",
      "Epoch 00074: val_accuracy improved from 0.99201 to 0.99369, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Su_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0369 - accuracy: 0.9871 - val_loss: 0.0393 - val_accuracy: 0.9937\n",
      "Epoch 75/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9870\n",
      "Epoch 00075: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0375 - accuracy: 0.9870 - val_loss: 0.0412 - val_accuracy: 0.9886\n",
      "Epoch 76/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0421 - accuracy: 0.9853\n",
      "Epoch 00076: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0420 - accuracy: 0.9853 - val_loss: 0.0336 - val_accuracy: 0.9920\n",
      "Epoch 77/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0377 - accuracy: 0.9866\n",
      "Epoch 00077: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0377 - accuracy: 0.9865 - val_loss: 0.0396 - val_accuracy: 0.9916\n",
      "Epoch 78/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9872\n",
      "Epoch 00078: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0373 - accuracy: 0.9872 - val_loss: 0.0425 - val_accuracy: 0.9920\n",
      "Epoch 79/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0375 - accuracy: 0.9867\n",
      "Epoch 00079: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0374 - accuracy: 0.9867 - val_loss: 0.0450 - val_accuracy: 0.9899\n",
      "Epoch 80/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9882\n",
      "Epoch 00080: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0340 - accuracy: 0.9883 - val_loss: 0.0363 - val_accuracy: 0.9907\n",
      "Epoch 81/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0370 - accuracy: 0.9878\n",
      "Epoch 00081: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.0366 - val_accuracy: 0.9933\n",
      "Epoch 82/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0337 - accuracy: 0.9887\n",
      "Epoch 00082: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.0401 - val_accuracy: 0.9924\n",
      "Epoch 83/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0331 - accuracy: 0.9880\n",
      "Epoch 00083: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0332 - accuracy: 0.9880 - val_loss: 0.0448 - val_accuracy: 0.9895\n",
      "Epoch 84/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9881\n",
      "Epoch 00084: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0365 - accuracy: 0.9882 - val_loss: 0.0418 - val_accuracy: 0.9903\n",
      "Epoch 85/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9889\n",
      "Epoch 00085: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0322 - accuracy: 0.9890 - val_loss: 0.0385 - val_accuracy: 0.9899\n",
      "Epoch 86/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9874\n",
      "Epoch 00086: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0368 - accuracy: 0.9874 - val_loss: 0.0423 - val_accuracy: 0.9899\n",
      "Epoch 87/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9882\n",
      "Epoch 00087: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0329 - accuracy: 0.9882 - val_loss: 0.0419 - val_accuracy: 0.9912\n",
      "Epoch 88/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9892\n",
      "Epoch 00088: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0314 - accuracy: 0.9892 - val_loss: 0.0308 - val_accuracy: 0.9916\n",
      "Epoch 89/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9895\n",
      "Epoch 00089: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0313 - accuracy: 0.9895 - val_loss: 0.0373 - val_accuracy: 0.9929\n",
      "Epoch 90/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9898\n",
      "Epoch 00090: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0304 - accuracy: 0.9898 - val_loss: 0.0320 - val_accuracy: 0.9924\n",
      "Epoch 91/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9906\n",
      "Epoch 00091: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0272 - accuracy: 0.9907 - val_loss: 0.0425 - val_accuracy: 0.9895\n",
      "Epoch 92/100\n",
      "667/669 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9910\n",
      "Epoch 00092: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 22ms/step - loss: 0.0276 - accuracy: 0.9910 - val_loss: 0.0363 - val_accuracy: 0.9907\n",
      "Epoch 93/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0288 - accuracy: 0.9897\n",
      "Epoch 00093: val_accuracy did not improve from 0.99369\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0287 - accuracy: 0.9897 - val_loss: 0.0402 - val_accuracy: 0.9933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9910\n",
      "Epoch 00094: val_accuracy did not improve from 0.99369\n",
      "Restoring model weights from the end of the best epoch.\n",
      "669/669 [==============================] - 15s 23ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.0274 - val_accuracy: 0.9933\n",
      "Epoch 00094: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 1/2 [23:48<23:48, 1428.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.85      0.90      0.88       492\n",
      "        car_horn       0.90      0.99      0.94       192\n",
      "children_playing       0.90      0.89      0.89       600\n",
      "        dog_bark       0.90      0.79      0.85       600\n",
      "           siren       0.94      0.99      0.97       492\n",
      "\n",
      "        accuracy                           0.90      2376\n",
      "       macro avg       0.90      0.91      0.90      2376\n",
      "    weighted avg       0.90      0.90      0.90      2376\n",
      "\n",
      "Model: \"Model_CNN_2D_Luz\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 180, 173, 24)      624       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 180, 173, 24)      96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 90, 86, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 90, 86, 48)        28848     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 90, 86, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 45, 43, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 45, 43, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 22, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 22, 21, 48)        57648     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 22, 21, 48)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 10, 48)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 5280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                337984    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 492,389\n",
      "Trainable params: 492,053\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Model_CNN_2D_Luz_20\n",
      "Epoch 1/100\n",
      "  2/669 [..............................] - ETA: 20s - loss: 2.2094 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0211s vs `on_train_batch_end` time: 0.0404s). Check your callbacks.\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.9624 - accuracy: 0.6389\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67746, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 65ms/step - loss: 0.9624 - accuracy: 0.6389 - val_loss: 0.7859 - val_accuracy: 0.6775\n",
      "Epoch 2/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.5868 - accuracy: 0.7944\n",
      "Epoch 00002: val_accuracy did not improve from 0.67746\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.5866 - accuracy: 0.7946 - val_loss: 0.9879 - val_accuracy: 0.6514\n",
      "Epoch 3/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.4117 - accuracy: 0.8556\n",
      "Epoch 00003: val_accuracy improved from 0.67746 to 0.88015, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.4114 - accuracy: 0.8558 - val_loss: 0.3197 - val_accuracy: 0.8802\n",
      "Epoch 4/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.3180 - accuracy: 0.8921\n",
      "Epoch 00004: val_accuracy improved from 0.88015 to 0.91548, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.3183 - accuracy: 0.8921 - val_loss: 0.2445 - val_accuracy: 0.9155\n",
      "Epoch 5/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.2460 - accuracy: 0.9159\n",
      "Epoch 00005: val_accuracy did not improve from 0.91548\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.2460 - accuracy: 0.9160 - val_loss: 0.4059 - val_accuracy: 0.8629\n",
      "Epoch 6/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.2231 - accuracy: 0.9216\n",
      "Epoch 00006: val_accuracy improved from 0.91548 to 0.94029, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.2230 - accuracy: 0.9217 - val_loss: 0.1751 - val_accuracy: 0.9403\n",
      "Epoch 7/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.1738 - accuracy: 0.9414\n",
      "Epoch 00007: val_accuracy improved from 0.94029 to 0.94491, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.1739 - accuracy: 0.9413 - val_loss: 0.1510 - val_accuracy: 0.9449\n",
      "Epoch 8/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9499\n",
      "Epoch 00008: val_accuracy improved from 0.94491 to 0.96720, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 65ms/step - loss: 0.1467 - accuracy: 0.9499 - val_loss: 0.1035 - val_accuracy: 0.9672\n",
      "Epoch 9/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.1151 - accuracy: 0.9602\n",
      "Epoch 00009: val_accuracy did not improve from 0.96720\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.1150 - accuracy: 0.9603 - val_loss: 0.2588 - val_accuracy: 0.9066\n",
      "Epoch 10/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.1106 - accuracy: 0.9604\n",
      "Epoch 00010: val_accuracy did not improve from 0.96720\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.1106 - accuracy: 0.9605 - val_loss: 0.1616 - val_accuracy: 0.9437\n",
      "Epoch 11/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0853 - accuracy: 0.9707\n",
      "Epoch 00011: val_accuracy improved from 0.96720 to 0.97225, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0853 - accuracy: 0.9707 - val_loss: 0.0939 - val_accuracy: 0.9722\n",
      "Epoch 12/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9702\n",
      "Epoch 00012: val_accuracy did not improve from 0.97225\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0870 - accuracy: 0.9703 - val_loss: 0.0956 - val_accuracy: 0.9693\n",
      "Epoch 13/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0739 - accuracy: 0.9745\n",
      "Epoch 00013: val_accuracy improved from 0.97225 to 0.97393, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0739 - accuracy: 0.9745 - val_loss: 0.0831 - val_accuracy: 0.9739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0658 - accuracy: 0.9772\n",
      "Epoch 00014: val_accuracy did not improve from 0.97393\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0657 - accuracy: 0.9772 - val_loss: 0.1284 - val_accuracy: 0.9546\n",
      "Epoch 15/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9834\n",
      "Epoch 00015: val_accuracy improved from 0.97393 to 0.98066, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0493 - accuracy: 0.9835 - val_loss: 0.0597 - val_accuracy: 0.9807\n",
      "Epoch 16/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.9859\n",
      "Epoch 00016: val_accuracy improved from 0.98066 to 0.98486, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0431 - accuracy: 0.9859 - val_loss: 0.0468 - val_accuracy: 0.9849\n",
      "Epoch 17/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.9835\n",
      "Epoch 00017: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0499 - accuracy: 0.9835 - val_loss: 0.0604 - val_accuracy: 0.9798\n",
      "Epoch 18/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0398 - accuracy: 0.9865\n",
      "Epoch 00018: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0398 - accuracy: 0.9865 - val_loss: 0.1045 - val_accuracy: 0.9689\n",
      "Epoch 19/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0446 - accuracy: 0.9864\n",
      "Epoch 00019: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0446 - accuracy: 0.9864 - val_loss: 0.1193 - val_accuracy: 0.9638\n",
      "Epoch 20/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9872\n",
      "Epoch 00020: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 49s 73ms/step - loss: 0.0375 - accuracy: 0.9872 - val_loss: 0.0770 - val_accuracy: 0.9790\n",
      "Epoch 21/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9878\n",
      "Epoch 00021: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0371 - accuracy: 0.9878 - val_loss: 0.1340 - val_accuracy: 0.9630\n",
      "Epoch 22/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9931\n",
      "Epoch 00022: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.1028 - val_accuracy: 0.9718\n",
      "Epoch 23/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9898\n",
      "Epoch 00023: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 45s 67ms/step - loss: 0.0311 - accuracy: 0.9899 - val_loss: 0.0721 - val_accuracy: 0.9794\n",
      "Epoch 24/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9902\n",
      "Epoch 00024: val_accuracy did not improve from 0.98486\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0276 - accuracy: 0.9902 - val_loss: 0.1003 - val_accuracy: 0.9756\n",
      "Epoch 25/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9930\n",
      "Epoch 00025: val_accuracy improved from 0.98486 to 0.98528, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0222 - accuracy: 0.9930 - val_loss: 0.0627 - val_accuracy: 0.9853\n",
      "Epoch 26/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9935\n",
      "Epoch 00026: val_accuracy did not improve from 0.98528\n",
      "669/669 [==============================] - 42s 64ms/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.0676 - val_accuracy: 0.9815\n",
      "Epoch 27/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9943\n",
      "Epoch 00027: val_accuracy did not improve from 0.98528\n",
      "669/669 [==============================] - 46s 69ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.0987 - val_accuracy: 0.9731\n",
      "Epoch 28/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9956\n",
      "Epoch 00028: val_accuracy did not improve from 0.98528\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.0915 - val_accuracy: 0.9773\n",
      "Epoch 29/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9933\n",
      "Epoch 00029: val_accuracy improved from 0.98528 to 0.98654, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.0566 - val_accuracy: 0.9865\n",
      "Epoch 30/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9929\n",
      "Epoch 00030: val_accuracy did not improve from 0.98654\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 0.0611 - val_accuracy: 0.9853\n",
      "Epoch 31/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9950\n",
      "Epoch 00031: val_accuracy improved from 0.98654 to 0.98780, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.0593 - val_accuracy: 0.9878\n",
      "Epoch 32/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9945\n",
      "Epoch 00032: val_accuracy improved from 0.98780 to 0.98865, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0187 - accuracy: 0.9945 - val_loss: 0.0462 - val_accuracy: 0.9886\n",
      "Epoch 33/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9944\n",
      "Epoch 00033: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0572 - val_accuracy: 0.9828\n",
      "Epoch 34/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9948\n",
      "Epoch 00034: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.0629 - val_accuracy: 0.9853\n",
      "Epoch 35/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0088 - accuracy: 0.9970\n",
      "Epoch 00035: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 0.0564 - val_accuracy: 0.9878\n",
      "Epoch 36/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9958\n",
      "Epoch 00036: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 52s 78ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 0.1218 - val_accuracy: 0.9710\n",
      "Epoch 37/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9959\n",
      "Epoch 00037: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 55s 83ms/step - loss: 0.0135 - accuracy: 0.9959 - val_loss: 0.0686 - val_accuracy: 0.9849\n",
      "Epoch 38/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 0.9966\n",
      "Epoch 00038: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 67s 99ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.0495 - val_accuracy: 0.9886\n",
      "Epoch 39/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9978\n",
      "Epoch 00039: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 0.0609 - val_accuracy: 0.9853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9968\n",
      "Epoch 00040: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.0613 - val_accuracy: 0.9853\n",
      "Epoch 41/100\n",
      "669/669 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9977\n",
      "Epoch 00041: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 45s 67ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 0.0554 - val_accuracy: 0.9870\n",
      "Epoch 42/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00042: val_accuracy did not improve from 0.98865\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0785 - val_accuracy: 0.9840\n",
      "Epoch 43/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9978\n",
      "Epoch 00043: val_accuracy improved from 0.98865 to 0.98907, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0480 - val_accuracy: 0.9891\n",
      "Epoch 44/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9959\n",
      "Epoch 00044: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 47s 70ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.1452 - val_accuracy: 0.9676\n",
      "Epoch 45/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9966\n",
      "Epoch 00045: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0673 - val_accuracy: 0.9878\n",
      "Epoch 46/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9973\n",
      "Epoch 00046: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.0601 - val_accuracy: 0.9857\n",
      "Epoch 47/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9983\n",
      "Epoch 00047: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.2932 - val_accuracy: 0.9487\n",
      "Epoch 48/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 00048: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0539 - val_accuracy: 0.9874\n",
      "Epoch 49/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 00049: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0643 - val_accuracy: 0.9865\n",
      "Epoch 50/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9978\n",
      "Epoch 00050: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 44s 65ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0788 - val_accuracy: 0.9857\n",
      "Epoch 51/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9979\n",
      "Epoch 00051: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.0677 - val_accuracy: 0.9861\n",
      "Epoch 52/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9969\n",
      "Epoch 00052: val_accuracy did not improve from 0.98907\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0715 - val_accuracy: 0.9849\n",
      "Epoch 53/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9967\n",
      "Epoch 00053: val_accuracy improved from 0.98907 to 0.98949, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0632 - val_accuracy: 0.9895\n",
      "Epoch 54/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9984\n",
      "Epoch 00054: val_accuracy did not improve from 0.98949\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.0638 - val_accuracy: 0.9853\n",
      "Epoch 55/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0105 - accuracy: 0.9971\n",
      "Epoch 00055: val_accuracy did not improve from 0.98949\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0906 - val_accuracy: 0.9769\n",
      "Epoch 56/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 00056: val_accuracy did not improve from 0.98949\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0659 - val_accuracy: 0.9870\n",
      "Epoch 57/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9985\n",
      "Epoch 00057: val_accuracy improved from 0.98949 to 0.99117, saving model to C:\\Andre_Florentino\\03_particular\\04_mestrado-FEI\\97_master\\US8K_AV_saved_models\\Model_CNN_2D_Luz_weights_0_best_augmented.hdf5\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0435 - val_accuracy: 0.9912\n",
      "Epoch 58/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 00058: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0568 - val_accuracy: 0.9874\n",
      "Epoch 59/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9982\n",
      "Epoch 00059: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0737 - val_accuracy: 0.9870\n",
      "Epoch 60/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982\n",
      "Epoch 00060: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0698 - val_accuracy: 0.9865\n",
      "Epoch 61/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9978\n",
      "Epoch 00061: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.0646 - val_accuracy: 0.9878\n",
      "Epoch 62/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 00062: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0679 - val_accuracy: 0.9886\n",
      "Epoch 63/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9981\n",
      "Epoch 00063: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.0863 - val_accuracy: 0.9828\n",
      "Epoch 64/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0047 - accuracy: 0.9984\n",
      "Epoch 00064: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 0.0589 - val_accuracy: 0.9874\n",
      "Epoch 65/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9972\n",
      "Epoch 00065: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 0.0601 - val_accuracy: 0.9874\n",
      "Epoch 66/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0083 - accuracy: 0.9973\n",
      "Epoch 00066: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 43s 64ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0701 - val_accuracy: 0.9836\n",
      "Epoch 67/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 00067: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.0672 - val_accuracy: 0.9865\n",
      "Epoch 68/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9979\n",
      "Epoch 00068: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0536 - val_accuracy: 0.9886\n",
      "Epoch 69/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 00069: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0552 - val_accuracy: 0.9886\n",
      "Epoch 70/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\n",
      "Epoch 00070: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0550 - val_accuracy: 0.9891\n",
      "Epoch 71/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 00071: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0463 - val_accuracy: 0.9912\n",
      "Epoch 72/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 00072: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0638 - val_accuracy: 0.9878\n",
      "Epoch 73/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 00073: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0799 - val_accuracy: 0.9874\n",
      "Epoch 74/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9988\n",
      "Epoch 00074: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0603 - val_accuracy: 0.9899\n",
      "Epoch 75/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 00075: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0730 - val_accuracy: 0.9874\n",
      "Epoch 76/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9988\n",
      "Epoch 00076: val_accuracy did not improve from 0.99117\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.0637 - val_accuracy: 0.9874\n",
      "Epoch 77/100\n",
      "668/669 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 00077: val_accuracy did not improve from 0.99117\n",
      "Restoring model weights from the end of the best epoch.\n",
      "669/669 [==============================] - 42s 63ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0530 - val_accuracy: 0.9903\n",
      "Epoch 00077: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 2/2 [1:19:46<00:00, 2393.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      background       0.86      0.92      0.89       492\n",
      "        car_horn       0.87      0.97      0.91       192\n",
      "children_playing       0.87      0.88      0.88       600\n",
      "        dog_bark       0.88      0.78      0.83       600\n",
      "           siren       0.98      0.98      0.98       492\n",
      "\n",
      "        accuracy                           0.89      2376\n",
      "       macro avg       0.89      0.91      0.90      2376\n",
      "    weighted avg       0.89      0.89      0.89      2376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "metrics_set, models_set  = model_classifiers(classifiers, DB_from_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy(Train)</th>\n",
       "      <th>Accuracy(Val)</th>\n",
       "      <th>F1(Train)</th>\n",
       "      <th>F1(Val)</th>\n",
       "      <th>...</th>\n",
       "      <th>Precision(Val)</th>\n",
       "      <th>Recall(Train)</th>\n",
       "      <th>Recall(Val)</th>\n",
       "      <th>Conf_M</th>\n",
       "      <th>Process_time</th>\n",
       "      <th>Class_report(Val)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.872025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877201</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>[[555, 17, 31, 19, 26], [18, 198, 0, 0, 0], [11, 0, 543, 46, 0], [0, 0, 74, 517, 9], [20, 0, 60, 2, 434]]</td>\n",
       "      <td>1140.625</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.92      0.86      0.89       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>[[560, 2, 24, 46, 16], [33, 183, 0, 0, 0], [15, 0, 558, 25, 2], [4, 0, 18, 570, 8], [20, 0, 51, 2, 443]]</td>\n",
       "      <td>2156.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.89      0.86      0.87       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.803807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>[[562, 23, 13, 3, 17], [13, 185, 0, 0, 0], [22, 0, 539, 34, 5], [43, 5, 73, 472, 7], [26, 1, 91, 103, 277]]</td>\n",
       "      <td>1171.875</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.84      0.91      0.88       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.842998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854174</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>[[543, 24, 25, 12, 14], [9, 189, 0, 0, 0], [17, 5, 543, 28, 7], [28, 3, 23, 534, 12], [13, 5, 15, 149, 316]]</td>\n",
       "      <td>2312.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.89      0.88      0.88       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>[[531, 3, 25, 10, 7], [41, 202, 2, 6, 1], [53, 0, 536, 5, 6], [28, 13, 9, 545, 5], [32, 0, 47, 35, 432]]</td>\n",
       "      <td>1187.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.78      0.92      0.84       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>[[504, 19, 41, 12, 0], [9, 196, 34, 13, 0], [17, 0, 571, 11, 1], [10, 7, 12, 570, 1], [12, 12, 28, 9, 485]]</td>\n",
       "      <td>1859.375</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.91      0.88      0.89       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.856747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864665</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>[[609, 51, 37, 7, 16], [0, 257, 0, 1, 0], [17, 3, 531, 47, 2], [53, 9, 24, 501, 13], [113, 18, 3, 3, 577]]</td>\n",
       "      <td>781.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.77      0.85      0.81       7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>[[656, 17, 29, 6, 12], [3, 253, 0, 2, 0], [39, 0, 504, 57, 0], [36, 0, 14, 550, 0], [84, 3, 7, 1, 619]]</td>\n",
       "      <td>1750.000</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.80      0.91      0.85       7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.832186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841149</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>[[587, 18, 41, 9, 29], [102, 246, 2, 0, 4], [75, 0, 456, 58, 11], [6, 0, 57, 530, 7], [42, 0, 72, 15, 867]]</td>\n",
       "      <td>1218.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.86      0.78       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861982</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>[[601, 8, 30, 13, 32], [110, 231, 5, 5, 3], [73, 0, 471, 49, 7], [22, 0, 34, 536, 8], [27, 0, 43, 12, 914]]</td>\n",
       "      <td>2562.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.88      0.79       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.865765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875693</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>[[560, 2, 9, 21, 2], [56, 520, 6, 0, 6], [78, 0, 500, 21, 1], [35, 0, 80, 485, 0], [28, 15, 2, 20, 361]]</td>\n",
       "      <td>953.125</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.74      0.94      0.83       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>[[548, 3, 5, 35, 3], [63, 523, 1, 0, 1], [112, 0, 466, 16, 6], [27, 0, 48, 522, 3], [6, 13, 4, 21, 382]]</td>\n",
       "      <td>2593.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.92      0.81       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.855425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857062</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>[[456, 32, 33, 22, 45], [11, 147, 4, 3, 3], [20, 1, 567, 11, 1], [7, 5, 29, 554, 5], [76, 8, 19, 9, 332]]</td>\n",
       "      <td>828.125</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.80      0.78      0.79       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>[[488, 20, 24, 28, 28], [21, 145, 1, 1, 0], [30, 1, 553, 16, 0], [3, 0, 18, 575, 4], [64, 1, 7, 11, 361]]</td>\n",
       "      <td>1687.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.81      0.83      0.82       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838288</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>[[472, 6, 47, 53, 22], [22, 136, 3, 3, 4], [27, 0, 546, 14, 13], [17, 8, 26, 527, 22], [77, 18, 11, 1, 355]]</td>\n",
       "      <td>984.375</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.77      0.79      0.78       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>0.999437</td>\n",
       "      <td>0.857198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858832</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>[[501, 6, 25, 54, 14], [17, 140, 4, 4, 3], [36, 0, 545, 7, 12], [8, 5, 24, 539, 24], [83, 12, 5, 4, 358]]</td>\n",
       "      <td>1718.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.78      0.83      0.80       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.753047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795096</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>[[420, 8, 22, 8, 22], [13, 156, 11, 0, 0], [165, 0, 404, 3, 28], [30, 17, 41, 484, 28], [192, 0, 9, 0, 279]]</td>\n",
       "      <td>875.000</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.51      0.88      0.65       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>[[408, 1, 26, 23, 22], [11, 161, 8, 0, 0], [70, 6, 471, 33, 20], [4, 15, 38, 517, 26], [232, 0, 3, 2, 243]]</td>\n",
       "      <td>1906.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.56      0.85      0.68       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.896910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898546</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>[[445, 7, 24, 5, 11], [0, 191, 0, 1, 0], [17, 0, 534, 43, 6], [62, 15, 35, 476, 12], [0, 0, 3, 1, 488]]</td>\n",
       "      <td>968.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.85      0.90      0.88       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>[[453, 11, 14, 8, 6], [2, 186, 0, 2, 2], [11, 1, 530, 55, 3], [52, 17, 62, 468, 1], [7, 0, 1, 0, 484]]</td>\n",
       "      <td>1781.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.86      0.92      0.89       4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Fold  Accuracy(Train)  Accuracy(Val)  F1(Train)   F1(Val)  ...  Precision(Val)  Recall(Train)  Recall(Val)                                                                                                        Conf_M Process_time  \\\n",
       "0    Model_CNN_2D_Su    1         0.998774       0.870930   0.998775  0.872025  ...        0.877201       0.998774     0.870930     [[555, 17, 31, 19, 26], [18, 198, 0, 0, 0], [11, 0, 543, 46, 0], [0, 0, 74, 517, 9], [20, 0, 60, 2, 434]]     1140.625   \n",
       "1   Model_CNN_2D_Luz    1         1.000000       0.896899   1.000000  0.896829  ...        0.899769       1.000000     0.896899      [[560, 2, 24, 46, 16], [33, 183, 0, 0, 0], [15, 0, 558, 25, 2], [4, 0, 18, 570, 8], [20, 0, 51, 2, 443]]     2156.250   \n",
       "2    Model_CNN_2D_Su   10         0.999953       0.809467   0.999953  0.803807  ...        0.818571       0.999953     0.809467   [[562, 23, 13, 3, 17], [13, 185, 0, 0, 0], [22, 0, 539, 34, 5], [43, 5, 73, 472, 7], [26, 1, 91, 103, 277]]     1171.875   \n",
       "3   Model_CNN_2D_Luz   10         0.999953       0.845267   0.999953  0.842998  ...        0.854174       0.999953     0.845267  [[543, 24, 25, 12, 14], [9, 189, 0, 0, 0], [17, 5, 543, 28, 7], [28, 3, 23, 534, 12], [13, 5, 15, 149, 316]]     2312.500   \n",
       "4    Model_CNN_2D_Su    2         1.000000       0.872572   1.000000  0.872987  ...        0.880594       1.000000     0.872572      [[531, 3, 25, 10, 7], [41, 202, 2, 6, 1], [53, 0, 536, 5, 6], [28, 13, 9, 545, 5], [32, 0, 47, 35, 432]]     1187.500   \n",
       "5   Model_CNN_2D_Luz    2         1.000000       0.903652   1.000000  0.903831  ...        0.907639       1.000000     0.903652   [[504, 19, 41, 12, 0], [9, 196, 34, 13, 0], [17, 0, 571, 11, 1], [10, 7, 12, 570, 1], [12, 12, 28, 9, 485]]     1859.375   \n",
       "6    Model_CNN_2D_Su    3         0.999952       0.855809   0.999952  0.856747  ...        0.864665       0.999952     0.855809    [[609, 51, 37, 7, 16], [0, 257, 0, 1, 0], [17, 3, 531, 47, 2], [53, 9, 24, 501, 13], [113, 18, 3, 3, 577]]      781.250   \n",
       "7   Model_CNN_2D_Luz    3         1.000000       0.892808   1.000000  0.893536  ...        0.898510       1.000000     0.892808       [[656, 17, 29, 6, 12], [3, 253, 0, 2, 0], [39, 0, 504, 57, 0], [36, 0, 14, 550, 0], [84, 3, 7, 1, 619]]     1750.000   \n",
       "8    Model_CNN_2D_Su    4         0.999612       0.830550   0.999612  0.832186  ...        0.841149       0.999612     0.830550   [[587, 18, 41, 9, 29], [102, 246, 2, 0, 4], [75, 0, 456, 58, 11], [6, 0, 57, 530, 7], [42, 0, 72, 15, 867]]     1218.750   \n",
       "9   Model_CNN_2D_Luz    4         0.999903       0.851268   0.999903  0.851528  ...        0.861982       0.999903     0.851268   [[601, 8, 30, 13, 32], [110, 231, 5, 5, 3], [73, 0, 471, 49, 7], [22, 0, 34, 536, 8], [27, 0, 43, 12, 914]]     2562.500   \n",
       "10   Model_CNN_2D_Su    5         0.999381       0.863960   0.999381  0.865765  ...        0.875693       0.999381     0.863960      [[560, 2, 9, 21, 2], [56, 520, 6, 0, 6], [78, 0, 500, 21, 1], [35, 0, 80, 485, 0], [28, 15, 2, 20, 361]]      953.125   \n",
       "11  Model_CNN_2D_Luz    5         1.000000       0.869302   1.000000  0.871273  ...        0.881039       1.000000     0.869302      [[548, 3, 5, 35, 3], [63, 523, 1, 0, 1], [112, 0, 466, 16, 6], [27, 0, 48, 522, 3], [6, 13, 4, 21, 382]]     2593.750   \n",
       "12   Model_CNN_2D_Su    6         0.999298       0.856667   0.999298  0.855425  ...        0.857062       0.999298     0.856667     [[456, 32, 33, 22, 45], [11, 147, 4, 3, 3], [20, 1, 567, 11, 1], [7, 5, 29, 554, 5], [76, 8, 19, 9, 332]]      828.125   \n",
       "13  Model_CNN_2D_Luz    6         1.000000       0.884167   1.000000  0.883839  ...        0.885092       1.000000     0.884167     [[488, 20, 24, 28, 28], [21, 145, 1, 1, 0], [30, 1, 553, 16, 0], [3, 0, 18, 575, 4], [64, 1, 7, 11, 361]]     1687.500   \n",
       "14   Model_CNN_2D_Su    7         0.999438       0.837860   0.999438  0.837464  ...        0.838288       0.999438     0.837860  [[472, 6, 47, 53, 22], [22, 136, 3, 3, 4], [27, 0, 546, 14, 13], [17, 8, 26, 527, 22], [77, 18, 11, 1, 355]]      984.375   \n",
       "15  Model_CNN_2D_Luz    7         0.999438       0.857202   0.999437  0.857198  ...        0.858832       0.999438     0.857202     [[501, 6, 25, 54, 14], [17, 140, 4, 4, 3], [36, 0, 545, 7, 12], [8, 5, 24, 539, 24], [83, 12, 5, 4, 358]]     1718.750   \n",
       "16   Model_CNN_2D_Su    8         0.999487       0.744872   0.999487  0.753047  ...        0.795096       0.999487     0.744872  [[420, 8, 22, 8, 22], [13, 156, 11, 0, 0], [165, 0, 404, 3, 28], [30, 17, 41, 484, 28], [192, 0, 9, 0, 279]]      875.000   \n",
       "17  Model_CNN_2D_Luz    8         1.000000       0.769231   1.000000  0.769584  ...        0.795126       1.000000     0.769231   [[408, 1, 26, 23, 22], [11, 161, 8, 0, 0], [70, 6, 471, 33, 20], [4, 15, 38, 517, 26], [232, 0, 3, 2, 243]]     1906.250   \n",
       "18   Model_CNN_2D_Su    9         0.999860       0.898148   0.999860  0.896910  ...        0.898546       0.999860     0.898148       [[445, 7, 24, 5, 11], [0, 191, 0, 1, 0], [17, 0, 534, 43, 6], [62, 15, 35, 476, 12], [0, 0, 3, 1, 488]]      968.750   \n",
       "19  Model_CNN_2D_Luz    9         1.000000       0.892677   1.000000  0.891596  ...        0.892863       1.000000     0.892677        [[453, 11, 14, 8, 6], [2, 186, 0, 2, 2], [11, 1, 530, 55, 3], [52, 17, 62, 468, 1], [7, 0, 1, 0, 484]]     1781.250   \n",
       "\n",
       "                                                                                                          Class_report(Val)  \n",
       "0                     precision    recall  f1-score   support\\n\\n      background       0.92      0.86      0.89       6...  \n",
       "1                     precision    recall  f1-score   support\\n\\n      background       0.89      0.86      0.87       6...  \n",
       "2                     precision    recall  f1-score   support\\n\\n      background       0.84      0.91      0.88       6...  \n",
       "3                     precision    recall  f1-score   support\\n\\n      background       0.89      0.88      0.88       6...  \n",
       "4                     precision    recall  f1-score   support\\n\\n      background       0.78      0.92      0.84       5...  \n",
       "5                     precision    recall  f1-score   support\\n\\n      background       0.91      0.88      0.89       5...  \n",
       "6                     precision    recall  f1-score   support\\n\\n      background       0.77      0.85      0.81       7...  \n",
       "7                     precision    recall  f1-score   support\\n\\n      background       0.80      0.91      0.85       7...  \n",
       "8                     precision    recall  f1-score   support\\n\\n      background       0.72      0.86      0.78       6...  \n",
       "9                     precision    recall  f1-score   support\\n\\n      background       0.72      0.88      0.79       6...  \n",
       "10                    precision    recall  f1-score   support\\n\\n      background       0.74      0.94      0.83       5...  \n",
       "11                    precision    recall  f1-score   support\\n\\n      background       0.72      0.92      0.81       5...  \n",
       "12                    precision    recall  f1-score   support\\n\\n      background       0.80      0.78      0.79       5...  \n",
       "13                    precision    recall  f1-score   support\\n\\n      background       0.81      0.83      0.82       5...  \n",
       "14                    precision    recall  f1-score   support\\n\\n      background       0.77      0.79      0.78       6...  \n",
       "15                    precision    recall  f1-score   support\\n\\n      background       0.78      0.83      0.80       6...  \n",
       "16                    precision    recall  f1-score   support\\n\\n      background       0.51      0.88      0.65       4...  \n",
       "17                    precision    recall  f1-score   support\\n\\n      background       0.56      0.85      0.68       4...  \n",
       "18                    precision    recall  f1-score   support\\n\\n      background       0.85      0.90      0.88       4...  \n",
       "19                    precision    recall  f1-score   support\\n\\n      background       0.86      0.92      0.89       4...  \n",
       "\n",
       "[20 rows x 13 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy(Train)</th>\n",
       "      <th>Accuracy(Val)</th>\n",
       "      <th>F1(Train)</th>\n",
       "      <th>...</th>\n",
       "      <th>Precision(Val)</th>\n",
       "      <th>Recall(Train)</th>\n",
       "      <th>Recall(Val)</th>\n",
       "      <th>Conf_M</th>\n",
       "      <th>Process_time</th>\n",
       "      <th>Class_report(Val)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>[[408, 1, 26, 23, 22], [11, 161, 8, 0, 0], [70, 6, 471, 33, 20], [4, 15, 38, 517, 26], [232, 0, 3, 2, 243]]</td>\n",
       "      <td>1906.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.56      0.85      0.68       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854174</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>[[543, 24, 25, 12, 14], [9, 189, 0, 0, 0], [17, 5, 543, 28, 7], [28, 3, 23, 534, 12], [13, 5, 15, 149, 316]]</td>\n",
       "      <td>2312.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.89      0.88      0.88       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861982</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>[[601, 8, 30, 13, 32], [110, 231, 5, 5, 3], [73, 0, 471, 49, 7], [22, 0, 34, 536, 8], [27, 0, 43, 12, 914]]</td>\n",
       "      <td>2562.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.88      0.79       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>0.999437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858832</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>[[501, 6, 25, 54, 14], [17, 140, 4, 4, 3], [36, 0, 545, 7, 12], [8, 5, 24, 539, 24], [83, 12, 5, 4, 358]]</td>\n",
       "      <td>1718.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.78      0.83      0.80       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>[[548, 3, 5, 35, 3], [63, 523, 1, 0, 1], [112, 0, 466, 16, 6], [27, 0, 48, 522, 3], [6, 13, 4, 21, 382]]</td>\n",
       "      <td>2593.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.92      0.81       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>[[488, 20, 24, 28, 28], [21, 145, 1, 1, 0], [30, 1, 553, 16, 0], [3, 0, 18, 575, 4], [64, 1, 7, 11, 361]]</td>\n",
       "      <td>1687.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.81      0.83      0.82       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>[[453, 11, 14, 8, 6], [2, 186, 0, 2, 2], [11, 1, 530, 55, 3], [52, 17, 62, 468, 1], [7, 0, 1, 0, 484]]</td>\n",
       "      <td>1781.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.86      0.92      0.89       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>[[656, 17, 29, 6, 12], [3, 253, 0, 2, 0], [39, 0, 504, 57, 0], [36, 0, 14, 550, 0], [84, 3, 7, 1, 619]]</td>\n",
       "      <td>1750.000</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.80      0.91      0.85       7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>[[560, 2, 24, 46, 16], [33, 183, 0, 0, 0], [15, 0, 558, 25, 2], [4, 0, 18, 570, 8], [20, 0, 51, 2, 443]]</td>\n",
       "      <td>2156.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.89      0.86      0.87       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>[[504, 19, 41, 12, 0], [9, 196, 34, 13, 0], [17, 0, 571, 11, 1], [10, 7, 12, 570, 1], [12, 12, 28, 9, 485]]</td>\n",
       "      <td>1859.375</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.91      0.88      0.89       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795096</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>[[420, 8, 22, 8, 22], [13, 156, 11, 0, 0], [165, 0, 404, 3, 28], [30, 17, 41, 484, 28], [192, 0, 9, 0, 279]]</td>\n",
       "      <td>875.000</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.51      0.88      0.65       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>[[562, 23, 13, 3, 17], [13, 185, 0, 0, 0], [22, 0, 539, 34, 5], [43, 5, 73, 472, 7], [26, 1, 91, 103, 277]]</td>\n",
       "      <td>1171.875</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.84      0.91      0.88       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841149</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>[[587, 18, 41, 9, 29], [102, 246, 2, 0, 4], [75, 0, 456, 58, 11], [6, 0, 57, 530, 7], [42, 0, 72, 15, 867]]</td>\n",
       "      <td>1218.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.86      0.78       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838288</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>[[472, 6, 47, 53, 22], [22, 136, 3, 3, 4], [27, 0, 546, 14, 13], [17, 8, 26, 527, 22], [77, 18, 11, 1, 355]]</td>\n",
       "      <td>984.375</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.77      0.79      0.78       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864665</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>[[609, 51, 37, 7, 16], [0, 257, 0, 1, 0], [17, 3, 531, 47, 2], [53, 9, 24, 501, 13], [113, 18, 3, 3, 577]]</td>\n",
       "      <td>781.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.77      0.85      0.81       7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857062</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>[[456, 32, 33, 22, 45], [11, 147, 4, 3, 3], [20, 1, 567, 11, 1], [7, 5, 29, 554, 5], [76, 8, 19, 9, 332]]</td>\n",
       "      <td>828.125</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.80      0.78      0.79       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875693</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>[[560, 2, 9, 21, 2], [56, 520, 6, 0, 6], [78, 0, 500, 21, 1], [35, 0, 80, 485, 0], [28, 15, 2, 20, 361]]</td>\n",
       "      <td>953.125</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.74      0.94      0.83       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877201</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>[[555, 17, 31, 19, 26], [18, 198, 0, 0, 0], [11, 0, 543, 46, 0], [0, 0, 74, 517, 9], [20, 0, 60, 2, 434]]</td>\n",
       "      <td>1140.625</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.92      0.86      0.89       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>[[531, 3, 25, 10, 7], [41, 202, 2, 6, 1], [53, 0, 536, 5, 6], [28, 13, 9, 545, 5], [32, 0, 47, 35, 432]]</td>\n",
       "      <td>1187.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.78      0.92      0.84       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898546</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>[[445, 7, 24, 5, 11], [0, 191, 0, 1, 0], [17, 0, 534, 43, 6], [62, 15, 35, 476, 12], [0, 0, 3, 1, 488]]</td>\n",
       "      <td>968.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.85      0.90      0.88       4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index             Model Fold  Accuracy(Train)  Accuracy(Val)  F1(Train)  ...  Precision(Val)  Recall(Train)  Recall(Val)                                                                                                        Conf_M  Process_time  \\\n",
       "0      17  Model_CNN_2D_Luz    8         1.000000       0.769231   1.000000  ...        0.795126       1.000000     0.769231   [[408, 1, 26, 23, 22], [11, 161, 8, 0, 0], [70, 6, 471, 33, 20], [4, 15, 38, 517, 26], [232, 0, 3, 2, 243]]      1906.250   \n",
       "1       3  Model_CNN_2D_Luz   10         0.999953       0.845267   0.999953  ...        0.854174       0.999953     0.845267  [[543, 24, 25, 12, 14], [9, 189, 0, 0, 0], [17, 5, 543, 28, 7], [28, 3, 23, 534, 12], [13, 5, 15, 149, 316]]      2312.500   \n",
       "2       9  Model_CNN_2D_Luz    4         0.999903       0.851268   0.999903  ...        0.861982       0.999903     0.851268   [[601, 8, 30, 13, 32], [110, 231, 5, 5, 3], [73, 0, 471, 49, 7], [22, 0, 34, 536, 8], [27, 0, 43, 12, 914]]      2562.500   \n",
       "3      15  Model_CNN_2D_Luz    7         0.999438       0.857202   0.999437  ...        0.858832       0.999438     0.857202     [[501, 6, 25, 54, 14], [17, 140, 4, 4, 3], [36, 0, 545, 7, 12], [8, 5, 24, 539, 24], [83, 12, 5, 4, 358]]      1718.750   \n",
       "4      11  Model_CNN_2D_Luz    5         1.000000       0.869302   1.000000  ...        0.881039       1.000000     0.869302      [[548, 3, 5, 35, 3], [63, 523, 1, 0, 1], [112, 0, 466, 16, 6], [27, 0, 48, 522, 3], [6, 13, 4, 21, 382]]      2593.750   \n",
       "5      13  Model_CNN_2D_Luz    6         1.000000       0.884167   1.000000  ...        0.885092       1.000000     0.884167     [[488, 20, 24, 28, 28], [21, 145, 1, 1, 0], [30, 1, 553, 16, 0], [3, 0, 18, 575, 4], [64, 1, 7, 11, 361]]      1687.500   \n",
       "6      19  Model_CNN_2D_Luz    9         1.000000       0.892677   1.000000  ...        0.892863       1.000000     0.892677        [[453, 11, 14, 8, 6], [2, 186, 0, 2, 2], [11, 1, 530, 55, 3], [52, 17, 62, 468, 1], [7, 0, 1, 0, 484]]      1781.250   \n",
       "7       7  Model_CNN_2D_Luz    3         1.000000       0.892808   1.000000  ...        0.898510       1.000000     0.892808       [[656, 17, 29, 6, 12], [3, 253, 0, 2, 0], [39, 0, 504, 57, 0], [36, 0, 14, 550, 0], [84, 3, 7, 1, 619]]      1750.000   \n",
       "8       1  Model_CNN_2D_Luz    1         1.000000       0.896899   1.000000  ...        0.899769       1.000000     0.896899      [[560, 2, 24, 46, 16], [33, 183, 0, 0, 0], [15, 0, 558, 25, 2], [4, 0, 18, 570, 8], [20, 0, 51, 2, 443]]      2156.250   \n",
       "9       5  Model_CNN_2D_Luz    2         1.000000       0.903652   1.000000  ...        0.907639       1.000000     0.903652   [[504, 19, 41, 12, 0], [9, 196, 34, 13, 0], [17, 0, 571, 11, 1], [10, 7, 12, 570, 1], [12, 12, 28, 9, 485]]      1859.375   \n",
       "10     16   Model_CNN_2D_Su    8         0.999487       0.744872   0.999487  ...        0.795096       0.999487     0.744872  [[420, 8, 22, 8, 22], [13, 156, 11, 0, 0], [165, 0, 404, 3, 28], [30, 17, 41, 484, 28], [192, 0, 9, 0, 279]]       875.000   \n",
       "11      2   Model_CNN_2D_Su   10         0.999953       0.809467   0.999953  ...        0.818571       0.999953     0.809467   [[562, 23, 13, 3, 17], [13, 185, 0, 0, 0], [22, 0, 539, 34, 5], [43, 5, 73, 472, 7], [26, 1, 91, 103, 277]]      1171.875   \n",
       "12      8   Model_CNN_2D_Su    4         0.999612       0.830550   0.999612  ...        0.841149       0.999612     0.830550   [[587, 18, 41, 9, 29], [102, 246, 2, 0, 4], [75, 0, 456, 58, 11], [6, 0, 57, 530, 7], [42, 0, 72, 15, 867]]      1218.750   \n",
       "13     14   Model_CNN_2D_Su    7         0.999438       0.837860   0.999438  ...        0.838288       0.999438     0.837860  [[472, 6, 47, 53, 22], [22, 136, 3, 3, 4], [27, 0, 546, 14, 13], [17, 8, 26, 527, 22], [77, 18, 11, 1, 355]]       984.375   \n",
       "14      6   Model_CNN_2D_Su    3         0.999952       0.855809   0.999952  ...        0.864665       0.999952     0.855809    [[609, 51, 37, 7, 16], [0, 257, 0, 1, 0], [17, 3, 531, 47, 2], [53, 9, 24, 501, 13], [113, 18, 3, 3, 577]]       781.250   \n",
       "15     12   Model_CNN_2D_Su    6         0.999298       0.856667   0.999298  ...        0.857062       0.999298     0.856667     [[456, 32, 33, 22, 45], [11, 147, 4, 3, 3], [20, 1, 567, 11, 1], [7, 5, 29, 554, 5], [76, 8, 19, 9, 332]]       828.125   \n",
       "16     10   Model_CNN_2D_Su    5         0.999381       0.863960   0.999381  ...        0.875693       0.999381     0.863960      [[560, 2, 9, 21, 2], [56, 520, 6, 0, 6], [78, 0, 500, 21, 1], [35, 0, 80, 485, 0], [28, 15, 2, 20, 361]]       953.125   \n",
       "17      0   Model_CNN_2D_Su    1         0.998774       0.870930   0.998775  ...        0.877201       0.998774     0.870930     [[555, 17, 31, 19, 26], [18, 198, 0, 0, 0], [11, 0, 543, 46, 0], [0, 0, 74, 517, 9], [20, 0, 60, 2, 434]]      1140.625   \n",
       "18      4   Model_CNN_2D_Su    2         1.000000       0.872572   1.000000  ...        0.880594       1.000000     0.872572      [[531, 3, 25, 10, 7], [41, 202, 2, 6, 1], [53, 0, 536, 5, 6], [28, 13, 9, 545, 5], [32, 0, 47, 35, 432]]      1187.500   \n",
       "19     18   Model_CNN_2D_Su    9         0.999860       0.898148   0.999860  ...        0.898546       0.999860     0.898148       [[445, 7, 24, 5, 11], [0, 191, 0, 1, 0], [17, 0, 534, 43, 6], [62, 15, 35, 476, 12], [0, 0, 3, 1, 488]]       968.750   \n",
       "\n",
       "                                                                                                          Class_report(Val)  \n",
       "0                     precision    recall  f1-score   support\\n\\n      background       0.56      0.85      0.68       4...  \n",
       "1                     precision    recall  f1-score   support\\n\\n      background       0.89      0.88      0.88       6...  \n",
       "2                     precision    recall  f1-score   support\\n\\n      background       0.72      0.88      0.79       6...  \n",
       "3                     precision    recall  f1-score   support\\n\\n      background       0.78      0.83      0.80       6...  \n",
       "4                     precision    recall  f1-score   support\\n\\n      background       0.72      0.92      0.81       5...  \n",
       "5                     precision    recall  f1-score   support\\n\\n      background       0.81      0.83      0.82       5...  \n",
       "6                     precision    recall  f1-score   support\\n\\n      background       0.86      0.92      0.89       4...  \n",
       "7                     precision    recall  f1-score   support\\n\\n      background       0.80      0.91      0.85       7...  \n",
       "8                     precision    recall  f1-score   support\\n\\n      background       0.89      0.86      0.87       6...  \n",
       "9                     precision    recall  f1-score   support\\n\\n      background       0.91      0.88      0.89       5...  \n",
       "10                    precision    recall  f1-score   support\\n\\n      background       0.51      0.88      0.65       4...  \n",
       "11                    precision    recall  f1-score   support\\n\\n      background       0.84      0.91      0.88       6...  \n",
       "12                    precision    recall  f1-score   support\\n\\n      background       0.72      0.86      0.78       6...  \n",
       "13                    precision    recall  f1-score   support\\n\\n      background       0.77      0.79      0.78       6...  \n",
       "14                    precision    recall  f1-score   support\\n\\n      background       0.77      0.85      0.81       7...  \n",
       "15                    precision    recall  f1-score   support\\n\\n      background       0.80      0.78      0.79       5...  \n",
       "16                    precision    recall  f1-score   support\\n\\n      background       0.74      0.94      0.83       5...  \n",
       "17                    precision    recall  f1-score   support\\n\\n      background       0.92      0.86      0.89       6...  \n",
       "18                    precision    recall  f1-score   support\\n\\n      background       0.78      0.92      0.84       5...  \n",
       "19                    precision    recall  f1-score   support\\n\\n      background       0.85      0.90      0.88       4...  \n",
       "\n",
       "[20 rows x 14 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by Model and Accuracy test. Reset the index.\n",
    "\n",
    "metrics_set = metrics_set.sort_values(['Model', 'Accuracy(Val)'], ascending = [True, True]).reset_index()\n",
    "metrics_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_db288_row0_col1 {\n",
       "  background-color: #d9e7f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_db288_row1_col1 {\n",
       "  background-color: #4090c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row2_col1 {\n",
       "  background-color: #3686c0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row3_col1 {\n",
       "  background-color: #2c7cba;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row4_col1 {\n",
       "  background-color: #1a68ae;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row5_col1 {\n",
       "  background-color: #08509b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row6_col1, #T_db288_row7_col1 {\n",
       "  background-color: #084285;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row8_col1 {\n",
       "  background-color: #083a7a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row9_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row10_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_db288_row11_col1 {\n",
       "  background-color: #91c3de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_db288_row12_col1 {\n",
       "  background-color: #5da5d1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row13_col1 {\n",
       "  background-color: #4f9bcb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row14_col1 {\n",
       "  background-color: #2f7fbc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row15_col1 {\n",
       "  background-color: #2d7dbb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row16_col1 {\n",
       "  background-color: #2070b4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row17_col1 {\n",
       "  background-color: #1865ac;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row18_col1 {\n",
       "  background-color: #1663aa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_db288_row19_col1 {\n",
       "  background-color: #083877;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_db288\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_db288_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_db288_level0_col1\" class=\"col_heading level0 col1\" >Accuracy(Val)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_db288_row0_col0\" class=\"data row0 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row0_col1\" class=\"data row0 col1\" >0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_db288_row1_col0\" class=\"data row1 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row1_col1\" class=\"data row1 col1\" >0.845267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_db288_row2_col0\" class=\"data row2 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row2_col1\" class=\"data row2 col1\" >0.851268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_db288_row3_col0\" class=\"data row3 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row3_col1\" class=\"data row3 col1\" >0.857202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_db288_row4_col0\" class=\"data row4 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row4_col1\" class=\"data row4 col1\" >0.869302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_db288_row5_col0\" class=\"data row5 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row5_col1\" class=\"data row5 col1\" >0.884167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_db288_row6_col0\" class=\"data row6 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row6_col1\" class=\"data row6 col1\" >0.892677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_db288_row7_col0\" class=\"data row7 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row7_col1\" class=\"data row7 col1\" >0.892808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_db288_row8_col0\" class=\"data row8 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row8_col1\" class=\"data row8 col1\" >0.896899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_db288_row9_col0\" class=\"data row9 col0\" >Model_CNN_2D_Luz</td>\n",
       "      <td id=\"T_db288_row9_col1\" class=\"data row9 col1\" >0.903652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_db288_row10_col0\" class=\"data row10 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row10_col1\" class=\"data row10 col1\" >0.744872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_db288_row11_col0\" class=\"data row11 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row11_col1\" class=\"data row11 col1\" >0.809467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_db288_row12_col0\" class=\"data row12 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row12_col1\" class=\"data row12 col1\" >0.830550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_db288_row13_col0\" class=\"data row13 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row13_col1\" class=\"data row13 col1\" >0.837860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_db288_row14_col0\" class=\"data row14 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row14_col1\" class=\"data row14 col1\" >0.855809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_db288_row15_col0\" class=\"data row15 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row15_col1\" class=\"data row15 col1\" >0.856667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_db288_row16_col0\" class=\"data row16 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row16_col1\" class=\"data row16 col1\" >0.863960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_db288_row17_col0\" class=\"data row17 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row17_col1\" class=\"data row17 col1\" >0.870930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_db288_row18_col0\" class=\"data row18 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row18_col1\" class=\"data row18 col1\" >0.872572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_db288_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_db288_row19_col0\" class=\"data row19 col0\" >Model_CNN_2D_Su</td>\n",
       "      <td id=\"T_db288_row19_col1\" class=\"data row19 col1\" >0.898148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1457f08ad00>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_set[['Model', 'Accuracy(Val)']].style.background_gradient(cmap = cmap_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model\n",
       "Model_CNN_2D_Luz    0.903652\n",
       "Model_CNN_2D_Su     0.898148\n",
       "Name: Accuracy(Val), dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_accuracy = metrics_set.groupby('Model')['Accuracy(Val)'].max()\n",
    "highest_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dictionary of each classifier and its data explanation\n",
    "\n",
    "unique_models = []\n",
    "results       = {}\n",
    "\n",
    "for c in classifiers:\n",
    "    unique_models.append(c)\n",
    "\n",
    "for model in unique_models:\n",
    "    result = metrics_set[metrics_set['Model'] == model].describe().round(4)\n",
    "    results[model] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model...: Model_CNN_2D_Su\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Accuracy(Train)</th>\n",
       "      <th>Accuracy(Val)</th>\n",
       "      <th>F1(Train)</th>\n",
       "      <th>F1(Val)</th>\n",
       "      <th>Precision(Train)</th>\n",
       "      <th>Precision(Val)</th>\n",
       "      <th>Recall(Train)</th>\n",
       "      <th>Recall(Val)</th>\n",
       "      <th>Process_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.0000</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.8441</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.8446</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.8547</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>0.8441</td>\n",
       "      <td>1010.9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.0553</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>159.0120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.7449</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>0.7449</td>\n",
       "      <td>781.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.8335</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>894.5312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.0000</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8561</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8609</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.8562</td>\n",
       "      <td>976.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.5000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8705</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8768</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>1164.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8969</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8985</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>1218.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  Accuracy(Train)  Accuracy(Val)  F1(Train)  F1(Val)  Precision(Train)  Precision(Val)  Recall(Train)  Recall(Val)  Process_time\n",
       "count  10.0000          10.0000        10.0000    10.0000  10.0000           10.0000         10.0000        10.0000      10.0000       10.0000\n",
       "mean    9.0000           0.9996         0.8441     0.9996   0.8446            0.9996          0.8547         0.9996       0.8441     1010.9375\n",
       "std     6.0553           0.0004         0.0427     0.0004   0.0412            0.0004          0.0315         0.0004       0.0427      159.0120\n",
       "min     0.0000           0.9988         0.7449     0.9988   0.7530            0.9988          0.7951         0.9988       0.7449      781.2500\n",
       "25%     4.5000           0.9994         0.8324     0.9994   0.8335            0.9994          0.8390         0.9994       0.8324      894.5312\n",
       "50%     9.0000           0.9995         0.8562     0.9995   0.8561            0.9995          0.8609         0.9995       0.8562      976.5625\n",
       "75%    13.5000           0.9999         0.8692     0.9999   0.8705            0.9999          0.8768         0.9999       0.8692     1164.0625\n",
       "max    18.0000           1.0000         0.8981     1.0000   0.8969            1.0000          0.8985         1.0000       0.8981     1218.7500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model...: Model_CNN_2D_Luz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Accuracy(Train)</th>\n",
       "      <th>Accuracy(Val)</th>\n",
       "      <th>F1(Train)</th>\n",
       "      <th>F1(Val)</th>\n",
       "      <th>Precision(Train)</th>\n",
       "      <th>Precision(Val)</th>\n",
       "      <th>Recall(Train)</th>\n",
       "      <th>Recall(Val)</th>\n",
       "      <th>Process_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8735</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.8662</td>\n",
       "      <td>2032.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.0553</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>348.9544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.7696</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.7951</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.7692</td>\n",
       "      <td>1687.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.5000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8529</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>1757.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8767</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8776</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8767</td>\n",
       "      <td>1882.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.5000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8931</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8971</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8928</td>\n",
       "      <td>2273.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9076</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>2593.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  Accuracy(Train)  Accuracy(Val)  F1(Train)  F1(Val)  Precision(Train)  Precision(Val)  Recall(Train)  Recall(Val)  Process_time\n",
       "count  10.0000          10.0000        10.0000    10.0000  10.0000           10.0000         10.0000        10.0000      10.0000       10.0000\n",
       "mean   10.0000           0.9999         0.8662     0.9999   0.8662            0.9999          0.8735         0.9999       0.8662     2032.8125\n",
       "std     6.0553           0.0002         0.0398     0.0002   0.0398            0.0002          0.0332         0.0002       0.0398      348.9544\n",
       "min     1.0000           0.9994         0.7692     0.9994   0.7696            0.9994          0.7951         0.9994       0.7692     1687.5000\n",
       "25%     5.5000           1.0000         0.8528     1.0000   0.8529            1.0000          0.8596         1.0000       0.8528     1757.8125\n",
       "50%    10.0000           1.0000         0.8767     1.0000   0.8776            1.0000          0.8831         1.0000       0.8767     1882.8125\n",
       "75%    14.5000           1.0000         0.8928     1.0000   0.8931            1.0000          0.8971         1.0000       0.8928     2273.4375\n",
       "max    19.0000           1.0000         0.9037     1.0000   0.9038            1.0000          0.9076         1.0000       0.9037     2593.7500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in results.keys():\n",
    "    print(f'Model...: {model}')\n",
    "    display(results[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy(Train)</th>\n",
       "      <th>Accuracy(Val)</th>\n",
       "      <th>F1(Train)</th>\n",
       "      <th>F1(Val)</th>\n",
       "      <th>Precision(Train)</th>\n",
       "      <th>Precision(Val)</th>\n",
       "      <th>Recall(Train)</th>\n",
       "      <th>Recall(Val)</th>\n",
       "      <th>Process_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.795126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1906.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.842998</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.854174</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>2312.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851528</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.861982</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>2562.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>0.999437</td>\n",
       "      <td>0.857198</td>\n",
       "      <td>0.999439</td>\n",
       "      <td>0.858832</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>1718.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>2593.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>1687.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>1781.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.898510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>1750.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.899769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>2156.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>1859.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.753047</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.795096</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>875.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.803807</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>1171.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.832186</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.841149</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>1218.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837464</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.838288</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>984.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.856747</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.864665</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>781.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.855425</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.857062</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>828.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.865765</td>\n",
       "      <td>0.999382</td>\n",
       "      <td>0.875693</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>953.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>0.872025</td>\n",
       "      <td>0.998776</td>\n",
       "      <td>0.877201</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>1140.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>1187.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.896910</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898546</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>968.750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index             Model Fold  Accuracy(Train)  Accuracy(Val)  F1(Train)   F1(Val)  Precision(Train)  Precision(Val)  Recall(Train)  Recall(Val)  Process_time\n",
       "0      17  Model_CNN_2D_Luz    8         1.000000       0.769231   1.000000  0.769584          1.000000        0.795126       1.000000     0.769231      1906.250\n",
       "1       3  Model_CNN_2D_Luz   10         0.999953       0.845267   0.999953  0.842998          0.999953        0.854174       0.999953     0.845267      2312.500\n",
       "2       9  Model_CNN_2D_Luz    4         0.999903       0.851268   0.999903  0.851528          0.999903        0.861982       0.999903     0.851268      2562.500\n",
       "3      15  Model_CNN_2D_Luz    7         0.999438       0.857202   0.999437  0.857198          0.999439        0.858832       0.999438     0.857202      1718.750\n",
       "4      11  Model_CNN_2D_Luz    5         1.000000       0.869302   1.000000  0.871273          1.000000        0.881039       1.000000     0.869302      2593.750\n",
       "5      13  Model_CNN_2D_Luz    6         1.000000       0.884167   1.000000  0.883839          1.000000        0.885092       1.000000     0.884167      1687.500\n",
       "6      19  Model_CNN_2D_Luz    9         1.000000       0.892677   1.000000  0.891596          1.000000        0.892863       1.000000     0.892677      1781.250\n",
       "7       7  Model_CNN_2D_Luz    3         1.000000       0.892808   1.000000  0.893536          1.000000        0.898510       1.000000     0.892808      1750.000\n",
       "8       1  Model_CNN_2D_Luz    1         1.000000       0.896899   1.000000  0.896829          1.000000        0.899769       1.000000     0.896899      2156.250\n",
       "9       5  Model_CNN_2D_Luz    2         1.000000       0.903652   1.000000  0.903831          1.000000        0.907639       1.000000     0.903652      1859.375\n",
       "10     16   Model_CNN_2D_Su    8         0.999487       0.744872   0.999487  0.753047          0.999487        0.795096       0.999487     0.744872       875.000\n",
       "11      2   Model_CNN_2D_Su   10         0.999953       0.809467   0.999953  0.803807          0.999953        0.818571       0.999953     0.809467      1171.875\n",
       "12      8   Model_CNN_2D_Su    4         0.999612       0.830550   0.999612  0.832186          0.999612        0.841149       0.999612     0.830550      1218.750\n",
       "13     14   Model_CNN_2D_Su    7         0.999438       0.837860   0.999438  0.837464          0.999438        0.838288       0.999438     0.837860       984.375\n",
       "14      6   Model_CNN_2D_Su    3         0.999952       0.855809   0.999952  0.856747          0.999952        0.864665       0.999952     0.855809       781.250\n",
       "15     12   Model_CNN_2D_Su    6         0.999298       0.856667   0.999298  0.855425          0.999300        0.857062       0.999298     0.856667       828.125\n",
       "16     10   Model_CNN_2D_Su    5         0.999381       0.863960   0.999381  0.865765          0.999382        0.875693       0.999381     0.863960       953.125\n",
       "17      0   Model_CNN_2D_Su    1         0.998774       0.870930   0.998775  0.872025          0.998776        0.877201       0.998774     0.870930      1140.625\n",
       "18      4   Model_CNN_2D_Su    2         1.000000       0.872572   1.000000  0.872987          1.000000        0.880594       1.000000     0.872572      1187.500\n",
       "19     18   Model_CNN_2D_Su    9         0.999860       0.898148   0.999860  0.896910          0.999860        0.898546       0.999860     0.898148       968.750"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_set_no_cm = metrics_set.drop(['Conf_M', 'Class_report(Val)'], axis=1)\n",
    "metrics_set_no_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US8K_AV_metrics_set_CNN_2D_augmented.pkl\n",
      "US8K_AV_metrics_set_CNN_2D_augmented_no_cm.csv\n"
     ]
    }
   ],
   "source": [
    "metrics_set_name       = nom_dataset + '_metrics_set_CNN_2D' +  model_surname + '.pkl'\n",
    "metrics_set_name_no_cm = nom_dataset + '_metrics_set_CNN_2D' +  model_surname + '_no_cm.csv'\n",
    "\n",
    "print(metrics_set_name)\n",
    "print(metrics_set_name_no_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes de results to a PKL and CSV file\n",
    "\n",
    "with open(os.path.join(path_models, metrics_set_name), 'wb') as file:\n",
    "    pickle.dump(metrics_set, file)\n",
    "    \n",
    "metrics_set_no_cm.to_csv(os.path.join(path_models, metrics_set_name_no_cm), sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy(Train)</th>\n",
       "      <th>Accuracy(Val)</th>\n",
       "      <th>F1(Train)</th>\n",
       "      <th>...</th>\n",
       "      <th>Precision(Val)</th>\n",
       "      <th>Recall(Train)</th>\n",
       "      <th>Recall(Val)</th>\n",
       "      <th>Conf_M</th>\n",
       "      <th>Process_time</th>\n",
       "      <th>Class_report(Val)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>[[408, 1, 26, 23, 22], [11, 161, 8, 0, 0], [70, 6, 471, 33, 20], [4, 15, 38, 517, 26], [232, 0, 3, 2, 243]]</td>\n",
       "      <td>1906.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.56      0.85      0.68       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854174</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.845267</td>\n",
       "      <td>[[543, 24, 25, 12, 14], [9, 189, 0, 0, 0], [17, 5, 543, 28, 7], [28, 3, 23, 534, 12], [13, 5, 15, 149, 316]]</td>\n",
       "      <td>2312.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.89      0.88      0.88       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.861982</td>\n",
       "      <td>0.999903</td>\n",
       "      <td>0.851268</td>\n",
       "      <td>[[601, 8, 30, 13, 32], [110, 231, 5, 5, 3], [73, 0, 471, 49, 7], [22, 0, 34, 536, 8], [27, 0, 43, 12, 914]]</td>\n",
       "      <td>2562.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.88      0.79       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>0.999437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858832</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.857202</td>\n",
       "      <td>[[501, 6, 25, 54, 14], [17, 140, 4, 4, 3], [36, 0, 545, 7, 12], [8, 5, 24, 539, 24], [83, 12, 5, 4, 358]]</td>\n",
       "      <td>1718.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.78      0.83      0.80       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869302</td>\n",
       "      <td>[[548, 3, 5, 35, 3], [63, 523, 1, 0, 1], [112, 0, 466, 16, 6], [27, 0, 48, 522, 3], [6, 13, 4, 21, 382]]</td>\n",
       "      <td>2593.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.92      0.81       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.884167</td>\n",
       "      <td>[[488, 20, 24, 28, 28], [21, 145, 1, 1, 0], [30, 1, 553, 16, 0], [3, 0, 18, 575, 4], [64, 1, 7, 11, 361]]</td>\n",
       "      <td>1687.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.81      0.83      0.82       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>9</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892677</td>\n",
       "      <td>[[453, 11, 14, 8, 6], [2, 186, 0, 2, 2], [11, 1, 530, 55, 3], [52, 17, 62, 468, 1], [7, 0, 1, 0, 484]]</td>\n",
       "      <td>1781.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.86      0.92      0.89       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898510</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892808</td>\n",
       "      <td>[[656, 17, 29, 6, 12], [3, 253, 0, 2, 0], [39, 0, 504, 57, 0], [36, 0, 14, 550, 0], [84, 3, 7, 1, 619]]</td>\n",
       "      <td>1750.000</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.80      0.91      0.85       7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.899769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896899</td>\n",
       "      <td>[[560, 2, 24, 46, 16], [33, 183, 0, 0, 0], [15, 0, 558, 25, 2], [4, 0, 18, 570, 8], [20, 0, 51, 2, 443]]</td>\n",
       "      <td>2156.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.89      0.86      0.87       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>Model_CNN_2D_Luz</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.907639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903652</td>\n",
       "      <td>[[504, 19, 41, 12, 0], [9, 196, 34, 13, 0], [17, 0, 571, 11, 1], [10, 7, 12, 570, 1], [12, 12, 28, 9, 485]]</td>\n",
       "      <td>1859.375</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.91      0.88      0.89       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>8</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795096</td>\n",
       "      <td>0.999487</td>\n",
       "      <td>0.744872</td>\n",
       "      <td>[[420, 8, 22, 8, 22], [13, 156, 11, 0, 0], [165, 0, 404, 3, 28], [30, 17, 41, 484, 28], [192, 0, 9, 0, 279]]</td>\n",
       "      <td>875.000</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.51      0.88      0.65       4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.999953</td>\n",
       "      <td>0.809467</td>\n",
       "      <td>[[562, 23, 13, 3, 17], [13, 185, 0, 0, 0], [22, 0, 539, 34, 5], [43, 5, 73, 472, 7], [26, 1, 91, 103, 277]]</td>\n",
       "      <td>1171.875</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.84      0.91      0.88       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841149</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.830550</td>\n",
       "      <td>[[587, 18, 41, 9, 29], [102, 246, 2, 0, 4], [75, 0, 456, 58, 11], [6, 0, 57, 530, 7], [42, 0, 72, 15, 867]]</td>\n",
       "      <td>1218.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.72      0.86      0.78       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>7</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838288</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.837860</td>\n",
       "      <td>[[472, 6, 47, 53, 22], [22, 136, 3, 3, 4], [27, 0, 546, 14, 13], [17, 8, 26, 527, 22], [77, 18, 11, 1, 355]]</td>\n",
       "      <td>984.375</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.77      0.79      0.78       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864665</td>\n",
       "      <td>0.999952</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>[[609, 51, 37, 7, 16], [0, 257, 0, 1, 0], [17, 3, 531, 47, 2], [53, 9, 24, 501, 13], [113, 18, 3, 3, 577]]</td>\n",
       "      <td>781.250</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.77      0.85      0.81       7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>6</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857062</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>[[456, 32, 33, 22, 45], [11, 147, 4, 3, 3], [20, 1, 567, 11, 1], [7, 5, 29, 554, 5], [76, 8, 19, 9, 332]]</td>\n",
       "      <td>828.125</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.80      0.78      0.79       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>5</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875693</td>\n",
       "      <td>0.999381</td>\n",
       "      <td>0.863960</td>\n",
       "      <td>[[560, 2, 9, 21, 2], [56, 520, 6, 0, 6], [78, 0, 500, 21, 1], [35, 0, 80, 485, 0], [28, 15, 2, 20, 361]]</td>\n",
       "      <td>953.125</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.74      0.94      0.83       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>0.998775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877201</td>\n",
       "      <td>0.998774</td>\n",
       "      <td>0.870930</td>\n",
       "      <td>[[555, 17, 31, 19, 26], [18, 198, 0, 0, 0], [11, 0, 543, 46, 0], [0, 0, 74, 517, 9], [20, 0, 60, 2, 434]]</td>\n",
       "      <td>1140.625</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.92      0.86      0.89       6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880594</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.872572</td>\n",
       "      <td>[[531, 3, 25, 10, 7], [41, 202, 2, 6, 1], [53, 0, 536, 5, 6], [28, 13, 9, 545, 5], [32, 0, 47, 35, 432]]</td>\n",
       "      <td>1187.500</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.78      0.92      0.84       5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>Model_CNN_2D_Su</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898546</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.898148</td>\n",
       "      <td>[[445, 7, 24, 5, 11], [0, 191, 0, 1, 0], [17, 0, 534, 43, 6], [62, 15, 35, 476, 12], [0, 0, 3, 1, 488]]</td>\n",
       "      <td>968.750</td>\n",
       "      <td>precision    recall  f1-score   support\\n\\n      background       0.85      0.90      0.88       4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index             Model Fold  Accuracy(Train)  Accuracy(Val)  F1(Train)  ...  Precision(Val)  Recall(Train)  Recall(Val)                                                                                                        Conf_M  Process_time  \\\n",
       "0      17  Model_CNN_2D_Luz    8         1.000000       0.769231   1.000000  ...        0.795126       1.000000     0.769231   [[408, 1, 26, 23, 22], [11, 161, 8, 0, 0], [70, 6, 471, 33, 20], [4, 15, 38, 517, 26], [232, 0, 3, 2, 243]]      1906.250   \n",
       "1       3  Model_CNN_2D_Luz   10         0.999953       0.845267   0.999953  ...        0.854174       0.999953     0.845267  [[543, 24, 25, 12, 14], [9, 189, 0, 0, 0], [17, 5, 543, 28, 7], [28, 3, 23, 534, 12], [13, 5, 15, 149, 316]]      2312.500   \n",
       "2       9  Model_CNN_2D_Luz    4         0.999903       0.851268   0.999903  ...        0.861982       0.999903     0.851268   [[601, 8, 30, 13, 32], [110, 231, 5, 5, 3], [73, 0, 471, 49, 7], [22, 0, 34, 536, 8], [27, 0, 43, 12, 914]]      2562.500   \n",
       "3      15  Model_CNN_2D_Luz    7         0.999438       0.857202   0.999437  ...        0.858832       0.999438     0.857202     [[501, 6, 25, 54, 14], [17, 140, 4, 4, 3], [36, 0, 545, 7, 12], [8, 5, 24, 539, 24], [83, 12, 5, 4, 358]]      1718.750   \n",
       "4      11  Model_CNN_2D_Luz    5         1.000000       0.869302   1.000000  ...        0.881039       1.000000     0.869302      [[548, 3, 5, 35, 3], [63, 523, 1, 0, 1], [112, 0, 466, 16, 6], [27, 0, 48, 522, 3], [6, 13, 4, 21, 382]]      2593.750   \n",
       "5      13  Model_CNN_2D_Luz    6         1.000000       0.884167   1.000000  ...        0.885092       1.000000     0.884167     [[488, 20, 24, 28, 28], [21, 145, 1, 1, 0], [30, 1, 553, 16, 0], [3, 0, 18, 575, 4], [64, 1, 7, 11, 361]]      1687.500   \n",
       "6      19  Model_CNN_2D_Luz    9         1.000000       0.892677   1.000000  ...        0.892863       1.000000     0.892677        [[453, 11, 14, 8, 6], [2, 186, 0, 2, 2], [11, 1, 530, 55, 3], [52, 17, 62, 468, 1], [7, 0, 1, 0, 484]]      1781.250   \n",
       "7       7  Model_CNN_2D_Luz    3         1.000000       0.892808   1.000000  ...        0.898510       1.000000     0.892808       [[656, 17, 29, 6, 12], [3, 253, 0, 2, 0], [39, 0, 504, 57, 0], [36, 0, 14, 550, 0], [84, 3, 7, 1, 619]]      1750.000   \n",
       "8       1  Model_CNN_2D_Luz    1         1.000000       0.896899   1.000000  ...        0.899769       1.000000     0.896899      [[560, 2, 24, 46, 16], [33, 183, 0, 0, 0], [15, 0, 558, 25, 2], [4, 0, 18, 570, 8], [20, 0, 51, 2, 443]]      2156.250   \n",
       "9       5  Model_CNN_2D_Luz    2         1.000000       0.903652   1.000000  ...        0.907639       1.000000     0.903652   [[504, 19, 41, 12, 0], [9, 196, 34, 13, 0], [17, 0, 571, 11, 1], [10, 7, 12, 570, 1], [12, 12, 28, 9, 485]]      1859.375   \n",
       "10     16   Model_CNN_2D_Su    8         0.999487       0.744872   0.999487  ...        0.795096       0.999487     0.744872  [[420, 8, 22, 8, 22], [13, 156, 11, 0, 0], [165, 0, 404, 3, 28], [30, 17, 41, 484, 28], [192, 0, 9, 0, 279]]       875.000   \n",
       "11      2   Model_CNN_2D_Su   10         0.999953       0.809467   0.999953  ...        0.818571       0.999953     0.809467   [[562, 23, 13, 3, 17], [13, 185, 0, 0, 0], [22, 0, 539, 34, 5], [43, 5, 73, 472, 7], [26, 1, 91, 103, 277]]      1171.875   \n",
       "12      8   Model_CNN_2D_Su    4         0.999612       0.830550   0.999612  ...        0.841149       0.999612     0.830550   [[587, 18, 41, 9, 29], [102, 246, 2, 0, 4], [75, 0, 456, 58, 11], [6, 0, 57, 530, 7], [42, 0, 72, 15, 867]]      1218.750   \n",
       "13     14   Model_CNN_2D_Su    7         0.999438       0.837860   0.999438  ...        0.838288       0.999438     0.837860  [[472, 6, 47, 53, 22], [22, 136, 3, 3, 4], [27, 0, 546, 14, 13], [17, 8, 26, 527, 22], [77, 18, 11, 1, 355]]       984.375   \n",
       "14      6   Model_CNN_2D_Su    3         0.999952       0.855809   0.999952  ...        0.864665       0.999952     0.855809    [[609, 51, 37, 7, 16], [0, 257, 0, 1, 0], [17, 3, 531, 47, 2], [53, 9, 24, 501, 13], [113, 18, 3, 3, 577]]       781.250   \n",
       "15     12   Model_CNN_2D_Su    6         0.999298       0.856667   0.999298  ...        0.857062       0.999298     0.856667     [[456, 32, 33, 22, 45], [11, 147, 4, 3, 3], [20, 1, 567, 11, 1], [7, 5, 29, 554, 5], [76, 8, 19, 9, 332]]       828.125   \n",
       "16     10   Model_CNN_2D_Su    5         0.999381       0.863960   0.999381  ...        0.875693       0.999381     0.863960      [[560, 2, 9, 21, 2], [56, 520, 6, 0, 6], [78, 0, 500, 21, 1], [35, 0, 80, 485, 0], [28, 15, 2, 20, 361]]       953.125   \n",
       "17      0   Model_CNN_2D_Su    1         0.998774       0.870930   0.998775  ...        0.877201       0.998774     0.870930     [[555, 17, 31, 19, 26], [18, 198, 0, 0, 0], [11, 0, 543, 46, 0], [0, 0, 74, 517, 9], [20, 0, 60, 2, 434]]      1140.625   \n",
       "18      4   Model_CNN_2D_Su    2         1.000000       0.872572   1.000000  ...        0.880594       1.000000     0.872572      [[531, 3, 25, 10, 7], [41, 202, 2, 6, 1], [53, 0, 536, 5, 6], [28, 13, 9, 545, 5], [32, 0, 47, 35, 432]]      1187.500   \n",
       "19     18   Model_CNN_2D_Su    9         0.999860       0.898148   0.999860  ...        0.898546       0.999860     0.898148       [[445, 7, 24, 5, 11], [0, 191, 0, 1, 0], [17, 0, 534, 43, 6], [62, 15, 35, 476, 12], [0, 0, 3, 1, 488]]       968.750   \n",
       "\n",
       "                                                                                                          Class_report(Val)  \n",
       "0                     precision    recall  f1-score   support\\n\\n      background       0.56      0.85      0.68       4...  \n",
       "1                     precision    recall  f1-score   support\\n\\n      background       0.89      0.88      0.88       6...  \n",
       "2                     precision    recall  f1-score   support\\n\\n      background       0.72      0.88      0.79       6...  \n",
       "3                     precision    recall  f1-score   support\\n\\n      background       0.78      0.83      0.80       6...  \n",
       "4                     precision    recall  f1-score   support\\n\\n      background       0.72      0.92      0.81       5...  \n",
       "5                     precision    recall  f1-score   support\\n\\n      background       0.81      0.83      0.82       5...  \n",
       "6                     precision    recall  f1-score   support\\n\\n      background       0.86      0.92      0.89       4...  \n",
       "7                     precision    recall  f1-score   support\\n\\n      background       0.80      0.91      0.85       7...  \n",
       "8                     precision    recall  f1-score   support\\n\\n      background       0.89      0.86      0.87       6...  \n",
       "9                     precision    recall  f1-score   support\\n\\n      background       0.91      0.88      0.89       5...  \n",
       "10                    precision    recall  f1-score   support\\n\\n      background       0.51      0.88      0.65       4...  \n",
       "11                    precision    recall  f1-score   support\\n\\n      background       0.84      0.91      0.88       6...  \n",
       "12                    precision    recall  f1-score   support\\n\\n      background       0.72      0.86      0.78       6...  \n",
       "13                    precision    recall  f1-score   support\\n\\n      background       0.77      0.79      0.78       6...  \n",
       "14                    precision    recall  f1-score   support\\n\\n      background       0.77      0.85      0.81       7...  \n",
       "15                    precision    recall  f1-score   support\\n\\n      background       0.80      0.78      0.79       5...  \n",
       "16                    precision    recall  f1-score   support\\n\\n      background       0.74      0.94      0.83       5...  \n",
       "17                    precision    recall  f1-score   support\\n\\n      background       0.92      0.86      0.89       6...  \n",
       "18                    precision    recall  f1-score   support\\n\\n      background       0.78      0.92      0.84       5...  \n",
       "19                    precision    recall  f1-score   support\\n\\n      background       0.85      0.90      0.88       4...  \n",
       "\n",
       "[20 rows x 14 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_set_from_pkl = pd.read_pickle(os.path.join(path_models, metrics_set_name))\n",
    "metrics_set_from_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model_CNN_2D_Luz': {'Accuracy(Val)': 0.9036519036519036,\n",
       "  'Conf_M': array([[504,  19,  41,  12,   0],\n",
       "         [  9, 196,  34,  13,   0],\n",
       "         [ 17,   0, 571,  11,   1],\n",
       "         [ 10,   7,  12, 570,   1],\n",
       "         [ 12,  12,  28,   9, 485]], dtype=int64)},\n",
       " 'Model_CNN_2D_Su': {'Accuracy(Val)': 0.8981481481481481,\n",
       "  'Conf_M': array([[445,   7,  24,   5,  11],\n",
       "         [  0, 191,   0,   1,   0],\n",
       "         [ 17,   0, 534,  43,   6],\n",
       "         [ 62,  15,  35, 476,  12],\n",
       "         [  0,   0,   3,   1, 488]], dtype=int64)}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = metrics_set.groupby('Model')['Accuracy(Val)'].idxmax()\n",
    "conf_matrices = metrics_set.loc[idx, ['Model','Accuracy(Val)','Conf_M']]\n",
    "conf_matrices.set_index('Model', inplace=True)\n",
    "conf_matrices_dict = conf_matrices.to_dict('index')\n",
    "conf_matrices_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[445,   7,  24,   5,  11],\n",
       "       [  0, 191,   0,   1,   0],\n",
       "       [ 17,   0, 534,  43,   6],\n",
       "       [ 62,  15,  35, 476,  12],\n",
       "       [  0,   0,   3,   1, 488]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrices_dict['Model_CNN_2D_Su']['Conf_M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Model_CNN_2D_Luz\n",
      "0.9036519036519036\n",
      "[[504  19  41  12   0]\n",
      " [  9 196  34  13   0]\n",
      " [ 17   0 571  11   1]\n",
      " [ 10   7  12 570   1]\n",
      " [ 12  12  28   9 485]]\n",
      "2\n",
      "Model_CNN_2D_Su\n",
      "0.8981481481481481\n",
      "[[445   7  24   5  11]\n",
      " [  0 191   0   1   0]\n",
      " [ 17   0 534  43   6]\n",
      " [ 62  15  35 476  12]\n",
      " [  0   0   3   1 488]]\n"
     ]
    }
   ],
   "source": [
    "for i, idx in zip(conf_matrices_dict.keys(), range(1, len(conf_matrices_dict) + 1)):\n",
    "    print(idx)\n",
    "    print(i)\n",
    "    print(conf_matrices_dict[i]['Accuracy(Val)'])\n",
    "    print(conf_matrices_dict[i]['Conf_M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the confusion matrix for the highest accuracy test classifiers\n",
    "\n",
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.suptitle(nom_dataset + model_surname + ' - Confusion matrices of the best results for each classifier', fontsize = 16,  y=0.99)\n",
    "for i, idx in zip(conf_matrices_dict.keys(), range(1, len(conf_matrices_dict) + 1)):\n",
    "    title = 'Classifier '+ i + ' (Highest accuracy validation of the best models: ' + str(\"{:0.4f}\".format(conf_matrices_dict[i]['Accuracy(Val)'])) +')'\n",
    "    plt.subplot(1,2,idx)\n",
    "    plot_confusion_matrix(conf_matrices_dict[i]['Conf_M'],  \n",
    "                          nom_classes, \n",
    "                          title,\n",
    "                          cmap = None,                          \n",
    "                          normalize = False)\n",
    "\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.suptitle(f'{nom_dataset} - Box plot each classifier (batch type: {model_surname})', fontsize = 16,  y=0.97)\n",
    "box_plot = sns.boxplot(data=metrics_set, x=\"Model\", y=\"Accuracy(Val)\", showfliers = True)\n",
    "\n",
    "medians = list(metrics_set.groupby(['Model'])['Accuracy(Val)'].median())\n",
    "medians = [round(element, 2) for element in medians]\n",
    "\n",
    "vertical_offset = metrics_set['Accuracy(Val)'].median()*0.0001  # offset from median for display\n",
    "\n",
    "for xtick in box_plot.get_xticks():\n",
    "    box_plot.text(xtick, medians[xtick] + vertical_offset, medians[xtick], \n",
    "            horizontalalignment='center',size='medium',color='w',weight='semibold')\n",
    "plt.savefig(os.path.join(path_pic, picture_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mark3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
