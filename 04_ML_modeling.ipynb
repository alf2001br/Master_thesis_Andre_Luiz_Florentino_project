{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3faa6a4b",
   "metadata": {},
   "source": [
    "### Faculdade de Engenharia Industrial - FEI\n",
    "\n",
    "### Centro Universitário da Fundação Educacional Inaciana \"Padre Sabóia de Medeiros\" (FEI)\n",
    "\n",
    "\n",
    "*FEI's Stricto Sensu Graduate Program in Electrical Engineering*\n",
    "\n",
    "Concentration area: ARTIFICIAL INTELLIGENCE APPLIED TO AUTOMATION AND ROBOTICS\n",
    "\n",
    "Master's thesis student Andre Luiz Florentino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd16632",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02245d16",
   "metadata": {},
   "source": [
    "## Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffabcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "pd = tf.config.experimental.list_physical_devices()\n",
    "for i in pd:\n",
    "    print(i)\n",
    "print('------------------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "# [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
    "\n",
    "print(tf.test.is_built_with_cuda)\n",
    "# <function is_built_with_cuda at 0x000001AA24AFEC10>\n",
    "\n",
    "print(tf.test.gpu_device_name())\n",
    "# /device:GPU:0\n",
    "\n",
    "#gvd = tf.config.get_visible_devices()\n",
    "for j in tf.config.get_visible_devices():\n",
    "    print(j)\n",
    "# PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
    "# PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de63c0",
   "metadata": {},
   "source": [
    "# Chapter 3: ML modeling \n",
    "\n",
    "ASSUMPTION: run for datasets ESC-10, BDLib2 and US8k:\n",
    "\n",
    "* *01_Feature_extraction_exploration.ipynb*\n",
    "* *02_PreProcessing_and_ML_modeling.ipynb* \n",
    "\n",
    "And run for the new dataset US8K_AV:\n",
    "* *03_New_dataset_US8K_AV.ipynb*\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4504379",
   "metadata": {},
   "source": [
    "## Importe modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c662aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mimetypes\n",
    "import warnings\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "\n",
    "import pandas          as pd\n",
    "import numpy           as np\n",
    "import seaborn         as sns\n",
    "\n",
    "from matplotlib  import pyplot as plt\n",
    "\n",
    "from matplotlib.patches        import Patch\n",
    "from collections               import Counter\n",
    "from sklearn.model_selection   import StratifiedKFold, StratifiedShuffleSplit, KFold, learning_curve, cross_val_score\n",
    "from sklearn.feature_selection import mutual_info_classif, SelectKBest, chi2\n",
    "from sklearn                   import preprocessing\n",
    "from sklearn.linear_model      import LogisticRegression\n",
    "from sklearn.naive_bayes       import GaussianNB\n",
    "from sklearn.svm               import SVC\n",
    "from sklearn.neighbors         import KNeighborsClassifier\n",
    "from sklearn.ensemble          import RandomForestClassifier, VotingClassifier\n",
    "from sklearn                   import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution to play .ogg files in the IPython \n",
    "# https://stackoverflow.com/questions/39077987/ipython-display-audio-cannot-correctly-handle-ogg-file-type\n",
    "\n",
    "mimetypes.init()\n",
    "mimetypes.add_type('audio/ogg','.ogg')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.width', 300)\n",
    "pd.set_option('display.max_colwidth', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60052244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "current_path = os.getcwd()\n",
    "\n",
    "# For the picture names\n",
    "pic_first_name = '04_ML_modeling_'\n",
    "\n",
    "# For Librosa\n",
    "FRAME_SIZE  = 1024\n",
    "HOP_LENGTH  = 512\n",
    "SEED        = 1000\n",
    "SR          = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60734623",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53326eea",
   "metadata": {},
   "source": [
    "## Loading the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64563cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the dataset\n",
    "\n",
    "opc = 0\n",
    "while str(opc) not in '1234':\n",
    "    print()\n",
    "    print(\"1-) ESC-10\")\n",
    "    print(\"2-) BDLib2\")\n",
    "    print(\"3-) US8K\")\n",
    "    print(\"4-) US8K_AV\")\n",
    "\n",
    "\n",
    "    opc = input(\"\\nSelect the dataset: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "\n",
    "if opc == 1:\n",
    "\n",
    "    path        = os.path.join(current_path, \"_dataset\", \"ESC-10\")\n",
    "    path_pic    = os.path.join(current_path, \"ESC-10_results\")\n",
    "    path_models = os.path.join(current_path, \"ESC-10_saved_models\")\n",
    "    \n",
    "   \n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'ESC-10' \n",
    "    csv_file    = 'ESC-10.csv'\n",
    "    fold        = '1'\n",
    "\n",
    "    pkl_features           = 'ESC-10_features_original.pkl'\n",
    "    pkl_aug_features      = 'ESC-10_features_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features = 'ESC-10_features_augmented.pkl'\n",
    "\n",
    "    \n",
    "if opc == 2:\n",
    "    \n",
    "    path        = os.path.join(current_path, \"_dataset\", \"BDLib2\")\n",
    "    path_pic    = os.path.join(current_path, \"BDLib2_results\")\n",
    "    path_models = os.path.join(current_path, \"BDLib2_saved_models\")\n",
    "\n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'BDLib2' \n",
    "    csv_file    = 'BDLib2.csv'\n",
    "    fold        = 'fold-1'\n",
    "\n",
    "    pkl_features          = 'BDLib2_features_original.pkl'\n",
    "    pkl_aug_features      = 'BDLib2_features_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features = 'BDLib2_features_augmented.pkl'\n",
    "\n",
    "    \n",
    "if opc == 3:\n",
    "    \n",
    "    path        = os.path.join(current_path, \"_dataset\", \"US8K\")\n",
    "    path_pic    = os.path.join(current_path, \"US8K_results\")\n",
    "    path_models = os.path.join(current_path, \"US8K_saved_models\")\n",
    "    \n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'US8K' \n",
    "    csv_file    = 'US8K.csv'\n",
    "    fold        = '1'\n",
    "    \n",
    "    pkl_features          = 'US8K_features_original.pkl'\n",
    "    pkl_aug_features      = 'US8K_features_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features = 'US8K_features_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large\n",
    "    \n",
    "\n",
    "if opc == 4:\n",
    "\n",
    "    path        = os.path.join(current_path, \"_dataset\", \"US8K_AV\")\n",
    "    path_pic    = os.path.join(current_path, \"US8K_AV_results\")\n",
    "    path_models = os.path.join(current_path, \"US8K_AV_saved_models\")\n",
    "\n",
    "    subfolders  = next(os.walk(path))[1]\n",
    "    nom_dataset = 'US8K_AV' \n",
    "    csv_file    = 'US8K_AV.csv'\n",
    "    fold        = '1'\n",
    "\n",
    "    pkl_features          = 'US8K_AV_features_original.pkl'\n",
    "    pkl_aug_features      = 'US8K_AV_features_augmented_no_windowing.pkl'\n",
    "    pkl_aug_wind_features = 'US8K_AV_features_windowed.pkl' # augmented and windowed makes no sense. Dataset is already quite large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_file_number(folder: str):\n",
    "    files = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f)) and f.startswith(pic_first_name)]\n",
    "    if not files:\n",
    "        return 1\n",
    "    else:\n",
    "        numbers = [int(f.split('.')[0].split('_')[-1]) for f in files]\n",
    "        return max(numbers) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f01f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MT_loadDataset import loadDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290e5f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadDataset = loadDataset(path)\n",
    "DB          = loadDataset.db_B\n",
    "\n",
    "print(\"\\nClasses:\\n--------------------\")\n",
    "print(DB[\"Class_categorical\"].value_counts())\n",
    "print(\"\\nTotal number of unique files..........: \", len(np.unique(DB[\"File_name\"])))\n",
    "print(\"Total number of AUDIO files...........: \", len(DB))\n",
    "DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da5133",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28674adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of the class balancing\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "gTitle = f'{nom_dataset} - Number of classes = ' + str(len(pd.Series(DB['Class_categorical']).unique()))\n",
    "g = sns.displot(DB,x='Class_categorical', hue='Class_categorical',height = 5, aspect = 2).set(title=gTitle)\n",
    "g.set_xticklabels(rotation=90)\n",
    "g.set_titles('Number of classes')\n",
    "\n",
    "# Retrieve the axes object from the plot\n",
    "axes = g.ax\n",
    "\n",
    "# Iterate over each bar in the plot\n",
    "for p in axes.patches:\n",
    "    # Get the coordinates of the bar\n",
    "    width = p.get_width()\n",
    "    height = p.get_height()\n",
    "    cord_x, cord_y = p.get_xy()\n",
    "    if height > 0:\n",
    "        axes.annotate(f'{height}', (cord_x + width/2, cord_y + height), ha='center')\n",
    "        \n",
    "g._legend.remove()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2012816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pkl file with the augmented features extracted\n",
    "\n",
    "opc = 0\n",
    "while str(opc) not in '123':\n",
    "    print()\n",
    "    print(\"1-) Features original\")\n",
    "    print(\"2-) Features augmented\")\n",
    "    print(\"3-) Features augmented and windowed (US8K only windowed)\")\n",
    "\n",
    "    opc = input(\"\\nSelect the dataset: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "\n",
    "if opc == 1:\n",
    "    DB_from_pkl   = pd.read_pickle(os.path.join(path_models, pkl_features))\n",
    "    model_surname = '_original'\n",
    "\n",
    "if opc == 2:\n",
    "    DB_from_pkl   = pd.read_pickle(os.path.join(path_models, pkl_aug_features))\n",
    "    model_surname = '_augmented'\n",
    "\n",
    "if opc == 3:\n",
    "    DB_from_pkl = pd.read_pickle(os.path.join(path_models, pkl_aug_wind_features))\n",
    "    model_surname = '_windowed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005d7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8734c954",
   "metadata": {},
   "source": [
    "## Input split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9fa9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate 1 fold for validation and create a DB for the training / testing according to the datasets specification\n",
    "\n",
    "DB_from_pkl_VAL = DB_from_pkl[DB_from_pkl['Fold'] == fold].copy()\n",
    "DB_from_pkl_TRN = DB_from_pkl[DB_from_pkl['Fold'] != fold].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(DB_from_pkl_VAL))\n",
    "print(len(DB_from_pkl_TRN))\n",
    "print('Total: ', len(DB_from_pkl_VAL) + len(DB_from_pkl_TRN),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl_VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fdd6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_from_pkl_TRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47130220",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in DB_from_pkl_TRN.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e81deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating data and labels\n",
    "\n",
    "X      = DB_from_pkl_TRN.drop(columns=['Audio','Class_categorical','Class_OHEV', 'Fold'])\n",
    "y      = np.array(DB_from_pkl_TRN.Class_categorical.to_list())\n",
    "y_OHEV = np.array(DB_from_pkl_TRN.Class_OHEV.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the augmented dataset (only validation set)\n",
    "\n",
    "X_val      = DB_from_pkl_VAL.drop(columns=['Audio','Class_categorical','Class_OHEV', 'Fold'])\n",
    "y_val      = np.array(DB_from_pkl_VAL.Class_categorical.to_list())\n",
    "y_OHEV_val = np.array(DB_from_pkl_VAL.Class_OHEV.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c2c03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3333e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b12329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd97c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = X.apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e07ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard = X.apply(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a32a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08a37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = X_norm.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d6e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard = X_standard.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb463ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c3a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4928f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c4fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eaa2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ec10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee7320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e31f47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8acb1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_norm = X_val.apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a789557",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_standard = X_val.apply(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7786c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_norm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ce969",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_standard.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f94c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_norm = X_val_norm.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ceefca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_standard = X_val_standard.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f47a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_standard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380823f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfdaf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter_val = Counter(y_val)\n",
    "Counter_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be74f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the class and get one random sample of each class\n",
    "k = DB_from_pkl.groupby('Class_categorical')['Class_OHEV'].apply(lambda s: s.sample(1))\n",
    "print(k)\n",
    "\n",
    "# Convert the pandas series into a dataframe\n",
    "temp_k_df = k.reset_index()\n",
    "\n",
    "# Delete the index from the grouppby result\n",
    "del temp_k_df['level_1']\n",
    "\n",
    "# Set the \"Class\" as the dataframe index\n",
    "temp_k_df.set_index(\"Class_categorical\", inplace=True)\n",
    "\n",
    "# Convert the dataframe to a dictionary (Class: Class_encoder)\n",
    "encoder_dict = temp_k_df[\"Class_OHEV\"].to_dict()\n",
    "encoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655ad008",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_classes = list(encoder_dict.keys())\n",
    "nom_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0361ab3",
   "metadata": {},
   "source": [
    "## StratifiedKFold\n",
    "\n",
    "It is used for performing stratified k-fold cross-validation. It divides your dataset into 'k' equal-sized folds while ensuring that each fold maintains the same class distribution as the original dataset. This technique is valuable when you have a limited amount of data, and you want to maximize the use of your data for training and testing by creating multiple train-test splits.\n",
    "\n",
    "Key points about StratifiedKFold:\n",
    "\n",
    "- It's typically used for model evaluation, especially when you have a small dataset.\n",
    "- You specify the number of folds (n_splits), and it creates 'k' folds with each fold maintaining the class distribution.\n",
    "- It's used in conjunction with cross-validation functions like cross_val_score or cross_validate to assess your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ff7df",
   "metadata": {},
   "source": [
    "## StratifiedShuffleSplit \n",
    "\n",
    "It is primarily used for creating random train-test splits while ensuring that the class distribution is maintained in both the training and testing sets. This is particularly useful when you have a relatively large dataset and want to create multiple random splits to evaluate your model's performance or perform hyperparameter tuning.\n",
    "\n",
    "Key points about StratifiedShuffleSplit:\n",
    "\n",
    "- It randomly shuffles the data and splits it into train and test sets, preserving the class distribution.\n",
    "- You specify the number of splits (n_splits), the test set size or proportion (test_size), and can optionally set a random seed for reproducibility.\n",
    "- It's commonly used for tasks like model evaluation, cross-validation, and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d29587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS  = 5\n",
    "cmap_data = plt.cm.viridis\n",
    "cmap_cv   = plt.cm.coolwarm\n",
    "cmap_cm   = plt.cm.Blues\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits = N_SPLITS, test_size=0.1, random_state=100)\n",
    "skf = StratifiedKFold(n_splits = N_SPLITS, random_state=None, shuffle=False)\n",
    "kfd = KFold(N_SPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a50279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a92ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea68c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb9da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the train / test split\n",
    "for idx_trn, idx_tst in sss.split(X_norm, y):\n",
    "    X_train      = X_norm[idx_trn]\n",
    "    X_test       = X_norm[idx_tst]\n",
    "    y_train      = y[idx_trn]\n",
    "    y_test       = y[idx_tst]\n",
    "    y_train_OHEV = y_OHEV[idx_trn]\n",
    "    y_test_OHEV  = y_OHEV[idx_tst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ed20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_test))\n",
    "print(np.shape(y_train_OHEV))\n",
    "print(np.shape(y_test_OHEV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e867670",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8969e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e8f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_OHEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in y_test:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e01a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d785c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_counter_test = Counter(y_test)\n",
    "list_counter_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_counter_test_OHEV = Counter(map(tuple, y_test_OHEV))\n",
    "list_counter_test_OHEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab804d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_counter_train = Counter(y_train)\n",
    "list_counter_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba9e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_counter_train_OHEV = Counter(map(tuple, y_train_OHEV))\n",
    "list_counter_train_OHEV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba75e3b",
   "metadata": {},
   "source": [
    "### Mutual information\n",
    "\n",
    "Mutual information is calculated between two variables and measures the reduction in uncertainty for one variable given a known value of the other variable.\n",
    "\n",
    "A quantity called mutual information measures the amount of information one can obtain from one random variable given another.\n",
    "\n",
    "The mutual information between two random variables X and Y can be stated formally as follows:\n",
    "\n",
    "\\begin{aligned}\n",
    "I(X ; Y) = H(X) – H(X | Y)\n",
    "\\end{aligned}\n",
    "\n",
    "Where $I(X ; Y)$ is the mutual information for $X$ and $Y$, $H(X)$ is the entropy for $X$ and $H(X | Y)$ is the conditional entropy for $X$ given $Y$. The result has the units of bits. Since mutual information is a measure of dependence or “mutual dependence” between two random variables, the result measure is symmetrical, meaning that $I(X ; Y) = I(Y ; X)$.\n",
    "\n",
    "\\begin{aligned}\n",
    "E=-\\sum_i^C p_i \\log _2 p_i\n",
    "\\end{aligned}\n",
    "\n",
    "Where $p_i$ is the probability of randomly picking an element of class $i$ (i.e. the proportion of the dataset made up of class $i$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4f813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute the mutual information\n",
    "\n",
    "mutual_info = mutual_info_classif(X_norm, y)\n",
    "mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info       = pd.Series(mutual_info)\n",
    "mutual_info.index = X.columns\n",
    "mutual_info.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27813a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.mean(mutual_info.sort_values(ascending=False))\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mutual = sum(1 for element in mutual_info if element > threshold)\n",
    "count_mutual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab8d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the sorted features based on their mutual information calculation\n",
    "\n",
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize=(20, 8))\n",
    "plt.title(nom_dataset + model_surname + ' - Mutual information for ' + str(len(mutual_info)) + ' features', fontsize = 14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2e9a6",
   "metadata": {},
   "source": [
    "### Backup for experiments using *n* relevant features\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/10/feature-selection-techniques-in-machine-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f39d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_selector = SelectKBest(chi2, k=count_mutual).fit(X_norm, y)\n",
    "f = chi2_selector.get_support(1)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c5c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores the indexes for future use\n",
    "f.tofile(os.path.join(path_models, '_mutual_idx_' + nom_dataset + model_surname + '.csv'), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d156ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X[X.columns[f]] # final features\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd23922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutual_info (X: pd.DataFrame, X_norm: list, y: list):\n",
    "    \n",
    "    mutual_info = mutual_info_classif(X_norm, y)\n",
    "    mutual_info = pd.Series(mutual_info)\n",
    "    mutual_info.index = X.columns\n",
    "    mutual_info.sort_values(ascending=False)\n",
    "    \n",
    "    threshold = np.mean(mutual_info.sort_values(ascending=False))\n",
    "    print(f' Threshold: {threshold}')\n",
    "    \n",
    "    count_mutual = sum(1 for element in mutual_info if element > threshold)\n",
    "    print(f' Count mutual: {count_mutual}')\n",
    "    \n",
    "    chi2_selector = SelectKBest(chi2, k=count_mutual).fit(X_norm, y)\n",
    "    f = chi2_selector.get_support(1)\n",
    "    \n",
    "    X_mutual = X[X.columns[f]] # final features\n",
    "\n",
    "    return X_mutual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f30ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mutual = get_mutual_info(X, X_norm, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_k_best = mutual_info_classif(X_new, y)\n",
    "mutual_info_k_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66ccd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_k_best       = pd.Series(mutual_info_k_best)\n",
    "mutual_info_k_best.index = X_new.columns\n",
    "mutual_info_k_best.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa43a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the sorted features based on their mutual information calculation\n",
    "\n",
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "mutual_info_k_best.sort_values(ascending=False).plot.bar(figsize=(20, 8))\n",
    "plt.title(nom_dataset + model_surname + ' - Mutual information for ' + str(len(mutual_info_k_best)) + ' features', fontsize = 14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d89236",
   "metadata": {},
   "source": [
    "### Remark: by selection the features, re-nornamalize the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcbf781",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bee6bf",
   "metadata": {},
   "source": [
    "### Plotting the Pearson's correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42649bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X.corr(method='pearson')\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f654d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "opc = 0\n",
    "while str(opc) not in '12':\n",
    "    print()\n",
    "    print(\"1-) Print Pearson\\'s correlation heatmap.\")\n",
    "    print(\"2-) Skip printing.\")\n",
    "\n",
    "    opc = input(\"\\nSelect the dataset: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "    \n",
    "    if opc == 1:\n",
    "        picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "        plt.figure(figsize=(40, 40))\n",
    "        plt.title(f'{nom_dataset} - Pearson\\'s correlation heatmap', fontsize = 16)\n",
    "        a = sns.heatmap(corr_matrix, \n",
    "                        square=True, \n",
    "                        annot=True, \n",
    "                        fmt='.1f', \n",
    "                        linecolor='black', \n",
    "                        cbar_kws={\"shrink\": .80},\n",
    "                        annot_kws={\"fontsize\":6})\n",
    "        a.set_xticklabels(a.get_xticklabels(), fontsize=7)\n",
    "        a.set_yticklabels(a.get_yticklabels(), fontsize=7) \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(path_pic, picture_name))\n",
    "        plt.show()\n",
    "    \n",
    "    if opc == 2:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc2a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método para visualizar a divisão do teste / treino por meio de K Fold e Stratified K Fold\n",
    "\n",
    "def visualizar_Kfold(dataset, cv, X, y, n_splits):\n",
    "    \n",
    "    picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "    \n",
    "    sns.set_style(\"darkgrid\")\n",
    "    \n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    y_enc = label_encoder.fit_transform(y)\n",
    "    y_enc = np.sort(y_enc)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Cria a visualização do treino / test para cada divisão do CV\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y_enc)):\n",
    "        \n",
    "        # Preenche os índices com os valores do treino / teste\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualiza os resultados\n",
    "        ax.scatter(range(len(indices)),\n",
    "                   [ii + 0.5] * len(indices),\n",
    "                   c=indices,\n",
    "                   marker=\"_\",\n",
    "                   lw=25,\n",
    "                   cmap=cmap_cv,\n",
    "                   vmin=-0.2,\n",
    "                   vmax=1.2)\n",
    "\n",
    "    # Imprime a linha das classes no final\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X), c=y_enc, marker=\"_\", lw=40, cmap=cmap_data)\n",
    "\n",
    "\n",
    "    # Formatação\n",
    "    yticklabels = list(range(n_splits)) + [\"Classes\"]\n",
    "    ax.set(yticks=np.arange(n_splits + 1) + 0.5,\n",
    "           yticklabels=yticklabels,\n",
    "           ylim=[n_splits + 1.0, 0.0],\n",
    "           xlim=[0, len(y_enc)])\n",
    "    \n",
    "    ax.set_xlabel('Samples', fontsize=12)\n",
    "    ax.set_ylabel('CV iterations', fontsize=12)\n",
    "    ax.set_title(\"{}\".format(type(cv).__name__) + \" \" + dataset, fontsize=15)\n",
    "    \n",
    "    ax.legend([Patch(color=cmap_cv(0.8)), \n",
    "               Patch(color=cmap_cv(0.02))],\n",
    "              [\"Validation set\", \"Training set\"],\n",
    "              loc=(1.02, 0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_pic, picture_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza a divisão do treino / teste por meio do Stratified K Fold\n",
    "\n",
    "print(sss)\n",
    "print(skf)\n",
    "print(kfd)\n",
    "print()\n",
    "\n",
    "visualizar_Kfold(nom_dataset, skf, X_norm, y, N_SPLITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0504cb8",
   "metadata": {},
   "source": [
    "## ML Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bcd7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del DB_from_pkl_VAL, DB_from_pkl_TRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06577b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate 1 fold for validation and create a DB for the training / testing\n",
    "\n",
    "opc = 0\n",
    "while str(opc) not in '12':\n",
    "    print()\n",
    "    print(\"1-) Normalization\")\n",
    "    print(\"2-) Standardization\")\n",
    "\n",
    "    opc = input(\"\\nSelect the dataset: \")\n",
    "    if opc.isdigit():\n",
    "        opc = int(opc)\n",
    "    else:\n",
    "        opc = 0\n",
    "\n",
    "\n",
    "    DB_from_pkl_VAL = DB_from_pkl[DB_from_pkl['Fold'] == fold].copy()\n",
    "    DB_from_pkl_TRN = DB_from_pkl[DB_from_pkl['Fold'] != fold].copy()\n",
    "    \n",
    "    X      = DB_from_pkl_TRN.drop(columns=['Audio','Class_categorical','Class_OHEV', 'Fold'])\n",
    "    y      = np.array(DB_from_pkl_TRN.Class_categorical.to_list())\n",
    "    y_OHEV = np.array(DB_from_pkl_TRN.Class_OHEV.to_list())\n",
    "\n",
    "    X_val      = DB_from_pkl_VAL.drop(columns=['Audio','Class_categorical','Class_OHEV', 'Fold'])\n",
    "    y_val      = np.array(DB_from_pkl_VAL.Class_categorical.to_list())\n",
    "    y_OHEV_val = np.array(DB_from_pkl_VAL.Class_OHEV.to_list())\n",
    "\n",
    "    X_statistics = pd.DataFrame({'mean': X.mean(), 'std': X.std(), 'min': X.min(), 'max': X.max()})\n",
    "\n",
    "    X_mean   = X_statistics.values[:, 0]\n",
    "    X_std    = X_statistics.values[:, 1]\n",
    "    X_min    = X_statistics.values[:, 2]\n",
    "    X_max    = X_statistics.values[:, 3]\n",
    "    \n",
    "    # Normalization or standardization using values from the training set.\n",
    "    if opc == 1:\n",
    "        X_norm     = (X.values - X_min) / (X_max - X_min)\n",
    "        X_val_norm = (X_val.values - X_min) / (X_max - X_min)\n",
    "        norm_type  = '_norm'\n",
    "\n",
    "    if opc == 2:\n",
    "        X_norm     = (X.values - X_mean) / X_std\n",
    "        X_val_norm = (X_val.values - X_mean) / X_std\n",
    "        norm_type  = '_std'\n",
    "        \n",
    "    # Separated training and testing for hyperparameter cross-validation (10% testing).\n",
    "    # Testing was not used in this notebook, but it was in the neural networks. In order to achieve a fair comparisson,\n",
    "    # the same number of samples for training were considered in both notebooks.\n",
    "\n",
    "    for idx_trn, idx_tst in sss.split(X_norm, y):\n",
    "        X_train      = X_norm[idx_trn]\n",
    "        X_test       = X_norm[idx_tst]\n",
    "        y_train      = y[idx_trn]\n",
    "        y_test       = y[idx_tst]\n",
    "        y_train_OHEV = y_OHEV[idx_trn]\n",
    "        y_test_OHEV  = y_OHEV[idx_tst]\n",
    "        \n",
    "        # Stores the indexes for future use\n",
    "        idx_trn.tofile(os.path.join(path_models, '_idx_trn_' + nom_dataset + model_surname + '.csv'), sep=',')\n",
    "        idx_tst.tofile(os.path.join(path_models, '_idx_tst_' + nom_dataset + model_surname + '.csv'), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e5b941",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n==================================\")\n",
    "print(\"Training set\\n\")\n",
    "\n",
    "print(f'X_train.........: {np.shape(X_train)}')\n",
    "print(f'y_train.........: {np.shape(y_train)}')\n",
    "print(f'y_train_OHEV....: {np.shape(y_train_OHEV)}')\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Testing set\\n\")\n",
    "\n",
    "print(f'X_test..........: {np.shape(X_test)}')\n",
    "print(f'y_test..........: {np.shape(y_test)}')\n",
    "print(f'y_test_OHEV.....: {np.shape(y_test_OHEV)}')\n",
    "\n",
    "print(\"\\n==================================\")\n",
    "print(\"Validation set\\n\")\n",
    "\n",
    "print(f'X_val_norm......: {np.shape(X_val_norm)}')\n",
    "print(f'y_val...........: {np.shape(y_val)}')\n",
    "print(f'y_OHEV_val......: {np.shape(y_OHEV_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9cab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple confusion matrix\n",
    "\n",
    "def simple_conf_matrix(y_true, y_pred, nom_classes, clf, acc):\n",
    "    \n",
    "    picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "    conf_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "    title = nom_dataset + model_surname + norm_type + ' - Classifier ' + clf + ' - Validation accuracy: '+ str(\"{:0.2f} %\".format(acc*100))\n",
    "\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sns.heatmap(conf_matrix, \n",
    "                annot=True, \n",
    "                fmt='g', \n",
    "                cmap=cmap_cm, \n",
    "                annot_kws={\"size\": 8}, \n",
    "                xticklabels=nom_classes, \n",
    "                yticklabels=nom_classes)\n",
    "    plt.title(title, fontsize = 12)\n",
    "    plt.savefig(os.path.join(path_pic, picture_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, title, cmap, normalize):\n",
    "\n",
    "    picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "    if labels is not None:\n",
    "        tick_marks = np.arange(len(labels))\n",
    "        plt.xticks(tick_marks, labels, fontsize=10, rotation=45)\n",
    "        plt.yticks(tick_marks, labels, fontsize=10)\n",
    "   \n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    \n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 8)\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 8)\n",
    "\n",
    "    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n",
    "    plt.title(title, fontsize=13)\n",
    "    plt.colorbar(shrink=1)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.grid(None)\n",
    "    plt.savefig(os.path.join(path_pic, picture_name))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15571e04",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240cc9bf",
   "metadata": {},
   "source": [
    "- **Gaussian Naive Bayes** (GaussianNB) is a probabilistic machine learning algorithm mainly used for classification tasks based on the Naive Bayes theorem and assumes that features are independent and follow a Gaussian (normal) distribution. GaussianNB is particularly suitable for datasets with continuous or real-valued features. It calculates the probabilities of different classes for a given set of input features and assigns the class with the highest probability as the predicted class. Despite its simplifying assumption of feature independence (which is often not met in practice), GaussianNB performs surprisingly well in various real-world applications, such as text classification and spam email detection, due to its simplicity and efficiency. \n",
    "***\n",
    "- The **Support Vector Classifier** (SVC)  is a supervised machine learning algorithm that is primarily used for classification tasksby finding the optimal hyperplane that best separates different classes in the input data. It does this by identifying support vectors, which are the data points closest to the decision boundary. SVC aims to maximize the margin between these support vectors and the decision boundary, making it robust to outliers and capable of handling non-linear data through the use of kernel functions. The algorithm allows for multi-class classification and can be fine-tuned through various parameters like the choice of kernel, regularization strength (C), and kernel-specific parameters. \n",
    "***\n",
    "- **Logistic Regression** is a supervised machine learning algorithm that's primarily employed for binary classification tasks, though it can be extended to handle multiclass classification as well. Despite its name, it's used for classification, not regression. Logistic Regression models the probability of an instance belonging to a particular class as a logistic function of the input features. It's particularly well-suited for linearly separable data, where it tries to find a linear decision boundary that separates the two classes. Regularization techniques like L1 and L2 can be applied to prevent overfitting, while logistic regression assumes a linear relationship between features and the log-odds of the target variable, it can be effective in many practical scenarios and serves as a fundamental building block for more complex models in machine learning.\n",
    "***\n",
    "- The **k-Nearest Neighbors** (KNN) algorithm is a simple supervised machine learning technique used primarily for classification and regression tasks. In KNN, a data point's class or value is determined by the majority class or average of its k-nearest neighbors in the feature space. It operates under the assumption that similar data points tend to have similar class labels or target values. The choice of the \"k\" parameter determines how many neighboring data points are considered when making predictions; a smaller k value leads to more localized decision boundaries, while a larger k value results in smoother, global boundaries. KNN is a non-parametric algorithm, meaning it doesn't make assumptions about the underlying data distribution but it can be computationally expensive for large datasets and may require proper feature scaling and distance metric selection to perform optimally.\n",
    "***\n",
    "- **Random Forest** is an ensemble machine learning algorithm used for both classification and regression tasks. It's based on the concept of decision trees, but it builds multiple trees and combines their predictions to improve accuracy and reduce overfitting. In a Random Forest, a random subset of the training data and a random subset of the features are used to grow each tree. This randomness helps create diverse trees that collectively make more robust predictions. During classification, the algorithm aggregates the votes from individual trees, and for regression, it averages their predictions. Random Forest is known for its high accuracy, ability to handle large datasets with many features, and resistance to overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608a3f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curve for the classifier\n",
    "\n",
    "def plot_learning_curve(train_sizes, train_mean, train_std, test_mean, test_std, classifier):\n",
    "\n",
    "    picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "\n",
    "    plt.figsize=(30, 30)\n",
    "    plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')\n",
    "    plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "    plt.plot(train_sizes, test_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation Accuracy')\n",
    "    plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "    plt.title(nom_dataset + model_surname + norm_type + ' - Learning curve for ' + classifier)\n",
    "    plt.xlabel('Training data size')\n",
    "    plt.ylabel('Model accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(path_pic, picture_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9027b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_c = GaussianNB()\n",
    "NB_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c619e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator = NB_c, X = X_train, y = y_train,\n",
    "                                                        cv = 5, train_sizes = np.linspace(0.1, 1.0, 10),\n",
    "                                                        n_jobs = -1, verbose = 10)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std  = np.std(train_scores, axis=1)\n",
    "test_mean  = np.mean(test_scores, axis=1)\n",
    "test_std   = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(train_sizes, \n",
    "                    train_mean, \n",
    "                    train_std, \n",
    "                    test_mean, \n",
    "                    test_std, \n",
    "                    'Naïve Bayes')\n",
    "\n",
    "print(f\"{train_sizes} samples were used to train the model\\n\")\n",
    "print(f\"The average train accuracy is....: {train_scores.mean()*100:.2f} % (+/-{train_std.mean()*100:.2f} %)\")\n",
    "print(f\"The average test accuracy is.....: {test_scores.mean()*100:.2f} % (+/-{test_std.mean()*100:.2f} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef6cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_c.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df979123",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_c_predict = NB_c.predict(X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa0a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier to file in the current working directory\n",
    "\n",
    "pkl_filename = \"Model_GaussianNB\" + norm_type + model_surname + \".pkl\"\n",
    "with open(os.path.join(path_models, pkl_filename), 'wb') as file:\n",
    "    pickle.dump(NB_c, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302afcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier from file\n",
    "\n",
    "with open(os.path.join(path_models, pkl_filename), 'rb') as file:\n",
    "    NB_c_saved = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b2b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_NB_c_saved = NB_c_saved.score(X_val_norm, y_val)\n",
    "print(\"Test score (R2): {0:.2f} %\".format(100 * score_NB_c_saved))\n",
    "NB_c_saved_predict = NB_c_saved.predict(X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91196f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_srt = time.process_time_ns()\n",
    "\n",
    "NB_c_saved_predict_val = NB_c_saved.predict(X_val_norm)\n",
    "\n",
    "t_end = time.process_time_ns()\n",
    "tempoProc = ((t_end - t_srt) / 1000000)\n",
    "print(\"Processing time:\", ('%.4f' % tempoProc).replace('.', ','), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b4dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBC_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                             NB_c_saved_predict_val, \n",
    "                                                             target_names = nom_classes, \n",
    "                                                             output_dict = False)\n",
    "print(NBC_c_saved_val_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2964fbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NBC_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                             NB_c_saved_predict_val, \n",
    "                                                             target_names = nom_classes, \n",
    "                                                             output_dict = True)\n",
    "\n",
    "NBC_c_saved_val_class_report_acc = NBC_c_saved_val_class_report['accuracy']\n",
    "print(NBC_c_saved_val_class_report_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c49d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(NB_c_predict, NB_c_saved_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb97229",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conf_matrix(y_val, \n",
    "                   NB_c_saved_predict_val, \n",
    "                   nom_classes,\n",
    "                   'Naïve Bayes',\n",
    "                   NBC_c_saved_val_class_report_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c671d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_sample(array1, array2):\n",
    "    # Check if both arrays have the same length\n",
    "    if len(array1) != len(array2):\n",
    "        raise ValueError(\"Arrays must have the same length\")\n",
    "\n",
    "    # Select a random index\n",
    "    random_index = random.randint(0, len(array1) - 1)\n",
    "    print(random_index)\n",
    "\n",
    "    # Get the sample from the first array and the associated element from the second array\n",
    "    sample = array1[random_index]\n",
    "    associated_element = array2[random_index]\n",
    "\n",
    "    # Return the result as a tuple\n",
    "    return (sample, associated_element, random_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e8973",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_sample = get_random_sample(y_val, X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05719a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_sample(model, data_label, data, nom_classes):\n",
    "    \n",
    "    random_sample = get_random_sample(data_label, data)\n",
    "    \n",
    "    print(random_sample[0])\n",
    "    predict_sample = model.predict([random_sample[1]])[0]\n",
    "\n",
    "    predict_sample_proba = model.predict_proba([random_sample[1]])\n",
    "    print(predict_sample)\n",
    "    \n",
    "    if random_sample[0] == predict_sample:\n",
    "        predict_col = 'g'\n",
    "    else:\n",
    "        predict_col = 'r'\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize = (16,6))\n",
    "    plt.bar(nom_classes, predict_sample_proba[0], color = predict_col, alpha = 0.5)\n",
    "    plt.xlabel('Classes')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('Probabilities')\n",
    "    plt.title(f'Prediction for sample: {random_sample[0]}', fontsize = 14)\n",
    "    plt.show()\n",
    "    return random_sample[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fcbfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = plot_pred_sample(NB_c_saved, y_val, X_val_norm, nom_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19623ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_val[random_index])\n",
    "print(NB_c_saved.predict([X_val_norm[random_index]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing hyperparameters for SVC classifier - After several test, the hyperparameters were set\n",
    "\n",
    "#SVC_hp = {'kernel':['linear', 'poly', 'rbf', 'sigmoid'], \n",
    "#          'degree': [9, 15, 20],\n",
    "#          'C':[0.010, 0.030, 0.1, 0.2, 0.5], \n",
    "#          'probability': [True, False],\n",
    "#          'random_state': [SEED]}\n",
    "\n",
    "#grid_SVC = GridSearchCV(SVC(), SVC_hp, refit = True, verbose=3)\n",
    "\n",
    "#grid_SVC.fit(X_train, y_train)\n",
    "\n",
    "#print(\" Results from Grid Search in the SVC classifier \" )\n",
    "#print(\"\\n The best estimator across ALL searched params....:\\n\",grid_SVC.best_estimator_)\n",
    "#print(\"\\n The best score across ALL searched params........:\\n\",grid_SVC.best_score_)\n",
    "#print(\"\\n The best parameters across ALL searched params...:\\n\",grid_SVC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0cd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_SVC.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3decce8",
   "metadata": {},
   "source": [
    "{'C': 0.5,\n",
    " 'degree': 9,\n",
    " 'kernel': 'linear',\n",
    " 'probability': True,\n",
    " 'random_state': 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33c2414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree = degree of the polynomial kernel function (‘poly’). Must be non-negative. Ignored by all other kernels.\n",
    "\n",
    "SVC_c = SVC(kernel       = 'linear',\n",
    "            degree       = 9,  \n",
    "            C            = 0.5, \n",
    "            probability  = True, \n",
    "            random_state = SEED,\n",
    "            verbose      = True)\n",
    "SVC_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator = SVC_c, X = X_train, y = y_train,\n",
    "                                                        cv = 5, train_sizes = np.linspace(0.2, 1.0, 10),\n",
    "                                                        n_jobs = -1, verbose = 10)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std  = np.std(train_scores, axis=1)\n",
    "test_mean  = np.mean(test_scores, axis=1)\n",
    "test_std   = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3361a2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(train_sizes, \n",
    "                    train_mean, \n",
    "                    train_std, \n",
    "                    test_mean, \n",
    "                    test_std, \n",
    "                    'SVC')\n",
    "\n",
    "print(f\"{train_sizes} samples were used to train the model\\n\")\n",
    "print(f\"The average train accuracy is....: {train_scores.mean()*100:.2f} % (+/-{train_std.mean()*100:.2f} %)\")\n",
    "print(f\"The average test accuracy is.....: {test_scores.mean()*100:.2f} % (+/-{test_std.mean()*100:.2f} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd270cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_c.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288cb512",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_c_predict = SVC_c.predict(X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca947a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier to file in the current working directory\n",
    "\n",
    "pkl_filename = \"Model_SVC\" + norm_type + model_surname + \".pkl\"\n",
    "with open(os.path.join(path_models, pkl_filename), 'wb') as file:\n",
    "    pickle.dump(SVC_c, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920dca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier from file\n",
    "\n",
    "with open(os.path.join(path_models, pkl_filename), 'rb') as file:\n",
    "    SVC_c_saved = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee1eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_SVC_c_saved = SVC_c_saved.score(X_val_norm, y_val)\n",
    "print(\"Test score (R2): {0:.2f} %\".format(100 * score_SVC_c_saved))\n",
    "SVC_c_saved_predict = SVC_c_saved.predict(X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd63fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_srt = time.process_time_ns()\n",
    "\n",
    "SVC_c_saved_predict_val = SVC_c_saved.predict(X_val_norm)\n",
    "2\n",
    "t_end = time.process_time_ns()\n",
    "tempoProc = ((t_end - t_srt) / 1000000)\n",
    "print(\"Processing time:\", ('%.4f' % tempoProc).replace('.', ','), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20abbf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                             SVC_c_saved_predict_val, \n",
    "                                                             target_names = nom_classes, \n",
    "                                                             output_dict = False)\n",
    "print(SVC_c_saved_val_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                             SVC_c_saved_predict_val, \n",
    "                                                             target_names = nom_classes, \n",
    "                                                             output_dict = True)\n",
    "SVC_c_saved_val_class_report_acc = SVC_c_saved_val_class_report['accuracy']\n",
    "SVC_c_saved_val_class_report_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f81356",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(SVC_c_predict, SVC_c_saved_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750792a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conf_matrix(y_val, \n",
    "                   SVC_c_saved_predict_val, \n",
    "                   nom_classes,\n",
    "                   'SVC',\n",
    "                   SVC_c_saved_val_class_report_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449d1800",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = plot_pred_sample(SVC_c_saved, y_val, X_val_norm, nom_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f62bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_index)\n",
    "print(y_val[random_index])\n",
    "print(SVC_c_saved.predict([X_val_norm[random_index]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99c0965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing hyperparameters for Logistic Regression classifier - After several test, the hyperparameters were set\n",
    "\n",
    "#LogisticR_hp = {'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'], \n",
    "#                'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "#                'max_iter':[100, 150, 200, 500],\n",
    "#                'C':[0.010, 0.030, 0.1, 0.2, 0.5]}\n",
    "\n",
    "#grid_LogisticR = GridSearchCV(LogisticRegression(), LogisticR_hp, refit = True, verbose=3)\n",
    "\n",
    "#grid_LogisticR.fit(X_train, y_train)\n",
    "\n",
    "#print(\" Results from Grid Search in the Logistic Regression classifier \" )\n",
    "#print(\"\\n The best estimator across ALL searched params....:\\n\",grid_LogisticR.best_estimator_)\n",
    "#print(\"\\n The best score across ALL searched params........:\\n\",grid_LogisticR.best_score_)\n",
    "#print(\"\\n The best parameters across ALL searched params...:\\n\",grid_LogisticR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde6e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_LogisticR.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6608237d",
   "metadata": {},
   "source": [
    "{'C': 0.03, 'max_iter': 150, 'penalty': None, 'solver': 'saga'}\n",
    "\n",
    "Higher C and max_iter actually produced better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229cc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticR_c = LogisticRegression(solver    = 'saga', \n",
    "                                 C         = 0.5, \n",
    "                                 max_iter  = 500,\n",
    "                                 verbose   = 10,\n",
    "                                 n_jobs    = -1)\n",
    "LogisticR_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec542039",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator = LogisticR_c, X = X_train, y = y_train,\n",
    "                                                        cv = 5, train_sizes = np.linspace(0.2, 1.0, 10),\n",
    "                                                        n_jobs = -1, verbose = 10)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std  = np.std(train_scores, axis=1)\n",
    "test_mean  = np.mean(test_scores, axis=1)\n",
    "test_std   = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c3e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(train_sizes, \n",
    "                    train_mean, \n",
    "                    train_std, \n",
    "                    test_mean, \n",
    "                    test_std, \n",
    "                    'Logistic regression')\n",
    "\n",
    "print(f\"{train_sizes} samples were used to train the model\\n\")\n",
    "print(f\"The average train accuracy is....: {train_scores.mean()*100:.2f} % (+/-{train_std.mean()*100:.2f} %)\")\n",
    "print(f\"The average test accuracy is.....: {test_scores.mean()*100:.2f} % (+/-{test_std.mean()*100:.2f} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a334a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticR_c.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c495324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticR_c_predict = LogisticR_c.predict(X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier to file in the current working directory\n",
    "\n",
    "pkl_filename = \"Model_LogisticR\" + norm_type + model_surname + \".pkl\"\n",
    "with open(os.path.join(path_models, pkl_filename), 'wb') as file:\n",
    "    pickle.dump(LogisticR_c, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31550800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier from file\n",
    "\n",
    "with open(os.path.join(path_models, pkl_filename), 'rb') as file:\n",
    "    LogisticR_c_saved = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a321417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_LogisticR_c_saved = LogisticR_c_saved.score(X_val_norm, y_val)\n",
    "print(\"Test score (R2): {0:.2f} %\".format(100 * score_LogisticR_c_saved))\n",
    "LogisticR_c_saved_predict = LogisticR_c_saved.predict(X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bde08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_srt = time.process_time_ns()\n",
    "\n",
    "LogisticR_c_saved_predict_val = LogisticR_c_saved.predict(X_val_norm)\n",
    "\n",
    "t_end = time.process_time_ns()\n",
    "tempoProc = ((t_end - t_srt) / 1000000)\n",
    "print(\"Processing time:\", ('%.4f' % tempoProc).replace('.', ','), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df314fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticR_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                                   LogisticR_c_saved_predict_val, \n",
    "                                                                   target_names = nom_classes, \n",
    "                                                                   output_dict = False)\n",
    "print(LogisticR_c_saved_val_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4dac88",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticR_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                                   LogisticR_c_saved_predict_val, \n",
    "                                                                   target_names = nom_classes, \n",
    "                                                                   output_dict = True)\n",
    "LogisticR_c_saved_val_class_report_acc = LogisticR_c_saved_val_class_report['accuracy']\n",
    "LogisticR_c_saved_val_class_report_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a98338",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(LogisticR_c_predict, LogisticR_c_saved_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a40c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conf_matrix(y_val, \n",
    "                   LogisticR_c_saved_predict_val, \n",
    "                   nom_classes,\n",
    "                   'Logistic regression',\n",
    "                   LogisticR_c_saved_val_class_report_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad57c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = plot_pred_sample(LogisticR_c_saved, y_val, X_val_norm, nom_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bfef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_val[random_index])\n",
    "print(LogisticR_c_saved.predict([X_val_norm[random_index]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac74103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing hyperparameters for KNN classifier - After several test, the hyperparameters were set\n",
    "\n",
    "#KNN_hp = {'n_neighbors':[3, 5, 8, 12], \n",
    "#          'metric': ['mahalanobis', 'euclidean', 'minkowski'],\n",
    "#          'p':[1, 2], \n",
    "#          'leaf_size': [20, 40, 80]}\n",
    "\n",
    "#grid_KNN = GridSearchCV(KNeighborsClassifier(), KNN_hp, refit = True, verbose=3)\n",
    "\n",
    "#grid_KNN.fit(X_train, y_train)\n",
    "\n",
    "#print(\" Results from Grid Search in the SVC classifier \" )\n",
    "#print(\"\\n The best estimator across ALL searched params....:\\n\",grid_KNN.best_estimator_)\n",
    "#print(\"\\n The best score across ALL searched params........:\\n\",grid_KNN.best_score_)\n",
    "#print(\"\\n The best parameters across ALL searched params...:\\n\",grid_KNN.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f734da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_KNN.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0e3fc33",
   "metadata": {},
   "source": [
    "{'leaf_size': 20, 'metric': 'euclidean', 'n_neighbors': 3, 'p': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c1c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_c = KNeighborsClassifier(n_neighbors = 3,\n",
    "                             metric      = 'minkowski',\n",
    "                             p           = 2,\n",
    "                             leaf_size   = 20,\n",
    "                             n_jobs      = -1)\n",
    "KNN_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e2525",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator = KNN_c, X = X_train, y = y_train,\n",
    "                                                        cv = 5, train_sizes = np.linspace(0.1, 1.0, 10),\n",
    "                                                        n_jobs = -1, verbose = 10)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std  = np.std(train_scores, axis=1)\n",
    "test_mean  = np.mean(test_scores, axis=1)\n",
    "test_std   = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de54752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(train_sizes, \n",
    "                    train_mean, \n",
    "                    train_std, \n",
    "                    test_mean, \n",
    "                    test_std, \n",
    "                    'KNN')\n",
    "\n",
    "print(f\"{train_sizes} samples were used to train the model\\n\")\n",
    "print(f\"The average train accuracy is....: {train_scores.mean()*100:.2f} % (+/-{train_std.mean()*100:.2f} %)\")\n",
    "print(f\"The average test accuracy is.....: {test_scores.mean()*100:.2f} % (+/-{test_std.mean()*100:.2f} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50958828",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_c.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d187aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_c_predict = KNN_c.predict(X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da635fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier to file in the current working directory\n",
    "\n",
    "pkl_filename = \"Model_KNN\" + norm_type + model_surname + \".pkl\"\n",
    "with open(os.path.join(path_models, pkl_filename), 'wb') as file:\n",
    "    pickle.dump(KNN_c, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ac666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier from file\n",
    "\n",
    "with open(os.path.join(path_models, pkl_filename), 'rb') as file:\n",
    "    KNN_c_saved = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5bc1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_KNN_c_saved = KNN_c_saved.score(X_val_norm, y_val)\n",
    "print(\"Test score (R2): {0:.2f} %\".format(100 * score_KNN_c_saved))\n",
    "KNN_c_saved_predict = KNN_c_saved.predict(X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed00625",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_srt = time.process_time_ns()\n",
    "\n",
    "KNN_c_saved_predict_val = KNN_c_saved.predict(X_val_norm)\n",
    "\n",
    "t_end = time.process_time_ns()\n",
    "tempoProc = ((t_end - t_srt) / 1000000)\n",
    "print(\"Processing time:\", ('%.4f' % tempoProc).replace('.', ','), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                             KNN_c_saved_predict_val, \n",
    "                                                             target_names = nom_classes, \n",
    "                                                             output_dict = False)\n",
    "print(KNN_c_saved_val_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d67bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                             KNN_c_saved_predict_val, \n",
    "                                                             target_names = nom_classes, \n",
    "                                                             output_dict = True)\n",
    "KNN_c_saved_val_class_report_acc = KNN_c_saved_val_class_report['accuracy']\n",
    "KNN_c_saved_val_class_report_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faddc1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(KNN_c_predict, KNN_c_saved_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac5b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conf_matrix(y_val, \n",
    "                   KNN_c_saved_predict_val, \n",
    "                   nom_classes,\n",
    "                   'KNN',\n",
    "                   KNN_c_saved_val_class_report_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d96cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = plot_pred_sample(KNN_c_saved, y_val, X_val_norm, nom_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6de1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_val[random_index])\n",
    "print(KNN_c_saved.predict([X_val_norm[random_index]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cb5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing hyperparameters for random forest classifier (ensemble method) - After several test, the hyperparameters were set\n",
    "\n",
    "#forest_hp = {'n_estimators':[10, 25, 50, 100, 200, 500], \n",
    "#             'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "#             'bootstrap':[True, False]}\n",
    "\n",
    "#grid_forest = GridSearchCV(RandomForestClassifier(), forest_hp, refit = True, verbose=3)\n",
    "\n",
    "#grid_forest.fit(X_train, y_train)\n",
    "\n",
    "#print(\" Results from Grid Search in the SVC classifier \" )\n",
    "#print(\"\\n The best estimator across ALL searched params....:\\n\",grid_forest.best_estimator_)\n",
    "#print(\"\\n The best score across ALL searched params........:\\n\",grid_forest.best_score_)\n",
    "#print(\"\\n The best parameters across ALL searched params...:\\n\",grid_forest.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_forest.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a294a13e",
   "metadata": {},
   "source": [
    "{'bootstrap': False, 'criterion': 'log_loss', 'n_estimators': 100}\n",
    "\n",
    "Higher n_estimators and bootstrap True produced better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b55075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to verbose = 0 when running the US8K_AV to avoid showing the information during the evaluation flow\n",
    "forest_c = RandomForestClassifier(criterion    = 'gini',\n",
    "                                  n_estimators = 500,\n",
    "                                  bootstrap    = True,\n",
    "                                  n_jobs       = -1,\n",
    "                                  verbose      = 0)\n",
    "forest_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b68346",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(estimator = forest_c, X = X_train, y = y_train,\n",
    "                                                        cv = 5, train_sizes = np.linspace(0.1, 1.0, 10),\n",
    "                                                        n_jobs = -1, verbose = 10)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std  = np.std(train_scores, axis=1)\n",
    "test_mean  = np.mean(test_scores, axis=1)\n",
    "test_std   = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5b767",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(train_sizes, \n",
    "                    train_mean, \n",
    "                    train_std, \n",
    "                    test_mean, \n",
    "                    test_std, \n",
    "                    'Random forest')\n",
    "\n",
    "print(f\"{train_sizes} samples were used to train the model\\n\")\n",
    "print(f\"The average train accuracy is....: {train_scores.mean()*100:.2f} % (+/-{train_std.mean()*100:.2f} %)\")\n",
    "print(f\"The average test accuracy is.....: {test_scores.mean()*100:.2f} % (+/-{test_std.mean()*100:.2f} %)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ca82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_c.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7dcc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_c_predict = forest_c.predict(X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c25fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importances of the random forest classifier\n",
    "\n",
    "picture_name = f'{pic_first_name}{get_next_file_number(path_pic):02d}.png'\n",
    "plt.figure(num=None, figsize=(20,8), facecolor='w', edgecolor='k')\n",
    "feat_importances = pd.Series(forest_c.feature_importances_, index= X.columns)\n",
    "temp_feature     = feat_importances.nlargest(375).reset_index()\n",
    "rff = feat_importances.nlargest(375).plot(kind='bar')\n",
    "rff.set_xticklabels(temp_feature['index'], fontsize=8)\n",
    "plt.title(nom_dataset + model_surname + ' - The impurity-based feature importances of the random forest classifier', fontsize = 14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(path_pic, picture_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc772dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_importances.nlargest(375).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8731c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier to file in the current working directory\n",
    "\n",
    "pkl_filename = \"Model_Forest\" + norm_type + model_surname + \".pkl\"\n",
    "with open(os.path.join(path_models, pkl_filename), 'wb') as file:\n",
    "    pickle.dump(forest_c, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61b65de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier from file\n",
    "\n",
    "with open(os.path.join(path_models, pkl_filename), 'rb') as file:\n",
    "    forest_c_saved = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdafac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_forest_c_saved = forest_c_saved.score(X_val_norm, y_val)\n",
    "print(\"Test score (R2): {0:.2f} %\".format(100 * score_forest_c_saved))\n",
    "forest_c_saved_predict = forest_c_saved.predict(X_val_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403188eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_srt = time.process_time_ns()\n",
    "\n",
    "forest_c_saved_predict_val = forest_c_saved.predict(X_val_norm)\n",
    "\n",
    "t_end = time.process_time_ns()\n",
    "tempoProc = ((t_end - t_srt) / 1000000)\n",
    "print(\"Processing time:\", ('%.4f' % tempoProc).replace('.', ','), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631b5ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                                forest_c_saved_predict_val, \n",
    "                                                                target_names = nom_classes, \n",
    "                                                                output_dict = False)\n",
    "print(forest_c_saved_val_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea1953e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                                forest_c_saved_predict_val, \n",
    "                                                                target_names = nom_classes, \n",
    "                                                                output_dict = True)\n",
    "forest_c_saved_val_class_report_acc = forest_c_saved_val_class_report['accuracy']\n",
    "forest_c_saved_val_class_report_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94487a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(forest_c_predict, forest_c_saved_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9f0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conf_matrix(y_val, \n",
    "                   forest_c_saved_predict_val, \n",
    "                   nom_classes,\n",
    "                   'Random forest',\n",
    "                   forest_c_saved_val_class_report_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663fe756",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = plot_pred_sample(forest_c_saved, y_val, X_val_norm, nom_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a612a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_val[random_index])\n",
    "print(forest_c_saved.predict([X_val_norm[random_index]])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc21964",
   "metadata": {},
   "source": [
    "### Evaluating a voting classifier for the ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b14d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Naïves Bayes', 'SVC', 'Logistic regression', 'KNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949f0763",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, label in zip([NB_c, SVC_c, LogisticR_c, KNN_c], labels):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv = 5, scoring = 'accuracy', n_jobs = -1, verbose = 10)\n",
    "    print(label, \" Accuracy: {0:.2f} % (+/- {1:.2f} %)\".format(100*scores.mean(), 100*scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a23114",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_hard = VotingClassifier(estimators = [(labels[0], NB_c),\n",
    "                                                 (labels[1], SVC_c),\n",
    "                                                 (labels[2], LogisticR_c),\n",
    "                                                 (labels[3], KNN_c)],\n",
    "                                   voting = 'hard',\n",
    "                                   n_jobs = -1,\n",
    "                                   verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_soft = VotingClassifier(estimators = [(labels[0], NB_c),\n",
    "                                                 (labels[1], SVC_c),\n",
    "                                                 (labels[2], LogisticR_c),\n",
    "                                                 (labels[3], KNN_c)],\n",
    "                                   voting = 'soft',\n",
    "                                   n_jobs = -1,\n",
    "                                   verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef14e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier to file in the current working directory\n",
    "\n",
    "pkl_filename_hard = \"Model_voting_hard\" + norm_type + model_surname + \".pkl\"\n",
    "with open(os.path.join(path_models, pkl_filename_hard), 'wb') as file:\n",
    "    pickle.dump(voting_clf_hard, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bba178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier to file in the current working directory\n",
    "\n",
    "pkl_filename_soft = \"Model_voting_soft\" + norm_type + model_surname + \".pkl\"\n",
    "with open(os.path.join(path_models, pkl_filename_soft), 'wb') as file:\n",
    "    pickle.dump(voting_clf_soft, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2884b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_new = ['Naïves Bayes', 'SVC', 'Logistic regression', 'KNN', 'Random forest', 'Voting hard', 'Voting soft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021ea799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier from file\n",
    "\n",
    "with open(os.path.join(path_models, pkl_filename_hard), 'rb') as file:\n",
    "    voting_clf_hard_saved = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classifier from file\n",
    "\n",
    "with open(os.path.join(path_models, pkl_filename_soft), 'rb') as file:\n",
    "    voting_clf_soft_saved = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3bd87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, label in zip([NB_c, SVC_c, LogisticR_c, KNN_c, forest_c, voting_clf_hard, voting_clf_soft], labels_new):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv = 5, scoring = 'accuracy', n_jobs = -1, verbose = 10)\n",
    "    print(label, \" Accuracy: {0:.2f} % (+/- {1:.2f} %)\".format(100*scores.mean(), 100*scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58242f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, label in zip([NB_c, SVC_c, LogisticR_c, KNN_c, forest_c, voting_clf_hard_saved, voting_clf_soft_saved], labels_new):\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv = 5, scoring = 'accuracy', n_jobs = -1, verbose = 10)\n",
    "    print(label, \"Accuracy: {0:.2f} % (+/- {1:.2f} %)\".format(100*scores.mean(), 100*scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8ef5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_hard_saved.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_srt = time.process_time_ns()\n",
    "\n",
    "votingHard_c_saved_predict_val = voting_clf_hard_saved.predict(X_val_norm)\n",
    "\n",
    "t_end = time.process_time_ns()\n",
    "tempoProc = ((t_end - t_srt) / 1000000)\n",
    "print(\"Processing time:\", ('%.4f' % tempoProc).replace('.', ','), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbdd549",
   "metadata": {},
   "outputs": [],
   "source": [
    "votingHard_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                                    votingHard_c_saved_predict_val, \n",
    "                                                                    target_names = nom_classes, \n",
    "                                                                    output_dict = False)\n",
    "print(votingHard_c_saved_val_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27214279",
   "metadata": {},
   "outputs": [],
   "source": [
    "votingHard_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                                    votingHard_c_saved_predict_val, \n",
    "                                                                    target_names = nom_classes, \n",
    "                                                                    output_dict = True)\n",
    "votingHard_c_saved_val_class_report_acc = votingHard_c_saved_val_class_report['accuracy']\n",
    "votingHard_c_saved_val_class_report_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conf_matrix(y_val, \n",
    "                   votingHard_c_saved_predict_val, \n",
    "                   nom_classes,\n",
    "                   'Voting hard',\n",
    "                   votingHard_c_saved_val_class_report_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_soft_saved.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_srt = time.process_time_ns()\n",
    "\n",
    "votingSoft_c_saved_predict_val = voting_clf_soft_saved.predict(X_val_norm)\n",
    "\n",
    "t_end = time.process_time_ns()\n",
    "tempoProc = ((t_end - t_srt) / 1000000)\n",
    "print(\"Processing time:\", ('%.4f' % tempoProc).replace('.', ','), \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd6eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "votingSoft_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                                    votingSoft_c_saved_predict_val, \n",
    "                                                                    target_names = nom_classes, \n",
    "                                                                    output_dict = False)\n",
    "print(votingSoft_c_saved_val_class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89cecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "votingSoft_c_saved_val_class_report = metrics.classification_report(y_val, \n",
    "                                                                    votingSoft_c_saved_predict_val, \n",
    "                                                                    target_names = nom_classes, \n",
    "                                                                    output_dict = True)\n",
    "votingSoft_c_saved_val_class_report_acc = votingSoft_c_saved_val_class_report['accuracy']\n",
    "votingSoft_c_saved_val_class_report_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfed63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_conf_matrix(y_val, \n",
    "                   votingSoft_c_saved_predict_val, \n",
    "                   nom_classes,\n",
    "                   'Voting soft',\n",
    "                   votingSoft_c_saved_val_class_report_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff244f0",
   "metadata": {},
   "source": [
    "# End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc505b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
